{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we are on colab: this clones the repo and installs the dependencies\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "from gluefactory.datasets import get_dataset\n",
    "from gluefactory.utils.tensor import batch_to_device\n",
    "import torch\n",
    "\n",
    "torch.set_grad_enabled(True)\n",
    "images = Path(\"assets\")\n",
    "\n",
    "\n",
    "from gluefactory.models import get_model\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = OmegaConf.load(\"gluefactory/configs/superpoint+simpleglue_homography_test.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device= 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/17/2024 21:06:27 gluefactory.datasets.base_dataset INFO] Creating dataset HomographyDataset\n",
      "[08/17/2024 21:06:28 gluefactory.datasets.homographies INFO] Found 510 images in list file.\n"
     ]
    }
   ],
   "source": [
    "data_conf = (conf.data)\n",
    "dataset = get_dataset(data_conf.name)(data_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dataset.get_data_loader(\"train\", distributed=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(conf.model.name)(conf.model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0/10000- lr: [4.96969696969697e-07] - Loss total: 55388.51953125, Last rpr Loss: 53904.65625, Last lagvar Loss: 0.0\n",
      "Step 1/10000- lr: [5.939393939393941e-07] - Loss total: 55359.5703125, Last rpr Loss: 53823.38671875, Last lagvar Loss: 0.0\n",
      "Step 2/10000- lr: [6.90909090909091e-07] - Loss total: 55323.67578125, Last rpr Loss: 53722.94140625, Last lagvar Loss: 0.0\n",
      "Step 3/10000- lr: [7.878787878787879e-07] - Loss total: 55280.86328125, Last rpr Loss: 53603.6875, Last lagvar Loss: 0.0\n",
      "Step 4/10000- lr: [8.848484848484849e-07] - Loss total: 55231.203125, Last rpr Loss: 53466.05859375, Last lagvar Loss: 0.0\n",
      "Step 5/10000- lr: [9.81818181818182e-07] - Loss total: 55174.76953125, Last rpr Loss: 53310.6171875, Last lagvar Loss: 0.0\n",
      "Step 6/10000- lr: [1.078787878787879e-06] - Loss total: 55111.64453125, Last rpr Loss: 53137.984375, Last lagvar Loss: 0.0\n",
      "Step 7/10000- lr: [1.1757575757575759e-06] - Loss total: 55041.92578125, Last rpr Loss: 52948.85546875, Last lagvar Loss: 0.0\n",
      "Step 8/10000- lr: [1.2727272727272728e-06] - Loss total: 54965.72265625, Last rpr Loss: 52743.953125, Last lagvar Loss: 0.0\n",
      "Step 9/10000- lr: [1.3696969696969697e-06] - Loss total: 54883.1171875, Last rpr Loss: 52524.078125, Last lagvar Loss: 0.0\n",
      "Step 10/10000- lr: [1.4666666666666667e-06] - Loss total: 54794.23828125, Last rpr Loss: 52290.06640625, Last lagvar Loss: 0.0\n",
      "Step 11/10000- lr: [1.5636363636363638e-06] - Loss total: 54699.203125, Last rpr Loss: 52042.765625, Last lagvar Loss: 0.0\n",
      "Step 12/10000- lr: [1.660606060606061e-06] - Loss total: 54598.1171875, Last rpr Loss: 51783.0234375, Last lagvar Loss: 0.0\n",
      "Step 13/10000- lr: [1.7575757575757577e-06] - Loss total: 54491.10546875, Last rpr Loss: 51511.671875, Last lagvar Loss: 0.0\n",
      "Step 14/10000- lr: [1.8545454545454548e-06] - Loss total: 54378.25390625, Last rpr Loss: 51229.51953125, Last lagvar Loss: 0.0\n",
      "Step 15/10000- lr: [1.9515151515151518e-06] - Loss total: 54259.6875, Last rpr Loss: 50937.3046875, Last lagvar Loss: 0.0\n",
      "Step 16/10000- lr: [2.048484848484849e-06] - Loss total: 54135.48828125, Last rpr Loss: 50635.7265625, Last lagvar Loss: 0.0\n",
      "Step 17/10000- lr: [2.1454545454545456e-06] - Loss total: 54005.73828125, Last rpr Loss: 50325.375, Last lagvar Loss: 0.0\n",
      "Step 18/10000- lr: [2.2424242424242428e-06] - Loss total: 53870.4921875, Last rpr Loss: 50006.7421875, Last lagvar Loss: 0.0\n",
      "Step 19/10000- lr: [2.3393939393939395e-06] - Loss total: 53729.80078125, Last rpr Loss: 49680.20703125, Last lagvar Loss: 0.0\n",
      "Step 20/10000- lr: [2.4363636363636366e-06] - Loss total: 53583.69140625, Last rpr Loss: 49346.0078125, Last lagvar Loss: 0.0\n",
      "Step 21/10000- lr: [2.5333333333333334e-06] - Loss total: 53432.16796875, Last rpr Loss: 49004.2578125, Last lagvar Loss: 0.0\n",
      "Step 22/10000- lr: [2.6303030303030305e-06] - Loss total: 53275.203125, Last rpr Loss: 48654.90625, Last lagvar Loss: 0.0\n",
      "Step 23/10000- lr: [2.7272727272727276e-06] - Loss total: 53112.76953125, Last rpr Loss: 48297.765625, Last lagvar Loss: 0.0\n",
      "Step 24/10000- lr: [2.824242424242425e-06] - Loss total: 52944.76953125, Last rpr Loss: 47932.4921875, Last lagvar Loss: 0.0\n",
      "Step 25/10000- lr: [2.921212121212122e-06] - Loss total: 52771.11328125, Last rpr Loss: 47558.5859375, Last lagvar Loss: 0.0\n",
      "Step 26/10000- lr: [3.0181818181818182e-06] - Loss total: 52591.6640625, Last rpr Loss: 47175.421875, Last lagvar Loss: 0.0\n",
      "Step 27/10000- lr: [3.1151515151515154e-06] - Loss total: 52406.2578125, Last rpr Loss: 46782.234375, Last lagvar Loss: 0.0\n",
      "Step 28/10000- lr: [3.2121212121212125e-06] - Loss total: 52214.67578125, Last rpr Loss: 46378.1171875, Last lagvar Loss: 0.0\n",
      "Step 29/10000- lr: [3.3090909090909097e-06] - Loss total: 52016.69140625, Last rpr Loss: 45962.0625, Last lagvar Loss: 0.0\n",
      "Step 30/10000- lr: [3.406060606060607e-06] - Loss total: 51812.02734375, Last rpr Loss: 45532.9296875, Last lagvar Loss: 0.0\n",
      "Step 31/10000- lr: [3.5030303030303035e-06] - Loss total: 51600.36328125, Last rpr Loss: 45089.4921875, Last lagvar Loss: 0.0\n",
      "Step 32/10000- lr: [3.6000000000000003e-06] - Loss total: 51381.34375, Last rpr Loss: 44630.39453125, Last lagvar Loss: 0.0\n",
      "Step 33/10000- lr: [3.6969696969696974e-06] - Loss total: 51154.58203125, Last rpr Loss: 44154.19921875, Last lagvar Loss: 0.0\n",
      "Step 34/10000- lr: [3.7939393939393946e-06] - Loss total: 50919.61328125, Last rpr Loss: 43659.359375, Last lagvar Loss: 0.0\n",
      "Step 35/10000- lr: [3.890909090909092e-06] - Loss total: 50675.96875, Last rpr Loss: 43144.23046875, Last lagvar Loss: 0.0\n",
      "Step 36/10000- lr: [3.987878787878789e-06] - Loss total: 50423.12890625, Last rpr Loss: 42607.09375, Last lagvar Loss: 0.0\n",
      "Step 37/10000- lr: [4.084848484848485e-06] - Loss total: 50160.51953125, Last rpr Loss: 42046.15625, Last lagvar Loss: 0.0\n",
      "Step 38/10000- lr: [4.181818181818182e-06] - Loss total: 49887.55078125, Last rpr Loss: 41459.5859375, Last lagvar Loss: 0.0\n",
      "Step 39/10000- lr: [4.2787878787878794e-06] - Loss total: 49603.61328125, Last rpr Loss: 40845.6015625, Last lagvar Loss: 0.0\n",
      "Step 40/10000- lr: [4.3757575757575766e-06] - Loss total: 49308.09765625, Last rpr Loss: 40202.53125, Last lagvar Loss: 0.0\n",
      "Step 41/10000- lr: [4.472727272727274e-06] - Loss total: 49000.40234375, Last rpr Loss: 39529.00390625, Last lagvar Loss: 0.0\n",
      "Step 42/10000- lr: [4.569696969696971e-06] - Loss total: 48680.015625, Last rpr Loss: 38824.125, Last lagvar Loss: 0.0\n",
      "Step 43/10000- lr: [4.666666666666667e-06] - Loss total: 48346.51953125, Last rpr Loss: 38087.75, Last lagvar Loss: 0.0\n",
      "Step 44/10000- lr: [4.763636363636364e-06] - Loss total: 47999.67578125, Last rpr Loss: 37320.796875, Last lagvar Loss: 0.0\n",
      "Step 45/10000- lr: [4.8606060606060615e-06] - Loss total: 47639.47265625, Last rpr Loss: 36525.4921875, Last lagvar Loss: 0.0\n",
      "Step 46/10000- lr: [4.957575757575759e-06] - Loss total: 47266.16796875, Last rpr Loss: 35705.625, Last lagvar Loss: 0.0\n",
      "Step 47/10000- lr: [5.054545454545456e-06] - Loss total: 46880.36328125, Last rpr Loss: 34866.5859375, Last lagvar Loss: 0.0\n",
      "Step 48/10000- lr: [5.151515151515153e-06] - Loss total: 46482.9609375, Last rpr Loss: 34015.203125, Last lagvar Loss: 0.0\n",
      "Step 49/10000- lr: [5.24848484848485e-06] - Loss total: 46075.15625, Last rpr Loss: 33159.36328125, Last lagvar Loss: 0.0\n",
      "Step 50/10000- lr: [5.345454545454546e-06] - Loss total: 45658.36328125, Last rpr Loss: 32307.400390625, Last lagvar Loss: 0.0\n",
      "Step 51/10000- lr: [5.442424242424244e-06] - Loss total: 45234.06640625, Last rpr Loss: 31467.34375, Last lagvar Loss: 0.0\n",
      "Step 52/10000- lr: [5.539393939393941e-06] - Loss total: 44803.68359375, Last rpr Loss: 30646.162109375, Last lagvar Loss: 0.0\n",
      "Step 53/10000- lr: [5.636363636363637e-06] - Loss total: 44368.49609375, Last rpr Loss: 29849.115234375, Last lagvar Loss: 0.0\n",
      "Step 54/10000- lr: [5.733333333333335e-06] - Loss total: 43929.515625, Last rpr Loss: 29079.43359375, Last lagvar Loss: 0.0\n",
      "Step 55/10000- lr: [5.830303030303031e-06] - Loss total: 43487.51171875, Last rpr Loss: 28338.396484375, Last lagvar Loss: 0.0\n",
      "Step 56/10000- lr: [5.927272727272729e-06] - Loss total: 43043.11328125, Last rpr Loss: 27625.779296875, Last lagvar Loss: 0.0\n",
      "Step 57/10000- lr: [6.0242424242424255e-06] - Loss total: 42596.87890625, Last rpr Loss: 26940.37109375, Last lagvar Loss: 0.0\n",
      "Step 58/10000- lr: [6.121212121212122e-06] - Loss total: 42149.40234375, Last rpr Loss: 26280.48828125, Last lagvar Loss: 0.0\n",
      "Step 59/10000- lr: [6.21818181818182e-06] - Loss total: 41701.33203125, Last rpr Loss: 25644.11328125, Last lagvar Loss: 0.0\n",
      "Step 60/10000- lr: [6.315151515151516e-06] - Loss total: 41253.265625, Last rpr Loss: 25028.81640625, Last lagvar Loss: 0.0\n",
      "Step 61/10000- lr: [6.412121212121214e-06] - Loss total: 40805.6875, Last rpr Loss: 24431.4765625, Last lagvar Loss: 0.0\n",
      "Step 62/10000- lr: [6.50909090909091e-06] - Loss total: 40358.859375, Last rpr Loss: 23848.244140625, Last lagvar Loss: 0.0\n",
      "Step 63/10000- lr: [6.6060606060606075e-06] - Loss total: 39912.76171875, Last rpr Loss: 23274.681640625, Last lagvar Loss: 0.0\n",
      "Step 64/10000- lr: [6.703030303030305e-06] - Loss total: 39467.17578125, Last rpr Loss: 22706.20703125, Last lagvar Loss: 0.0\n",
      "Step 65/10000- lr: [6.800000000000001e-06] - Loss total: 39021.70703125, Last rpr Loss: 22138.62890625, Last lagvar Loss: 0.0\n",
      "Step 66/10000- lr: [6.896969696969698e-06] - Loss total: 38576.015625, Last rpr Loss: 21568.763671875, Last lagvar Loss: 0.0\n",
      "Step 67/10000- lr: [6.993939393939395e-06] - Loss total: 38129.875, Last rpr Loss: 20995.265625, Last lagvar Loss: 0.0\n",
      "Step 68/10000- lr: [7.090909090909092e-06] - Loss total: 37683.39453125, Last rpr Loss: 20419.498046875, Last lagvar Loss: 0.0\n",
      "Step 69/10000- lr: [7.1878787878787895e-06] - Loss total: 37237.0703125, Last rpr Loss: 19845.84375, Last lagvar Loss: 0.0\n",
      "Step 70/10000- lr: [7.284848484848486e-06] - Loss total: 36791.65625, Last rpr Loss: 19280.529296875, Last lagvar Loss: 0.0\n",
      "Step 71/10000- lr: [7.381818181818183e-06] - Loss total: 36347.88671875, Last rpr Loss: 18729.296875, Last lagvar Loss: 0.0\n",
      "Step 72/10000- lr: [7.47878787878788e-06] - Loss total: 35906.23828125, Last rpr Loss: 18195.693359375, Last lagvar Loss: 0.0\n",
      "Step 73/10000- lr: [7.575757575757577e-06] - Loss total: 35466.83203125, Last rpr Loss: 17681.099609375, Last lagvar Loss: 0.0\n",
      "Step 74/10000- lr: [7.672727272727274e-06] - Loss total: 35029.61328125, Last rpr Loss: 17185.767578125, Last lagvar Loss: 0.0\n",
      "Step 75/10000- lr: [7.76969696969697e-06] - Loss total: 34594.484375, Last rpr Loss: 16709.587890625, Last lagvar Loss: 0.0\n",
      "Step 76/10000- lr: [7.866666666666667e-06] - Loss total: 34161.40625, Last rpr Loss: 16251.974609375, Last lagvar Loss: 0.0\n",
      "Step 77/10000- lr: [7.963636363636365e-06] - Loss total: 33730.3515625, Last rpr Loss: 15811.5498046875, Last lagvar Loss: 0.0\n",
      "Step 78/10000- lr: [8.060606060606061e-06] - Loss total: 33301.37109375, Last rpr Loss: 15386.431640625, Last lagvar Loss: 0.0\n",
      "Step 79/10000- lr: [8.157575757575758e-06] - Loss total: 32874.6171875, Last rpr Loss: 14974.57421875, Last lagvar Loss: 0.0\n",
      "Step 80/10000- lr: [8.254545454545456e-06] - Loss total: 32450.337890625, Last rpr Loss: 14573.81640625, Last lagvar Loss: 0.0\n",
      "Step 81/10000- lr: [8.351515151515152e-06] - Loss total: 32028.986328125, Last rpr Loss: 14183.15625, Last lagvar Loss: 0.0\n",
      "Step 82/10000- lr: [8.448484848484848e-06] - Loss total: 31611.244140625, Last rpr Loss: 13804.1953125, Last lagvar Loss: 0.0\n",
      "Step 83/10000- lr: [8.545454545454546e-06] - Loss total: 31197.677734375, Last rpr Loss: 13439.3359375, Last lagvar Loss: 0.0\n",
      "Step 84/10000- lr: [8.642424242424242e-06] - Loss total: 30788.41015625, Last rpr Loss: 13088.8994140625, Last lagvar Loss: 0.0\n",
      "Step 85/10000- lr: [8.73939393939394e-06] - Loss total: 30383.3125, Last rpr Loss: 12752.0390625, Last lagvar Loss: 0.0\n",
      "Step 86/10000- lr: [8.836363636363637e-06] - Loss total: 29982.326171875, Last rpr Loss: 12428.2255859375, Last lagvar Loss: 0.0\n",
      "Step 87/10000- lr: [8.933333333333333e-06] - Loss total: 29585.5390625, Last rpr Loss: 12116.666015625, Last lagvar Loss: 0.0\n",
      "Step 88/10000- lr: [9.030303030303031e-06] - Loss total: 29193.0078125, Last rpr Loss: 11815.7314453125, Last lagvar Loss: 0.0\n",
      "Step 89/10000- lr: [9.127272727272727e-06] - Loss total: 28804.638671875, Last rpr Loss: 11523.1318359375, Last lagvar Loss: 0.0\n",
      "Step 90/10000- lr: [9.224242424242425e-06] - Loss total: 28420.138671875, Last rpr Loss: 11236.12109375, Last lagvar Loss: 0.0\n",
      "Step 91/10000- lr: [9.321212121212122e-06] - Loss total: 28039.068359375, Last rpr Loss: 10951.6298828125, Last lagvar Loss: 0.0\n",
      "Step 92/10000- lr: [9.41818181818182e-06] - Loss total: 27661.009765625, Last rpr Loss: 10666.642578125, Last lagvar Loss: 0.0\n",
      "Step 93/10000- lr: [9.515151515151516e-06] - Loss total: 27285.7421875, Last rpr Loss: 10379.2138671875, Last lagvar Loss: 0.0\n",
      "Step 94/10000- lr: [9.612121212121212e-06] - Loss total: 26913.40234375, Last rpr Loss: 10090.236328125, Last lagvar Loss: 0.0\n",
      "Step 95/10000- lr: [9.70909090909091e-06] - Loss total: 26544.6015625, Last rpr Loss: 9804.70703125, Last lagvar Loss: 0.0\n",
      "Step 96/10000- lr: [9.806060606060607e-06] - Loss total: 26180.294921875, Last rpr Loss: 9529.896484375, Last lagvar Loss: 0.0\n",
      "Step 97/10000- lr: [9.903030303030305e-06] - Loss total: 25821.1953125, Last rpr Loss: 9269.3203125, Last lagvar Loss: 0.0\n",
      "Step 98/10000- lr: [1e-05] - Loss total: 25467.21484375, Last rpr Loss: 9018.8037109375, Last lagvar Loss: 0.0\n",
      "Step 99/10000- lr: [9.998989903030304e-06] - Loss total: 25117.419921875, Last rpr Loss: 8769.59375, Last lagvar Loss: 0.0\n",
      "Step 100/10000- lr: [9.997979806060607e-06] - Loss total: 24770.4921875, Last rpr Loss: 8514.48828125, Last lagvar Loss: 0.0\n",
      "Step 101/10000- lr: [9.99696970909091e-06] - Loss total: 24429.39453125, Last rpr Loss: 8261.15234375, Last lagvar Loss: 0.0\n",
      "Step 102/10000- lr: [9.995959612121212e-06] - Loss total: 24094.62890625, Last rpr Loss: 8024.876953125, Last lagvar Loss: 0.0\n",
      "Step 103/10000- lr: [9.994949515151516e-06] - Loss total: 23766.271484375, Last rpr Loss: 7808.2978515625, Last lagvar Loss: 0.0\n",
      "Step 104/10000- lr: [9.993939418181819e-06] - Loss total: 23445.15625, Last rpr Loss: 7606.7568359375, Last lagvar Loss: 0.0\n",
      "Step 105/10000- lr: [9.992929321212122e-06] - Loss total: 23133.3359375, Last rpr Loss: 7417.12548828125, Last lagvar Loss: 0.0\n",
      "Step 106/10000- lr: [9.991919224242425e-06] - Loss total: 22831.44140625, Last rpr Loss: 7236.92236328125, Last lagvar Loss: 0.0\n",
      "Step 107/10000- lr: [9.990909127272729e-06] - Loss total: 22538.162109375, Last rpr Loss: 7065.189453125, Last lagvar Loss: 0.0\n",
      "Step 108/10000- lr: [9.989899030303032e-06] - Loss total: 22252.080078125, Last rpr Loss: 6901.796875, Last lagvar Loss: 0.0\n",
      "Step 109/10000- lr: [9.988888933333333e-06] - Loss total: 21972.09375, Last rpr Loss: 6745.1162109375, Last lagvar Loss: 0.0\n",
      "Step 110/10000- lr: [9.987878836363637e-06] - Loss total: 21697.408203125, Last rpr Loss: 6592.31982421875, Last lagvar Loss: 0.0\n",
      "Step 111/10000- lr: [9.98686873939394e-06] - Loss total: 21427.6171875, Last rpr Loss: 6441.671875, Last lagvar Loss: 0.0\n",
      "Step 112/10000- lr: [9.985858642424243e-06] - Loss total: 21162.837890625, Last rpr Loss: 6293.81201171875, Last lagvar Loss: 0.0\n",
      "Step 113/10000- lr: [9.984848545454547e-06] - Loss total: 20903.2734375, Last rpr Loss: 6150.44970703125, Last lagvar Loss: 0.0\n",
      "Step 114/10000- lr: [9.98383844848485e-06] - Loss total: 20648.751953125, Last rpr Loss: 6012.97265625, Last lagvar Loss: 0.0\n",
      "Step 115/10000- lr: [9.982828351515153e-06] - Loss total: 20399.041015625, Last rpr Loss: 5882.857421875, Last lagvar Loss: 0.0\n",
      "Step 116/10000- lr: [9.981818254545455e-06] - Loss total: 20154.017578125, Last rpr Loss: 5761.0380859375, Last lagvar Loss: 0.0\n",
      "Step 117/10000- lr: [9.980808157575758e-06] - Loss total: 19913.560546875, Last rpr Loss: 5646.869140625, Last lagvar Loss: 0.0\n",
      "Step 118/10000- lr: [9.979798060606061e-06] - Loss total: 19677.462890625, Last rpr Loss: 5538.7958984375, Last lagvar Loss: 0.0\n",
      "Step 119/10000- lr: [9.978787963636365e-06] - Loss total: 19445.3515625, Last rpr Loss: 5435.0966796875, Last lagvar Loss: 0.0\n",
      "Step 120/10000- lr: [9.977777866666668e-06] - Loss total: 19216.84375, Last rpr Loss: 5334.3505859375, Last lagvar Loss: 0.0\n",
      "Step 121/10000- lr: [9.976767769696971e-06] - Loss total: 18991.806640625, Last rpr Loss: 5236.15283203125, Last lagvar Loss: 0.0\n",
      "Step 122/10000- lr: [9.975757672727274e-06] - Loss total: 18770.154296875, Last rpr Loss: 5140.34228515625, Last lagvar Loss: 0.0\n",
      "Step 123/10000- lr: [9.974747575757576e-06] - Loss total: 18551.623046875, Last rpr Loss: 5045.8603515625, Last lagvar Loss: 0.0\n",
      "Step 124/10000- lr: [9.97373747878788e-06] - Loss total: 18335.869140625, Last rpr Loss: 4951.607421875, Last lagvar Loss: 0.0\n",
      "Step 125/10000- lr: [9.972727381818183e-06] - Loss total: 18122.650390625, Last rpr Loss: 4857.08984375, Last lagvar Loss: 0.0\n",
      "Step 126/10000- lr: [9.971717284848486e-06] - Loss total: 17911.919921875, Last rpr Loss: 4762.2587890625, Last lagvar Loss: 0.0\n",
      "Step 127/10000- lr: [9.970707187878789e-06] - Loss total: 17703.720703125, Last rpr Loss: 4667.49853515625, Last lagvar Loss: 0.0\n",
      "Step 128/10000- lr: [9.969697090909092e-06] - Loss total: 17498.169921875, Last rpr Loss: 4574.27685546875, Last lagvar Loss: 0.0\n",
      "Step 129/10000- lr: [9.968686993939394e-06] - Loss total: 17295.49609375, Last rpr Loss: 4485.5361328125, Last lagvar Loss: 0.0\n",
      "Step 130/10000- lr: [9.967676896969697e-06] - Loss total: 17095.63671875, Last rpr Loss: 4403.45947265625, Last lagvar Loss: 0.0\n",
      "Step 131/10000- lr: [9.9666668e-06] - Loss total: 16897.568359375, Last rpr Loss: 4327.07666015625, Last lagvar Loss: 0.0\n",
      "Step 132/10000- lr: [9.965656703030304e-06] - Loss total: 16699.19140625, Last rpr Loss: 4253.28515625, Last lagvar Loss: 0.0\n",
      "Step 133/10000- lr: [9.964646606060607e-06] - Loss total: 16500.09765625, Last rpr Loss: 4176.783203125, Last lagvar Loss: 0.0\n",
      "Step 134/10000- lr: [9.96363650909091e-06] - Loss total: 16299.2138671875, Last rpr Loss: 4079.5185546875, Last lagvar Loss: 0.0\n",
      "Step 135/10000- lr: [9.962626412121214e-06] - Loss total: 16094.591796875, Last rpr Loss: 3928.669921875, Last lagvar Loss: 0.0\n",
      "Step 136/10000- lr: [9.961616315151515e-06] - Loss total: 15909.23828125, Last rpr Loss: 3816.302490234375, Last lagvar Loss: 0.0\n",
      "Step 137/10000- lr: [9.960606218181818e-06] - Loss total: 15740.87890625, Last rpr Loss: 3747.5361328125, Last lagvar Loss: 0.0\n",
      "Step 138/10000- lr: [9.959596121212122e-06] - Loss total: 15579.25390625, Last rpr Loss: 3686.502685546875, Last lagvar Loss: 0.0\n",
      "Step 139/10000- lr: [9.958586024242425e-06] - Loss total: 15420.8095703125, Last rpr Loss: 3627.81005859375, Last lagvar Loss: 0.0\n",
      "Step 140/10000- lr: [9.957575927272728e-06] - Loss total: 15264.748046875, Last rpr Loss: 3573.055908203125, Last lagvar Loss: 0.0\n",
      "Step 141/10000- lr: [9.956565830303032e-06] - Loss total: 15111.78515625, Last rpr Loss: 3524.52099609375, Last lagvar Loss: 0.0\n",
      "Step 142/10000- lr: [9.955555733333335e-06] - Loss total: 14961.8798828125, Last rpr Loss: 3480.408447265625, Last lagvar Loss: 0.0\n",
      "Step 143/10000- lr: [9.954545636363636e-06] - Loss total: 14814.7763671875, Last rpr Loss: 3438.115234375, Last lagvar Loss: 0.0\n",
      "Step 144/10000- lr: [9.95353553939394e-06] - Loss total: 14669.96875, Last rpr Loss: 3396.1748046875, Last lagvar Loss: 0.0\n",
      "Step 145/10000- lr: [9.952525442424243e-06] - Loss total: 14527.087890625, Last rpr Loss: 3354.046142578125, Last lagvar Loss: 0.0\n",
      "Step 146/10000- lr: [9.951515345454546e-06] - Loss total: 14386.251953125, Last rpr Loss: 3311.37158203125, Last lagvar Loss: 0.0\n",
      "Step 147/10000- lr: [9.95050524848485e-06] - Loss total: 14247.3408203125, Last rpr Loss: 3268.25537109375, Last lagvar Loss: 0.0\n",
      "Step 148/10000- lr: [9.949495151515153e-06] - Loss total: 14110.4619140625, Last rpr Loss: 3226.80126953125, Last lagvar Loss: 0.0\n",
      "Step 149/10000- lr: [9.948485054545456e-06] - Loss total: 13975.658203125, Last rpr Loss: 3188.84619140625, Last lagvar Loss: 0.0\n",
      "Step 150/10000- lr: [9.947474957575758e-06] - Loss total: 13842.638671875, Last rpr Loss: 3153.708740234375, Last lagvar Loss: 0.0\n",
      "Step 151/10000- lr: [9.946464860606061e-06] - Loss total: 13711.2216796875, Last rpr Loss: 3120.055419921875, Last lagvar Loss: 0.0\n",
      "Step 152/10000- lr: [9.945454763636364e-06] - Loss total: 13581.1728515625, Last rpr Loss: 3086.60302734375, Last lagvar Loss: 0.0\n",
      "Step 153/10000- lr: [9.944444666666668e-06] - Loss total: 13452.5078125, Last rpr Loss: 3052.325927734375, Last lagvar Loss: 0.0\n",
      "Step 154/10000- lr: [9.94343456969697e-06] - Loss total: 13325.484375, Last rpr Loss: 3017.253173828125, Last lagvar Loss: 0.0\n",
      "Step 155/10000- lr: [9.942424472727274e-06] - Loss total: 13200.3056640625, Last rpr Loss: 2982.3515625, Last lagvar Loss: 0.0\n",
      "Step 156/10000- lr: [9.941414375757577e-06] - Loss total: 13077.03515625, Last rpr Loss: 2947.970458984375, Last lagvar Loss: 0.0\n",
      "Step 157/10000- lr: [9.940404278787879e-06] - Loss total: 12955.583984375, Last rpr Loss: 2913.79443359375, Last lagvar Loss: 0.0\n",
      "Step 158/10000- lr: [9.939394181818182e-06] - Loss total: 12836.03515625, Last rpr Loss: 2879.66845703125, Last lagvar Loss: 0.0\n",
      "Step 159/10000- lr: [9.938384084848485e-06] - Loss total: 12718.6298828125, Last rpr Loss: 2846.403076171875, Last lagvar Loss: 0.0\n",
      "Step 160/10000- lr: [9.937373987878789e-06] - Loss total: 12603.5546875, Last rpr Loss: 2815.591064453125, Last lagvar Loss: 0.0\n",
      "Step 161/10000- lr: [9.936363890909092e-06] - Loss total: 12490.7958984375, Last rpr Loss: 2787.589599609375, Last lagvar Loss: 0.0\n",
      "Step 162/10000- lr: [9.935353793939395e-06] - Loss total: 12380.1044921875, Last rpr Loss: 2761.48486328125, Last lagvar Loss: 0.0\n",
      "Step 163/10000- lr: [9.934343696969699e-06] - Loss total: 12271.287109375, Last rpr Loss: 2736.6630859375, Last lagvar Loss: 0.0\n",
      "Step 164/10000- lr: [9.9333336e-06] - Loss total: 12164.2255859375, Last rpr Loss: 2712.916015625, Last lagvar Loss: 0.0\n",
      "Step 165/10000- lr: [9.932323503030303e-06] - Loss total: 12058.8544921875, Last rpr Loss: 2689.99609375, Last lagvar Loss: 0.0\n",
      "Step 166/10000- lr: [9.931313406060607e-06] - Loss total: 11955.125, Last rpr Loss: 2667.74755859375, Last lagvar Loss: 0.0\n",
      "Step 167/10000- lr: [9.93030330909091e-06] - Loss total: 11852.96875, Last rpr Loss: 2646.120849609375, Last lagvar Loss: 0.0\n",
      "Step 168/10000- lr: [9.929293212121213e-06] - Loss total: 11752.3173828125, Last rpr Loss: 2625.04150390625, Last lagvar Loss: 0.0\n",
      "Step 169/10000- lr: [9.928283115151517e-06] - Loss total: 11653.1005859375, Last rpr Loss: 2604.35693359375, Last lagvar Loss: 0.0\n",
      "Step 170/10000- lr: [9.92727301818182e-06] - Loss total: 11555.2841796875, Last rpr Loss: 2583.880859375, Last lagvar Loss: 0.0\n",
      "Step 171/10000- lr: [9.926262921212121e-06] - Loss total: 11458.8095703125, Last rpr Loss: 2563.437255859375, Last lagvar Loss: 0.0\n",
      "Step 172/10000- lr: [9.925252824242425e-06] - Loss total: 11363.6142578125, Last rpr Loss: 2542.88818359375, Last lagvar Loss: 0.0\n",
      "Step 173/10000- lr: [9.924242727272728e-06] - Loss total: 11269.6357421875, Last rpr Loss: 2522.138671875, Last lagvar Loss: 0.0\n",
      "Step 174/10000- lr: [9.923232630303031e-06] - Loss total: 11176.796875, Last rpr Loss: 2501.097900390625, Last lagvar Loss: 0.0\n",
      "Step 175/10000- lr: [9.922222533333335e-06] - Loss total: 11085.0361328125, Last rpr Loss: 2479.658935546875, Last lagvar Loss: 0.0\n",
      "Step 176/10000- lr: [9.921212436363638e-06] - Loss total: 10994.2666015625, Last rpr Loss: 2457.9892578125, Last lagvar Loss: 0.0\n",
      "Step 177/10000- lr: [9.92020233939394e-06] - Loss total: 10904.49609375, Last rpr Loss: 2437.087890625, Last lagvar Loss: 0.0\n",
      "Step 178/10000- lr: [9.919192242424243e-06] - Loss total: 10815.841796875, Last rpr Loss: 2418.28759765625, Last lagvar Loss: 0.0\n",
      "Step 179/10000- lr: [9.918182145454546e-06] - Loss total: 10728.4423828125, Last rpr Loss: 2401.8330078125, Last lagvar Loss: 0.0\n",
      "Step 180/10000- lr: [9.91717204848485e-06] - Loss total: 10642.359375, Last rpr Loss: 2387.051025390625, Last lagvar Loss: 0.0\n",
      "Step 181/10000- lr: [9.916161951515152e-06] - Loss total: 10557.5263671875, Last rpr Loss: 2373.27783203125, Last lagvar Loss: 0.0\n",
      "Step 182/10000- lr: [9.915151854545456e-06] - Loss total: 10473.8046875, Last rpr Loss: 2360.08203125, Last lagvar Loss: 0.0\n",
      "Step 183/10000- lr: [9.914141757575759e-06] - Loss total: 10391.0498046875, Last rpr Loss: 2347.1572265625, Last lagvar Loss: 0.0\n",
      "Step 184/10000- lr: [9.91313166060606e-06] - Loss total: 10309.13671875, Last rpr Loss: 2334.3515625, Last lagvar Loss: 0.0\n",
      "Step 185/10000- lr: [9.912121563636364e-06] - Loss total: 10228.0048828125, Last rpr Loss: 2321.8037109375, Last lagvar Loss: 0.0\n",
      "Step 186/10000- lr: [9.911111466666667e-06] - Loss total: 10147.64453125, Last rpr Loss: 2309.769287109375, Last lagvar Loss: 0.0\n",
      "Step 187/10000- lr: [9.91010136969697e-06] - Loss total: 10068.0126953125, Last rpr Loss: 2298.221435546875, Last lagvar Loss: 0.0\n",
      "Step 188/10000- lr: [9.909091272727274e-06] - Loss total: 9988.9853515625, Last rpr Loss: 2286.91796875, Last lagvar Loss: 0.0\n",
      "Step 189/10000- lr: [9.908081175757577e-06] - Loss total: 9910.3076171875, Last rpr Loss: 2275.65625, Last lagvar Loss: 0.0\n",
      "Step 190/10000- lr: [9.90707107878788e-06] - Loss total: 9831.7841796875, Last rpr Loss: 2263.867431640625, Last lagvar Loss: 0.0\n",
      "Step 191/10000- lr: [9.906060981818182e-06] - Loss total: 9753.525390625, Last rpr Loss: 2248.106689453125, Last lagvar Loss: 0.0\n",
      "Step 192/10000- lr: [9.905050884848485e-06] - Loss total: 9676.2607421875, Last rpr Loss: 2228.89599609375, Last lagvar Loss: 0.0\n",
      "Step 193/10000- lr: [9.904040787878788e-06] - Loss total: 9600.6875, Last rpr Loss: 2215.5927734375, Last lagvar Loss: 0.0\n",
      "Step 194/10000- lr: [9.903030690909092e-06] - Loss total: 9525.77734375, Last rpr Loss: 2203.157958984375, Last lagvar Loss: 0.0\n",
      "Step 195/10000- lr: [9.902020593939395e-06] - Loss total: 9451.224609375, Last rpr Loss: 2190.333984375, Last lagvar Loss: 0.0\n",
      "Step 196/10000- lr: [9.901010496969698e-06] - Loss total: 9377.005859375, Last rpr Loss: 2177.15869140625, Last lagvar Loss: 0.0\n",
      "Step 197/10000- lr: [9.900000400000002e-06] - Loss total: 9303.037109375, Last rpr Loss: 2163.638671875, Last lagvar Loss: 0.0\n",
      "Step 198/10000- lr: [9.898990303030303e-06] - Loss total: 9229.23046875, Last rpr Loss: 2149.774169921875, Last lagvar Loss: 0.0\n",
      "Step 199/10000- lr: [9.897980206060606e-06] - Loss total: 9155.6123046875, Last rpr Loss: 2135.766845703125, Last lagvar Loss: 0.0\n",
      "Step 200/10000- lr: [9.89697010909091e-06] - Loss total: 9082.1875, Last rpr Loss: 2121.805908203125, Last lagvar Loss: 0.0\n",
      "Step 201/10000- lr: [9.895960012121213e-06] - Loss total: 9008.9228515625, Last rpr Loss: 2107.52880859375, Last lagvar Loss: 0.0\n",
      "Step 202/10000- lr: [9.894949915151516e-06] - Loss total: 8935.6884765625, Last rpr Loss: 2091.327392578125, Last lagvar Loss: 0.0\n",
      "Step 203/10000- lr: [9.89393981818182e-06] - Loss total: 8861.9228515625, Last rpr Loss: 2069.28125, Last lagvar Loss: 0.0\n",
      "Step 204/10000- lr: [9.892929721212123e-06] - Loss total: 8788.9892578125, Last rpr Loss: 2048.8662109375, Last lagvar Loss: 0.0\n",
      "Step 205/10000- lr: [9.891919624242424e-06] - Loss total: 8718.8505859375, Last rpr Loss: 2034.9306640625, Last lagvar Loss: 0.0\n",
      "Step 206/10000- lr: [9.890909527272728e-06] - Loss total: 8650.2294921875, Last rpr Loss: 2022.6778564453125, Last lagvar Loss: 0.0\n",
      "Step 207/10000- lr: [9.889899430303031e-06] - Loss total: 8582.34765625, Last rpr Loss: 2011.708251953125, Last lagvar Loss: 0.0\n",
      "Step 208/10000- lr: [9.888889333333334e-06] - Loss total: 8514.931640625, Last rpr Loss: 2001.66845703125, Last lagvar Loss: 0.0\n",
      "Step 209/10000- lr: [9.887879236363637e-06] - Loss total: 8448.0009765625, Last rpr Loss: 1991.7685546875, Last lagvar Loss: 0.0\n",
      "Step 210/10000- lr: [9.88686913939394e-06] - Loss total: 8381.3662109375, Last rpr Loss: 1981.147705078125, Last lagvar Loss: 0.0\n",
      "Step 211/10000- lr: [9.885859042424244e-06] - Loss total: 8314.958984375, Last rpr Loss: 1969.3046875, Last lagvar Loss: 0.0\n",
      "Step 212/10000- lr: [9.884848945454546e-06] - Loss total: 8248.92578125, Last rpr Loss: 1956.681396484375, Last lagvar Loss: 0.0\n",
      "Step 213/10000- lr: [9.883838848484849e-06] - Loss total: 8183.447265625, Last rpr Loss: 1945.038330078125, Last lagvar Loss: 0.0\n",
      "Step 214/10000- lr: [9.882828751515152e-06] - Loss total: 8118.6259765625, Last rpr Loss: 1935.0555419921875, Last lagvar Loss: 0.0\n",
      "Step 215/10000- lr: [9.881818654545455e-06] - Loss total: 8054.3349609375, Last rpr Loss: 1925.6278076171875, Last lagvar Loss: 0.0\n",
      "Step 216/10000- lr: [9.880808557575759e-06] - Loss total: 7990.484375, Last rpr Loss: 1915.784912109375, Last lagvar Loss: 0.0\n",
      "Step 217/10000- lr: [9.879798460606062e-06] - Loss total: 7927.14599609375, Last rpr Loss: 1905.523193359375, Last lagvar Loss: 0.0\n",
      "Step 218/10000- lr: [9.878788363636365e-06] - Loss total: 7864.3212890625, Last rpr Loss: 1895.7943115234375, Last lagvar Loss: 0.0\n",
      "Step 219/10000- lr: [9.877778266666667e-06] - Loss total: 7801.955078125, Last rpr Loss: 1887.2620849609375, Last lagvar Loss: 0.0\n",
      "Step 220/10000- lr: [9.87676816969697e-06] - Loss total: 7740.0634765625, Last rpr Loss: 1879.7122802734375, Last lagvar Loss: 0.0\n",
      "Step 221/10000- lr: [9.875758072727273e-06] - Loss total: 7678.7099609375, Last rpr Loss: 1872.671875, Last lagvar Loss: 0.0\n",
      "Step 222/10000- lr: [9.874747975757577e-06] - Loss total: 7617.95068359375, Last rpr Loss: 1865.755615234375, Last lagvar Loss: 0.0\n",
      "Step 223/10000- lr: [9.87373787878788e-06] - Loss total: 7557.7646484375, Last rpr Loss: 1858.7646484375, Last lagvar Loss: 0.0\n",
      "Step 224/10000- lr: [9.872727781818183e-06] - Loss total: 7498.134765625, Last rpr Loss: 1851.682373046875, Last lagvar Loss: 0.0\n",
      "Step 225/10000- lr: [9.871717684848485e-06] - Loss total: 7439.1025390625, Last rpr Loss: 1844.6558837890625, Last lagvar Loss: 0.0\n",
      "Step 226/10000- lr: [9.870707587878788e-06] - Loss total: 7380.6708984375, Last rpr Loss: 1837.912109375, Last lagvar Loss: 0.0\n",
      "Step 227/10000- lr: [9.869697490909091e-06] - Loss total: 7322.767578125, Last rpr Loss: 1831.531494140625, Last lagvar Loss: 0.0\n",
      "Step 228/10000- lr: [9.868687393939395e-06] - Loss total: 7265.29541015625, Last rpr Loss: 1825.378662109375, Last lagvar Loss: 0.0\n",
      "Step 229/10000- lr: [9.867677296969698e-06] - Loss total: 7208.14208984375, Last rpr Loss: 1819.2618408203125, Last lagvar Loss: 0.0\n",
      "Step 230/10000- lr: [9.866667200000001e-06] - Loss total: 7151.17626953125, Last rpr Loss: 1813.0531005859375, Last lagvar Loss: 0.0\n",
      "Step 231/10000- lr: [9.865657103030304e-06] - Loss total: 7094.2392578125, Last rpr Loss: 1806.678466796875, Last lagvar Loss: 0.0\n",
      "Step 232/10000- lr: [9.864647006060606e-06] - Loss total: 7037.27099609375, Last rpr Loss: 1799.9727783203125, Last lagvar Loss: 0.0\n",
      "Step 233/10000- lr: [9.86363690909091e-06] - Loss total: 6980.26806640625, Last rpr Loss: 1792.126708984375, Last lagvar Loss: 0.0\n",
      "Step 234/10000- lr: [9.862626812121213e-06] - Loss total: 6923.54052734375, Last rpr Loss: 1779.468017578125, Last lagvar Loss: 0.0\n",
      "Step 235/10000- lr: [9.861616715151516e-06] - Loss total: 6868.19580078125, Last rpr Loss: 1761.43505859375, Last lagvar Loss: 0.0\n",
      "Step 236/10000- lr: [9.86060661818182e-06] - Loss total: 6814.95263671875, Last rpr Loss: 1750.312255859375, Last lagvar Loss: 0.0\n",
      "Step 237/10000- lr: [9.859596521212122e-06] - Loss total: 6762.60546875, Last rpr Loss: 1742.31103515625, Last lagvar Loss: 0.0\n",
      "Step 238/10000- lr: [9.858586424242426e-06] - Loss total: 6710.42236328125, Last rpr Loss: 1734.6693115234375, Last lagvar Loss: 0.0\n",
      "Step 239/10000- lr: [9.857576327272727e-06] - Loss total: 6658.12646484375, Last rpr Loss: 1726.8912353515625, Last lagvar Loss: 0.0\n",
      "Step 240/10000- lr: [9.85656623030303e-06] - Loss total: 6605.31494140625, Last rpr Loss: 1718.3671875, Last lagvar Loss: 0.0\n",
      "Step 241/10000- lr: [9.855556133333334e-06] - Loss total: 6550.9658203125, Last rpr Loss: 1705.081787109375, Last lagvar Loss: 0.0\n",
      "Step 242/10000- lr: [9.854546036363637e-06] - Loss total: 6496.60693359375, Last rpr Loss: 1678.9066162109375, Last lagvar Loss: 0.0\n",
      "Step 243/10000- lr: [9.85353593939394e-06] - Loss total: 6448.2177734375, Last rpr Loss: 1665.43310546875, Last lagvar Loss: 0.0\n",
      "Step 244/10000- lr: [9.852525842424244e-06] - Loss total: 6401.474609375, Last rpr Loss: 1655.85107421875, Last lagvar Loss: 0.0\n",
      "Step 245/10000- lr: [9.851515745454547e-06] - Loss total: 6354.7626953125, Last rpr Loss: 1646.721435546875, Last lagvar Loss: 0.0\n",
      "Step 246/10000- lr: [9.850505648484849e-06] - Loss total: 6307.5087890625, Last rpr Loss: 1637.837158203125, Last lagvar Loss: 0.0\n",
      "Step 247/10000- lr: [9.849495551515152e-06] - Loss total: 6260.7939453125, Last rpr Loss: 1629.09765625, Last lagvar Loss: 0.0\n",
      "Step 248/10000- lr: [9.848485454545455e-06] - Loss total: 6214.8212890625, Last rpr Loss: 1619.125, Last lagvar Loss: 0.0\n",
      "Step 249/10000- lr: [9.847475357575758e-06] - Loss total: 6167.51416015625, Last rpr Loss: 1602.663330078125, Last lagvar Loss: 0.0\n",
      "Step 250/10000- lr: [9.846465260606062e-06] - Loss total: 6121.47607421875, Last rpr Loss: 1586.865478515625, Last lagvar Loss: 0.0\n",
      "Step 251/10000- lr: [9.845455163636365e-06] - Loss total: 6078.58447265625, Last rpr Loss: 1579.138427734375, Last lagvar Loss: 0.0\n",
      "Step 252/10000- lr: [9.844445066666668e-06] - Loss total: 6036.12060546875, Last rpr Loss: 1571.3428955078125, Last lagvar Loss: 0.0\n",
      "Step 253/10000- lr: [9.84343496969697e-06] - Loss total: 5993.30078125, Last rpr Loss: 1563.01904296875, Last lagvar Loss: 0.0\n",
      "Step 254/10000- lr: [9.842424872727273e-06] - Loss total: 5950.71435546875, Last rpr Loss: 1554.6539306640625, Last lagvar Loss: 0.0\n",
      "Step 255/10000- lr: [9.841414775757576e-06] - Loss total: 5908.34326171875, Last rpr Loss: 1546.458740234375, Last lagvar Loss: 0.0\n",
      "Step 256/10000- lr: [9.84040467878788e-06] - Loss total: 5865.71826171875, Last rpr Loss: 1538.386962890625, Last lagvar Loss: 0.0\n",
      "Step 257/10000- lr: [9.839394581818183e-06] - Loss total: 5822.966796875, Last rpr Loss: 1530.900634765625, Last lagvar Loss: 0.0\n",
      "Step 258/10000- lr: [9.838384484848486e-06] - Loss total: 5780.23046875, Last rpr Loss: 1524.943603515625, Last lagvar Loss: 0.0\n",
      "Step 259/10000- lr: [9.83737438787879e-06] - Loss total: 5737.681640625, Last rpr Loss: 1520.58642578125, Last lagvar Loss: 0.0\n",
      "Step 260/10000- lr: [9.836364290909091e-06] - Loss total: 5695.6494140625, Last rpr Loss: 1517.0963134765625, Last lagvar Loss: 0.0\n",
      "Step 261/10000- lr: [9.835354193939394e-06] - Loss total: 5653.88427734375, Last rpr Loss: 1513.5810546875, Last lagvar Loss: 0.0\n",
      "Step 262/10000- lr: [9.834344096969698e-06] - Loss total: 5611.98681640625, Last rpr Loss: 1509.298095703125, Last lagvar Loss: 0.0\n",
      "Step 263/10000- lr: [9.833334000000001e-06] - Loss total: 5569.95166015625, Last rpr Loss: 1503.595458984375, Last lagvar Loss: 0.0\n",
      "Step 264/10000- lr: [9.832323903030304e-06] - Loss total: 5527.59619140625, Last rpr Loss: 1495.5029296875, Last lagvar Loss: 0.0\n",
      "Step 265/10000- lr: [9.831313806060607e-06] - Loss total: 5484.66748046875, Last rpr Loss: 1484.4610595703125, Last lagvar Loss: 0.0\n",
      "Step 266/10000- lr: [9.830303709090909e-06] - Loss total: 5442.00830078125, Last rpr Loss: 1475.09765625, Last lagvar Loss: 0.0\n",
      "Step 267/10000- lr: [9.829293612121212e-06] - Loss total: 5400.3994140625, Last rpr Loss: 1468.69140625, Last lagvar Loss: 0.0\n",
      "Step 268/10000- lr: [9.828283515151516e-06] - Loss total: 5359.51416015625, Last rpr Loss: 1462.78369140625, Last lagvar Loss: 0.0\n",
      "Step 269/10000- lr: [9.827273418181819e-06] - Loss total: 5319.0146484375, Last rpr Loss: 1457.032958984375, Last lagvar Loss: 0.0\n",
      "Step 270/10000- lr: [9.826263321212122e-06] - Loss total: 5278.7333984375, Last rpr Loss: 1451.486572265625, Last lagvar Loss: 0.0\n",
      "Step 271/10000- lr: [9.825253224242425e-06] - Loss total: 5238.59521484375, Last rpr Loss: 1446.0634765625, Last lagvar Loss: 0.0\n",
      "Step 272/10000- lr: [9.824243127272729e-06] - Loss total: 5198.63623046875, Last rpr Loss: 1440.8157958984375, Last lagvar Loss: 0.0\n",
      "Step 273/10000- lr: [9.823233030303032e-06] - Loss total: 5158.87255859375, Last rpr Loss: 1435.8447265625, Last lagvar Loss: 0.0\n",
      "Step 274/10000- lr: [9.822222933333334e-06] - Loss total: 5119.25537109375, Last rpr Loss: 1431.160400390625, Last lagvar Loss: 0.0\n",
      "Step 275/10000- lr: [9.821212836363637e-06] - Loss total: 5079.7705078125, Last rpr Loss: 1426.7489013671875, Last lagvar Loss: 0.0\n",
      "Step 276/10000- lr: [9.82020273939394e-06] - Loss total: 5040.427734375, Last rpr Loss: 1422.5643310546875, Last lagvar Loss: 0.0\n",
      "Step 277/10000- lr: [9.819192642424243e-06] - Loss total: 5001.22265625, Last rpr Loss: 1418.542724609375, Last lagvar Loss: 0.0\n",
      "Step 278/10000- lr: [9.818182545454547e-06] - Loss total: 4962.177734375, Last rpr Loss: 1414.715087890625, Last lagvar Loss: 0.0\n",
      "Step 279/10000- lr: [9.81717244848485e-06] - Loss total: 4923.306640625, Last rpr Loss: 1411.1383056640625, Last lagvar Loss: 0.0\n",
      "Step 280/10000- lr: [9.816162351515152e-06] - Loss total: 4884.61181640625, Last rpr Loss: 1407.7449951171875, Last lagvar Loss: 0.0\n",
      "Step 281/10000- lr: [9.815152254545455e-06] - Loss total: 4846.091796875, Last rpr Loss: 1404.4453125, Last lagvar Loss: 0.0\n",
      "Step 282/10000- lr: [9.814142157575758e-06] - Loss total: 4807.7099609375, Last rpr Loss: 1401.161865234375, Last lagvar Loss: 0.0\n",
      "Step 283/10000- lr: [9.813132060606061e-06] - Loss total: 4769.36376953125, Last rpr Loss: 1397.727783203125, Last lagvar Loss: 0.0\n",
      "Step 284/10000- lr: [9.812121963636365e-06] - Loss total: 4730.84228515625, Last rpr Loss: 1393.7786865234375, Last lagvar Loss: 0.0\n",
      "Step 285/10000- lr: [9.811111866666668e-06] - Loss total: 4691.7529296875, Last rpr Loss: 1388.6199951171875, Last lagvar Loss: 0.0\n",
      "Step 286/10000- lr: [9.810101769696971e-06] - Loss total: 4652.03662109375, Last rpr Loss: 1378.18310546875, Last lagvar Loss: 0.0\n",
      "Step 287/10000- lr: [9.809091672727273e-06] - Loss total: 4613.47705078125, Last rpr Loss: 1365.89599609375, Last lagvar Loss: 0.0\n",
      "Step 288/10000- lr: [9.808081575757576e-06] - Loss total: 4576.8583984375, Last rpr Loss: 1362.0438232421875, Last lagvar Loss: 0.0\n",
      "Step 289/10000- lr: [9.80707147878788e-06] - Loss total: 4540.97119140625, Last rpr Loss: 1359.114013671875, Last lagvar Loss: 0.0\n",
      "Step 290/10000- lr: [9.806061381818183e-06] - Loss total: 4505.4765625, Last rpr Loss: 1356.383056640625, Last lagvar Loss: 0.0\n",
      "Step 291/10000- lr: [9.805051284848486e-06] - Loss total: 4470.296875, Last rpr Loss: 1353.83154296875, Last lagvar Loss: 0.0\n",
      "Step 292/10000- lr: [9.804041187878789e-06] - Loss total: 4435.431640625, Last rpr Loss: 1351.456787109375, Last lagvar Loss: 0.0\n",
      "Step 293/10000- lr: [9.803031090909092e-06] - Loss total: 4400.87744140625, Last rpr Loss: 1349.209716796875, Last lagvar Loss: 0.0\n",
      "Step 294/10000- lr: [9.802020993939394e-06] - Loss total: 4366.61328125, Last rpr Loss: 1347.01611328125, Last lagvar Loss: 0.0\n",
      "Step 295/10000- lr: [9.801010896969697e-06] - Loss total: 4332.6181640625, Last rpr Loss: 1344.796142578125, Last lagvar Loss: 0.0\n",
      "Step 296/10000- lr: [9.8000008e-06] - Loss total: 4298.869140625, Last rpr Loss: 1342.490966796875, Last lagvar Loss: 0.0\n",
      "Step 297/10000- lr: [9.798990703030304e-06] - Loss total: 4265.35498046875, Last rpr Loss: 1340.10498046875, Last lagvar Loss: 0.0\n",
      "Step 298/10000- lr: [9.797980606060607e-06] - Loss total: 4232.109375, Last rpr Loss: 1337.71484375, Last lagvar Loss: 0.0\n",
      "Step 299/10000- lr: [9.79697050909091e-06] - Loss total: 4199.17822265625, Last rpr Loss: 1335.4078369140625, Last lagvar Loss: 0.0\n",
      "Step 300/10000- lr: [9.795960412121214e-06] - Loss total: 4166.58642578125, Last rpr Loss: 1333.1820068359375, Last lagvar Loss: 0.0\n",
      "Step 301/10000- lr: [9.794950315151515e-06] - Loss total: 4134.3310546875, Last rpr Loss: 1330.935791015625, Last lagvar Loss: 0.0\n",
      "Step 302/10000- lr: [9.793940218181819e-06] - Loss total: 4102.41650390625, Last rpr Loss: 1328.675048828125, Last lagvar Loss: 0.0\n",
      "Step 303/10000- lr: [9.792930121212122e-06] - Loss total: 4070.861572265625, Last rpr Loss: 1326.63818359375, Last lagvar Loss: 0.0\n",
      "Step 304/10000- lr: [9.791920024242425e-06] - Loss total: 4039.697998046875, Last rpr Loss: 1324.916015625, Last lagvar Loss: 0.0\n",
      "Step 305/10000- lr: [9.790909927272728e-06] - Loss total: 4008.951904296875, Last rpr Loss: 1323.452392578125, Last lagvar Loss: 0.0\n",
      "Step 306/10000- lr: [9.789899830303032e-06] - Loss total: 3978.6181640625, Last rpr Loss: 1322.1474609375, Last lagvar Loss: 0.0\n",
      "Step 307/10000- lr: [9.788889733333335e-06] - Loss total: 3948.663330078125, Last rpr Loss: 1320.8641357421875, Last lagvar Loss: 0.0\n",
      "Step 308/10000- lr: [9.787879636363636e-06] - Loss total: 3919.034423828125, Last rpr Loss: 1319.460205078125, Last lagvar Loss: 0.0\n",
      "Step 309/10000- lr: [9.78686953939394e-06] - Loss total: 3889.625, Last rpr Loss: 1317.7816162109375, Last lagvar Loss: 0.0\n",
      "Step 310/10000- lr: [9.785859442424243e-06] - Loss total: 3860.26513671875, Last rpr Loss: 1315.598876953125, Last lagvar Loss: 0.0\n",
      "Step 311/10000- lr: [9.784849345454546e-06] - Loss total: 3830.698486328125, Last rpr Loss: 1312.34619140625, Last lagvar Loss: 0.0\n",
      "Step 312/10000- lr: [9.78383924848485e-06] - Loss total: 3797.53515625, Last rpr Loss: 1297.828857421875, Last lagvar Loss: 0.0\n",
      "Step 313/10000- lr: [9.782829151515153e-06] - Loss total: 3764.001708984375, Last rpr Loss: 1286.2647705078125, Last lagvar Loss: 0.0\n",
      "Step 314/10000- lr: [9.781819054545456e-06] - Loss total: 3737.3056640625, Last rpr Loss: 1284.139404296875, Last lagvar Loss: 0.0\n",
      "Step 315/10000- lr: [9.780808957575758e-06] - Loss total: 3711.62939453125, Last rpr Loss: 1281.26318359375, Last lagvar Loss: 0.0\n",
      "Step 316/10000- lr: [9.779798860606061e-06] - Loss total: 3686.291748046875, Last rpr Loss: 1279.0853271484375, Last lagvar Loss: 0.0\n",
      "Step 317/10000- lr: [9.778788763636364e-06] - Loss total: 3661.39111328125, Last rpr Loss: 1277.628662109375, Last lagvar Loss: 0.0\n",
      "Step 318/10000- lr: [9.777778666666668e-06] - Loss total: 3636.785888671875, Last rpr Loss: 1276.3809814453125, Last lagvar Loss: 0.0\n",
      "Step 319/10000- lr: [9.77676856969697e-06] - Loss total: 3612.1015625, Last rpr Loss: 1275.1458740234375, Last lagvar Loss: 0.0\n",
      "Step 320/10000- lr: [9.775758472727274e-06] - Loss total: 3587.14453125, Last rpr Loss: 1273.6357421875, Last lagvar Loss: 0.0\n",
      "Step 321/10000- lr: [9.774748375757576e-06] - Loss total: 3562.094970703125, Last rpr Loss: 1270.4864501953125, Last lagvar Loss: 0.0\n",
      "Step 322/10000- lr: [9.773738278787879e-06] - Loss total: 3537.5576171875, Last rpr Loss: 1266.742919921875, Last lagvar Loss: 0.0\n",
      "Step 323/10000- lr: [9.772728181818182e-06] - Loss total: 3513.586181640625, Last rpr Loss: 1265.0615234375, Last lagvar Loss: 0.0\n",
      "Step 324/10000- lr: [9.771718084848486e-06] - Loss total: 3489.68896484375, Last rpr Loss: 1263.541015625, Last lagvar Loss: 0.0\n",
      "Step 325/10000- lr: [9.770707987878789e-06] - Loss total: 3465.749267578125, Last rpr Loss: 1261.82568359375, Last lagvar Loss: 0.0\n",
      "Step 326/10000- lr: [9.769697890909092e-06] - Loss total: 3441.719970703125, Last rpr Loss: 1259.6021728515625, Last lagvar Loss: 0.0\n",
      "Step 327/10000- lr: [9.768687793939395e-06] - Loss total: 3417.6435546875, Last rpr Loss: 1256.7508544921875, Last lagvar Loss: 0.0\n",
      "Step 328/10000- lr: [9.767677696969697e-06] - Loss total: 3393.810302734375, Last rpr Loss: 1254.6473388671875, Last lagvar Loss: 0.0\n",
      "Step 329/10000- lr: [9.7666676e-06] - Loss total: 3370.2451171875, Last rpr Loss: 1253.282470703125, Last lagvar Loss: 0.0\n",
      "Step 330/10000- lr: [9.765657503030304e-06] - Loss total: 3346.812255859375, Last rpr Loss: 1251.9791259765625, Last lagvar Loss: 0.0\n",
      "Step 331/10000- lr: [9.764647406060607e-06] - Loss total: 3323.373291015625, Last rpr Loss: 1250.44189453125, Last lagvar Loss: 0.0\n",
      "Step 332/10000- lr: [9.76363730909091e-06] - Loss total: 3299.697265625, Last rpr Loss: 1248.391845703125, Last lagvar Loss: 0.0\n",
      "Step 333/10000- lr: [9.762627212121213e-06] - Loss total: 3275.5107421875, Last rpr Loss: 1245.11962890625, Last lagvar Loss: 0.0\n",
      "Step 334/10000- lr: [9.761617115151517e-06] - Loss total: 3250.87744140625, Last rpr Loss: 1238.5537109375, Last lagvar Loss: 0.0\n",
      "Step 335/10000- lr: [9.760607018181818e-06] - Loss total: 3226.63671875, Last rpr Loss: 1231.6318359375, Last lagvar Loss: 0.0\n",
      "Step 336/10000- lr: [9.759596921212121e-06] - Loss total: 3203.294921875, Last rpr Loss: 1228.3740234375, Last lagvar Loss: 0.0\n",
      "Step 337/10000- lr: [9.758586824242425e-06] - Loss total: 3180.105712890625, Last rpr Loss: 1221.3203125, Last lagvar Loss: 0.0\n",
      "Step 338/10000- lr: [9.757576727272728e-06] - Loss total: 3158.698974609375, Last rpr Loss: 1217.6103515625, Last lagvar Loss: 0.0\n",
      "Step 339/10000- lr: [9.756566630303031e-06] - Loss total: 3138.192626953125, Last rpr Loss: 1216.09912109375, Last lagvar Loss: 0.0\n",
      "Step 340/10000- lr: [9.755556533333335e-06] - Loss total: 3117.861572265625, Last rpr Loss: 1214.531982421875, Last lagvar Loss: 0.0\n",
      "Step 341/10000- lr: [9.754546436363638e-06] - Loss total: 3097.64404296875, Last rpr Loss: 1212.730224609375, Last lagvar Loss: 0.0\n",
      "Step 342/10000- lr: [9.75353633939394e-06] - Loss total: 3077.518310546875, Last rpr Loss: 1210.7255859375, Last lagvar Loss: 0.0\n",
      "Step 343/10000- lr: [9.752526242424243e-06] - Loss total: 3057.42529296875, Last rpr Loss: 1208.6953125, Last lagvar Loss: 0.0\n",
      "Step 344/10000- lr: [9.751516145454546e-06] - Loss total: 3037.264892578125, Last rpr Loss: 1206.52197265625, Last lagvar Loss: 0.0\n",
      "Step 345/10000- lr: [9.75050604848485e-06] - Loss total: 3016.966552734375, Last rpr Loss: 1203.3834228515625, Last lagvar Loss: 0.0\n",
      "Step 346/10000- lr: [9.749495951515153e-06] - Loss total: 2996.460205078125, Last rpr Loss: 1197.106201171875, Last lagvar Loss: 0.0\n",
      "Step 347/10000- lr: [9.748485854545456e-06] - Loss total: 2976.271728515625, Last rpr Loss: 1191.7110595703125, Last lagvar Loss: 0.0\n",
      "Step 348/10000- lr: [9.747475757575759e-06] - Loss total: 2957.23583984375, Last rpr Loss: 1189.51806640625, Last lagvar Loss: 0.0\n",
      "Step 349/10000- lr: [9.74646566060606e-06] - Loss total: 2938.409423828125, Last rpr Loss: 1187.07763671875, Last lagvar Loss: 0.0\n",
      "Step 350/10000- lr: [9.745455563636364e-06] - Loss total: 2918.87939453125, Last rpr Loss: 1181.385009765625, Last lagvar Loss: 0.0\n",
      "Step 351/10000- lr: [9.744445466666667e-06] - Loss total: 2898.921630859375, Last rpr Loss: 1172.1063232421875, Last lagvar Loss: 0.0\n",
      "Step 352/10000- lr: [9.74343536969697e-06] - Loss total: 2881.134521484375, Last rpr Loss: 1168.660888671875, Last lagvar Loss: 0.0\n",
      "Step 353/10000- lr: [9.742425272727274e-06] - Loss total: 2864.385986328125, Last rpr Loss: 1165.7587890625, Last lagvar Loss: 0.0\n",
      "Step 354/10000- lr: [9.741415175757577e-06] - Loss total: 2847.489501953125, Last rpr Loss: 1161.25244140625, Last lagvar Loss: 0.0\n",
      "Step 355/10000- lr: [9.74040507878788e-06] - Loss total: 2829.865234375, Last rpr Loss: 1154.3746337890625, Last lagvar Loss: 0.0\n",
      "Step 356/10000- lr: [9.739394981818182e-06] - Loss total: 2811.995849609375, Last rpr Loss: 1146.0257568359375, Last lagvar Loss: 0.0\n",
      "Step 357/10000- lr: [9.738384884848485e-06] - Loss total: 2792.51220703125, Last rpr Loss: 1132.508544921875, Last lagvar Loss: 0.0\n",
      "Step 358/10000- lr: [9.737374787878788e-06] - Loss total: 2774.645263671875, Last rpr Loss: 1128.6943359375, Last lagvar Loss: 0.0\n",
      "Step 359/10000- lr: [9.736364690909092e-06] - Loss total: 2758.517578125, Last rpr Loss: 1125.0101318359375, Last lagvar Loss: 0.0\n",
      "Step 360/10000- lr: [9.735354593939395e-06] - Loss total: 2744.676025390625, Last rpr Loss: 1123.6575927734375, Last lagvar Loss: 0.0\n",
      "Step 361/10000- lr: [9.734344496969698e-06] - Loss total: 2731.3876953125, Last rpr Loss: 1122.227294921875, Last lagvar Loss: 0.0\n",
      "Step 362/10000- lr: [9.7333344e-06] - Loss total: 2717.822998046875, Last rpr Loss: 1120.4434814453125, Last lagvar Loss: 0.0\n",
      "Step 363/10000- lr: [9.732324303030303e-06] - Loss total: 2703.839111328125, Last rpr Loss: 1117.898681640625, Last lagvar Loss: 0.0\n",
      "Step 364/10000- lr: [9.731314206060606e-06] - Loss total: 2689.572998046875, Last rpr Loss: 1113.2017822265625, Last lagvar Loss: 0.0\n",
      "Step 365/10000- lr: [9.73030410909091e-06] - Loss total: 2676.018798828125, Last rpr Loss: 1109.9197998046875, Last lagvar Loss: 0.0\n",
      "Step 366/10000- lr: [9.729294012121213e-06] - Loss total: 2662.990478515625, Last rpr Loss: 1108.2171630859375, Last lagvar Loss: 0.0\n",
      "Step 367/10000- lr: [9.728283915151516e-06] - Loss total: 2649.861083984375, Last rpr Loss: 1106.3056640625, Last lagvar Loss: 0.0\n",
      "Step 368/10000- lr: [9.72727381818182e-06] - Loss total: 2636.5166015625, Last rpr Loss: 1104.0628662109375, Last lagvar Loss: 0.0\n",
      "Step 369/10000- lr: [9.726263721212123e-06] - Loss total: 2623.03125, Last rpr Loss: 1101.7562255859375, Last lagvar Loss: 0.0\n",
      "Step 370/10000- lr: [9.725253624242424e-06] - Loss total: 2609.517333984375, Last rpr Loss: 1099.449462890625, Last lagvar Loss: 0.0\n",
      "Step 371/10000- lr: [9.724243527272728e-06] - Loss total: 2596.221923828125, Last rpr Loss: 1097.0, Last lagvar Loss: 0.0\n",
      "Step 372/10000- lr: [9.723233430303031e-06] - Loss total: 2582.983642578125, Last rpr Loss: 1093.9432373046875, Last lagvar Loss: 0.0\n",
      "Step 373/10000- lr: [9.722223333333334e-06] - Loss total: 2569.643310546875, Last rpr Loss: 1090.636474609375, Last lagvar Loss: 0.0\n",
      "Step 374/10000- lr: [9.721213236363638e-06] - Loss total: 2556.482666015625, Last rpr Loss: 1088.55908203125, Last lagvar Loss: 0.0\n",
      "Step 375/10000- lr: [9.72020313939394e-06] - Loss total: 2543.449462890625, Last rpr Loss: 1086.6085205078125, Last lagvar Loss: 0.0\n",
      "Step 376/10000- lr: [9.719193042424242e-06] - Loss total: 2530.291748046875, Last rpr Loss: 1082.741943359375, Last lagvar Loss: 0.0\n",
      "Step 377/10000- lr: [9.718182945454546e-06] - Loss total: 2516.951904296875, Last rpr Loss: 1079.60595703125, Last lagvar Loss: 0.0\n",
      "Step 378/10000- lr: [9.717172848484849e-06] - Loss total: 2503.570556640625, Last rpr Loss: 1078.0736083984375, Last lagvar Loss: 0.0\n",
      "Step 379/10000- lr: [9.716162751515152e-06] - Loss total: 2490.6650390625, Last rpr Loss: 1076.3382568359375, Last lagvar Loss: 0.0\n",
      "Step 380/10000- lr: [9.715152654545455e-06] - Loss total: 2477.823486328125, Last rpr Loss: 1074.0697021484375, Last lagvar Loss: 0.0\n",
      "Step 381/10000- lr: [9.714142557575759e-06] - Loss total: 2464.857177734375, Last rpr Loss: 1071.25, Last lagvar Loss: 0.0\n",
      "Step 382/10000- lr: [9.713132460606062e-06] - Loss total: 2451.725830078125, Last rpr Loss: 1067.4080810546875, Last lagvar Loss: 0.0\n",
      "Step 383/10000- lr: [9.712122363636364e-06] - Loss total: 2438.273681640625, Last rpr Loss: 1061.81201171875, Last lagvar Loss: 0.0\n",
      "Step 384/10000- lr: [9.711112266666667e-06] - Loss total: 2424.47998046875, Last rpr Loss: 1057.9085693359375, Last lagvar Loss: 0.0\n",
      "Step 385/10000- lr: [9.71010216969697e-06] - Loss total: 2410.598388671875, Last rpr Loss: 1054.880859375, Last lagvar Loss: 0.0\n",
      "Step 386/10000- lr: [9.709092072727273e-06] - Loss total: 2396.92333984375, Last rpr Loss: 1051.5755615234375, Last lagvar Loss: 0.0\n",
      "Step 387/10000- lr: [9.708081975757577e-06] - Loss total: 2383.46337890625, Last rpr Loss: 1047.39697265625, Last lagvar Loss: 0.0\n",
      "Step 388/10000- lr: [9.70707187878788e-06] - Loss total: 2370.387939453125, Last rpr Loss: 1043.514404296875, Last lagvar Loss: 0.0\n",
      "Step 389/10000- lr: [9.706061781818183e-06] - Loss total: 2357.655517578125, Last rpr Loss: 1040.857177734375, Last lagvar Loss: 0.0\n",
      "Step 390/10000- lr: [9.705051684848485e-06] - Loss total: 2345.102783203125, Last rpr Loss: 1038.232421875, Last lagvar Loss: 0.0\n",
      "Step 391/10000- lr: [9.704041587878788e-06] - Loss total: 2332.63916015625, Last rpr Loss: 1035.6217041015625, Last lagvar Loss: 0.0\n",
      "Step 392/10000- lr: [9.703031490909091e-06] - Loss total: 2320.0986328125, Last rpr Loss: 1032.533447265625, Last lagvar Loss: 0.0\n",
      "Step 393/10000- lr: [9.702021393939395e-06] - Loss total: 2307.56298828125, Last rpr Loss: 1030.0576171875, Last lagvar Loss: 0.0\n",
      "Step 394/10000- lr: [9.701011296969698e-06] - Loss total: 2295.222900390625, Last rpr Loss: 1028.839599609375, Last lagvar Loss: 0.0\n",
      "Step 395/10000- lr: [9.700001200000001e-06] - Loss total: 2283.178955078125, Last rpr Loss: 1027.148681640625, Last lagvar Loss: 0.0\n",
      "Step 396/10000- lr: [9.698991103030305e-06] - Loss total: 2271.283935546875, Last rpr Loss: 1025.9990234375, Last lagvar Loss: 0.0\n",
      "Step 397/10000- lr: [9.697981006060606e-06] - Loss total: 2259.2255859375, Last rpr Loss: 1025.578125, Last lagvar Loss: 0.0\n",
      "Step 398/10000- lr: [9.69697090909091e-06] - Loss total: 2247.18408203125, Last rpr Loss: 1024.6505126953125, Last lagvar Loss: 0.0\n",
      "Step 399/10000- lr: [9.695960812121213e-06] - Loss total: 2234.766845703125, Last rpr Loss: 1020.9813842773438, Last lagvar Loss: 0.0\n",
      "Step 400/10000- lr: [9.694950715151516e-06] - Loss total: 2221.4326171875, Last rpr Loss: 1015.34619140625, Last lagvar Loss: 0.0\n",
      "Step 401/10000- lr: [9.69394061818182e-06] - Loss total: 2208.86376953125, Last rpr Loss: 1009.9456787109375, Last lagvar Loss: 0.0\n",
      "Step 402/10000- lr: [9.692930521212123e-06] - Loss total: 2197.46240234375, Last rpr Loss: 1007.4395751953125, Last lagvar Loss: 0.0\n",
      "Step 403/10000- lr: [9.691920424242426e-06] - Loss total: 2186.17822265625, Last rpr Loss: 1003.6865234375, Last lagvar Loss: 0.0\n",
      "Step 404/10000- lr: [9.690910327272727e-06] - Loss total: 2174.739501953125, Last rpr Loss: 999.3295288085938, Last lagvar Loss: 0.0\n",
      "Step 405/10000- lr: [9.68990023030303e-06] - Loss total: 2163.254150390625, Last rpr Loss: 996.5906372070312, Last lagvar Loss: 0.0\n",
      "Step 406/10000- lr: [9.688890133333334e-06] - Loss total: 2152.130615234375, Last rpr Loss: 995.3883056640625, Last lagvar Loss: 0.0\n",
      "Step 407/10000- lr: [9.687880036363637e-06] - Loss total: 2141.28369140625, Last rpr Loss: 994.00634765625, Last lagvar Loss: 0.0\n",
      "Step 408/10000- lr: [9.68686993939394e-06] - Loss total: 2130.338134765625, Last rpr Loss: 992.2023315429688, Last lagvar Loss: 0.0\n",
      "Step 409/10000- lr: [9.685859842424244e-06] - Loss total: 2119.30322265625, Last rpr Loss: 989.4531860351562, Last lagvar Loss: 0.0\n",
      "Step 410/10000- lr: [9.684849745454547e-06] - Loss total: 2107.966796875, Last rpr Loss: 985.2982788085938, Last lagvar Loss: 0.0\n",
      "Step 411/10000- lr: [9.683839648484849e-06] - Loss total: 2097.356689453125, Last rpr Loss: 983.2855224609375, Last lagvar Loss: 0.0\n",
      "Step 412/10000- lr: [9.682829551515152e-06] - Loss total: 2087.109619140625, Last rpr Loss: 980.7923583984375, Last lagvar Loss: 0.0\n",
      "Step 413/10000- lr: [9.681819454545455e-06] - Loss total: 2077.026123046875, Last rpr Loss: 978.1451416015625, Last lagvar Loss: 0.0\n",
      "Step 414/10000- lr: [9.680809357575758e-06] - Loss total: 2066.898193359375, Last rpr Loss: 975.76953125, Last lagvar Loss: 0.0\n",
      "Step 415/10000- lr: [9.679799260606062e-06] - Loss total: 2056.851318359375, Last rpr Loss: 973.6453857421875, Last lagvar Loss: 0.0\n",
      "Step 416/10000- lr: [9.678789163636365e-06] - Loss total: 2046.9676513671875, Last rpr Loss: 970.7185668945312, Last lagvar Loss: 0.0\n",
      "Step 417/10000- lr: [9.677779066666667e-06] - Loss total: 2037.1060791015625, Last rpr Loss: 967.6663818359375, Last lagvar Loss: 0.0\n",
      "Step 418/10000- lr: [9.67676896969697e-06] - Loss total: 2027.6353759765625, Last rpr Loss: 966.0989990234375, Last lagvar Loss: 0.0\n",
      "Step 419/10000- lr: [9.675758872727273e-06] - Loss total: 2018.4071044921875, Last rpr Loss: 964.8031005859375, Last lagvar Loss: 0.0\n",
      "Step 420/10000- lr: [9.674748775757576e-06] - Loss total: 2009.2965087890625, Last rpr Loss: 963.5958251953125, Last lagvar Loss: 0.0\n",
      "Step 421/10000- lr: [9.67373867878788e-06] - Loss total: 2000.325927734375, Last rpr Loss: 962.5162963867188, Last lagvar Loss: 0.0\n",
      "Step 422/10000- lr: [9.672728581818183e-06] - Loss total: 1991.474365234375, Last rpr Loss: 961.499755859375, Last lagvar Loss: 0.0\n",
      "Step 423/10000- lr: [9.671718484848486e-06] - Loss total: 1982.68994140625, Last rpr Loss: 960.4683227539062, Last lagvar Loss: 0.0\n",
      "Step 424/10000- lr: [9.67070838787879e-06] - Loss total: 1973.9205322265625, Last rpr Loss: 959.3496704101562, Last lagvar Loss: 0.0\n",
      "Step 425/10000- lr: [9.669698290909091e-06] - Loss total: 1965.043212890625, Last rpr Loss: 957.6522216796875, Last lagvar Loss: 0.0\n",
      "Step 426/10000- lr: [9.668688193939394e-06] - Loss total: 1955.919921875, Last rpr Loss: 954.10400390625, Last lagvar Loss: 0.0\n",
      "Step 427/10000- lr: [9.667678096969698e-06] - Loss total: 1947.2823486328125, Last rpr Loss: 950.8670043945312, Last lagvar Loss: 0.0\n",
      "Step 428/10000- lr: [9.666668000000001e-06] - Loss total: 1939.12744140625, Last rpr Loss: 949.6397094726562, Last lagvar Loss: 0.0\n",
      "Step 429/10000- lr: [9.665657903030304e-06] - Loss total: 1930.9993896484375, Last rpr Loss: 949.0211181640625, Last lagvar Loss: 0.0\n",
      "Step 430/10000- lr: [9.664647806060607e-06] - Loss total: 1922.8677978515625, Last rpr Loss: 948.3047485351562, Last lagvar Loss: 0.0\n",
      "Step 431/10000- lr: [9.663637709090909e-06] - Loss total: 1914.6796875, Last rpr Loss: 947.2946166992188, Last lagvar Loss: 0.0\n",
      "Step 432/10000- lr: [9.662627612121212e-06] - Loss total: 1906.5560302734375, Last rpr Loss: 945.8372192382812, Last lagvar Loss: 0.0\n",
      "Step 433/10000- lr: [9.661617515151516e-06] - Loss total: 1898.41064453125, Last rpr Loss: 944.0492553710938, Last lagvar Loss: 0.0\n",
      "Step 434/10000- lr: [9.660607418181819e-06] - Loss total: 1890.2161865234375, Last rpr Loss: 942.5867919921875, Last lagvar Loss: 0.0\n",
      "Step 435/10000- lr: [9.659597321212122e-06] - Loss total: 1882.1810302734375, Last rpr Loss: 941.4205322265625, Last lagvar Loss: 0.0\n",
      "Step 436/10000- lr: [9.658587224242425e-06] - Loss total: 1874.4029541015625, Last rpr Loss: 940.0708618164062, Last lagvar Loss: 0.0\n",
      "Step 437/10000- lr: [9.657577127272729e-06] - Loss total: 1866.8038330078125, Last rpr Loss: 938.7901611328125, Last lagvar Loss: 0.0\n",
      "Step 438/10000- lr: [9.65656703030303e-06] - Loss total: 1859.3741455078125, Last rpr Loss: 937.95849609375, Last lagvar Loss: 0.0\n",
      "Step 439/10000- lr: [9.655556933333334e-06] - Loss total: 1851.91015625, Last rpr Loss: 936.708251953125, Last lagvar Loss: 0.0\n",
      "Step 440/10000- lr: [9.654546836363637e-06] - Loss total: 1844.2918701171875, Last rpr Loss: 934.12353515625, Last lagvar Loss: 0.0\n",
      "Step 441/10000- lr: [9.65353673939394e-06] - Loss total: 1836.49853515625, Last rpr Loss: 931.7144165039062, Last lagvar Loss: 0.0\n",
      "Step 442/10000- lr: [9.652526642424243e-06] - Loss total: 1828.8660888671875, Last rpr Loss: 929.9308471679688, Last lagvar Loss: 0.0\n",
      "Step 443/10000- lr: [9.651516545454547e-06] - Loss total: 1821.6473388671875, Last rpr Loss: 928.7777099609375, Last lagvar Loss: 0.0\n",
      "Step 444/10000- lr: [9.65050644848485e-06] - Loss total: 1814.5343017578125, Last rpr Loss: 927.9435424804688, Last lagvar Loss: 0.0\n",
      "Step 445/10000- lr: [9.649496351515152e-06] - Loss total: 1807.4239501953125, Last rpr Loss: 927.03173828125, Last lagvar Loss: 0.0\n",
      "Step 446/10000- lr: [9.648486254545455e-06] - Loss total: 1800.342529296875, Last rpr Loss: 925.9476318359375, Last lagvar Loss: 0.0\n",
      "Step 447/10000- lr: [9.647476157575758e-06] - Loss total: 1793.231201171875, Last rpr Loss: 924.731689453125, Last lagvar Loss: 0.0\n",
      "Step 448/10000- lr: [9.646466060606061e-06] - Loss total: 1786.0693359375, Last rpr Loss: 923.468017578125, Last lagvar Loss: 0.0\n",
      "Step 449/10000- lr: [9.645455963636365e-06] - Loss total: 1778.9993896484375, Last rpr Loss: 922.2882080078125, Last lagvar Loss: 0.0\n",
      "Step 450/10000- lr: [9.644445866666668e-06] - Loss total: 1772.0107421875, Last rpr Loss: 920.990234375, Last lagvar Loss: 0.0\n",
      "Step 451/10000- lr: [9.643435769696971e-06] - Loss total: 1765.1461181640625, Last rpr Loss: 919.7625732421875, Last lagvar Loss: 0.0\n",
      "Step 452/10000- lr: [9.642425672727273e-06] - Loss total: 1758.447998046875, Last rpr Loss: 918.8248901367188, Last lagvar Loss: 0.0\n",
      "Step 453/10000- lr: [9.641415575757576e-06] - Loss total: 1751.881591796875, Last rpr Loss: 918.0596923828125, Last lagvar Loss: 0.0\n",
      "Step 454/10000- lr: [9.64040547878788e-06] - Loss total: 1745.3892822265625, Last rpr Loss: 917.259033203125, Last lagvar Loss: 0.0\n",
      "Step 455/10000- lr: [9.639395381818183e-06] - Loss total: 1738.925048828125, Last rpr Loss: 916.33447265625, Last lagvar Loss: 0.0\n",
      "Step 456/10000- lr: [9.638385284848486e-06] - Loss total: 1732.4765625, Last rpr Loss: 915.4228515625, Last lagvar Loss: 0.0\n",
      "Step 457/10000- lr: [9.63737518787879e-06] - Loss total: 1726.0577392578125, Last rpr Loss: 914.617431640625, Last lagvar Loss: 0.0\n",
      "Step 458/10000- lr: [9.636365090909092e-06] - Loss total: 1719.6533203125, Last rpr Loss: 913.7975463867188, Last lagvar Loss: 0.0\n",
      "Step 459/10000- lr: [9.635354993939394e-06] - Loss total: 1713.1724853515625, Last rpr Loss: 912.6891479492188, Last lagvar Loss: 0.0\n",
      "Step 460/10000- lr: [9.634344896969697e-06] - Loss total: 1706.3580322265625, Last rpr Loss: 910.5538940429688, Last lagvar Loss: 0.0\n",
      "Step 461/10000- lr: [9.6333348e-06] - Loss total: 1698.5511474609375, Last rpr Loss: 906.7786865234375, Last lagvar Loss: 0.0\n",
      "Step 462/10000- lr: [9.632324703030304e-06] - Loss total: 1692.061279296875, Last rpr Loss: 905.0975341796875, Last lagvar Loss: 0.0\n",
      "Step 463/10000- lr: [9.631314606060607e-06] - Loss total: 1685.9769287109375, Last rpr Loss: 903.2974853515625, Last lagvar Loss: 0.0\n",
      "Step 464/10000- lr: [9.63030450909091e-06] - Loss total: 1679.7659912109375, Last rpr Loss: 900.664794921875, Last lagvar Loss: 0.0\n",
      "Step 465/10000- lr: [9.629294412121214e-06] - Loss total: 1673.7442626953125, Last rpr Loss: 898.7679443359375, Last lagvar Loss: 0.0\n",
      "Step 466/10000- lr: [9.628284315151515e-06] - Loss total: 1668.02099609375, Last rpr Loss: 897.7393188476562, Last lagvar Loss: 0.0\n",
      "Step 467/10000- lr: [9.627274218181819e-06] - Loss total: 1662.52001953125, Last rpr Loss: 896.9239501953125, Last lagvar Loss: 0.0\n",
      "Step 468/10000- lr: [9.626264121212122e-06] - Loss total: 1657.1263427734375, Last rpr Loss: 896.1151123046875, Last lagvar Loss: 0.0\n",
      "Step 469/10000- lr: [9.625254024242425e-06] - Loss total: 1651.745361328125, Last rpr Loss: 895.2355346679688, Last lagvar Loss: 0.0\n",
      "Step 470/10000- lr: [9.624243927272728e-06] - Loss total: 1646.3160400390625, Last rpr Loss: 894.2908935546875, Last lagvar Loss: 0.0\n",
      "Step 471/10000- lr: [9.623233830303032e-06] - Loss total: 1640.777587890625, Last rpr Loss: 893.3375854492188, Last lagvar Loss: 0.0\n",
      "Step 472/10000- lr: [9.622223733333333e-06] - Loss total: 1635.13671875, Last rpr Loss: 892.438232421875, Last lagvar Loss: 0.0\n",
      "Step 473/10000- lr: [9.621213636363637e-06] - Loss total: 1629.537841796875, Last rpr Loss: 891.6177978515625, Last lagvar Loss: 0.0\n",
      "Step 474/10000- lr: [9.62020353939394e-06] - Loss total: 1624.2208251953125, Last rpr Loss: 890.843994140625, Last lagvar Loss: 0.0\n",
      "Step 475/10000- lr: [9.619193442424243e-06] - Loss total: 1619.1856689453125, Last rpr Loss: 890.098876953125, Last lagvar Loss: 0.0\n",
      "Step 476/10000- lr: [9.618183345454546e-06] - Loss total: 1614.2857666015625, Last rpr Loss: 889.4486083984375, Last lagvar Loss: 0.0\n",
      "Step 477/10000- lr: [9.61717324848485e-06] - Loss total: 1609.4617919921875, Last rpr Loss: 888.955078125, Last lagvar Loss: 0.0\n",
      "Step 478/10000- lr: [9.616163151515153e-06] - Loss total: 1604.708251953125, Last rpr Loss: 888.5958251953125, Last lagvar Loss: 0.0\n",
      "Step 479/10000- lr: [9.615153054545455e-06] - Loss total: 1600.0247802734375, Last rpr Loss: 888.3212890625, Last lagvar Loss: 0.0\n",
      "Step 480/10000- lr: [9.614142957575758e-06] - Loss total: 1595.4141845703125, Last rpr Loss: 888.0970458984375, Last lagvar Loss: 0.0\n",
      "Step 481/10000- lr: [9.613132860606061e-06] - Loss total: 1590.8890380859375, Last rpr Loss: 887.8958740234375, Last lagvar Loss: 0.0\n",
      "Step 482/10000- lr: [9.612122763636364e-06] - Loss total: 1586.4539794921875, Last rpr Loss: 887.6998291015625, Last lagvar Loss: 0.0\n",
      "Step 483/10000- lr: [9.611112666666668e-06] - Loss total: 1582.0911865234375, Last rpr Loss: 887.5018310546875, Last lagvar Loss: 0.0\n",
      "Step 484/10000- lr: [9.610102569696971e-06] - Loss total: 1577.7698974609375, Last rpr Loss: 887.280517578125, Last lagvar Loss: 0.0\n",
      "Step 485/10000- lr: [9.609092472727274e-06] - Loss total: 1573.463623046875, Last rpr Loss: 886.9945678710938, Last lagvar Loss: 0.0\n",
      "Step 486/10000- lr: [9.608082375757576e-06] - Loss total: 1569.1436767578125, Last rpr Loss: 886.5849609375, Last lagvar Loss: 0.0\n",
      "Step 487/10000- lr: [9.607072278787879e-06] - Loss total: 1564.8834228515625, Last rpr Loss: 885.5645141601562, Last lagvar Loss: 0.0\n",
      "Step 488/10000- lr: [9.606062181818182e-06] - Loss total: 1560.843994140625, Last rpr Loss: 884.7247314453125, Last lagvar Loss: 0.0\n",
      "Step 489/10000- lr: [9.605052084848486e-06] - Loss total: 1556.9033203125, Last rpr Loss: 884.3643798828125, Last lagvar Loss: 0.0\n",
      "Step 490/10000- lr: [9.604041987878789e-06] - Loss total: 1552.9869384765625, Last rpr Loss: 884.0352783203125, Last lagvar Loss: 0.0\n",
      "Step 491/10000- lr: [9.603031890909092e-06] - Loss total: 1549.091552734375, Last rpr Loss: 883.606201171875, Last lagvar Loss: 0.0\n",
      "Step 492/10000- lr: [9.602021793939395e-06] - Loss total: 1545.2291259765625, Last rpr Loss: 882.99267578125, Last lagvar Loss: 0.0\n",
      "Step 493/10000- lr: [9.601011696969697e-06] - Loss total: 1541.439453125, Last rpr Loss: 882.4619750976562, Last lagvar Loss: 0.0\n",
      "Step 494/10000- lr: [9.6000016e-06] - Loss total: 1537.728759765625, Last rpr Loss: 882.0423583984375, Last lagvar Loss: 0.0\n",
      "Step 495/10000- lr: [9.598991503030304e-06] - Loss total: 1534.10009765625, Last rpr Loss: 881.7036743164062, Last lagvar Loss: 0.0\n",
      "Step 496/10000- lr: [9.597981406060607e-06] - Loss total: 1530.539306640625, Last rpr Loss: 881.3607788085938, Last lagvar Loss: 0.0\n",
      "Step 497/10000- lr: [9.59697130909091e-06] - Loss total: 1527.0018310546875, Last rpr Loss: 880.9180908203125, Last lagvar Loss: 0.0\n",
      "Step 498/10000- lr: [9.595961212121213e-06] - Loss total: 1523.4407958984375, Last rpr Loss: 880.2560424804688, Last lagvar Loss: 0.0\n",
      "Step 499/10000- lr: [9.594951115151517e-06] - Loss total: 1519.7784423828125, Last rpr Loss: 879.4180908203125, Last lagvar Loss: 0.0\n",
      "Step 500/10000- lr: [9.593941018181818e-06] - Loss total: 4384.80029296875, Last rpr Loss: 3437.163330078125, Last lagvar Loss: -0.2851414978504181\n",
      "Step 501/10000- lr: [9.592930921212122e-06] - Loss total: 4024.283447265625, Last rpr Loss: 3205.447265625, Last lagvar Loss: -0.2665521502494812\n",
      "Step 502/10000- lr: [9.591920824242425e-06] - Loss total: 3532.966064453125, Last rpr Loss: 2833.273193359375, Last lagvar Loss: -0.22783848643302917\n",
      "Step 503/10000- lr: [9.590910727272728e-06] - Loss total: 3052.28466796875, Last rpr Loss: 2392.8212890625, Last lagvar Loss: -0.1710585206747055\n",
      "Step 504/10000- lr: [9.589900630303031e-06] - Loss total: 2642.366455078125, Last rpr Loss: 1945.825927734375, Last lagvar Loss: -0.09776222705841064\n",
      "Step 505/10000- lr: [9.588890533333335e-06] - Loss total: 2312.960205078125, Last rpr Loss: 1538.789306640625, Last lagvar Loss: -0.009574353694915771\n",
      "Step 506/10000- lr: [9.587880436363638e-06] - Loss total: 2052.448486328125, Last rpr Loss: 1197.3544921875, Last lagvar Loss: 0.09200307726860046\n",
      "Step 507/10000- lr: [9.58687033939394e-06] - Loss total: 1843.7574462890625, Last rpr Loss: 924.382080078125, Last lagvar Loss: 0.205468088388443\n",
      "Step 508/10000- lr: [9.585860242424243e-06] - Loss total: 1673.3946533203125, Last rpr Loss: 714.632080078125, Last lagvar Loss: 0.3289237916469574\n",
      "Step 509/10000- lr: [9.584850145454546e-06] - Loss total: 1528.9501953125, Last rpr Loss: 558.46142578125, Last lagvar Loss: 0.4587055444717407\n",
      "Step 510/10000- lr: [9.58384004848485e-06] - Loss total: 1402.312744140625, Last rpr Loss: 441.949951171875, Last lagvar Loss: 0.5931941270828247\n",
      "Step 511/10000- lr: [9.582829951515153e-06] - Loss total: 1289.9185791015625, Last rpr Loss: 353.2245788574219, Last lagvar Loss: 0.732695996761322\n",
      "Step 512/10000- lr: [9.581819854545456e-06] - Loss total: 1188.9725341796875, Last rpr Loss: 284.743408203125, Last lagvar Loss: 0.8766554594039917\n",
      "Step 513/10000- lr: [9.580809757575757e-06] - Loss total: 1098.1600341796875, Last rpr Loss: 231.44876098632812, Last lagvar Loss: 1.0241223573684692\n",
      "Step 514/10000- lr: [9.57979966060606e-06] - Loss total: 1016.6246948242188, Last rpr Loss: 189.7339630126953, Last lagvar Loss: 1.1737380027770996\n",
      "Step 515/10000- lr: [9.578789563636364e-06] - Loss total: 943.4849243164062, Last rpr Loss: 157.15774536132812, Last lagvar Loss: 1.3236024379730225\n",
      "Step 516/10000- lr: [9.577779466666667e-06] - Loss total: 877.7452392578125, Last rpr Loss: 132.07594299316406, Last lagvar Loss: 1.4713547229766846\n",
      "Step 517/10000- lr: [9.57676936969697e-06] - Loss total: 818.2708129882812, Last rpr Loss: 112.07295227050781, Last lagvar Loss: 1.6145684719085693\n",
      "Step 518/10000- lr: [9.575759272727274e-06] - Loss total: 764.1013793945312, Last rpr Loss: 96.08976745605469, Last lagvar Loss: 1.7511988878250122\n",
      "Step 519/10000- lr: [9.574749175757577e-06] - Loss total: 714.2395629882812, Last rpr Loss: 83.28228759765625, Last lagvar Loss: 1.879846215248108\n",
      "Step 520/10000- lr: [9.57373907878788e-06] - Loss total: 667.8850708007812, Last rpr Loss: 72.75877380371094, Last lagvar Loss: 2.0000200271606445\n",
      "Step 521/10000- lr: [9.572728981818182e-06] - Loss total: 624.60986328125, Last rpr Loss: 63.9222412109375, Last lagvar Loss: 2.112030029296875\n",
      "Step 522/10000- lr: [9.571718884848485e-06] - Loss total: 584.2890014648438, Last rpr Loss: 56.6166877746582, Last lagvar Loss: 2.216777801513672\n",
      "Step 523/10000- lr: [9.570708787878789e-06] - Loss total: 546.9151000976562, Last rpr Loss: 50.827415466308594, Last lagvar Loss: 2.3156685829162598\n",
      "Step 524/10000- lr: [9.569698690909092e-06] - Loss total: 512.34912109375, Last rpr Loss: 46.121002197265625, Last lagvar Loss: 2.4103798866271973\n",
      "Step 525/10000- lr: [9.568688593939395e-06] - Loss total: 480.3673095703125, Last rpr Loss: 42.12846374511719, Last lagvar Loss: 2.5025572776794434\n",
      "Step 526/10000- lr: [9.567678496969698e-06] - Loss total: 450.7157287597656, Last rpr Loss: 38.63887023925781, Last lagvar Loss: 2.59365177154541\n",
      "Step 527/10000- lr: [9.5666684e-06] - Loss total: 423.13006591796875, Last rpr Loss: 35.500465393066406, Last lagvar Loss: 2.6848397254943848\n",
      "Step 528/10000- lr: [9.565658303030303e-06] - Loss total: 397.3699035644531, Last rpr Loss: 32.610443115234375, Last lagvar Loss: 2.7770140171051025\n",
      "Step 529/10000- lr: [9.564648206060607e-06] - Loss total: 373.2438049316406, Last rpr Loss: 29.915307998657227, Last lagvar Loss: 2.8708150386810303\n",
      "Step 530/10000- lr: [9.56363810909091e-06] - Loss total: 350.6102294921875, Last rpr Loss: 27.393821716308594, Last lagvar Loss: 2.966648817062378\n",
      "Step 531/10000- lr: [9.562628012121213e-06] - Loss total: 329.3678894042969, Last rpr Loss: 25.038761138916016, Last lagvar Loss: 3.0646815299987793\n",
      "Step 532/10000- lr: [9.561617915151516e-06] - Loss total: 309.4438781738281, Last rpr Loss: 22.848215103149414, Last lagvar Loss: 3.164829730987549\n",
      "Step 533/10000- lr: [9.56060781818182e-06] - Loss total: 290.7782287597656, Last rpr Loss: 20.819889068603516, Last lagvar Loss: 3.266788959503174\n",
      "Step 534/10000- lr: [9.559597721212121e-06] - Loss total: 273.3050537109375, Last rpr Loss: 18.950183868408203, Last lagvar Loss: 3.370089054107666\n",
      "Step 535/10000- lr: [9.558587624242424e-06] - Loss total: 256.9437561035156, Last rpr Loss: 17.237518310546875, Last lagvar Loss: 3.4741568565368652\n",
      "Step 536/10000- lr: [9.557577527272728e-06] - Loss total: 241.6039276123047, Last rpr Loss: 15.682075500488281, Last lagvar Loss: 3.578392505645752\n",
      "Step 537/10000- lr: [9.556567430303031e-06] - Loss total: 227.2005615234375, Last rpr Loss: 14.281106948852539, Last lagvar Loss: 3.6822574138641357\n",
      "Step 538/10000- lr: [9.555557333333334e-06] - Loss total: 213.67083740234375, Last rpr Loss: 13.02519416809082, Last lagvar Loss: 3.785353660583496\n",
      "Step 539/10000- lr: [9.554547236363638e-06] - Loss total: 200.977294921875, Last rpr Loss: 11.900561332702637, Last lagvar Loss: 3.8874588012695312\n",
      "Step 540/10000- lr: [9.553537139393941e-06] - Loss total: 189.09288024902344, Last rpr Loss: 10.897171974182129, Last lagvar Loss: 3.988492965698242\n",
      "Step 541/10000- lr: [9.552527042424242e-06] - Loss total: 177.98077392578125, Last rpr Loss: 10.005062103271484, Last lagvar Loss: 4.088454246520996\n",
      "Step 542/10000- lr: [9.551516945454546e-06] - Loss total: 167.5878448486328, Last rpr Loss: 9.206035614013672, Last lagvar Loss: 4.1873674392700195\n",
      "Step 543/10000- lr: [9.550506848484849e-06] - Loss total: 157.85427856445312, Last rpr Loss: 8.48236083984375, Last lagvar Loss: 4.285244941711426\n",
      "Step 544/10000- lr: [9.549496751515152e-06] - Loss total: 148.72621154785156, Last rpr Loss: 7.822606086730957, Last lagvar Loss: 4.382092475891113\n",
      "Step 545/10000- lr: [9.548486654545456e-06] - Loss total: 140.16311645507812, Last rpr Loss: 7.220499515533447, Last lagvar Loss: 4.477914810180664\n",
      "Step 546/10000- lr: [9.547476557575759e-06] - Loss total: 132.1350860595703, Last rpr Loss: 6.672638893127441, Last lagvar Loss: 4.572710037231445\n",
      "Step 547/10000- lr: [9.546466460606062e-06] - Loss total: 124.61531829833984, Last rpr Loss: 6.176430702209473, Last lagvar Loss: 4.666462421417236\n",
      "Step 548/10000- lr: [9.545456363636364e-06] - Loss total: 117.57489776611328, Last rpr Loss: 5.728681564331055, Last lagvar Loss: 4.759144306182861\n",
      "Step 549/10000- lr: [9.544446266666667e-06] - Loss total: 110.98267364501953, Last rpr Loss: 5.325076103210449, Last lagvar Loss: 4.850741863250732\n",
      "Step 550/10000- lr: [9.54343616969697e-06] - Loss total: 104.80778503417969, Last rpr Loss: 4.960568428039551, Last lagvar Loss: 4.941287994384766\n",
      "Step 551/10000- lr: [9.542426072727274e-06] - Loss total: 99.0218276977539, Last rpr Loss: 4.630147457122803, Last lagvar Loss: 5.030876159667969\n",
      "Step 552/10000- lr: [9.541415975757577e-06] - Loss total: 93.59915924072266, Last rpr Loss: 4.329315185546875, Last lagvar Loss: 5.119660377502441\n",
      "Step 553/10000- lr: [9.54040587878788e-06] - Loss total: 88.51712799072266, Last rpr Loss: 4.054360389709473, Last lagvar Loss: 5.207833290100098\n",
      "Step 554/10000- lr: [9.539395781818183e-06] - Loss total: 83.75530242919922, Last rpr Loss: 3.8022267818450928, Last lagvar Loss: 5.295603275299072\n",
      "Step 555/10000- lr: [9.538385684848485e-06] - Loss total: 79.29451751708984, Last rpr Loss: 3.5703892707824707, Last lagvar Loss: 5.3831586837768555\n",
      "Step 556/10000- lr: [9.537375587878788e-06] - Loss total: 75.11591339111328, Last rpr Loss: 3.3566620349884033, Last lagvar Loss: 5.470636367797852\n",
      "Step 557/10000- lr: [9.536365490909091e-06] - Loss total: 71.20083618164062, Last rpr Loss: 3.1591577529907227, Last lagvar Loss: 5.5580854415893555\n",
      "Step 558/10000- lr: [9.535355393939395e-06] - Loss total: 67.5316390991211, Last rpr Loss: 2.9762935638427734, Last lagvar Loss: 5.645461082458496\n",
      "Step 559/10000- lr: [9.534345296969698e-06] - Loss total: 64.09245300292969, Last rpr Loss: 2.8068466186523438, Last lagvar Loss: 5.7326154708862305\n",
      "Step 560/10000- lr: [9.533335200000001e-06] - Loss total: 60.86924362182617, Last rpr Loss: 2.6499414443969727, Last lagvar Loss: 5.819317817687988\n",
      "Step 561/10000- lr: [9.532325103030305e-06] - Loss total: 57.84891891479492, Last rpr Loss: 2.5049428939819336, Last lagvar Loss: 5.905272483825684\n",
      "Step 562/10000- lr: [9.531315006060606e-06] - Loss total: 55.018775939941406, Last rpr Loss: 2.371302843093872, Last lagvar Loss: 5.990154266357422\n",
      "Step 563/10000- lr: [9.53030490909091e-06] - Loss total: 52.3662223815918, Last rpr Loss: 2.2484219074249268, Last lagvar Loss: 6.0736403465271\n",
      "Step 564/10000- lr: [9.529294812121213e-06] - Loss total: 49.87921142578125, Last rpr Loss: 2.135590076446533, Last lagvar Loss: 6.155442237854004\n",
      "Step 565/10000- lr: [9.528284715151516e-06] - Loss total: 47.54643630981445, Last rpr Loss: 2.0319676399230957, Last lagvar Loss: 6.2353291511535645\n",
      "Step 566/10000- lr: [9.52727461818182e-06] - Loss total: 45.35750198364258, Last rpr Loss: 1.936662197113037, Last lagvar Loss: 6.313128471374512\n",
      "Step 567/10000- lr: [9.526264521212123e-06] - Loss total: 43.30279541015625, Last rpr Loss: 1.848818302154541, Last lagvar Loss: 6.388724327087402\n",
      "Step 568/10000- lr: [9.525254424242424e-06] - Loss total: 41.37343978881836, Last rpr Loss: 1.7677054405212402, Last lagvar Loss: 6.4620442390441895\n",
      "Step 569/10000- lr: [9.524244327272727e-06] - Loss total: 39.56129837036133, Last rpr Loss: 1.6927543878555298, Last lagvar Loss: 6.53304386138916\n",
      "Step 570/10000- lr: [9.52323423030303e-06] - Loss total: 37.858802795410156, Last rpr Loss: 1.6235442161560059, Last lagvar Loss: 6.601690292358398\n",
      "Step 571/10000- lr: [9.522224133333334e-06] - Loss total: 36.258846282958984, Last rpr Loss: 1.5597467422485352, Last lagvar Loss: 6.667954444885254\n",
      "Step 572/10000- lr: [9.521214036363637e-06] - Loss total: 34.75471496582031, Last rpr Loss: 1.5010795593261719, Last lagvar Loss: 6.7318010330200195\n",
      "Step 573/10000- lr: [9.52020393939394e-06] - Loss total: 33.34011459350586, Last rpr Loss: 1.4472730159759521, Last lagvar Loss: 6.7931904792785645\n",
      "Step 574/10000- lr: [9.519193842424244e-06] - Loss total: 32.00925064086914, Last rpr Loss: 1.398059368133545, Last lagvar Loss: 6.852075576782227\n",
      "Step 575/10000- lr: [9.518183745454547e-06] - Loss total: 30.75678825378418, Last rpr Loss: 1.3531668186187744, Last lagvar Loss: 6.9084062576293945\n",
      "Step 576/10000- lr: [9.517173648484849e-06] - Loss total: 29.57777976989746, Last rpr Loss: 1.3123327493667603, Last lagvar Loss: 6.962130546569824\n",
      "Step 577/10000- lr: [9.516163551515152e-06] - Loss total: 28.46761131286621, Last rpr Loss: 1.2753077745437622, Last lagvar Loss: 7.013195991516113\n",
      "Step 578/10000- lr: [9.515153454545455e-06] - Loss total: 27.421937942504883, Last rpr Loss: 1.241868019104004, Last lagvar Loss: 7.061554908752441\n",
      "Step 579/10000- lr: [9.514143357575759e-06] - Loss total: 26.43669891357422, Last rpr Loss: 1.2118091583251953, Last lagvar Loss: 7.1071648597717285\n",
      "Step 580/10000- lr: [9.513133260606062e-06] - Loss total: 25.508087158203125, Last rpr Loss: 1.1849493980407715, Last lagvar Loss: 7.149993896484375\n",
      "Step 581/10000- lr: [9.512123163636365e-06] - Loss total: 24.632558822631836, Last rpr Loss: 1.1611143350601196, Last lagvar Loss: 7.19002628326416\n",
      "Step 582/10000- lr: [9.511113066666667e-06] - Loss total: 23.806791305541992, Last rpr Loss: 1.1401325464248657, Last lagvar Loss: 7.2272629737854\n",
      "Step 583/10000- lr: [9.51010296969697e-06] - Loss total: 23.027708053588867, Last rpr Loss: 1.1218258142471313, Last lagvar Loss: 7.261728286743164\n",
      "Step 584/10000- lr: [9.509092872727273e-06] - Loss total: 22.29244613647461, Last rpr Loss: 1.106003999710083, Last lagvar Loss: 7.293467998504639\n",
      "Step 585/10000- lr: [9.508082775757576e-06] - Loss total: 21.598312377929688, Last rpr Loss: 1.0924720764160156, Last lagvar Loss: 7.322549819946289\n",
      "Step 586/10000- lr: [9.50707267878788e-06] - Loss total: 20.942825317382812, Last rpr Loss: 1.0810332298278809, Last lagvar Loss: 7.349061965942383\n",
      "Step 587/10000- lr: [9.506062581818183e-06] - Loss total: 20.32363510131836, Last rpr Loss: 1.071491003036499, Last lagvar Loss: 7.373106002807617\n",
      "Step 588/10000- lr: [9.505052484848486e-06] - Loss total: 19.738550186157227, Last rpr Loss: 1.063655972480774, Last lagvar Loss: 7.394800186157227\n",
      "Step 589/10000- lr: [9.504042387878788e-06] - Loss total: 19.185510635375977, Last rpr Loss: 1.0573508739471436, Last lagvar Loss: 7.414266586303711\n",
      "Step 590/10000- lr: [9.503032290909091e-06] - Loss total: 18.662593841552734, Last rpr Loss: 1.0523979663848877, Last lagvar Loss: 7.431636810302734\n",
      "Step 591/10000- lr: [9.502022193939394e-06] - Loss total: 18.168001174926758, Last rpr Loss: 1.0486218929290771, Last lagvar Loss: 7.447051048278809\n",
      "Step 592/10000- lr: [9.501012096969698e-06] - Loss total: 17.700056076049805, Last rpr Loss: 1.045846700668335, Last lagvar Loss: 7.4606523513793945\n",
      "Step 593/10000- lr: [9.500002000000001e-06] - Loss total: 17.25718116760254, Last rpr Loss: 1.043884038925171, Last lagvar Loss: 7.472594261169434\n",
      "Step 594/10000- lr: [9.498991903030304e-06] - Loss total: 16.837900161743164, Last rpr Loss: 1.0425465106964111, Last lagvar Loss: 7.483035564422607\n",
      "Step 595/10000- lr: [9.497981806060608e-06] - Loss total: 16.440828323364258, Last rpr Loss: 1.0416375398635864, Last lagvar Loss: 7.4921417236328125\n",
      "Step 596/10000- lr: [9.496971709090909e-06] - Loss total: 16.06466293334961, Last rpr Loss: 1.0409709215164185, Last lagvar Loss: 7.500077724456787\n",
      "Step 597/10000- lr: [9.495961612121212e-06] - Loss total: 15.708179473876953, Last rpr Loss: 1.0403612852096558, Last lagvar Loss: 7.50700569152832\n",
      "Step 598/10000- lr: [9.494951515151516e-06] - Loss total: 15.37022876739502, Last rpr Loss: 1.039644718170166, Last lagvar Loss: 7.5130791664123535\n",
      "Step 599/10000- lr: [9.493941418181819e-06] - Loss total: 15.049732208251953, Last rpr Loss: 1.0386772155761719, Last lagvar Loss: 7.518431663513184\n",
      "Step 600/10000- lr: [9.492931321212122e-06] - Loss total: 14.74567985534668, Last rpr Loss: 1.0373486280441284, Last lagvar Loss: 7.5231757164001465\n",
      "Step 601/10000- lr: [9.491921224242426e-06] - Loss total: 14.457122802734375, Last rpr Loss: 1.0355806350708008, Last lagvar Loss: 7.5273942947387695\n",
      "Step 602/10000- lr: [9.490911127272729e-06] - Loss total: 14.183170318603516, Last rpr Loss: 1.0333319902420044, Last lagvar Loss: 7.531136512756348\n",
      "Step 603/10000- lr: [9.48990103030303e-06] - Loss total: 13.922981262207031, Last rpr Loss: 1.0306060314178467, Last lagvar Loss: 7.534416198730469\n",
      "Step 604/10000- lr: [9.488890933333334e-06] - Loss total: 13.675776481628418, Last rpr Loss: 1.027446985244751, Last lagvar Loss: 7.537213325500488\n",
      "Step 605/10000- lr: [9.487880836363637e-06] - Loss total: 13.44080638885498, Last rpr Loss: 1.023938536643982, Last lagvar Loss: 7.539470672607422\n",
      "Step 606/10000- lr: [9.48687073939394e-06] - Loss total: 13.217387199401855, Last rpr Loss: 1.0202019214630127, Last lagvar Loss: 7.541104316711426\n",
      "Step 607/10000- lr: [9.485860642424243e-06] - Loss total: 13.00485897064209, Last rpr Loss: 1.0163798332214355, Last lagvar Loss: 7.5420050621032715\n",
      "Step 608/10000- lr: [9.484850545454547e-06] - Loss total: 12.8026123046875, Last rpr Loss: 1.0126326084136963, Last lagvar Loss: 7.542049407958984\n",
      "Step 609/10000- lr: [9.483840448484848e-06] - Loss total: 12.61007022857666, Last rpr Loss: 1.0091198682785034, Last lagvar Loss: 7.541110515594482\n",
      "Step 610/10000- lr: [9.482830351515152e-06] - Loss total: 12.426690101623535, Last rpr Loss: 1.0059847831726074, Last lagvar Loss: 7.539068222045898\n",
      "Step 611/10000- lr: [9.481820254545455e-06] - Loss total: 12.251961708068848, Last rpr Loss: 1.0033496618270874, Last lagvar Loss: 7.53582239151001\n",
      "Step 612/10000- lr: [9.480810157575758e-06] - Loss total: 12.085404396057129, Last rpr Loss: 1.0012961626052856, Last lagvar Loss: 7.531303882598877\n",
      "Step 613/10000- lr: [9.479800060606061e-06] - Loss total: 11.926569938659668, Last rpr Loss: 0.9998633861541748, Last lagvar Loss: 7.525485038757324\n",
      "Step 614/10000- lr: [9.478789963636365e-06] - Loss total: 11.775030136108398, Last rpr Loss: 0.9990432262420654, Last lagvar Loss: 7.518383979797363\n",
      "Step 615/10000- lr: [9.477779866666668e-06] - Loss total: 11.630383491516113, Last rpr Loss: 0.9987787008285522, Last lagvar Loss: 7.510067462921143\n",
      "Step 616/10000- lr: [9.476769769696971e-06] - Loss total: 11.492253303527832, Last rpr Loss: 0.9989701509475708, Last lagvar Loss: 7.500649929046631\n",
      "Step 617/10000- lr: [9.475759672727273e-06] - Loss total: 11.360283851623535, Last rpr Loss: 0.9994862675666809, Last lagvar Loss: 7.4902801513671875\n",
      "Step 618/10000- lr: [9.474749575757576e-06] - Loss total: 11.234138488769531, Last rpr Loss: 1.0001661777496338, Last lagvar Loss: 7.479133605957031\n",
      "Step 619/10000- lr: [9.47373947878788e-06] - Loss total: 11.113499641418457, Last rpr Loss: 1.0008506774902344, Last lagvar Loss: 7.467390060424805\n",
      "Step 620/10000- lr: [9.472729381818183e-06] - Loss total: 10.998066902160645, Last rpr Loss: 1.0013864040374756, Last lagvar Loss: 7.455216884613037\n",
      "Step 621/10000- lr: [9.471719284848486e-06] - Loss total: 10.887555122375488, Last rpr Loss: 1.001650333404541, Last lagvar Loss: 7.442752361297607\n",
      "Step 622/10000- lr: [9.47070918787879e-06] - Loss total: 10.781698226928711, Last rpr Loss: 1.0015637874603271, Last lagvar Loss: 7.430084228515625\n",
      "Step 623/10000- lr: [9.46969909090909e-06] - Loss total: 10.680241584777832, Last rpr Loss: 1.001105546951294, Last lagvar Loss: 7.417243957519531\n",
      "Step 624/10000- lr: [9.468688993939394e-06] - Loss total: 10.582944869995117, Last rpr Loss: 1.0003094673156738, Last lagvar Loss: 7.404203414916992\n",
      "Step 625/10000- lr: [9.467678896969697e-06] - Loss total: 10.489581108093262, Last rpr Loss: 0.999261736869812, Last lagvar Loss: 7.390881538391113\n",
      "Step 626/10000- lr: [9.4666688e-06] - Loss total: 10.399934768676758, Last rpr Loss: 0.9980875849723816, Last lagvar Loss: 7.377157211303711\n",
      "Step 627/10000- lr: [9.465658703030304e-06] - Loss total: 10.313802719116211, Last rpr Loss: 0.996924638748169, Last lagvar Loss: 7.362894535064697\n",
      "Step 628/10000- lr: [9.464648606060607e-06] - Loss total: 10.23099136352539, Last rpr Loss: 0.9959053993225098, Last lagvar Loss: 7.347963333129883\n",
      "Step 629/10000- lr: [9.46363850909091e-06] - Loss total: 10.151320457458496, Last rpr Loss: 0.9951275587081909, Last lagvar Loss: 7.332269668579102\n",
      "Step 630/10000- lr: [9.462628412121212e-06] - Loss total: 10.074616432189941, Last rpr Loss: 0.9946385622024536, Last lagvar Loss: 7.315765380859375\n",
      "Step 631/10000- lr: [9.461618315151515e-06] - Loss total: 10.000720024108887, Last rpr Loss: 0.9944268465042114, Last lagvar Loss: 7.298466682434082\n",
      "Step 632/10000- lr: [9.460608218181819e-06] - Loss total: 9.929476737976074, Last rpr Loss: 0.994422435760498, Last lagvar Loss: 7.280445098876953\n",
      "Step 633/10000- lr: [9.459598121212122e-06] - Loss total: 9.860743522644043, Last rpr Loss: 0.9945068359375, Last lagvar Loss: 7.261818885803223\n",
      "Step 634/10000- lr: [9.458588024242425e-06] - Loss total: 9.794382095336914, Last rpr Loss: 0.9945391416549683, Last lagvar Loss: 7.242722511291504\n",
      "Step 635/10000- lr: [9.457577927272728e-06] - Loss total: 9.730260848999023, Last rpr Loss: 0.9943806529045105, Last lagvar Loss: 7.22328519821167\n",
      "Step 636/10000- lr: [9.456567830303032e-06] - Loss total: 9.668254852294922, Last rpr Loss: 0.9939238429069519, Last lagvar Loss: 7.2035980224609375\n",
      "Step 637/10000- lr: [9.455557733333333e-06] - Loss total: 9.608240127563477, Last rpr Loss: 0.9931135773658752, Last lagvar Loss: 7.183691501617432\n",
      "Step 638/10000- lr: [9.454547636363637e-06] - Loss total: 9.550101280212402, Last rpr Loss: 0.9919608235359192, Last lagvar Loss: 7.1635284423828125\n",
      "Step 639/10000- lr: [9.45353753939394e-06] - Loss total: 9.493720054626465, Last rpr Loss: 0.99053555727005, Last lagvar Loss: 7.143006324768066\n",
      "Step 640/10000- lr: [9.452527442424243e-06] - Loss total: 9.438986778259277, Last rpr Loss: 0.9889483451843262, Last lagvar Loss: 7.121969699859619\n",
      "Step 641/10000- lr: [9.451517345454546e-06] - Loss total: 9.385787963867188, Last rpr Loss: 0.9873279929161072, Last lagvar Loss: 7.100237846374512\n",
      "Step 642/10000- lr: [9.45050724848485e-06] - Loss total: 9.334013938903809, Last rpr Loss: 0.9857923984527588, Last lagvar Loss: 7.077627182006836\n",
      "Step 643/10000- lr: [9.449497151515153e-06] - Loss total: 9.283555030822754, Last rpr Loss: 0.9844326972961426, Last lagvar Loss: 7.053979873657227\n",
      "Step 644/10000- lr: [9.448487054545455e-06] - Loss total: 9.23430347442627, Last rpr Loss: 0.9832900762557983, Last lagvar Loss: 7.029181480407715\n",
      "Step 645/10000- lr: [9.447476957575758e-06] - Loss total: 9.186148643493652, Last rpr Loss: 0.982359766960144, Last lagvar Loss: 7.003166198730469\n",
      "Step 646/10000- lr: [9.446466860606061e-06] - Loss total: 9.138989448547363, Last rpr Loss: 0.9816022515296936, Last lagvar Loss: 6.975912094116211\n",
      "Step 647/10000- lr: [9.445456763636364e-06] - Loss total: 9.0927152633667, Last rpr Loss: 0.9809695482254028, Last lagvar Loss: 6.947420120239258\n",
      "Step 648/10000- lr: [9.444446666666668e-06] - Loss total: 9.047223091125488, Last rpr Loss: 0.9804354906082153, Last lagvar Loss: 6.917690753936768\n",
      "Step 649/10000- lr: [9.443436569696971e-06] - Loss total: 9.002416610717773, Last rpr Loss: 0.980022132396698, Last lagvar Loss: 6.886704921722412\n",
      "Step 650/10000- lr: [9.442426472727274e-06] - Loss total: 8.958205223083496, Last rpr Loss: 0.9798197150230408, Last lagvar Loss: 6.8544230461120605\n",
      "Step 651/10000- lr: [9.441416375757576e-06] - Loss total: 8.914515495300293, Last rpr Loss: 0.9799625277519226, Last lagvar Loss: 6.820817470550537\n",
      "Step 652/10000- lr: [9.440406278787879e-06] - Loss total: 8.871293067932129, Last rpr Loss: 0.980563759803772, Last lagvar Loss: 6.78593111038208\n",
      "Step 653/10000- lr: [9.439396181818182e-06] - Loss total: 8.828508377075195, Last rpr Loss: 0.9816122651100159, Last lagvar Loss: 6.749931335449219\n",
      "Step 654/10000- lr: [9.438386084848486e-06] - Loss total: 8.786274909973145, Last rpr Loss: 0.9829410910606384, Last lagvar Loss: 6.713222980499268\n",
      "Step 655/10000- lr: [9.437375987878789e-06] - Loss total: 8.744683265686035, Last rpr Loss: 0.9842167496681213, Last lagvar Loss: 6.676253795623779\n",
      "Step 656/10000- lr: [9.436365890909092e-06] - Loss total: 8.703784942626953, Last rpr Loss: 0.9850805997848511, Last lagvar Loss: 6.639364719390869\n",
      "Step 657/10000- lr: [9.435355793939395e-06] - Loss total: 8.66359806060791, Last rpr Loss: 0.9853470325469971, Last lagvar Loss: 6.602644920349121\n",
      "Step 658/10000- lr: [9.434345696969697e-06] - Loss total: 8.624106407165527, Last rpr Loss: 0.9850936532020569, Last lagvar Loss: 6.565893650054932\n",
      "Step 659/10000- lr: [9.4333356e-06] - Loss total: 8.585282325744629, Last rpr Loss: 0.9846215844154358, Last lagvar Loss: 6.528693199157715\n",
      "Step 660/10000- lr: [9.432325503030304e-06] - Loss total: 8.547082901000977, Last rpr Loss: 0.9842798113822937, Last lagvar Loss: 6.490599632263184\n",
      "Step 661/10000- lr: [9.431315406060607e-06] - Loss total: 8.509468078613281, Last rpr Loss: 0.9843018651008606, Last lagvar Loss: 6.451347351074219\n",
      "Step 662/10000- lr: [9.43030530909091e-06] - Loss total: 8.472407341003418, Last rpr Loss: 0.984714150428772, Last lagvar Loss: 6.410978317260742\n",
      "Step 663/10000- lr: [9.429295212121213e-06] - Loss total: 8.435879707336426, Last rpr Loss: 0.9853329658508301, Last lagvar Loss: 6.369838237762451\n",
      "Step 664/10000- lr: [9.428285115151515e-06] - Loss total: 8.399868965148926, Last rpr Loss: 0.9858874678611755, Last lagvar Loss: 6.328412055969238\n",
      "Step 665/10000- lr: [9.427275018181818e-06] - Loss total: 8.364361763000488, Last rpr Loss: 0.9861798286437988, Last lagvar Loss: 6.2870683670043945\n",
      "Step 666/10000- lr: [9.426264921212122e-06] - Loss total: 8.329325675964355, Last rpr Loss: 0.986286997795105, Last lagvar Loss: 6.245848655700684\n",
      "Step 667/10000- lr: [9.425254824242425e-06] - Loss total: 8.294745445251465, Last rpr Loss: 0.9866255521774292, Last lagvar Loss: 6.20451545715332\n",
      "Step 668/10000- lr: [9.424244727272728e-06] - Loss total: 8.26064395904541, Last rpr Loss: 0.9876964092254639, Last lagvar Loss: 6.162968158721924\n",
      "Step 669/10000- lr: [9.423234630303031e-06] - Loss total: 8.227082252502441, Last rpr Loss: 0.9893897771835327, Last lagvar Loss: 6.121796607971191\n",
      "Step 670/10000- lr: [9.422224533333335e-06] - Loss total: 8.194106101989746, Last rpr Loss: 0.9905110597610474, Last lagvar Loss: 6.082319259643555\n",
      "Step 671/10000- lr: [9.421214436363638e-06] - Loss total: 8.161702156066895, Last rpr Loss: 0.9895575642585754, Last lagvar Loss: 6.045798301696777\n",
      "Step 672/10000- lr: [9.42020433939394e-06] - Loss total: 8.129826545715332, Last rpr Loss: 0.9861345291137695, Last lagvar Loss: 6.012359619140625\n",
      "Step 673/10000- lr: [9.419194242424243e-06] - Loss total: 8.09843635559082, Last rpr Loss: 0.9815022945404053, Last lagvar Loss: 5.9805450439453125\n",
      "Step 674/10000- lr: [9.418184145454546e-06] - Loss total: 8.067472457885742, Last rpr Loss: 0.9778544902801514, Last lagvar Loss: 5.94795036315918\n",
      "Step 675/10000- lr: [9.41717404848485e-06] - Loss total: 8.036858558654785, Last rpr Loss: 0.9768580198287964, Last lagvar Loss: 5.912571907043457\n",
      "Step 676/10000- lr: [9.416163951515153e-06] - Loss total: 8.00650691986084, Last rpr Loss: 0.9785845279693604, Last lagvar Loss: 5.873932838439941\n",
      "Step 677/10000- lr: [9.415153854545456e-06] - Loss total: 7.97636079788208, Last rpr Loss: 0.9815961122512817, Last lagvar Loss: 5.833196640014648\n",
      "Step 678/10000- lr: [9.414143757575758e-06] - Loss total: 7.946422100067139, Last rpr Loss: 0.9842311143875122, Last lagvar Loss: 5.792227745056152\n",
      "Step 679/10000- lr: [9.41313366060606e-06] - Loss total: 7.916765213012695, Last rpr Loss: 0.9858192801475525, Last lagvar Loss: 5.752387046813965\n",
      "Step 680/10000- lr: [9.412123563636364e-06] - Loss total: 7.887430191040039, Last rpr Loss: 0.9866030216217041, Last lagvar Loss: 5.713953018188477\n",
      "Step 681/10000- lr: [9.411113466666667e-06] - Loss total: 7.858396053314209, Last rpr Loss: 0.9869402647018433, Last lagvar Loss: 5.6764631271362305\n",
      "Step 682/10000- lr: [9.41010336969697e-06] - Loss total: 7.829611301422119, Last rpr Loss: 0.986782431602478, Last lagvar Loss: 5.639535903930664\n",
      "Step 683/10000- lr: [9.409093272727274e-06] - Loss total: 7.801016330718994, Last rpr Loss: 0.9856634140014648, Last lagvar Loss: 5.603292465209961\n",
      "Step 684/10000- lr: [9.408083175757577e-06] - Loss total: 7.772562026977539, Last rpr Loss: 0.9834369421005249, Last lagvar Loss: 5.567899703979492\n",
      "Step 685/10000- lr: [9.407073078787879e-06] - Loss total: 7.74425745010376, Last rpr Loss: 0.9810018539428711, Last lagvar Loss: 5.53286075592041\n",
      "Step 686/10000- lr: [9.406062981818182e-06] - Loss total: 7.7161383628845215, Last rpr Loss: 0.9796794652938843, Last lagvar Loss: 5.497223854064941\n",
      "Step 687/10000- lr: [9.405052884848485e-06] - Loss total: 7.688234329223633, Last rpr Loss: 0.9801054000854492, Last lagvar Loss: 5.460531234741211\n",
      "Step 688/10000- lr: [9.404042787878789e-06] - Loss total: 7.660562992095947, Last rpr Loss: 0.9817985892295837, Last lagvar Loss: 5.423309326171875\n",
      "Step 689/10000- lr: [9.403032690909092e-06] - Loss total: 7.633123874664307, Last rpr Loss: 0.9837216734886169, Last lagvar Loss: 5.386524200439453\n",
      "Step 690/10000- lr: [9.402022593939395e-06] - Loss total: 7.605863094329834, Last rpr Loss: 0.9853866696357727, Last lagvar Loss: 5.350512504577637\n",
      "Step 691/10000- lr: [9.401012496969698e-06] - Loss total: 7.5785980224609375, Last rpr Loss: 0.9873286485671997, Last lagvar Loss: 5.314520835876465\n",
      "Step 692/10000- lr: [9.4000024e-06] - Loss total: 7.551016807556152, Last rpr Loss: 0.9898886680603027, Last lagvar Loss: 5.277490139007568\n",
      "Step 693/10000- lr: [9.398992303030303e-06] - Loss total: 7.523268699645996, Last rpr Loss: 0.9896721839904785, Last lagvar Loss: 5.239917755126953\n",
      "Step 694/10000- lr: [9.397982206060607e-06] - Loss total: 7.496651649475098, Last rpr Loss: 0.9868026375770569, Last lagvar Loss: 5.204782485961914\n",
      "Step 695/10000- lr: [9.39697210909091e-06] - Loss total: 7.471343994140625, Last rpr Loss: 0.9829288721084595, Last lagvar Loss: 5.176365375518799\n",
      "Step 696/10000- lr: [9.395962012121213e-06] - Loss total: 7.446590900421143, Last rpr Loss: 0.9763723611831665, Last lagvar Loss: 5.152132987976074\n",
      "Step 697/10000- lr: [9.394951915151516e-06] - Loss total: 7.422408103942871, Last rpr Loss: 0.9737095236778259, Last lagvar Loss: 5.124613285064697\n",
      "Step 698/10000- lr: [9.39394181818182e-06] - Loss total: 7.398775100708008, Last rpr Loss: 0.9780806303024292, Last lagvar Loss: 5.090575218200684\n",
      "Step 699/10000- lr: [9.392931721212121e-06] - Loss total: 7.375662326812744, Last rpr Loss: 0.9853839874267578, Last lagvar Loss: 5.054368019104004\n",
      "Step 700/10000- lr: [9.391921624242425e-06] - Loss total: 7.352974891662598, Last rpr Loss: 0.98880934715271, Last lagvar Loss: 5.022800445556641\n",
      "Step 701/10000- lr: [9.390911527272728e-06] - Loss total: 7.330512046813965, Last rpr Loss: 0.9862033128738403, Last lagvar Loss: 4.997711181640625\n",
      "Step 702/10000- lr: [9.389901430303031e-06] - Loss total: 7.308216571807861, Last rpr Loss: 0.9819782972335815, Last lagvar Loss: 4.974566459655762\n",
      "Step 703/10000- lr: [9.388891333333334e-06] - Loss total: 7.2862091064453125, Last rpr Loss: 0.9807393550872803, Last lagvar Loss: 4.948689937591553\n",
      "Step 704/10000- lr: [9.387881236363638e-06] - Loss total: 7.26451301574707, Last rpr Loss: 0.9816274642944336, Last lagvar Loss: 4.920536994934082\n",
      "Step 705/10000- lr: [9.38687113939394e-06] - Loss total: 7.24296236038208, Last rpr Loss: 0.9810329675674438, Last lagvar Loss: 4.893126010894775\n",
      "Step 706/10000- lr: [9.385861042424243e-06] - Loss total: 7.221480369567871, Last rpr Loss: 0.9786721467971802, Last lagvar Loss: 4.866655349731445\n",
      "Step 707/10000- lr: [9.384850945454546e-06] - Loss total: 7.200087070465088, Last rpr Loss: 0.977162778377533, Last lagvar Loss: 4.838875770568848\n",
      "Step 708/10000- lr: [9.383840848484849e-06] - Loss total: 7.178764343261719, Last rpr Loss: 0.9768435955047607, Last lagvar Loss: 4.809580326080322\n",
      "Step 709/10000- lr: [9.382830751515152e-06] - Loss total: 7.157542705535889, Last rpr Loss: 0.9750841856002808, Last lagvar Loss: 4.781253814697266\n",
      "Step 710/10000- lr: [9.381820654545456e-06] - Loss total: 7.136507034301758, Last rpr Loss: 0.9716553688049316, Last lagvar Loss: 4.7541656494140625\n",
      "Step 711/10000- lr: [9.380810557575759e-06] - Loss total: 7.1156439781188965, Last rpr Loss: 0.9707326292991638, Last lagvar Loss: 4.724429130554199\n",
      "Step 712/10000- lr: [9.379800460606062e-06] - Loss total: 7.094868183135986, Last rpr Loss: 0.97520911693573, Last lagvar Loss: 4.689385890960693\n",
      "Step 713/10000- lr: [9.378790363636364e-06] - Loss total: 7.074207782745361, Last rpr Loss: 0.9819058179855347, Last lagvar Loss: 4.652431964874268\n",
      "Step 714/10000- lr: [9.377780266666667e-06] - Loss total: 7.0536699295043945, Last rpr Loss: 0.985560953617096, Last lagvar Loss: 4.6190080642700195\n",
      "Step 715/10000- lr: [9.37677016969697e-06] - Loss total: 7.033262729644775, Last rpr Loss: 0.9863345623016357, Last lagvar Loss: 4.589319229125977\n",
      "Step 716/10000- lr: [9.375760072727274e-06] - Loss total: 7.013033390045166, Last rpr Loss: 0.9874935150146484, Last lagvar Loss: 4.560326099395752\n",
      "Step 717/10000- lr: [9.374749975757577e-06] - Loss total: 6.992941379547119, Last rpr Loss: 0.988574206829071, Last lagvar Loss: 4.5320892333984375\n",
      "Step 718/10000- lr: [9.37373987878788e-06] - Loss total: 6.972904205322266, Last rpr Loss: 0.9877533912658691, Last lagvar Loss: 4.50594425201416\n",
      "Step 719/10000- lr: [9.372729781818182e-06] - Loss total: 6.952906131744385, Last rpr Loss: 0.9862037897109985, Last lagvar Loss: 4.480624198913574\n",
      "Step 720/10000- lr: [9.371719684848485e-06] - Loss total: 6.932876110076904, Last rpr Loss: 0.9840943217277527, Last lagvar Loss: 4.4557695388793945\n",
      "Step 721/10000- lr: [9.370709587878788e-06] - Loss total: 6.9127631187438965, Last rpr Loss: 0.979130744934082, Last lagvar Loss: 4.433302402496338\n",
      "Step 722/10000- lr: [9.369699490909092e-06] - Loss total: 6.892685890197754, Last rpr Loss: 0.973008930683136, Last lagvar Loss: 4.41150426864624\n",
      "Step 723/10000- lr: [9.368689393939395e-06] - Loss total: 6.872802257537842, Last rpr Loss: 0.9709413051605225, Last lagvar Loss: 4.385441780090332\n",
      "Step 724/10000- lr: [9.367679296969698e-06] - Loss total: 6.8531341552734375, Last rpr Loss: 0.9732075929641724, Last lagvar Loss: 4.354961395263672\n",
      "Step 725/10000- lr: [9.366669200000001e-06] - Loss total: 6.83364725112915, Last rpr Loss: 0.9765124917030334, Last lagvar Loss: 4.323583602905273\n",
      "Step 726/10000- lr: [9.365659103030303e-06] - Loss total: 6.814308166503906, Last rpr Loss: 0.9803035259246826, Last lagvar Loss: 4.292235374450684\n",
      "Step 727/10000- lr: [9.364649006060606e-06] - Loss total: 6.795100688934326, Last rpr Loss: 0.983706533908844, Last lagvar Loss: 4.261900901794434\n",
      "Step 728/10000- lr: [9.36363890909091e-06] - Loss total: 6.776014804840088, Last rpr Loss: 0.9843076467514038, Last lagvar Loss: 4.234723091125488\n",
      "Step 729/10000- lr: [9.362628812121213e-06] - Loss total: 6.757012844085693, Last rpr Loss: 0.9838389158248901, Last lagvar Loss: 4.208667278289795\n",
      "Step 730/10000- lr: [9.361618715151516e-06] - Loss total: 6.73807954788208, Last rpr Loss: 0.9839847087860107, Last lagvar Loss: 4.181824207305908\n",
      "Step 731/10000- lr: [9.36060861818182e-06] - Loss total: 6.719249725341797, Last rpr Loss: 0.9819502830505371, Last lagvar Loss: 4.156925201416016\n",
      "Step 732/10000- lr: [9.359598521212123e-06] - Loss total: 6.700534820556641, Last rpr Loss: 0.9783945679664612, Last lagvar Loss: 4.133502960205078\n",
      "Step 733/10000- lr: [9.358588424242424e-06] - Loss total: 6.681913375854492, Last rpr Loss: 0.975928008556366, Last lagvar Loss: 4.109035491943359\n",
      "Step 734/10000- lr: [9.357578327272727e-06] - Loss total: 6.663337707519531, Last rpr Loss: 0.9738869667053223, Last lagvar Loss: 4.0840301513671875\n",
      "Step 735/10000- lr: [9.35656823030303e-06] - Loss total: 6.644752502441406, Last rpr Loss: 0.9741324782371521, Last lagvar Loss: 4.056535720825195\n",
      "Step 736/10000- lr: [9.355558133333334e-06] - Loss total: 6.626132965087891, Last rpr Loss: 0.9776444435119629, Last lagvar Loss: 4.025667190551758\n",
      "Step 737/10000- lr: [9.354548036363637e-06] - Loss total: 6.607462406158447, Last rpr Loss: 0.9807226657867432, Last lagvar Loss: 3.995256185531616\n",
      "Step 738/10000- lr: [9.35353793939394e-06] - Loss total: 6.588744163513184, Last rpr Loss: 0.9831109642982483, Last lagvar Loss: 3.9656267166137695\n",
      "Step 739/10000- lr: [9.352527842424244e-06] - Loss total: 6.570008277893066, Last rpr Loss: 0.9843628406524658, Last lagvar Loss: 3.9370532035827637\n",
      "Step 740/10000- lr: [9.351517745454545e-06] - Loss total: 6.551249027252197, Last rpr Loss: 0.9827737808227539, Last lagvar Loss: 3.9109368324279785\n",
      "Step 741/10000- lr: [9.350507648484849e-06] - Loss total: 6.5324387550354, Last rpr Loss: 0.9815500378608704, Last lagvar Loss: 3.884031057357788\n",
      "Step 742/10000- lr: [9.349497551515152e-06] - Loss total: 6.513622283935547, Last rpr Loss: 0.9797621965408325, Last lagvar Loss: 3.85764217376709\n",
      "Step 743/10000- lr: [9.348487454545455e-06] - Loss total: 6.494853973388672, Last rpr Loss: 0.9785376191139221, Last lagvar Loss: 3.8310351371765137\n",
      "Step 744/10000- lr: [9.347477357575759e-06] - Loss total: 6.47616720199585, Last rpr Loss: 0.9789242148399353, Last lagvar Loss: 3.803211212158203\n",
      "Step 745/10000- lr: [9.346467260606062e-06] - Loss total: 6.457586288452148, Last rpr Loss: 0.9791967272758484, Last lagvar Loss: 3.7758631706237793\n",
      "Step 746/10000- lr: [9.345457163636363e-06] - Loss total: 6.439134120941162, Last rpr Loss: 0.9827683568000793, Last lagvar Loss: 3.7456064224243164\n",
      "Step 747/10000- lr: [9.344447066666667e-06] - Loss total: 6.420816421508789, Last rpr Loss: 0.984035849571228, Last lagvar Loss: 3.7179322242736816\n",
      "Step 748/10000- lr: [9.34343696969697e-06] - Loss total: 6.402637004852295, Last rpr Loss: 0.991197943687439, Last lagvar Loss: 3.684724807739258\n",
      "Step 749/10000- lr: [9.342426872727273e-06] - Loss total: 6.38460636138916, Last rpr Loss: 0.9863135814666748, Last lagvar Loss: 3.663639545440674\n",
      "Step 750/10000- lr: [9.341416775757577e-06] - Loss total: 6.366772174835205, Last rpr Loss: 1.0034106969833374, Last lagvar Loss: 3.6210544109344482\n",
      "Step 751/10000- lr: [9.34040667878788e-06] - Loss total: 6.349436283111572, Last rpr Loss: 0.9639676809310913, Last lagvar Loss: 3.635438919067383\n",
      "Step 752/10000- lr: [9.339396581818183e-06] - Loss total: 6.333561897277832, Last rpr Loss: 1.0480515956878662, Last lagvar Loss: 3.5297389030456543\n",
      "Step 753/10000- lr: [9.338386484848486e-06] - Loss total: 6.3206257820129395, Last rpr Loss: 0.8920340538024902, Last lagvar Loss: 3.6692912578582764\n",
      "Step 754/10000- lr: [9.337376387878788e-06] - Loss total: 6.298360824584961, Last rpr Loss: 1.0353389978408813, Last lagvar Loss: 3.491281032562256\n",
      "Step 755/10000- lr: [9.336366290909091e-06] - Loss total: 6.280541896820068, Last rpr Loss: 1.0091373920440674, Last lagvar Loss: 3.4917612075805664\n",
      "Step 756/10000- lr: [9.335356193939395e-06] - Loss total: 6.266902446746826, Last rpr Loss: 0.9058837294578552, Last lagvar Loss: 3.5770797729492188\n",
      "Step 757/10000- lr: [9.334346096969698e-06] - Loss total: 6.248330116271973, Last rpr Loss: 1.0431121587753296, Last lagvar Loss: 3.4135971069335938\n",
      "Step 758/10000- lr: [9.333336000000001e-06] - Loss total: 6.229799747467041, Last rpr Loss: 0.9826443195343018, Last lagvar Loss: 3.446614980697632\n",
      "Step 759/10000- lr: [9.332325903030304e-06] - Loss total: 6.213974952697754, Last rpr Loss: 0.9505181312561035, Last lagvar Loss: 3.456404209136963\n",
      "Step 760/10000- lr: [9.331315806060606e-06] - Loss total: 6.197993755340576, Last rpr Loss: 1.042842149734497, Last lagvar Loss: 3.343599796295166\n",
      "Step 761/10000- lr: [9.33030570909091e-06] - Loss total: 6.1808624267578125, Last rpr Loss: 0.9401500225067139, Last lagvar Loss: 3.420644760131836\n",
      "Step 762/10000- lr: [9.329295612121212e-06] - Loss total: 6.1631574630737305, Last rpr Loss: 0.9892122745513916, Last lagvar Loss: 3.3468692302703857\n",
      "Step 763/10000- lr: [9.328285515151516e-06] - Loss total: 6.147327899932861, Last rpr Loss: 1.0169999599456787, Last lagvar Loss: 3.2973172664642334\n",
      "Step 764/10000- lr: [9.327275418181819e-06] - Loss total: 6.132328510284424, Last rpr Loss: 0.9291092157363892, Last lagvar Loss: 3.363849639892578\n",
      "Step 765/10000- lr: [9.326265321212122e-06] - Loss total: 6.115381240844727, Last rpr Loss: 1.0368468761444092, Last lagvar Loss: 3.2337794303894043\n",
      "Step 766/10000- lr: [9.325255224242426e-06] - Loss total: 6.098233699798584, Last rpr Loss: 0.9630375504493713, Last lagvar Loss: 3.2825987339019775\n",
      "Step 767/10000- lr: [9.324245127272727e-06] - Loss total: 6.081640243530273, Last rpr Loss: 0.9880273938179016, Last lagvar Loss: 3.2351794242858887\n",
      "Step 768/10000- lr: [9.32323503030303e-06] - Loss total: 6.066120624542236, Last rpr Loss: 1.0281068086624146, Last lagvar Loss: 3.175201654434204\n",
      "Step 769/10000- lr: [9.322224933333334e-06] - Loss total: 6.050911903381348, Last rpr Loss: 0.9482510089874268, Last lagvar Loss: 3.2336130142211914\n",
      "Step 770/10000- lr: [9.321214836363637e-06] - Loss total: 6.034521102905273, Last rpr Loss: 1.0452934503555298, Last lagvar Loss: 3.1159300804138184\n",
      "Step 771/10000- lr: [9.32020473939394e-06] - Loss total: 6.017868995666504, Last rpr Loss: 0.9581964015960693, Last lagvar Loss: 3.178847312927246\n",
      "Step 772/10000- lr: [9.319194642424244e-06] - Loss total: 6.0009636878967285, Last rpr Loss: 1.0042765140533447, Last lagvar Loss: 3.1094369888305664\n",
      "Step 773/10000- lr: [9.318184545454547e-06] - Loss total: 5.984565258026123, Last rpr Loss: 0.9930123090744019, Last lagvar Loss: 3.097841739654541\n",
      "Step 774/10000- lr: [9.317174448484848e-06] - Loss total: 5.968728065490723, Last rpr Loss: 0.9632774591445923, Last lagvar Loss: 3.1063101291656494\n",
      "Step 775/10000- lr: [9.316164351515152e-06] - Loss total: 5.953135013580322, Last rpr Loss: 1.0309230089187622, Last lagvar Loss: 3.0184926986694336\n",
      "Step 776/10000- lr: [9.315154254545455e-06] - Loss total: 5.938111305236816, Last rpr Loss: 0.9395197629928589, Last lagvar Loss: 3.0898146629333496\n",
      "Step 777/10000- lr: [9.314144157575758e-06] - Loss total: 5.922661781311035, Last rpr Loss: 1.062007188796997, Last lagvar Loss: 2.947695732116699\n",
      "Step 778/10000- lr: [9.313134060606062e-06] - Loss total: 5.908545017242432, Last rpr Loss: 0.9197854399681091, Last lagvar Loss: 3.070802927017212\n",
      "Step 779/10000- lr: [9.312123963636365e-06] - Loss total: 5.89121150970459, Last rpr Loss: 1.0618762969970703, Last lagvar Loss: 2.9054789543151855\n",
      "Step 780/10000- lr: [9.311113866666668e-06] - Loss total: 5.8750715255737305, Last rpr Loss: 0.9451198577880859, Last lagvar Loss: 2.9995648860931396\n",
      "Step 781/10000- lr: [9.31010376969697e-06] - Loss total: 5.858643054962158, Last rpr Loss: 1.026619553565979, Last lagvar Loss: 2.8956172466278076\n",
      "Step 782/10000- lr: [9.309093672727273e-06] - Loss total: 5.842850685119629, Last rpr Loss: 0.9757272005081177, Last lagvar Loss: 2.925060272216797\n",
      "Step 783/10000- lr: [9.308083575757576e-06] - Loss total: 5.827466011047363, Last rpr Loss: 0.9940102100372314, Last lagvar Loss: 2.886249303817749\n",
      "Step 784/10000- lr: [9.30707347878788e-06] - Loss total: 5.812409400939941, Last rpr Loss: 1.0026490688323975, Last lagvar Loss: 2.8578286170959473\n",
      "Step 785/10000- lr: [9.306063381818183e-06] - Loss total: 5.797698020935059, Last rpr Loss: 0.9703906178474426, Last lagvar Loss: 2.8708746433258057\n",
      "Step 786/10000- lr: [9.305053284848486e-06] - Loss total: 5.783594608306885, Last rpr Loss: 1.04037606716156, Last lagvar Loss: 2.7836289405822754\n",
      "Step 787/10000- lr: [9.30404318787879e-06] - Loss total: 5.771986961364746, Last rpr Loss: 0.9185299873352051, Last lagvar Loss: 2.8901495933532715\n",
      "Step 788/10000- lr: [9.303033090909091e-06] - Loss total: 5.758089065551758, Last rpr Loss: 1.0907951593399048, Last lagvar Loss: 2.7041008472442627\n",
      "Step 789/10000- lr: [9.302022993939394e-06] - Loss total: 5.7410359382629395, Last rpr Loss: 0.9516909122467041, Last lagvar Loss: 2.815291166305542\n",
      "Step 790/10000- lr: [9.301012896969697e-06] - Loss total: 5.726120948791504, Last rpr Loss: 1.0248901844024658, Last lagvar Loss: 2.723118305206299\n",
      "Step 791/10000- lr: [9.3000028e-06] - Loss total: 5.712096214294434, Last rpr Loss: 0.9731125235557556, Last lagvar Loss: 2.755725383758545\n",
      "Step 792/10000- lr: [9.298992703030304e-06] - Loss total: 5.698362827301025, Last rpr Loss: 1.0158494710922241, Last lagvar Loss: 2.6952872276306152\n",
      "Step 793/10000- lr: [9.297982606060607e-06] - Loss total: 5.68517541885376, Last rpr Loss: 0.9578750133514404, Last lagvar Loss: 2.735607624053955\n",
      "Step 794/10000- lr: [9.29697250909091e-06] - Loss total: 5.673605918884277, Last rpr Loss: 1.069195032119751, Last lagvar Loss: 2.6113643646240234\n",
      "Step 795/10000- lr: [9.295962412121212e-06] - Loss total: 5.664750099182129, Last rpr Loss: 0.8972247242927551, Last lagvar Loss: 2.7723517417907715\n",
      "Step 796/10000- lr: [9.294952315151515e-06] - Loss total: 5.6443047523498535, Last rpr Loss: 0.9978142976760864, Last lagvar Loss: 2.6430959701538086\n",
      "Step 797/10000- lr: [9.293942218181819e-06] - Loss total: 5.63886022567749, Last rpr Loss: 1.108116626739502, Last lagvar Loss: 2.5309970378875732\n",
      "Step 798/10000- lr: [9.292932121212122e-06] - Loss total: 5.623362064361572, Last rpr Loss: 0.9233449697494507, Last lagvar Loss: 2.6934146881103516\n",
      "Step 799/10000- lr: [9.291922024242425e-06] - Loss total: 5.607767105102539, Last rpr Loss: 1.0247770547866821, Last lagvar Loss: 2.572061777114868\n",
      "Step 800/10000- lr: [9.290911927272729e-06] - Loss total: 5.595418453216553, Last rpr Loss: 1.0130101442337036, Last lagvar Loss: 2.568742275238037\n",
      "Step 801/10000- lr: [9.289901830303032e-06] - Loss total: 5.585052490234375, Last rpr Loss: 0.9457049369812012, Last lagvar Loss: 2.624236583709717\n",
      "Step 802/10000- lr: [9.288891733333333e-06] - Loss total: 5.578830242156982, Last rpr Loss: 1.1105175018310547, Last lagvar Loss: 2.456307888031006\n",
      "Step 803/10000- lr: [9.287881636363637e-06] - Loss total: 5.559840202331543, Last rpr Loss: 0.9759758710861206, Last lagvar Loss: 2.5638208389282227\n",
      "Step 804/10000- lr: [9.28687153939394e-06] - Loss total: 5.54911994934082, Last rpr Loss: 0.9536769390106201, Last lagvar Loss: 2.574071168899536\n",
      "Step 805/10000- lr: [9.285861442424243e-06] - Loss total: 5.5461835861206055, Last rpr Loss: 1.1188223361968994, Last lagvar Loss: 2.410940647125244\n",
      "Step 806/10000- lr: [9.284851345454547e-06] - Loss total: 5.52532958984375, Last rpr Loss: 0.9823077917098999, Last lagvar Loss: 2.5176825523376465\n",
      "Step 807/10000- lr: [9.28384124848485e-06] - Loss total: 5.51890230178833, Last rpr Loss: 0.9131840467453003, Last lagvar Loss: 2.5820469856262207\n",
      "Step 808/10000- lr: [9.282831151515153e-06] - Loss total: 5.511207580566406, Last rpr Loss: 1.1004586219787598, Last lagvar Loss: 2.3870086669921875\n",
      "Step 809/10000- lr: [9.281821054545455e-06] - Loss total: 5.493086338043213, Last rpr Loss: 0.9971266984939575, Last lagvar Loss: 2.466125249862671\n",
      "Step 810/10000- lr: [9.280810957575758e-06] - Loss total: 5.4904961585998535, Last rpr Loss: 0.8909140825271606, Last lagvar Loss: 2.5734498500823975\n",
      "Step 811/10000- lr: [9.279800860606061e-06] - Loss total: 5.473443508148193, Last rpr Loss: 1.0272846221923828, Last lagvar Loss: 2.413800001144409\n",
      "Step 812/10000- lr: [9.278790763636364e-06] - Loss total: 5.462088108062744, Last rpr Loss: 0.9904789924621582, Last lagvar Loss: 2.4375662803649902\n",
      "Step 813/10000- lr: [9.277780666666668e-06] - Loss total: 5.452070713043213, Last rpr Loss: 0.969205915927887, Last lagvar Loss: 2.4478578567504883\n",
      "Step 814/10000- lr: [9.276770569696971e-06] - Loss total: 5.444467544555664, Last rpr Loss: 1.0625877380371094, Last lagvar Loss: 2.347513198852539\n",
      "Step 815/10000- lr: [9.275760472727273e-06] - Loss total: 5.437528133392334, Last rpr Loss: 0.9108012318611145, Last lagvar Loss: 2.492659330368042\n",
      "Step 816/10000- lr: [9.274750375757576e-06] - Loss total: 5.420937538146973, Last rpr Loss: 1.003561019897461, Last lagvar Loss: 2.378999710083008\n",
      "Step 817/10000- lr: [9.27374027878788e-06] - Loss total: 5.4171671867370605, Last rpr Loss: 1.092908501625061, Last lagvar Loss: 2.2898545265197754\n",
      "Step 818/10000- lr: [9.272730181818182e-06] - Loss total: 5.406025409698486, Last rpr Loss: 0.9228388667106628, Last lagvar Loss: 2.4454424381256104\n",
      "Step 819/10000- lr: [9.271720084848486e-06] - Loss total: 5.3920440673828125, Last rpr Loss: 1.011976718902588, Last lagvar Loss: 2.3392810821533203\n",
      "Step 820/10000- lr: [9.270709987878789e-06] - Loss total: 5.383512496948242, Last rpr Loss: 1.0382611751556396, Last lagvar Loss: 2.304468870162964\n",
      "Step 821/10000- lr: [9.269699890909092e-06] - Loss total: 5.382993698120117, Last rpr Loss: 0.8946788311004639, Last lagvar Loss: 2.451226234436035\n",
      "Step 822/10000- lr: [9.268689793939396e-06] - Loss total: 5.363877296447754, Last rpr Loss: 0.9783179759979248, Last lagvar Loss: 2.34271502494812\n",
      "Step 823/10000- lr: [9.267679696969697e-06] - Loss total: 5.379831790924072, Last rpr Loss: 1.2040736675262451, Last lagvar Loss: 2.15204119682312\n",
      "Step 824/10000- lr: [9.2666696e-06] - Loss total: 5.352347373962402, Last rpr Loss: 1.0971276760101318, Last lagvar Loss: 2.2151875495910645\n",
      "Step 825/10000- lr: [9.265659503030304e-06] - Loss total: 5.3692097663879395, Last rpr Loss: 0.8294649124145508, Last lagvar Loss: 2.5114643573760986\n",
      "Step 826/10000- lr: [9.264649406060607e-06] - Loss total: 5.372557163238525, Last rpr Loss: 0.8045952320098877, Last lagvar Loss: 2.5445175170898438\n",
      "Step 827/10000- lr: [9.26363930909091e-06] - Loss total: 5.325685501098633, Last rpr Loss: 0.9424660801887512, Last lagvar Loss: 2.340399742126465\n",
      "Step 828/10000- lr: [9.262629212121214e-06] - Loss total: 5.459237098693848, Last rpr Loss: 1.595554232597351, Last lagvar Loss: 1.9437274932861328\n",
      "Step 829/10000- lr: [9.261619115151515e-06] - Loss total: 5.653634548187256, Last rpr Loss: 2.1543445587158203, Last lagvar Loss: 1.804577350616455\n",
      "Step 830/10000- lr: [9.260609018181818e-06] - Loss total: 5.464282989501953, Last rpr Loss: 1.6363310813903809, Last lagvar Loss: 1.8985333442687988\n",
      "Step 831/10000- lr: [9.259598921212122e-06] - Loss total: 5.303867340087891, Last rpr Loss: 1.0632976293563843, Last lagvar Loss: 2.1978342533111572\n",
      "Step 832/10000- lr: [9.258588824242425e-06] - Loss total: 5.396404266357422, Last rpr Loss: 0.7067686319351196, Last lagvar Loss: 2.6958627700805664\n",
      "Step 833/10000- lr: [9.257578727272728e-06] - Loss total: 5.491532802581787, Last rpr Loss: 0.6162824034690857, Last lagvar Loss: 2.9231653213500977\n",
      "Step 834/10000- lr: [9.256568630303031e-06] - Loss total: 5.465291976928711, Last rpr Loss: 0.6340795755386353, Last lagvar Loss: 2.8727564811706543\n",
      "Step 835/10000- lr: [9.255558533333335e-06] - Loss total: 5.349576950073242, Last rpr Loss: 0.760334312915802, Last lagvar Loss: 2.581907272338867\n",
      "Step 836/10000- lr: [9.254548436363636e-06] - Loss total: 5.310440540313721, Last rpr Loss: 1.15900719165802, Last lagvar Loss: 2.1133389472961426\n",
      "Step 837/10000- lr: [9.25353833939394e-06] - Loss total: 5.426558017730713, Last rpr Loss: 1.6035406589508057, Last lagvar Loss: 1.8584625720977783\n",
      "Step 838/10000- lr: [9.252528242424243e-06] - Loss total: 5.419347286224365, Last rpr Loss: 1.6273258924484253, Last lagvar Loss: 1.8293225765228271\n",
      "Step 839/10000- lr: [9.251518145454546e-06] - Loss total: 5.3135857582092285, Last rpr Loss: 1.2849026918411255, Last lagvar Loss: 2.0165092945098877\n",
      "Step 840/10000- lr: [9.25050804848485e-06] - Loss total: 5.303122043609619, Last rpr Loss: 0.8767481446266174, Last lagvar Loss: 2.402998924255371\n",
      "Step 841/10000- lr: [9.249497951515153e-06] - Loss total: 5.343047618865967, Last rpr Loss: 0.745993971824646, Last lagvar Loss: 2.5909042358398438\n",
      "Step 842/10000- lr: [9.248487854545456e-06] - Loss total: 5.319456100463867, Last rpr Loss: 0.7603055834770203, Last lagvar Loss: 2.546830654144287\n",
      "Step 843/10000- lr: [9.247477757575758e-06] - Loss total: 5.268618106842041, Last rpr Loss: 0.930317759513855, Last lagvar Loss: 2.3006744384765625\n",
      "Step 844/10000- lr: [9.246467660606061e-06] - Loss total: 5.325288772583008, Last rpr Loss: 1.3436896800994873, Last lagvar Loss: 1.9534715414047241\n",
      "Step 845/10000- lr: [9.245457563636364e-06] - Loss total: 5.402719974517822, Last rpr Loss: 1.598785638809204, Last lagvar Loss: 1.8150149583816528\n",
      "Step 846/10000- lr: [9.244447466666667e-06] - Loss total: 5.34591817855835, Last rpr Loss: 1.4594967365264893, Last lagvar Loss: 1.8815972805023193\n",
      "Step 847/10000- lr: [9.24343736969697e-06] - Loss total: 5.268779754638672, Last rpr Loss: 1.1013339757919312, Last lagvar Loss: 2.139011859893799\n",
      "Step 848/10000- lr: [9.242427272727274e-06] - Loss total: 5.284757614135742, Last rpr Loss: 0.8126227855682373, Last lagvar Loss: 2.4464669227600098\n",
      "Step 849/10000- lr: [9.241417175757577e-06] - Loss total: 5.304582118988037, Last rpr Loss: 0.7489389181137085, Last lagvar Loss: 2.5379345417022705\n",
      "Step 850/10000- lr: [9.240407078787879e-06] - Loss total: 5.278068542480469, Last rpr Loss: 0.8348177075386047, Last lagvar Loss: 2.4159252643585205\n",
      "Step 851/10000- lr: [9.239396981818182e-06] - Loss total: 5.282810688018799, Last rpr Loss: 1.1404160261154175, Last lagvar Loss: 2.1197924613952637\n",
      "Step 852/10000- lr: [9.238386884848485e-06] - Loss total: 5.306148529052734, Last rpr Loss: 1.3329248428344727, Last lagvar Loss: 1.971529483795166\n",
      "Step 853/10000- lr: [9.237376787878789e-06] - Loss total: 5.255688667297363, Last rpr Loss: 1.2339577674865723, Last lagvar Loss: 1.9924763441085815\n",
      "Step 854/10000- lr: [9.236366690909092e-06] - Loss total: 5.2328972816467285, Last rpr Loss: 1.0133967399597168, Last lagvar Loss: 2.1807150840759277\n",
      "Step 855/10000- lr: [9.235356593939395e-06] - Loss total: 5.245608806610107, Last rpr Loss: 0.89681476354599, Last lagvar Loss: 2.314113140106201\n",
      "Step 856/10000- lr: [9.234346496969699e-06] - Loss total: 5.228729248046875, Last rpr Loss: 0.897428035736084, Last lagvar Loss: 2.292992353439331\n",
      "Step 857/10000- lr: [9.2333364e-06] - Loss total: 5.215582847595215, Last rpr Loss: 1.0448338985443115, Last lagvar Loss: 2.122864246368408\n",
      "Step 858/10000- lr: [9.232326303030303e-06] - Loss total: 5.2196125984191895, Last rpr Loss: 1.076125144958496, Last lagvar Loss: 2.0969901084899902\n",
      "Step 859/10000- lr: [9.231316206060607e-06] - Loss total: 5.204785346984863, Last rpr Loss: 0.9625527858734131, Last lagvar Loss: 2.197566509246826\n",
      "Step 860/10000- lr: [9.23030610909091e-06] - Loss total: 5.202970027923584, Last rpr Loss: 0.9463880658149719, Last lagvar Loss: 2.2134060859680176\n",
      "Step 861/10000- lr: [9.229296012121213e-06] - Loss total: 5.199057102203369, Last rpr Loss: 1.068711519241333, Last lagvar Loss: 2.0889244079589844\n",
      "Step 862/10000- lr: [9.228285915151516e-06] - Loss total: 5.188177585601807, Last rpr Loss: 1.0052824020385742, Last lagvar Loss: 2.137483596801758\n",
      "Step 863/10000- lr: [9.22727581818182e-06] - Loss total: 5.187435626983643, Last rpr Loss: 0.9374433755874634, Last lagvar Loss: 2.205993175506592\n",
      "Step 864/10000- lr: [9.226265721212121e-06] - Loss total: 5.178284168243408, Last rpr Loss: 1.0028939247131348, Last lagvar Loss: 2.12913179397583\n",
      "Step 865/10000- lr: [9.225255624242425e-06] - Loss total: 5.172639846801758, Last rpr Loss: 1.0148717164993286, Last lagvar Loss: 2.1136646270751953\n",
      "Step 866/10000- lr: [9.224245527272728e-06] - Loss total: 5.166254043579102, Last rpr Loss: 0.9879124164581299, Last lagvar Loss: 2.1341114044189453\n",
      "Step 867/10000- lr: [9.223235430303031e-06] - Loss total: 5.158969879150391, Last rpr Loss: 1.005799651145935, Last lagvar Loss: 2.1086127758026123\n",
      "Step 868/10000- lr: [9.222225333333334e-06] - Loss total: 5.152830600738525, Last rpr Loss: 0.9574867486953735, Last lagvar Loss: 2.150878429412842\n",
      "Step 869/10000- lr: [9.221215236363638e-06] - Loss total: 5.144123077392578, Last rpr Loss: 0.9922343492507935, Last lagvar Loss: 2.107062578201294\n",
      "Step 870/10000- lr: [9.22020513939394e-06] - Loss total: 5.138987064361572, Last rpr Loss: 1.0339555740356445, Last lagvar Loss: 2.0624563694000244\n",
      "Step 871/10000- lr: [9.219195042424243e-06] - Loss total: 5.130469799041748, Last rpr Loss: 0.9655141830444336, Last lagvar Loss: 2.1207051277160645\n",
      "Step 872/10000- lr: [9.218184945454546e-06] - Loss total: 5.124863147735596, Last rpr Loss: 1.0174379348754883, Last lagvar Loss: 2.0657801628112793\n",
      "Step 873/10000- lr: [9.217174848484849e-06] - Loss total: 5.116039752960205, Last rpr Loss: 0.9674450159072876, Last lagvar Loss: 2.105562448501587\n",
      "Step 874/10000- lr: [9.216164751515152e-06] - Loss total: 5.10882568359375, Last rpr Loss: 1.033470630645752, Last lagvar Loss: 2.034656524658203\n",
      "Step 875/10000- lr: [9.215154654545456e-06] - Loss total: 5.100517272949219, Last rpr Loss: 0.9946033954620361, Last lagvar Loss: 2.0648550987243652\n",
      "Step 876/10000- lr: [9.214144557575759e-06] - Loss total: 5.09331750869751, Last rpr Loss: 0.9805359244346619, Last lagvar Loss: 2.073113441467285\n",
      "Step 877/10000- lr: [9.213134460606062e-06] - Loss total: 5.08566427230835, Last rpr Loss: 1.0001553297042847, Last lagvar Loss: 2.0469748973846436\n",
      "Step 878/10000- lr: [9.212124363636364e-06] - Loss total: 5.078592300415039, Last rpr Loss: 0.9767415523529053, Last lagvar Loss: 2.0638809204101562\n",
      "Step 879/10000- lr: [9.211114266666667e-06] - Loss total: 5.070981025695801, Last rpr Loss: 1.020695686340332, Last lagvar Loss: 2.0134639739990234\n",
      "Step 880/10000- lr: [9.21010416969697e-06] - Loss total: 5.063406944274902, Last rpr Loss: 0.9607231616973877, Last lagvar Loss: 2.0665836334228516\n",
      "Step 881/10000- lr: [9.209094072727274e-06] - Loss total: 5.056092739105225, Last rpr Loss: 1.010312795639038, Last lagvar Loss: 2.0114493370056152\n",
      "Step 882/10000- lr: [9.208083975757577e-06] - Loss total: 5.048463344573975, Last rpr Loss: 0.976302444934845, Last lagvar Loss: 2.037912607192993\n",
      "Step 883/10000- lr: [9.20707387878788e-06] - Loss total: 5.041566848754883, Last rpr Loss: 1.0422343015670776, Last lagvar Loss: 1.9679157733917236\n",
      "Step 884/10000- lr: [9.206063781818182e-06] - Loss total: 5.034481048583984, Last rpr Loss: 0.9501643776893616, Last lagvar Loss: 2.0530853271484375\n",
      "Step 885/10000- lr: [9.205053684848485e-06] - Loss total: 5.028437614440918, Last rpr Loss: 1.0409592390060425, Last lagvar Loss: 1.960034966468811\n",
      "Step 886/10000- lr: [9.204043587878788e-06] - Loss total: 5.0181097984313965, Last rpr Loss: 0.9767134189605713, Last lagvar Loss: 2.0121190547943115\n",
      "Step 887/10000- lr: [9.203033490909092e-06] - Loss total: 5.010931968688965, Last rpr Loss: 1.0016870498657227, Last lagvar Loss: 1.9812957048416138\n",
      "Step 888/10000- lr: [9.202023393939395e-06] - Loss total: 5.003992557525635, Last rpr Loss: 1.0221259593963623, Last lagvar Loss: 1.9561412334442139\n",
      "Step 889/10000- lr: [9.201013296969698e-06] - Loss total: 4.999756336212158, Last rpr Loss: 0.9369127750396729, Last lagvar Loss: 2.0381085872650146\n",
      "Step 890/10000- lr: [9.200003200000001e-06] - Loss total: 4.990917682647705, Last rpr Loss: 1.036441445350647, Last lagvar Loss: 1.932133674621582\n",
      "Step 891/10000- lr: [9.198993103030303e-06] - Loss total: 4.9839091300964355, Last rpr Loss: 0.9727961421012878, Last lagvar Loss: 1.988702416419983\n",
      "Step 892/10000- lr: [9.197983006060606e-06] - Loss total: 4.976324081420898, Last rpr Loss: 1.0327444076538086, Last lagvar Loss: 1.923122763633728\n",
      "Step 893/10000- lr: [9.19697290909091e-06] - Loss total: 4.970139980316162, Last rpr Loss: 0.9507465362548828, Last lagvar Loss: 1.9998424053192139\n",
      "Step 894/10000- lr: [9.195962812121213e-06] - Loss total: 4.9638671875, Last rpr Loss: 1.0341949462890625, Last lagvar Loss: 1.9129239320755005\n",
      "Step 895/10000- lr: [9.194952715151516e-06] - Loss total: 4.956806182861328, Last rpr Loss: 0.9592428207397461, Last lagvar Loss: 1.9806342124938965\n",
      "Step 896/10000- lr: [9.19394261818182e-06] - Loss total: 4.949820518493652, Last rpr Loss: 1.04011070728302, Last lagvar Loss: 1.894697904586792\n",
      "Step 897/10000- lr: [9.192932521212121e-06] - Loss total: 4.944345951080322, Last rpr Loss: 0.9438934922218323, Last lagvar Loss: 1.986617088317871\n",
      "Step 898/10000- lr: [9.191922424242424e-06] - Loss total: 4.936802864074707, Last rpr Loss: 1.0314186811447144, Last lagvar Loss: 1.894134283065796\n",
      "Step 899/10000- lr: [9.190912327272728e-06] - Loss total: 4.929615020751953, Last rpr Loss: 0.975763201713562, Last lagvar Loss: 1.942122459411621\n",
      "Step 900/10000- lr: [9.18990223030303e-06] - Loss total: 4.92315149307251, Last rpr Loss: 1.038083553314209, Last lagvar Loss: 1.8757665157318115\n",
      "Step 901/10000- lr: [9.188892133333334e-06] - Loss total: 4.917172431945801, Last rpr Loss: 0.9556847810745239, Last lagvar Loss: 1.9530891180038452\n",
      "Step 902/10000- lr: [9.187882036363637e-06] - Loss total: 4.911921501159668, Last rpr Loss: 1.037158489227295, Last lagvar Loss: 1.8696119785308838\n",
      "Step 903/10000- lr: [9.18687193939394e-06] - Loss total: 4.903782367706299, Last rpr Loss: 0.9671604037284851, Last lagvar Loss: 1.9306000471115112\n",
      "Step 904/10000- lr: [9.185861842424244e-06] - Loss total: 4.8973588943481445, Last rpr Loss: 1.0224573612213135, Last lagvar Loss: 1.8709748983383179\n",
      "Step 905/10000- lr: [9.184851745454546e-06] - Loss total: 4.890791893005371, Last rpr Loss: 0.9705920815467834, Last lagvar Loss: 1.9174362421035767\n",
      "Step 906/10000- lr: [9.183841648484849e-06] - Loss total: 4.885016918182373, Last rpr Loss: 1.0156152248382568, Last lagvar Loss: 1.8691329956054688\n",
      "Step 907/10000- lr: [9.182831551515152e-06] - Loss total: 4.879722595214844, Last rpr Loss: 0.9664150476455688, Last lagvar Loss: 1.9132742881774902\n",
      "Step 908/10000- lr: [9.181821454545455e-06] - Loss total: 4.875597953796387, Last rpr Loss: 1.0660736560821533, Last lagvar Loss: 1.8141822814941406\n",
      "Step 909/10000- lr: [9.180811357575759e-06] - Loss total: 4.866611957550049, Last rpr Loss: 0.9676341414451599, Last lagvar Loss: 1.9022166728973389\n",
      "Step 910/10000- lr: [9.179801260606062e-06] - Loss total: 4.86005163192749, Last rpr Loss: 1.0001518726348877, Last lagvar Loss: 1.8652349710464478\n",
      "Step 911/10000- lr: [9.178791163636363e-06] - Loss total: 4.853791236877441, Last rpr Loss: 1.002385139465332, Last lagvar Loss: 1.8575432300567627\n",
      "Step 912/10000- lr: [9.177781066666667e-06] - Loss total: 4.8484039306640625, Last rpr Loss: 0.9802360534667969, Last lagvar Loss: 1.8755258321762085\n",
      "Step 913/10000- lr: [9.17677096969697e-06] - Loss total: 4.843385696411133, Last rpr Loss: 1.027433156967163, Last lagvar Loss: 1.8264045715332031\n",
      "Step 914/10000- lr: [9.175760872727273e-06] - Loss total: 4.8418145179748535, Last rpr Loss: 0.9250776767730713, Last lagvar Loss: 1.9280524253845215\n",
      "Step 915/10000- lr: [9.174750775757577e-06] - Loss total: 4.830320835113525, Last rpr Loss: 0.9915149211883545, Last lagvar Loss: 1.8507752418518066\n",
      "Step 916/10000- lr: [9.17374067878788e-06] - Loss total: 4.833160877227783, Last rpr Loss: 1.0957753658294678, Last lagvar Loss: 1.756593108177185\n",
      "Step 917/10000- lr: [9.172730581818183e-06] - Loss total: 4.819599628448486, Last rpr Loss: 0.9925426840782166, Last lagvar Loss: 1.8417253494262695\n",
      "Step 918/10000- lr: [9.171720484848485e-06] - Loss total: 4.816450595855713, Last rpr Loss: 0.9539280533790588, Last lagvar Loss: 1.8787007331848145\n",
      "Step 919/10000- lr: [9.170710387878788e-06] - Loss total: 4.819316387176514, Last rpr Loss: 1.1001261472702026, Last lagvar Loss: 1.7432198524475098\n",
      "Step 920/10000- lr: [9.169700290909091e-06] - Loss total: 4.806366920471191, Last rpr Loss: 1.0468775033950806, Last lagvar Loss: 1.7797901630401611\n",
      "Step 921/10000- lr: [9.168690193939395e-06] - Loss total: 4.82190465927124, Last rpr Loss: 0.8730250597000122, Last lagvar Loss: 1.9710044860839844\n",
      "Step 922/10000- lr: [9.167680096969698e-06] - Loss total: 4.822575569152832, Last rpr Loss: 0.86201411485672, Last lagvar Loss: 1.9845106601715088\n",
      "Step 923/10000- lr: [9.166670000000001e-06] - Loss total: 4.791502952575684, Last rpr Loss: 0.9718215465545654, Last lagvar Loss: 1.842026948928833\n",
      "Step 924/10000- lr: [9.165659903030304e-06] - Loss total: 4.86110782623291, Last rpr Loss: 1.3296937942504883, Last lagvar Loss: 1.602832317352295\n",
      "Step 925/10000- lr: [9.164649806060606e-06] - Loss total: 4.918290615081787, Last rpr Loss: 1.50331449508667, Last lagvar Loss: 1.54396653175354\n",
      "Step 926/10000- lr: [9.16363970909091e-06] - Loss total: 4.812839031219482, Last rpr Loss: 1.193043828010559, Last lagvar Loss: 1.6586904525756836\n",
      "Step 927/10000- lr: [9.162629612121213e-06] - Loss total: 4.7862396240234375, Last rpr Loss: 0.909782886505127, Last lagvar Loss: 1.903928279876709\n",
      "Step 928/10000- lr: [9.161619515151516e-06] - Loss total: 4.800318241119385, Last rpr Loss: 0.8687031269073486, Last lagvar Loss: 1.9611942768096924\n",
      "Step 929/10000- lr: [9.160609418181819e-06] - Loss total: 4.777029514312744, Last rpr Loss: 0.9432814717292786, Last lagvar Loss: 1.8624982833862305\n",
      "Step 930/10000- lr: [9.159599321212122e-06] - Loss total: 4.797891616821289, Last rpr Loss: 1.196324348449707, Last lagvar Loss: 1.6370769739151\n",
      "Step 931/10000- lr: [9.158589224242426e-06] - Loss total: 4.8246002197265625, Last rpr Loss: 1.2842519283294678, Last lagvar Loss: 1.587262749671936\n",
      "Step 932/10000- lr: [9.157579127272727e-06] - Loss total: 4.773238658905029, Last rpr Loss: 1.1089681386947632, Last lagvar Loss: 1.6958239078521729\n",
      "Step 933/10000- lr: [9.15656903030303e-06] - Loss total: 4.7797675132751465, Last rpr Loss: 0.884170413017273, Last lagvar Loss: 1.9265028238296509\n",
      "Step 934/10000- lr: [9.155558933333334e-06] - Loss total: 4.795839786529541, Last rpr Loss: 0.8481548428535461, Last lagvar Loss: 1.9796760082244873\n",
      "Step 935/10000- lr: [9.154548836363637e-06] - Loss total: 4.767005920410156, Last rpr Loss: 0.9218145608901978, Last lagvar Loss: 1.8770557641983032\n",
      "Step 936/10000- lr: [9.15353873939394e-06] - Loss total: 4.771056175231934, Last rpr Loss: 1.157139539718628, Last lagvar Loss: 1.6491460800170898\n",
      "Step 937/10000- lr: [9.152528642424244e-06] - Loss total: 4.790352821350098, Last rpr Loss: 1.2253203392028809, Last lagvar Loss: 1.6037311553955078\n",
      "Step 938/10000- lr: [9.151518545454547e-06] - Loss total: 4.753268241882324, Last rpr Loss: 1.0689597129821777, Last lagvar Loss: 1.7167115211486816\n",
      "Step 939/10000- lr: [9.150508448484848e-06] - Loss total: 4.770416736602783, Last rpr Loss: 0.860200047492981, Last lagvar Loss: 1.945037603378296\n",
      "Step 940/10000- lr: [9.149498351515152e-06] - Loss total: 4.786619663238525, Last rpr Loss: 0.8239732384681702, Last lagvar Loss: 1.997650146484375\n",
      "Step 941/10000- lr: [9.148488254545455e-06] - Loss total: 4.7558135986328125, Last rpr Loss: 0.895841121673584, Last lagvar Loss: 1.8943817615509033\n",
      "Step 942/10000- lr: [9.147478157575758e-06] - Loss total: 4.75362491607666, Last rpr Loss: 1.1286388635635376, Last lagvar Loss: 1.6613250970840454\n",
      "Step 943/10000- lr: [9.146468060606062e-06] - Loss total: 4.773955345153809, Last rpr Loss: 1.2087196111679077, Last lagvar Loss: 1.6063717603683472\n",
      "Step 944/10000- lr: [9.145457963636365e-06] - Loss total: 4.740164756774902, Last rpr Loss: 1.0674704313278198, Last lagvar Loss: 1.7080113887786865\n",
      "Step 945/10000- lr: [9.144447866666668e-06] - Loss total: 4.755320072174072, Last rpr Loss: 0.8647994995117188, Last lagvar Loss: 1.925870418548584\n",
      "Step 946/10000- lr: [9.14343776969697e-06] - Loss total: 4.770195960998535, Last rpr Loss: 0.8329242467880249, Last lagvar Loss: 1.9716237783432007\n",
      "Step 947/10000- lr: [9.142427672727273e-06] - Loss total: 4.74090051651001, Last rpr Loss: 0.9096423387527466, Last lagvar Loss: 1.865578055381775\n",
      "Step 948/10000- lr: [9.141417575757576e-06] - Loss total: 4.743506908416748, Last rpr Loss: 1.153414011001587, Last lagvar Loss: 1.6306846141815186\n",
      "Step 949/10000- lr: [9.14040747878788e-06] - Loss total: 4.766727924346924, Last rpr Loss: 1.2435212135314941, Last lagvar Loss: 1.5715079307556152\n",
      "Step 950/10000- lr: [9.139397381818183e-06] - Loss total: 4.7302656173706055, Last rpr Loss: 1.098907709121704, Last lagvar Loss: 1.6700198650360107\n",
      "Step 951/10000- lr: [9.138387284848486e-06] - Loss total: 4.73983907699585, Last rpr Loss: 0.8836499452590942, Last lagvar Loss: 1.8930702209472656\n",
      "Step 952/10000- lr: [9.137377187878788e-06] - Loss total: 4.754184722900391, Last rpr Loss: 0.8433662056922913, Last lagvar Loss: 1.9472222328186035\n",
      "Step 953/10000- lr: [9.136367090909091e-06] - Loss total: 4.727396488189697, Last rpr Loss: 0.9129089117050171, Last lagvar Loss: 1.851627230644226\n",
      "Step 954/10000- lr: [9.135356993939394e-06] - Loss total: 4.733236312866211, Last rpr Loss: 1.1531217098236084, Last lagvar Loss: 1.6223355531692505\n",
      "Step 955/10000- lr: [9.134346896969698e-06] - Loss total: 4.759204387664795, Last rpr Loss: 1.2501753568649292, Last lagvar Loss: 1.5597738027572632\n",
      "Step 956/10000- lr: [9.1333368e-06] - Loss total: 4.720876693725586, Last rpr Loss: 1.1076622009277344, Last lagvar Loss: 1.6534955501556396\n",
      "Step 957/10000- lr: [9.132326703030304e-06] - Loss total: 4.7251458168029785, Last rpr Loss: 0.8883944749832153, Last lagvar Loss: 1.8764817714691162\n",
      "Step 958/10000- lr: [9.131316606060607e-06] - Loss total: 4.739278316497803, Last rpr Loss: 0.8452547192573547, Last lagvar Loss: 1.9339845180511475\n",
      "Step 959/10000- lr: [9.13030650909091e-06] - Loss total: 4.715000152587891, Last rpr Loss: 0.9114846587181091, Last lagvar Loss: 1.8440091609954834\n",
      "Step 960/10000- lr: [9.129296412121212e-06] - Loss total: 4.721996784210205, Last rpr Loss: 1.1470322608947754, Last lagvar Loss: 1.617567777633667\n",
      "Step 961/10000- lr: [9.128286315151515e-06] - Loss total: 4.748030185699463, Last rpr Loss: 1.2495957612991333, Last lagvar Loss: 1.5493922233581543\n",
      "Step 962/10000- lr: [9.127276218181819e-06] - Loss total: 4.71058464050293, Last rpr Loss: 1.1184303760528564, Last lagvar Loss: 1.6347332000732422\n",
      "Step 963/10000- lr: [9.126266121212122e-06] - Loss total: 4.712454319000244, Last rpr Loss: 0.900462806224823, Last lagvar Loss: 1.8528180122375488\n",
      "Step 964/10000- lr: [9.125256024242425e-06] - Loss total: 4.726382255554199, Last rpr Loss: 0.8546633720397949, Last lagvar Loss: 1.9127230644226074\n",
      "Step 965/10000- lr: [9.124245927272729e-06] - Loss total: 4.703646183013916, Last rpr Loss: 0.9169632792472839, Last lagvar Loss: 1.828974962234497\n",
      "Step 966/10000- lr: [9.12323583030303e-06] - Loss total: 4.709485054016113, Last rpr Loss: 1.1424367427825928, Last lagvar Loss: 1.6117329597473145\n",
      "Step 967/10000- lr: [9.122225733333333e-06] - Loss total: 4.73268461227417, Last rpr Loss: 1.2364349365234375, Last lagvar Loss: 1.5475085973739624\n",
      "Step 968/10000- lr: [9.121215636363637e-06] - Loss total: 4.6981201171875, Last rpr Loss: 1.110244870185852, Last lagvar Loss: 1.63218092918396\n",
      "Step 969/10000- lr: [9.12020553939394e-06] - Loss total: 4.7019758224487305, Last rpr Loss: 0.8971418142318726, Last lagvar Loss: 1.8472862243652344\n",
      "Step 970/10000- lr: [9.119195442424243e-06] - Loss total: 4.715940952301025, Last rpr Loss: 0.8509100079536438, Last lagvar Loss: 1.9075617790222168\n",
      "Step 971/10000- lr: [9.118185345454547e-06] - Loss total: 4.693170547485352, Last rpr Loss: 0.9106906056404114, Last lagvar Loss: 1.8263190984725952\n",
      "Step 972/10000- lr: [9.11717524848485e-06] - Loss total: 4.696061134338379, Last rpr Loss: 1.1281248331069946, Last lagvar Loss: 1.6139178276062012\n",
      "Step 973/10000- lr: [9.116165151515151e-06] - Loss total: 4.717138290405273, Last rpr Loss: 1.2183176279067993, Last lagvar Loss: 1.550552248954773\n",
      "Step 974/10000- lr: [9.115155054545455e-06] - Loss total: 4.6855149269104, Last rpr Loss: 1.099236249923706, Last lagvar Loss: 1.632382869720459\n",
      "Step 975/10000- lr: [9.114144957575758e-06] - Loss total: 4.691418170928955, Last rpr Loss: 0.8941786289215088, Last lagvar Loss: 1.8415400981903076\n",
      "Step 976/10000- lr: [9.113134860606061e-06] - Loss total: 4.705155849456787, Last rpr Loss: 0.850739598274231, Last lagvar Loss: 1.8984949588775635\n",
      "Step 977/10000- lr: [9.112124763636365e-06] - Loss total: 4.682295799255371, Last rpr Loss: 0.9111930727958679, Last lagvar Loss: 1.816387414932251\n",
      "Step 978/10000- lr: [9.111114666666668e-06] - Loss total: 4.683438301086426, Last rpr Loss: 1.1244280338287354, Last lagvar Loss: 1.6071439981460571\n",
      "Step 979/10000- lr: [9.110104569696971e-06] - Loss total: 4.702815532684326, Last rpr Loss: 1.2097244262695312, Last lagvar Loss: 1.5466240644454956\n",
      "Step 980/10000- lr: [9.109094472727273e-06] - Loss total: 4.6731719970703125, Last rpr Loss: 1.0921332836151123, Last lagvar Loss: 1.6292306184768677\n",
      "Step 981/10000- lr: [9.108084375757576e-06] - Loss total: 4.680838108062744, Last rpr Loss: 0.8907017111778259, Last lagvar Loss: 1.836350440979004\n",
      "Step 982/10000- lr: [9.10707427878788e-06] - Loss total: 4.694502830505371, Last rpr Loss: 0.847783088684082, Last lagvar Loss: 1.8926169872283936\n",
      "Step 983/10000- lr: [9.106064181818183e-06] - Loss total: 4.671518802642822, Last rpr Loss: 0.907288670539856, Last lagvar Loss: 1.8113439083099365\n",
      "Step 984/10000- lr: [9.105054084848486e-06] - Loss total: 4.670745372772217, Last rpr Loss: 1.115782618522644, Last lagvar Loss: 1.6048171520233154\n",
      "Step 985/10000- lr: [9.104043987878789e-06] - Loss total: 4.688713550567627, Last rpr Loss: 1.1983051300048828, Last lagvar Loss: 1.5451276302337646\n",
      "Step 986/10000- lr: [9.103033890909092e-06] - Loss total: 4.6609601974487305, Last rpr Loss: 1.0845823287963867, Last lagvar Loss: 1.6264362335205078\n",
      "Step 987/10000- lr: [9.102023793939394e-06] - Loss total: 4.669954776763916, Last rpr Loss: 0.888282299041748, Last lagvar Loss: 1.8299319744110107\n",
      "Step 988/10000- lr: [9.101013696969697e-06] - Loss total: 4.683360576629639, Last rpr Loss: 0.8470814228057861, Last lagvar Loss: 1.8841521739959717\n",
      "Step 989/10000- lr: [9.1000036e-06] - Loss total: 4.660367488861084, Last rpr Loss: 0.9069786071777344, Last lagvar Loss: 1.8024861812591553\n",
      "Step 990/10000- lr: [9.098993503030304e-06] - Loss total: 4.658541202545166, Last rpr Loss: 1.1132771968841553, Last lagvar Loss: 1.5973737239837646\n",
      "Step 991/10000- lr: [9.097983406060607e-06] - Loss total: 4.6757402420043945, Last rpr Loss: 1.194894790649414, Last lagvar Loss: 1.5377750396728516\n",
      "Step 992/10000- lr: [9.09697330909091e-06] - Loss total: 4.649134159088135, Last rpr Loss: 1.0832048654556274, Last lagvar Loss: 1.6181361675262451\n",
      "Step 993/10000- lr: [9.095963212121214e-06] - Loss total: 4.6585469245910645, Last rpr Loss: 0.8881171941757202, Last lagvar Loss: 1.8205695152282715\n",
      "Step 994/10000- lr: [9.094953115151515e-06] - Loss total: 4.671801567077637, Last rpr Loss: 0.8463530540466309, Last lagvar Loss: 1.8753553628921509\n",
      "Step 995/10000- lr: [9.093943018181818e-06] - Loss total: 4.649040222167969, Last rpr Loss: 0.9048137664794922, Last lagvar Loss: 1.7954983711242676\n",
      "Step 996/10000- lr: [9.092932921212122e-06] - Loss total: 4.646401882171631, Last rpr Loss: 1.1075475215911865, Last lagvar Loss: 1.5927214622497559\n",
      "Step 997/10000- lr: [9.091922824242425e-06] - Loss total: 4.663057327270508, Last rpr Loss: 1.1889921426773071, Last lagvar Loss: 1.5325279235839844\n",
      "Step 998/10000- lr: [9.090912727272728e-06] - Loss total: 4.637444496154785, Last rpr Loss: 1.0808064937591553, Last lagvar Loss: 1.6109004020690918\n",
      "Step 999/10000- lr: [9.089902630303032e-06] - Loss total: 4.646795749664307, Last rpr Loss: 0.8878631591796875, Last lagvar Loss: 1.8110774755477905\n",
      "Step 1000/10000- lr: [9.088892533333335e-06] - Loss total: 4.659797668457031, Last rpr Loss: 0.8465642929077148, Last lagvar Loss: 1.865135908126831\n",
      "Step 1001/10000- lr: [9.087882436363636e-06] - Loss total: 4.637396335601807, Last rpr Loss: 0.904987096786499, Last lagvar Loss: 1.785775899887085\n",
      "Step 1002/10000- lr: [9.08687233939394e-06] - Loss total: 4.634673595428467, Last rpr Loss: 1.107111930847168, Last lagvar Loss: 1.5837960243225098\n",
      "Step 1003/10000- lr: [9.085862242424243e-06] - Loss total: 4.651334285736084, Last rpr Loss: 1.190519094467163, Last lagvar Loss: 1.5219051837921143\n",
      "Step 1004/10000- lr: [9.084852145454546e-06] - Loss total: 4.626214027404785, Last rpr Loss: 1.0850040912628174, Last lagvar Loss: 1.597945213317871\n",
      "Step 1005/10000- lr: [9.08384204848485e-06] - Loss total: 4.634384632110596, Last rpr Loss: 0.8915634155273438, Last lagvar Loss: 1.79681396484375\n",
      "Step 1006/10000- lr: [9.082831951515153e-06] - Loss total: 4.64694881439209, Last rpr Loss: 0.8493084907531738, Last lagvar Loss: 1.8514723777770996\n",
      "Step 1007/10000- lr: [9.081821854545456e-06] - Loss total: 4.6252593994140625, Last rpr Loss: 0.9069430828094482, Last lagvar Loss: 1.7738046646118164\n",
      "Step 1008/10000- lr: [9.080811757575758e-06] - Loss total: 4.623751163482666, Last rpr Loss: 1.109052062034607, Last lagvar Loss: 1.5731337070465088\n",
      "Step 1009/10000- lr: [9.079801660606061e-06] - Loss total: 4.641193866729736, Last rpr Loss: 1.1954920291900635, Last lagvar Loss: 1.5093538761138916\n",
      "Step 1010/10000- lr: [9.078791563636364e-06] - Loss total: 4.615830421447754, Last rpr Loss: 1.0924742221832275, Last lagvar Loss: 1.5826869010925293\n",
      "Step 1011/10000- lr: [9.077781466666667e-06] - Loss total: 4.621101379394531, Last rpr Loss: 0.8982322216033936, Last lagvar Loss: 1.7789819240570068\n",
      "Step 1012/10000- lr: [9.07677136969697e-06] - Loss total: 4.632835865020752, Last rpr Loss: 0.8552442789077759, Last lagvar Loss: 1.8336234092712402\n",
      "Step 1013/10000- lr: [9.075761272727274e-06] - Loss total: 4.6124587059021, Last rpr Loss: 0.9130475521087646, Last lagvar Loss: 1.757233738899231\n",
      "Step 1014/10000- lr: [9.074751175757577e-06] - Loss total: 4.614233016967773, Last rpr Loss: 1.1181879043579102, Last lagvar Loss: 1.557133674621582\n",
      "Step 1015/10000- lr: [9.073741078787879e-06] - Loss total: 4.633375644683838, Last rpr Loss: 1.2090176343917847, Last lagvar Loss: 1.4914062023162842\n",
      "Step 1016/10000- lr: [9.072730981818182e-06] - Loss total: 4.606690406799316, Last rpr Loss: 1.1068623065948486, Last lagvar Loss: 1.5621776580810547\n",
      "Step 1017/10000- lr: [9.071720884848485e-06] - Loss total: 4.6072211265563965, Last rpr Loss: 0.9099782109260559, Last lagvar Loss: 1.755526065826416\n",
      "Step 1018/10000- lr: [9.070710787878789e-06] - Loss total: 4.617919921875, Last rpr Loss: 0.8647632598876953, Last lagvar Loss: 1.8113811016082764\n",
      "Step 1019/10000- lr: [9.069700690909092e-06] - Loss total: 4.5995001792907715, Last rpr Loss: 0.9218687415122986, Last lagvar Loss: 1.7378456592559814\n",
      "Step 1020/10000- lr: [9.068690593939395e-06] - Loss total: 4.605525970458984, Last rpr Loss: 1.1291364431381226, Last lagvar Loss: 1.5400601625442505\n",
      "Step 1021/10000- lr: [9.067680496969697e-06] - Loss total: 4.626114368438721, Last rpr Loss: 1.2216529846191406, Last lagvar Loss: 1.4745290279388428\n",
      "Step 1022/10000- lr: [9.0666704e-06] - Loss total: 4.5977559089660645, Last rpr Loss: 1.1186473369598389, Last lagvar Loss: 1.5443449020385742\n",
      "Step 1023/10000- lr: [9.065660303030303e-06] - Loss total: 4.594126224517822, Last rpr Loss: 0.9192794561386108, Last lagvar Loss: 1.7354695796966553\n",
      "Step 1024/10000- lr: [9.064650206060607e-06] - Loss total: 4.604205131530762, Last rpr Loss: 0.8712737560272217, Last lagvar Loss: 1.793532371520996\n",
      "Step 1025/10000- lr: [9.06364010909091e-06] - Loss total: 4.587532043457031, Last rpr Loss: 0.9269425272941589, Last lagvar Loss: 1.7233067750930786\n",
      "Step 1026/10000- lr: [9.062630012121213e-06] - Loss total: 4.595285415649414, Last rpr Loss: 1.1322693824768066, Last lagvar Loss: 1.529096245765686\n",
      "Step 1027/10000- lr: [9.061619915151517e-06] - Loss total: 4.615355491638184, Last rpr Loss: 1.2227952480316162, Last lagvar Loss: 1.4648399353027344\n",
      "Step 1028/10000- lr: [9.06060981818182e-06] - Loss total: 4.587100028991699, Last rpr Loss: 1.1204323768615723, Last lagvar Loss: 1.5345678329467773\n",
      "Step 1029/10000- lr: [9.059599721212121e-06] - Loss total: 4.582753658294678, Last rpr Loss: 0.9204392433166504, Last lagvar Loss: 1.7250369787216187\n",
      "Step 1030/10000- lr: [9.058589624242425e-06] - Loss total: 4.592965126037598, Last rpr Loss: 0.8709120154380798, Last lagvar Loss: 1.7848773002624512\n",
      "Step 1031/10000- lr: [9.057579527272728e-06] - Loss total: 4.576959133148193, Last rpr Loss: 0.9252209067344666, Last lagvar Loss: 1.7169653177261353\n",
      "Step 1032/10000- lr: [9.056569430303031e-06] - Loss total: 4.582845687866211, Last rpr Loss: 1.1244969367980957, Last lagvar Loss: 1.5265036821365356\n",
      "Step 1033/10000- lr: [9.055559333333334e-06] - Loss total: 4.601195335388184, Last rpr Loss: 1.2125959396362305, Last lagvar Loss: 1.4622583389282227\n",
      "Step 1034/10000- lr: [9.054549236363638e-06] - Loss total: 4.575325012207031, Last rpr Loss: 1.1153910160064697, Last lagvar Loss: 1.5303270816802979\n",
      "Step 1035/10000- lr: [9.05353913939394e-06] - Loss total: 4.572117328643799, Last rpr Loss: 0.9179755449295044, Last lagvar Loss: 1.7189699411392212\n",
      "Step 1036/10000- lr: [9.052529042424243e-06] - Loss total: 4.582265853881836, Last rpr Loss: 0.8688488602638245, Last lagvar Loss: 1.778573751449585\n",
      "Step 1037/10000- lr: [9.051518945454546e-06] - Loss total: 4.566502094268799, Last rpr Loss: 0.9234291315078735, Last lagvar Loss: 1.7109647989273071\n",
      "Step 1038/10000- lr: [9.05050884848485e-06] - Loss total: 4.57112455368042, Last rpr Loss: 1.1190112829208374, Last lagvar Loss: 1.5226001739501953\n",
      "Step 1039/10000- lr: [9.049498751515152e-06] - Loss total: 4.588778972625732, Last rpr Loss: 1.207606315612793, Last lagvar Loss: 1.4568238258361816\n",
      "Step 1040/10000- lr: [9.048488654545456e-06] - Loss total: 4.564844131469727, Last rpr Loss: 1.116019606590271, Last lagvar Loss: 1.5220203399658203\n",
      "Step 1041/10000- lr: [9.047478557575759e-06] - Loss total: 4.5606369972229, Last rpr Loss: 0.9211639761924744, Last lagvar Loss: 1.7065564393997192\n",
      "Step 1042/10000- lr: [9.04646846060606e-06] - Loss total: 4.570012092590332, Last rpr Loss: 0.8721354007720947, Last lagvar Loss: 1.7654441595077515\n",
      "Step 1043/10000- lr: [9.045458363636364e-06] - Loss total: 4.555331230163574, Last rpr Loss: 0.9280011653900146, Last lagvar Loss: 1.6979886293411255\n",
      "Step 1044/10000- lr: [9.044448266666667e-06] - Loss total: 4.560824394226074, Last rpr Loss: 1.1211556196212769, Last lagvar Loss: 1.5126423835754395\n",
      "Step 1045/10000- lr: [9.04343816969697e-06] - Loss total: 4.578026294708252, Last rpr Loss: 1.2080881595611572, Last lagvar Loss: 1.448086142539978\n",
      "Step 1046/10000- lr: [9.042428072727274e-06] - Loss total: 4.554883003234863, Last rpr Loss: 1.117354393005371, Last lagvar Loss: 1.5136265754699707\n",
      "Step 1047/10000- lr: [9.041417975757577e-06] - Loss total: 4.5493974685668945, Last rpr Loss: 0.9232327938079834, Last lagvar Loss: 1.695623755455017\n",
      "Step 1048/10000- lr: [9.04040787878788e-06] - Loss total: 4.558394432067871, Last rpr Loss: 0.8739089965820312, Last lagvar Loss: 1.7546361684799194\n",
      "Step 1049/10000- lr: [9.039397781818182e-06] - Loss total: 4.544981479644775, Last rpr Loss: 0.9307163953781128, Last lagvar Loss: 1.6877808570861816\n",
      "Step 1050/10000- lr: [9.038387684848485e-06] - Loss total: 4.549259662628174, Last rpr Loss: 1.116286039352417, Last lagvar Loss: 1.5081760883331299\n",
      "Step 1051/10000- lr: [9.037377587878788e-06] - Loss total: 4.564271450042725, Last rpr Loss: 1.1980469226837158, Last lagvar Loss: 1.4461390972137451\n",
      "Step 1052/10000- lr: [9.036367490909092e-06] - Loss total: 4.543833255767822, Last rpr Loss: 1.1096563339233398, Last lagvar Loss: 1.5127999782562256\n",
      "Step 1053/10000- lr: [9.035357393939395e-06] - Loss total: 4.5389862060546875, Last rpr Loss: 0.9202703237533569, Last lagvar Loss: 1.690384864807129\n",
      "Step 1054/10000- lr: [9.034347296969698e-06] - Loss total: 4.547276496887207, Last rpr Loss: 0.8741101026535034, Last lagvar Loss: 1.745970606803894\n",
      "Step 1055/10000- lr: [9.033337200000002e-06] - Loss total: 4.534846782684326, Last rpr Loss: 0.9349949359893799, Last lagvar Loss: 1.6763122081756592\n",
      "Step 1056/10000- lr: [9.032327103030303e-06] - Loss total: 4.537833213806152, Last rpr Loss: 1.1120350360870361, Last lagvar Loss: 1.5032215118408203\n",
      "Step 1057/10000- lr: [9.031317006060606e-06] - Loss total: 4.550589084625244, Last rpr Loss: 1.1876795291900635, Last lagvar Loss: 1.4447994232177734\n",
      "Step 1058/10000- lr: [9.03030690909091e-06] - Loss total: 4.53322172164917, Last rpr Loss: 1.1006252765655518, Last lagvar Loss: 1.5137697458267212\n",
      "Step 1059/10000- lr: [9.029296812121213e-06] - Loss total: 4.528395175933838, Last rpr Loss: 0.9187619686126709, Last lagvar Loss: 1.6835153102874756\n",
      "Step 1060/10000- lr: [9.028286715151516e-06] - Loss total: 4.5352020263671875, Last rpr Loss: 0.8780543804168701, Last lagvar Loss: 1.7327141761779785\n",
      "Step 1061/10000- lr: [9.02727661818182e-06] - Loss total: 4.524524211883545, Last rpr Loss: 0.9464371204376221, Last lagvar Loss: 1.6575870513916016\n",
      "Step 1062/10000- lr: [9.026266521212121e-06] - Loss total: 4.525237083435059, Last rpr Loss: 1.1036770343780518, Last lagvar Loss: 1.501053810119629\n",
      "Step 1063/10000- lr: [9.025256424242424e-06] - Loss total: 4.533186912536621, Last rpr Loss: 1.1601064205169678, Last lagvar Loss: 1.456373929977417\n",
      "Step 1064/10000- lr: [9.024246327272728e-06] - Loss total: 4.52055025100708, Last rpr Loss: 1.06582772731781, Last lagvar Loss: 1.5369458198547363\n",
      "Step 1065/10000- lr: [9.023236230303031e-06] - Loss total: 4.517806053161621, Last rpr Loss: 0.9098191261291504, Last lagvar Loss: 1.6840728521347046\n",
      "Step 1066/10000- lr: [9.022226133333334e-06] - Loss total: 4.521016597747803, Last rpr Loss: 0.8925164937973022, Last lagvar Loss: 1.7078696489334106\n",
      "Step 1067/10000- lr: [9.021216036363637e-06] - Loss total: 4.514224529266357, Last rpr Loss: 0.9873420596122742, Last lagvar Loss: 1.609670877456665\n",
      "Step 1068/10000- lr: [9.02020593939394e-06] - Loss total: 4.508413791656494, Last rpr Loss: 1.0711748600006104, Last lagvar Loss: 1.518216848373413\n",
      "Step 1069/10000- lr: [9.019195842424244e-06] - Loss total: 4.507283687591553, Last rpr Loss: 1.06147038936615, Last lagvar Loss: 1.527980089187622\n",
      "Step 1070/10000- lr: [9.018185745454546e-06] - Loss total: 4.50585412979126, Last rpr Loss: 0.9566062688827515, Last lagvar Loss: 1.6282310485839844\n",
      "Step 1071/10000- lr: [9.017175648484849e-06] - Loss total: 4.500341892242432, Last rpr Loss: 0.9288932681083679, Last lagvar Loss: 1.650943398475647\n",
      "Step 1072/10000- lr: [9.016165551515152e-06] - Loss total: 4.49979305267334, Last rpr Loss: 1.025977611541748, Last lagvar Loss: 1.5570003986358643\n",
      "Step 1073/10000- lr: [9.015155454545455e-06] - Loss total: 4.497875690460205, Last rpr Loss: 1.054796814918518, Last lagvar Loss: 1.5262229442596436\n",
      "Step 1074/10000- lr: [9.014145357575759e-06] - Loss total: 4.489006042480469, Last rpr Loss: 0.9907673597335815, Last lagvar Loss: 1.5793185234069824\n",
      "Step 1075/10000- lr: [9.013135260606062e-06] - Loss total: 4.490759372711182, Last rpr Loss: 0.9678965210914612, Last lagvar Loss: 1.603573203086853\n",
      "Step 1076/10000- lr: [9.012125163636364e-06] - Loss total: 4.483720302581787, Last rpr Loss: 1.0058043003082275, Last lagvar Loss: 1.5606021881103516\n",
      "Step 1077/10000- lr: [9.011115066666667e-06] - Loss total: 4.48488187789917, Last rpr Loss: 1.0304611921310425, Last lagvar Loss: 1.5390779972076416\n",
      "Step 1078/10000- lr: [9.01010496969697e-06] - Loss total: 4.47968053817749, Last rpr Loss: 0.9698711633682251, Last lagvar Loss: 1.5934072732925415\n",
      "Step 1079/10000- lr: [9.009094872727273e-06] - Loss total: 4.477381706237793, Last rpr Loss: 0.9757347106933594, Last lagvar Loss: 1.5848934650421143\n",
      "Step 1080/10000- lr: [9.008084775757577e-06] - Loss total: 4.47519588470459, Last rpr Loss: 1.0358359813690186, Last lagvar Loss: 1.524890422821045\n",
      "Step 1081/10000- lr: [9.00707467878788e-06] - Loss total: 4.470721244812012, Last rpr Loss: 0.9883177280426025, Last lagvar Loss: 1.5680865049362183\n",
      "Step 1082/10000- lr: [9.006064581818183e-06] - Loss total: 4.469137668609619, Last rpr Loss: 0.9624255895614624, Last lagvar Loss: 1.5925352573394775\n",
      "Step 1083/10000- lr: [9.005054484848485e-06] - Loss total: 4.464461803436279, Last rpr Loss: 1.0158404111862183, Last lagvar Loss: 1.5354721546173096\n",
      "Step 1084/10000- lr: [9.004044387878788e-06] - Loss total: 4.46239709854126, Last rpr Loss: 1.0242416858673096, Last lagvar Loss: 1.5261178016662598\n",
      "Step 1085/10000- lr: [9.003034290909091e-06] - Loss total: 4.458780765533447, Last rpr Loss: 0.9701403975486755, Last lagvar Loss: 1.576185941696167\n",
      "Step 1086/10000- lr: [9.002024193939395e-06] - Loss total: 4.455743312835693, Last rpr Loss: 0.9916921854019165, Last lagvar Loss: 1.553335189819336\n",
      "Step 1087/10000- lr: [9.001014096969698e-06] - Loss total: 4.451927661895752, Last rpr Loss: 1.014208436012268, Last lagvar Loss: 1.5275018215179443\n",
      "Step 1088/10000- lr: [9.000004000000001e-06] - Loss total: 4.449573516845703, Last rpr Loss: 0.9856433272361755, Last lagvar Loss: 1.553748369216919\n",
      "Step 1089/10000- lr: [8.998993903030303e-06] - Loss total: 4.4449944496154785, Last rpr Loss: 0.990669846534729, Last lagvar Loss: 1.5451785326004028\n",
      "Step 1090/10000- lr: [8.997983806060606e-06] - Loss total: 4.442995548248291, Last rpr Loss: 1.0121119022369385, Last lagvar Loss: 1.523493766784668\n",
      "Step 1091/10000- lr: [8.99697370909091e-06] - Loss total: 4.438772678375244, Last rpr Loss: 0.9771813154220581, Last lagvar Loss: 1.5535589456558228\n",
      "Step 1092/10000- lr: [8.995963612121213e-06] - Loss total: 4.435644149780273, Last rpr Loss: 0.9983043670654297, Last lagvar Loss: 1.5303155183792114\n",
      "Step 1093/10000- lr: [8.994953515151516e-06] - Loss total: 4.432150840759277, Last rpr Loss: 1.016793131828308, Last lagvar Loss: 1.5096302032470703\n",
      "Step 1094/10000- lr: [8.99394341818182e-06] - Loss total: 4.429051876068115, Last rpr Loss: 0.9763016700744629, Last lagvar Loss: 1.5473449230194092\n",
      "Step 1095/10000- lr: [8.992933321212122e-06] - Loss total: 4.424990653991699, Last rpr Loss: 0.9893474578857422, Last lagvar Loss: 1.53084135055542\n",
      "Step 1096/10000- lr: [8.991923224242426e-06] - Loss total: 4.422466278076172, Last rpr Loss: 1.0231382846832275, Last lagvar Loss: 1.495823621749878\n",
      "Step 1097/10000- lr: [8.990913127272727e-06] - Loss total: 4.418489933013916, Last rpr Loss: 0.9809703826904297, Last lagvar Loss: 1.5338671207427979\n",
      "Step 1098/10000- lr: [8.98990303030303e-06] - Loss total: 4.415098667144775, Last rpr Loss: 0.9893895387649536, Last lagvar Loss: 1.5233427286148071\n",
      "Step 1099/10000- lr: [8.988892933333334e-06] - Loss total: 4.411805152893066, Last rpr Loss: 1.0156545639038086, Last lagvar Loss: 1.4947781562805176\n",
      "Step 1100/10000- lr: [8.987882836363637e-06] - Loss total: 4.408572196960449, Last rpr Loss: 0.9854921102523804, Last lagvar Loss: 1.5216460227966309\n",
      "Step 1101/10000- lr: [8.98687273939394e-06] - Loss total: 4.404618740081787, Last rpr Loss: 0.9941248893737793, Last lagvar Loss: 1.5100245475769043\n",
      "Step 1102/10000- lr: [8.985862642424244e-06] - Loss total: 4.401827812194824, Last rpr Loss: 1.0113966464996338, Last lagvar Loss: 1.4913127422332764\n",
      "Step 1103/10000- lr: [8.984852545454545e-06] - Loss total: 4.398250102996826, Last rpr Loss: 0.9785740375518799, Last lagvar Loss: 1.520519733428955\n",
      "Step 1104/10000- lr: [8.983842448484849e-06] - Loss total: 4.394618034362793, Last rpr Loss: 1.0026334524154663, Last lagvar Loss: 1.4938178062438965\n",
      "Step 1105/10000- lr: [8.982832351515152e-06] - Loss total: 4.3913254737854, Last rpr Loss: 1.0124695301055908, Last lagvar Loss: 1.4816346168518066\n",
      "Step 1106/10000- lr: [8.981822254545455e-06] - Loss total: 4.388241767883301, Last rpr Loss: 0.9756747484207153, Last lagvar Loss: 1.5156571865081787\n",
      "Step 1107/10000- lr: [8.980812157575758e-06] - Loss total: 4.384311199188232, Last rpr Loss: 1.0017080307006836, Last lagvar Loss: 1.4865885972976685\n",
      "Step 1108/10000- lr: [8.979802060606062e-06] - Loss total: 4.381195068359375, Last rpr Loss: 1.0103154182434082, Last lagvar Loss: 1.4755747318267822\n",
      "Step 1109/10000- lr: [8.978791963636365e-06] - Loss total: 4.377997398376465, Last rpr Loss: 0.9758849143981934, Last lagvar Loss: 1.5070562362670898\n",
      "Step 1110/10000- lr: [8.977781866666668e-06] - Loss total: 4.374369144439697, Last rpr Loss: 1.0033416748046875, Last lagvar Loss: 1.4770681858062744\n",
      "Step 1111/10000- lr: [8.97677176969697e-06] - Loss total: 4.370865345001221, Last rpr Loss: 1.0026568174362183, Last lagvar Loss: 1.4747045040130615\n",
      "Step 1112/10000- lr: [8.975761672727273e-06] - Loss total: 4.367805480957031, Last rpr Loss: 0.9831942319869995, Last lagvar Loss: 1.4913654327392578\n",
      "Step 1113/10000- lr: [8.974751575757576e-06] - Loss total: 4.364339351654053, Last rpr Loss: 1.0080301761627197, Last lagvar Loss: 1.4642081260681152\n",
      "Step 1114/10000- lr: [8.97374147878788e-06] - Loss total: 4.360861301422119, Last rpr Loss: 0.9928914308547974, Last lagvar Loss: 1.4762299060821533\n",
      "Step 1115/10000- lr: [8.972731381818183e-06] - Loss total: 4.357607364654541, Last rpr Loss: 0.9912432432174683, Last lagvar Loss: 1.4751181602478027\n",
      "Step 1116/10000- lr: [8.971721284848486e-06] - Loss total: 4.354432582855225, Last rpr Loss: 1.0098111629486084, Last lagvar Loss: 1.454378604888916\n",
      "Step 1117/10000- lr: [8.970711187878788e-06] - Loss total: 4.351136684417725, Last rpr Loss: 0.9858700037002563, Last lagvar Loss: 1.475316047668457\n",
      "Step 1118/10000- lr: [8.969701090909091e-06] - Loss total: 4.347761631011963, Last rpr Loss: 0.9978348612785339, Last lagvar Loss: 1.4608025550842285\n",
      "Step 1119/10000- lr: [8.968690993939394e-06] - Loss total: 4.344618320465088, Last rpr Loss: 1.0047247409820557, Last lagvar Loss: 1.4515069723129272\n",
      "Step 1120/10000- lr: [8.967680896969698e-06] - Loss total: 4.341473579406738, Last rpr Loss: 0.9863110780715942, Last lagvar Loss: 1.467141032218933\n",
      "Step 1121/10000- lr: [8.966670800000001e-06] - Loss total: 4.3382487297058105, Last rpr Loss: 1.003502368927002, Last lagvar Loss: 1.4477198123931885\n",
      "Step 1122/10000- lr: [8.965660703030304e-06] - Loss total: 4.3349738121032715, Last rpr Loss: 0.9950847625732422, Last lagvar Loss: 1.4532922506332397\n",
      "Step 1123/10000- lr: [8.964650606060607e-06] - Loss total: 4.331869602203369, Last rpr Loss: 0.9930315613746643, Last lagvar Loss: 1.4528188705444336\n",
      "Step 1124/10000- lr: [8.96364050909091e-06] - Loss total: 4.3287577629089355, Last rpr Loss: 1.0046390295028687, Last lagvar Loss: 1.438974142074585\n",
      "Step 1125/10000- lr: [8.962630412121212e-06] - Loss total: 4.325638771057129, Last rpr Loss: 0.9889172315597534, Last lagvar Loss: 1.4519426822662354\n",
      "Step 1126/10000- lr: [8.961620315151516e-06] - Loss total: 4.322458744049072, Last rpr Loss: 1.000666618347168, Last lagvar Loss: 1.4377540349960327\n",
      "Step 1127/10000- lr: [8.960610218181819e-06] - Loss total: 4.319362163543701, Last rpr Loss: 1.0000823736190796, Last lagvar Loss: 1.4358186721801758\n",
      "Step 1128/10000- lr: [8.959600121212122e-06] - Loss total: 4.316319465637207, Last rpr Loss: 0.990444004535675, Last lagvar Loss: 1.442887544631958\n",
      "Step 1129/10000- lr: [8.958590024242425e-06] - Loss total: 4.313254356384277, Last rpr Loss: 1.0033133029937744, Last lagvar Loss: 1.427728533744812\n",
      "Step 1130/10000- lr: [8.957579927272727e-06] - Loss total: 4.310178279876709, Last rpr Loss: 0.992834210395813, Last lagvar Loss: 1.4354846477508545\n",
      "Step 1131/10000- lr: [8.95656983030303e-06] - Loss total: 4.307098865509033, Last rpr Loss: 0.997847318649292, Last lagvar Loss: 1.4280526638031006\n",
      "Step 1132/10000- lr: [8.955559733333334e-06] - Loss total: 4.304089546203613, Last rpr Loss: 0.9990107417106628, Last lagvar Loss: 1.4244943857192993\n",
      "Step 1133/10000- lr: [8.954549636363637e-06] - Loss total: 4.301087856292725, Last rpr Loss: 0.9910135269165039, Last lagvar Loss: 1.4298783540725708\n",
      "Step 1134/10000- lr: [8.95353953939394e-06] - Loss total: 4.298092365264893, Last rpr Loss: 1.0022261142730713, Last lagvar Loss: 1.4163799285888672\n",
      "Step 1135/10000- lr: [8.952529442424243e-06] - Loss total: 4.295076370239258, Last rpr Loss: 0.9920481443405151, Last lagvar Loss: 1.423944354057312\n",
      "Step 1136/10000- lr: [8.951519345454547e-06] - Loss total: 4.292080402374268, Last rpr Loss: 0.9967688322067261, Last lagvar Loss: 1.4168407917022705\n",
      "Step 1137/10000- lr: [8.95050924848485e-06] - Loss total: 4.289116382598877, Last rpr Loss: 0.9981288313865662, Last lagvar Loss: 1.4130332469940186\n",
      "Step 1138/10000- lr: [8.949499151515151e-06] - Loss total: 4.286170959472656, Last rpr Loss: 0.9920570850372314, Last lagvar Loss: 1.4165856838226318\n",
      "Step 1139/10000- lr: [8.948489054545455e-06] - Loss total: 4.283237934112549, Last rpr Loss: 1.000195026397705, Last lagvar Loss: 1.4061932563781738\n",
      "Step 1140/10000- lr: [8.947478957575758e-06] - Loss total: 4.280292510986328, Last rpr Loss: 0.9920812249183655, Last lagvar Loss: 1.41170072555542\n",
      "Step 1141/10000- lr: [8.946468860606061e-06] - Loss total: 4.277360916137695, Last rpr Loss: 0.9986695051193237, Last lagvar Loss: 1.4027730226516724\n",
      "Step 1142/10000- lr: [8.945458763636365e-06] - Loss total: 4.274439811706543, Last rpr Loss: 0.9957929849624634, Last lagvar Loss: 1.4031909704208374\n",
      "Step 1143/10000- lr: [8.944448666666668e-06] - Loss total: 4.271542549133301, Last rpr Loss: 0.9942706823348999, Last lagvar Loss: 1.4022712707519531\n",
      "Step 1144/10000- lr: [8.94343856969697e-06] - Loss total: 4.268660068511963, Last rpr Loss: 0.9995178580284119, Last lagvar Loss: 1.3946778774261475\n",
      "Step 1145/10000- lr: [8.942428472727273e-06] - Loss total: 4.265781879425049, Last rpr Loss: 0.9925462007522583, Last lagvar Loss: 1.399119257926941\n",
      "Step 1146/10000- lr: [8.941418375757576e-06] - Loss total: 4.262910842895508, Last rpr Loss: 0.9992035627365112, Last lagvar Loss: 1.3901610374450684\n",
      "Step 1147/10000- lr: [8.94040827878788e-06] - Loss total: 4.260039329528809, Last rpr Loss: 0.9937781095504761, Last lagvar Loss: 1.3930375576019287\n",
      "Step 1148/10000- lr: [8.939398181818183e-06] - Loss total: 4.257181644439697, Last rpr Loss: 0.9977197647094727, Last lagvar Loss: 1.386704921722412\n",
      "Step 1149/10000- lr: [8.938388084848486e-06] - Loss total: 4.25433349609375, Last rpr Loss: 0.9964351654052734, Last lagvar Loss: 1.385521411895752\n",
      "Step 1150/10000- lr: [8.937377987878789e-06] - Loss total: 4.251494407653809, Last rpr Loss: 0.9950649738311768, Last lagvar Loss: 1.3843977451324463\n",
      "Step 1151/10000- lr: [8.936367890909092e-06] - Loss total: 4.248664379119873, Last rpr Loss: 0.998744547367096, Last lagvar Loss: 1.3782857656478882\n",
      "Step 1152/10000- lr: [8.935357793939394e-06] - Loss total: 4.2458343505859375, Last rpr Loss: 0.9935945272445679, Last lagvar Loss: 1.3808724880218506\n",
      "Step 1153/10000- lr: [8.934347696969697e-06] - Loss total: 4.243007183074951, Last rpr Loss: 0.998960554599762, Last lagvar Loss: 1.373085379600525\n",
      "Step 1154/10000- lr: [8.9333376e-06] - Loss total: 4.240175724029541, Last rpr Loss: 0.9937431812286377, Last lagvar Loss: 1.375719666481018\n",
      "Step 1155/10000- lr: [8.932327503030304e-06] - Loss total: 4.237339496612549, Last rpr Loss: 0.9984959363937378, Last lagvar Loss: 1.3685481548309326\n",
      "Step 1156/10000- lr: [8.931317406060607e-06] - Loss total: 4.234499931335449, Last rpr Loss: 0.9947923421859741, Last lagvar Loss: 1.369777798652649\n",
      "Step 1157/10000- lr: [8.93030730909091e-06] - Loss total: 4.231649875640869, Last rpr Loss: 0.9975414872169495, Last lagvar Loss: 1.364670753479004\n",
      "Step 1158/10000- lr: [8.929297212121212e-06] - Loss total: 4.228796005249023, Last rpr Loss: 0.9967948198318481, Last lagvar Loss: 1.3630859851837158\n",
      "Step 1159/10000- lr: [8.928287115151515e-06] - Loss total: 4.225938320159912, Last rpr Loss: 0.9965522289276123, Last lagvar Loss: 1.3610646724700928\n",
      "Step 1160/10000- lr: [8.927277018181819e-06] - Loss total: 4.223082065582275, Last rpr Loss: 0.9981165528297424, Last lagvar Loss: 1.3572213649749756\n",
      "Step 1161/10000- lr: [8.926266921212122e-06] - Loss total: 4.220225811004639, Last rpr Loss: 0.9959242939949036, Last lagvar Loss: 1.35698401927948\n",
      "Step 1162/10000- lr: [8.925256824242425e-06] - Loss total: 4.217367649078369, Last rpr Loss: 0.9990519285202026, Last lagvar Loss: 1.3513813018798828\n",
      "Step 1163/10000- lr: [8.924246727272728e-06] - Loss total: 4.214510440826416, Last rpr Loss: 0.9949360489845276, Last lagvar Loss: 1.3528685569763184\n",
      "Step 1164/10000- lr: [8.923236630303032e-06] - Loss total: 4.211657524108887, Last rpr Loss: 0.9996806383132935, Last lagvar Loss: 1.3455965518951416\n",
      "Step 1165/10000- lr: [8.922226533333335e-06] - Loss total: 4.2088117599487305, Last rpr Loss: 0.9939461350440979, Last lagvar Loss: 1.3487234115600586\n",
      "Step 1166/10000- lr: [8.921216436363636e-06] - Loss total: 4.205981254577637, Last rpr Loss: 0.9999778866767883, Last lagvar Loss: 1.3402715921401978\n",
      "Step 1167/10000- lr: [8.92020633939394e-06] - Loss total: 4.203169822692871, Last rpr Loss: 0.9918042421340942, Last lagvar Loss: 1.3458178043365479\n",
      "Step 1168/10000- lr: [8.919196242424243e-06] - Loss total: 4.200380802154541, Last rpr Loss: 1.0010277032852173, Last lagvar Loss: 1.3342311382293701\n",
      "Step 1169/10000- lr: [8.918186145454546e-06] - Loss total: 4.197622776031494, Last rpr Loss: 0.9885672330856323, Last lagvar Loss: 1.3440299034118652\n",
      "Step 1170/10000- lr: [8.91717604848485e-06] - Loss total: 4.1948981285095215, Last rpr Loss: 1.005422830581665, Last lagvar Loss: 1.3249825239181519\n",
      "Step 1171/10000- lr: [8.916165951515153e-06] - Loss total: 4.192259311676025, Last rpr Loss: 0.9838789701461792, Last lagvar Loss: 1.3438292741775513\n",
      "Step 1172/10000- lr: [8.915155854545454e-06] - Loss total: 4.189696788787842, Last rpr Loss: 1.0151621103286743, Last lagvar Loss: 1.310821294784546\n",
      "Step 1173/10000- lr: [8.914145757575758e-06] - Loss total: 4.187488555908203, Last rpr Loss: 0.9716207981109619, Last lagvar Loss: 1.3518085479736328\n",
      "Step 1174/10000- lr: [8.913135660606061e-06] - Loss total: 4.185341835021973, Last rpr Loss: 1.032760739326477, Last lagvar Loss: 1.2899287939071655\n",
      "Step 1175/10000- lr: [8.912125563636364e-06] - Loss total: 4.184545516967773, Last rpr Loss: 0.9484533667564392, Last lagvar Loss: 1.3727335929870605\n",
      "Step 1176/10000- lr: [8.911115466666668e-06] - Loss total: 4.178865432739258, Last rpr Loss: 1.0079820156097412, Last lagvar Loss: 1.308071255683899\n",
      "Step 1177/10000- lr: [8.91010536969697e-06] - Loss total: 4.177560806274414, Last rpr Loss: 1.0318831205368042, Last lagvar Loss: 1.2836408615112305\n",
      "Step 1178/10000- lr: [8.909095272727274e-06] - Loss total: 4.1812357902526855, Last rpr Loss: 0.9221214056015015, Last lagvar Loss: 1.3968396186828613\n",
      "Step 1179/10000- lr: [8.908085175757577e-06] - Loss total: 4.173995018005371, Last rpr Loss: 0.9533781409263611, Last lagvar Loss: 1.3584074974060059\n",
      "Step 1180/10000- lr: [8.907075078787879e-06] - Loss total: 4.191498756408691, Last rpr Loss: 1.1557059288024902, Last lagvar Loss: 1.183632493019104\n",
      "Step 1181/10000- lr: [8.906064981818182e-06] - Loss total: 4.1947126388549805, Last rpr Loss: 1.178735613822937, Last lagvar Loss: 1.1639703512191772\n",
      "Step 1182/10000- lr: [8.905054884848486e-06] - Loss total: 4.165711402893066, Last rpr Loss: 1.0197160243988037, Last lagvar Loss: 1.285707712173462\n",
      "Step 1183/10000- lr: [8.904044787878789e-06] - Loss total: 4.18384313583374, Last rpr Loss: 0.8787257075309753, Last lagvar Loss: 1.4452433586120605\n",
      "Step 1184/10000- lr: [8.903034690909092e-06] - Loss total: 4.182770729064941, Last rpr Loss: 0.8739621639251709, Last lagvar Loss: 1.4492601156234741\n",
      "Step 1185/10000- lr: [8.902024593939395e-06] - Loss total: 4.160430431365967, Last rpr Loss: 0.9866704940795898, Last lagvar Loss: 1.3134129047393799\n",
      "Step 1186/10000- lr: [8.901014496969697e-06] - Loss total: 4.186914443969727, Last rpr Loss: 1.179666519165039, Last lagvar Loss: 1.1529326438903809\n",
      "Step 1187/10000- lr: [8.9000044e-06] - Loss total: 4.186151504516602, Last rpr Loss: 1.1857023239135742, Last lagvar Loss: 1.1483352184295654\n",
      "Step 1188/10000- lr: [8.898994303030303e-06] - Loss total: 4.1568922996521, Last rpr Loss: 1.0141098499298096, Last lagvar Loss: 1.284466028213501\n",
      "Step 1189/10000- lr: [8.897984206060607e-06] - Loss total: 4.173539161682129, Last rpr Loss: 0.8721681833267212, Last lagvar Loss: 1.4430744647979736\n",
      "Step 1190/10000- lr: [8.89697410909091e-06] - Loss total: 4.173355579376221, Last rpr Loss: 0.8731809854507446, Last lagvar Loss: 1.4428656101226807\n",
      "Step 1191/10000- lr: [8.895964012121213e-06] - Loss total: 4.158712863922119, Last rpr Loss: 1.001179575920105, Last lagvar Loss: 1.30162513256073\n",
      "Step 1192/10000- lr: [8.894953915151517e-06] - Loss total: 4.156078338623047, Last rpr Loss: 1.0796279907226562, Last lagvar Loss: 1.218675136566162\n",
      "Step 1193/10000- lr: [8.893943818181818e-06] - Loss total: 4.1525654792785645, Last rpr Loss: 1.0201122760772705, Last lagvar Loss: 1.276374340057373\n",
      "Step 1194/10000- lr: [8.892933721212121e-06] - Loss total: 4.156630039215088, Last rpr Loss: 0.9328815937042236, Last lagvar Loss: 1.36684250831604\n",
      "Step 1195/10000- lr: [8.891923624242425e-06] - Loss total: 4.1498260498046875, Last rpr Loss: 0.9770475625991821, Last lagvar Loss: 1.3158550262451172\n",
      "Step 1196/10000- lr: [8.890913527272728e-06] - Loss total: 4.1545281410217285, Last rpr Loss: 1.0925772190093994, Last lagvar Loss: 1.2065246105194092\n",
      "Step 1197/10000- lr: [8.889903430303031e-06] - Loss total: 4.158327579498291, Last rpr Loss: 1.0707474946975708, Last lagvar Loss: 1.2356820106506348\n",
      "Step 1198/10000- lr: [8.888893333333335e-06] - Loss total: 4.149232864379883, Last rpr Loss: 0.9319522380828857, Last lagvar Loss: 1.3595106601715088\n",
      "Step 1199/10000- lr: [8.887883236363636e-06] - Loss total: 4.1461567878723145, Last rpr Loss: 0.9365281462669373, Last lagvar Loss: 1.3515809774398804\n",
      "Step 1200/10000- lr: [8.88687313939394e-06] - Loss total: 4.1503801345825195, Last rpr Loss: 1.0818897485733032, Last lagvar Loss: 1.2150745391845703\n",
      "Step 1201/10000- lr: [8.885863042424243e-06] - Loss total: 4.148045063018799, Last rpr Loss: 1.107926607131958, Last lagvar Loss: 1.1862261295318604\n",
      "Step 1202/10000- lr: [8.884852945454546e-06] - Loss total: 4.138309478759766, Last rpr Loss: 0.9980221390724182, Last lagvar Loss: 1.2846729755401611\n",
      "Step 1203/10000- lr: [8.88384284848485e-06] - Loss total: 4.139499187469482, Last rpr Loss: 0.91675865650177, Last lagvar Loss: 1.3659425973892212\n",
      "Step 1204/10000- lr: [8.882832751515153e-06] - Loss total: 4.138478755950928, Last rpr Loss: 0.9819824695587158, Last lagvar Loss: 1.3024811744689941\n",
      "Step 1205/10000- lr: [8.881822654545456e-06] - Loss total: 4.131605625152588, Last rpr Loss: 1.0109069347381592, Last lagvar Loss: 1.263380527496338\n",
      "Step 1206/10000- lr: [8.880812557575759e-06] - Loss total: 4.13720178604126, Last rpr Loss: 0.9622392654418945, Last lagvar Loss: 1.319704294204712\n",
      "Step 1207/10000- lr: [8.87980246060606e-06] - Loss total: 4.135143756866455, Last rpr Loss: 0.9905849695205688, Last lagvar Loss: 1.2900221347808838\n",
      "Step 1208/10000- lr: [8.878792363636364e-06] - Loss total: 4.133932590484619, Last rpr Loss: 1.0764893293380737, Last lagvar Loss: 1.206502914428711\n",
      "Step 1209/10000- lr: [8.877782266666667e-06] - Loss total: 4.13054895401001, Last rpr Loss: 1.051307201385498, Last lagvar Loss: 1.226592779159546\n",
      "Step 1210/10000- lr: [8.87677216969697e-06] - Loss total: 4.13181209564209, Last rpr Loss: 0.9433761835098267, Last lagvar Loss: 1.3312294483184814\n",
      "Step 1211/10000- lr: [8.875762072727274e-06] - Loss total: 4.131259918212891, Last rpr Loss: 0.9645755887031555, Last lagvar Loss: 1.3114333152770996\n",
      "Step 1212/10000- lr: [8.874751975757577e-06] - Loss total: 4.123208045959473, Last rpr Loss: 1.049664855003357, Last lagvar Loss: 1.218616247177124\n",
      "Step 1213/10000- lr: [8.873741878787879e-06] - Loss total: 4.124147415161133, Last rpr Loss: 1.0052839517593384, Last lagvar Loss: 1.2647125720977783\n",
      "Step 1214/10000- lr: [8.872731781818182e-06] - Loss total: 4.123793601989746, Last rpr Loss: 0.9392291903495789, Last lagvar Loss: 1.3300423622131348\n",
      "Step 1215/10000- lr: [8.871721684848485e-06] - Loss total: 4.11785888671875, Last rpr Loss: 0.997626781463623, Last lagvar Loss: 1.2654058933258057\n",
      "Step 1216/10000- lr: [8.870711587878788e-06] - Loss total: 4.119237422943115, Last rpr Loss: 1.0335195064544678, Last lagvar Loss: 1.2313053607940674\n",
      "Step 1217/10000- lr: [8.869701490909092e-06] - Loss total: 4.1172566413879395, Last rpr Loss: 0.9609278440475464, Last lagvar Loss: 1.302074670791626\n",
      "Step 1218/10000- lr: [8.868691393939395e-06] - Loss total: 4.112112998962402, Last rpr Loss: 0.9718070030212402, Last lagvar Loss: 1.2846815586090088\n",
      "Step 1219/10000- lr: [8.867681296969698e-06] - Loss total: 4.117034435272217, Last rpr Loss: 1.080843210220337, Last lagvar Loss: 1.1847666501998901\n",
      "Step 1220/10000- lr: [8.866671200000002e-06] - Loss total: 4.1106672286987305, Last rpr Loss: 1.0321797132492065, Last lagvar Loss: 1.2255456447601318\n",
      "Step 1221/10000- lr: [8.865661103030303e-06] - Loss total: 4.11488151550293, Last rpr Loss: 0.9156973361968994, Last lagvar Loss: 1.3436282873153687\n",
      "Step 1222/10000- lr: [8.864651006060606e-06] - Loss total: 4.1111159324646, Last rpr Loss: 0.9436254501342773, Last lagvar Loss: 1.3126072883605957\n",
      "Step 1223/10000- lr: [8.86364090909091e-06] - Loss total: 4.120736598968506, Last rpr Loss: 1.1126881837844849, Last lagvar Loss: 1.1602425575256348\n",
      "Step 1224/10000- lr: [8.862630812121213e-06] - Loss total: 4.115213871002197, Last rpr Loss: 1.1245002746582031, Last lagvar Loss: 1.1423650979995728\n",
      "Step 1225/10000- lr: [8.861620715151516e-06] - Loss total: 4.102452754974365, Last rpr Loss: 0.9921966195106506, Last lagvar Loss: 1.2569057941436768\n",
      "Step 1226/10000- lr: [8.86061061818182e-06] - Loss total: 4.103872299194336, Last rpr Loss: 0.9613698720932007, Last lagvar Loss: 1.2894140481948853\n",
      "Step 1227/10000- lr: [8.859600521212121e-06] - Loss total: 4.100392818450928, Last rpr Loss: 1.0431640148162842, Last lagvar Loss: 1.2045328617095947\n",
      "Step 1228/10000- lr: [8.858590424242424e-06] - Loss total: 4.096828460693359, Last rpr Loss: 1.005988597869873, Last lagvar Loss: 1.2373546361923218\n",
      "Step 1229/10000- lr: [8.857580327272728e-06] - Loss total: 4.10161018371582, Last rpr Loss: 0.9049090147018433, Last lagvar Loss: 1.3443191051483154\n",
      "Step 1230/10000- lr: [8.856570230303031e-06] - Loss total: 4.095442295074463, Last rpr Loss: 0.9329980611801147, Last lagvar Loss: 1.3095836639404297\n",
      "Step 1231/10000- lr: [8.855560133333334e-06] - Loss total: 4.104805946350098, Last rpr Loss: 1.1138120889663696, Last lagvar Loss: 1.1407697200775146\n",
      "Step 1232/10000- lr: [8.854550036363638e-06] - Loss total: 4.108345031738281, Last rpr Loss: 1.1498847007751465, Last lagvar Loss: 1.1120201349258423\n",
      "Step 1233/10000- lr: [8.85353993939394e-06] - Loss total: 4.089229583740234, Last rpr Loss: 1.0214006900787354, Last lagvar Loss: 1.2159888744354248\n",
      "Step 1234/10000- lr: [8.852529842424242e-06] - Loss total: 4.098468780517578, Last rpr Loss: 0.9103338718414307, Last lagvar Loss: 1.3336873054504395\n",
      "Step 1235/10000- lr: [8.851519745454546e-06] - Loss total: 4.0944390296936035, Last rpr Loss: 0.9301958084106445, Last lagvar Loss: 1.3115415573120117\n",
      "Step 1236/10000- lr: [8.850509648484849e-06] - Loss total: 4.093699932098389, Last rpr Loss: 1.072694182395935, Last lagvar Loss: 1.1715925931930542\n",
      "Step 1237/10000- lr: [8.849499551515152e-06] - Loss total: 4.09105920791626, Last rpr Loss: 1.0854213237762451, Last lagvar Loss: 1.15544593334198\n",
      "Step 1238/10000- lr: [8.848489454545455e-06] - Loss total: 4.084345817565918, Last rpr Loss: 0.9706063270568848, Last lagvar Loss: 1.2629756927490234\n",
      "Step 1239/10000- lr: [8.847479357575759e-06] - Loss total: 4.082361698150635, Last rpr Loss: 0.9658742547035217, Last lagvar Loss: 1.2644450664520264\n",
      "Step 1240/10000- lr: [8.846469260606062e-06] - Loss total: 4.086512565612793, Last rpr Loss: 1.085952639579773, Last lagvar Loss: 1.151425838470459\n",
      "Step 1241/10000- lr: [8.845459163636364e-06] - Loss total: 4.081618309020996, Last rpr Loss: 1.0645955801010132, Last lagvar Loss: 1.1666544675827026\n",
      "Step 1242/10000- lr: [8.844449066666667e-06] - Loss total: 4.083487510681152, Last rpr Loss: 0.9252565503120422, Last lagvar Loss: 1.3059706687927246\n",
      "Step 1243/10000- lr: [8.84343896969697e-06] - Loss total: 4.083708763122559, Last rpr Loss: 0.9223257303237915, Last lagvar Loss: 1.3104244470596313\n",
      "Step 1244/10000- lr: [8.842428872727273e-06] - Loss total: 4.075167655944824, Last rpr Loss: 1.0318647623062134, Last lagvar Loss: 1.1927509307861328\n",
      "Step 1245/10000- lr: [8.841418775757577e-06] - Loss total: 4.074286937713623, Last rpr Loss: 1.034210205078125, Last lagvar Loss: 1.1903091669082642\n",
      "Step 1246/10000- lr: [8.84040867878788e-06] - Loss total: 4.076255798339844, Last rpr Loss: 0.933503270149231, Last lagvar Loss: 1.2925102710723877\n",
      "Step 1247/10000- lr: [8.839398581818183e-06] - Loss total: 4.070689678192139, Last rpr Loss: 0.9489747285842896, Last lagvar Loss: 1.270617961883545\n",
      "Step 1248/10000- lr: [8.838388484848485e-06] - Loss total: 4.0808424949646, Last rpr Loss: 1.1061078310012817, Last lagvar Loss: 1.1277403831481934\n",
      "Step 1249/10000- lr: [8.837378387878788e-06] - Loss total: 4.083704471588135, Last rpr Loss: 1.1241674423217773, Last lagvar Loss: 1.1152009963989258\n",
      "Step 1250/10000- lr: [8.836368290909091e-06] - Loss total: 4.065274238586426, Last rpr Loss: 0.9966863989830017, Last lagvar Loss: 1.218630075454712\n",
      "Step 1251/10000- lr: [8.835358193939395e-06] - Loss total: 4.072303295135498, Last rpr Loss: 0.9323180913925171, Last lagvar Loss: 1.2887828350067139\n",
      "Step 1252/10000- lr: [8.834348096969698e-06] - Loss total: 4.068732261657715, Last rpr Loss: 0.9780210852622986, Last lagvar Loss: 1.242379903793335\n",
      "Step 1253/10000- lr: [8.833338000000001e-06] - Loss total: 4.067166805267334, Last rpr Loss: 1.0768473148345947, Last lagvar Loss: 1.1426194906234741\n",
      "Step 1254/10000- lr: [8.832327903030303e-06] - Loss total: 4.065608501434326, Last rpr Loss: 1.0473809242248535, Last lagvar Loss: 1.1705760955810547\n",
      "Step 1255/10000- lr: [8.831317806060606e-06] - Loss total: 4.065235137939453, Last rpr Loss: 0.930317759513855, Last lagvar Loss: 1.2865164279937744\n",
      "Step 1256/10000- lr: [8.83030770909091e-06] - Loss total: 4.060564041137695, Last rpr Loss: 0.943183958530426, Last lagvar Loss: 1.2674742937088013\n",
      "Step 1257/10000- lr: [8.829297612121213e-06] - Loss total: 4.065107822418213, Last rpr Loss: 1.0833386182785034, Last lagvar Loss: 1.1358880996704102\n",
      "Step 1258/10000- lr: [8.828287515151516e-06] - Loss total: 4.061931610107422, Last rpr Loss: 1.0761929750442505, Last lagvar Loss: 1.1401252746582031\n",
      "Step 1259/10000- lr: [8.82727741818182e-06] - Loss total: 4.057155609130859, Last rpr Loss: 0.9502339363098145, Last lagvar Loss: 1.257944941520691\n",
      "Step 1260/10000- lr: [8.826267321212122e-06] - Loss total: 4.0554986000061035, Last rpr Loss: 0.9648125171661377, Last lagvar Loss: 1.242807149887085\n",
      "Step 1261/10000- lr: [8.825257224242426e-06] - Loss total: 4.05891752243042, Last rpr Loss: 1.0877814292907715, Last lagvar Loss: 1.1252250671386719\n",
      "Step 1262/10000- lr: [8.824247127272727e-06] - Loss total: 4.0551228523254395, Last rpr Loss: 1.0623118877410889, Last lagvar Loss: 1.1457387208938599\n",
      "Step 1263/10000- lr: [8.82323703030303e-06] - Loss total: 4.0547966957092285, Last rpr Loss: 0.9234992265701294, Last lagvar Loss: 1.283185601234436\n",
      "Step 1264/10000- lr: [8.822226933333334e-06] - Loss total: 4.053262233734131, Last rpr Loss: 0.9241372346878052, Last lagvar Loss: 1.2806286811828613\n",
      "Step 1265/10000- lr: [8.821216836363637e-06] - Loss total: 4.048401355743408, Last rpr Loss: 1.0523548126220703, Last lagvar Loss: 1.1492842435836792\n",
      "Step 1266/10000- lr: [8.82020673939394e-06] - Loss total: 4.04680061340332, Last rpr Loss: 1.0506670475006104, Last lagvar Loss: 1.1499873399734497\n",
      "Step 1267/10000- lr: [8.819196642424244e-06] - Loss total: 4.0507917404174805, Last rpr Loss: 0.924231767654419, Last lagvar Loss: 1.2783088684082031\n",
      "Step 1268/10000- lr: [8.818186545454545e-06] - Loss total: 4.048591613769531, Last rpr Loss: 0.93144291639328, Last lagvar Loss: 1.2699395418167114\n",
      "Step 1269/10000- lr: [8.817176448484849e-06] - Loss total: 4.045765399932861, Last rpr Loss: 1.0599699020385742, Last lagvar Loss: 1.1399214267730713\n",
      "Step 1270/10000- lr: [8.816166351515152e-06] - Loss total: 4.043985843658447, Last rpr Loss: 1.0632164478302002, Last lagvar Loss: 1.1350572109222412\n",
      "Step 1271/10000- lr: [8.815156254545455e-06] - Loss total: 4.043558597564697, Last rpr Loss: 0.9423060417175293, Last lagvar Loss: 1.2547240257263184\n",
      "Step 1272/10000- lr: [8.814146157575758e-06] - Loss total: 4.040863513946533, Last rpr Loss: 0.9457715749740601, Last lagvar Loss: 1.2483696937561035\n",
      "Step 1273/10000- lr: [8.813136060606062e-06] - Loss total: 4.042884826660156, Last rpr Loss: 1.076735019683838, Last lagvar Loss: 1.121462345123291\n",
      "Step 1274/10000- lr: [8.812125963636365e-06] - Loss total: 4.04141092300415, Last rpr Loss: 1.0750459432601929, Last lagvar Loss: 1.121862530708313\n",
      "Step 1275/10000- lr: [8.811115866666667e-06] - Loss total: 4.036523342132568, Last rpr Loss: 0.9490330219268799, Last lagvar Loss: 1.2409567832946777\n",
      "Step 1276/10000- lr: [8.81010576969697e-06] - Loss total: 4.034736633300781, Last rpr Loss: 0.9564914703369141, Last lagvar Loss: 1.2321593761444092\n",
      "Step 1277/10000- lr: [8.809095672727273e-06] - Loss total: 4.039247512817383, Last rpr Loss: 1.0873894691467285, Last lagvar Loss: 1.1082441806793213\n",
      "Step 1278/10000- lr: [8.808085575757576e-06] - Loss total: 4.036490440368652, Last rpr Loss: 1.0776128768920898, Last lagvar Loss: 1.115078330039978\n",
      "Step 1279/10000- lr: [8.80707547878788e-06] - Loss total: 4.032086372375488, Last rpr Loss: 0.9497360587120056, Last lagvar Loss: 1.2367855310440063\n",
      "Step 1280/10000- lr: [8.806065381818183e-06] - Loss total: 4.030097961425781, Last rpr Loss: 0.9552479982376099, Last lagvar Loss: 1.22933030128479\n",
      "Step 1281/10000- lr: [8.805055284848485e-06] - Loss total: 4.033244609832764, Last rpr Loss: 1.080198884010315, Last lagvar Loss: 1.1099821329116821\n",
      "Step 1282/10000- lr: [8.804045187878788e-06] - Loss total: 4.0302252769470215, Last rpr Loss: 1.0639281272888184, Last lagvar Loss: 1.1229125261306763\n",
      "Step 1283/10000- lr: [8.803035090909091e-06] - Loss total: 4.028539657592773, Last rpr Loss: 0.9376437664031982, Last lagvar Loss: 1.2458226680755615\n",
      "Step 1284/10000- lr: [8.802024993939394e-06] - Loss total: 4.026346206665039, Last rpr Loss: 0.9491428732872009, Last lagvar Loss: 1.2323055267333984\n",
      "Step 1285/10000- lr: [8.801014896969698e-06] - Loss total: 4.027781963348389, Last rpr Loss: 1.081061840057373, Last lagvar Loss: 1.1046457290649414\n",
      "Step 1286/10000- lr: [8.800004800000001e-06] - Loss total: 4.024745464324951, Last rpr Loss: 1.0654551982879639, Last lagvar Loss: 1.1165547370910645\n",
      "Step 1287/10000- lr: [8.798994703030304e-06] - Loss total: 4.024475574493408, Last rpr Loss: 0.9325782060623169, Last lagvar Loss: 1.2481584548950195\n",
      "Step 1288/10000- lr: [8.797984606060607e-06] - Loss total: 4.0222954750061035, Last rpr Loss: 0.9366821050643921, Last lagvar Loss: 1.2419917583465576\n",
      "Step 1289/10000- lr: [8.796974509090909e-06] - Loss total: 4.0223612785339355, Last rpr Loss: 1.068969488143921, Last lagvar Loss: 1.1112799644470215\n",
      "Step 1290/10000- lr: [8.795964412121212e-06] - Loss total: 4.020002841949463, Last rpr Loss: 1.0625752210617065, Last lagvar Loss: 1.115473747253418\n",
      "Step 1291/10000- lr: [8.794954315151516e-06] - Loss total: 4.019958972930908, Last rpr Loss: 0.9351783394813538, Last lagvar Loss: 1.2416532039642334\n",
      "Step 1292/10000- lr: [8.793944218181819e-06] - Loss total: 4.01816987991333, Last rpr Loss: 0.941326379776001, Last lagvar Loss: 1.233949899673462\n",
      "Step 1293/10000- lr: [8.792934121212122e-06] - Loss total: 4.017028331756592, Last rpr Loss: 1.0700937509536743, Last lagvar Loss: 1.1060413122177124\n",
      "Step 1294/10000- lr: [8.791924024242425e-06] - Loss total: 4.015009880065918, Last rpr Loss: 1.0622621774673462, Last lagvar Loss: 1.111748456954956\n",
      "Step 1295/10000- lr: [8.790913927272727e-06] - Loss total: 4.015478610992432, Last rpr Loss: 0.9323198795318604, Last lagvar Loss: 1.2407145500183105\n",
      "Step 1296/10000- lr: [8.78990383030303e-06] - Loss total: 4.013647556304932, Last rpr Loss: 0.9349838495254517, Last lagvar Loss: 1.2364588975906372\n",
      "Step 1297/10000- lr: [8.788893733333334e-06] - Loss total: 4.011979103088379, Last rpr Loss: 1.0608634948730469, Last lagvar Loss: 1.1104174852371216\n",
      "Step 1298/10000- lr: [8.787883636363637e-06] - Loss total: 4.009973526000977, Last rpr Loss: 1.0562593936920166, Last lagvar Loss: 1.1132640838623047\n",
      "Step 1299/10000- lr: [8.78687353939394e-06] - Loss total: 4.011231422424316, Last rpr Loss: 0.9321500658988953, Last lagvar Loss: 1.2376750707626343\n",
      "Step 1300/10000- lr: [8.785863442424243e-06] - Loss total: 4.0091376304626465, Last rpr Loss: 0.9358781576156616, Last lagvar Loss: 1.2319552898406982\n",
      "Step 1301/10000- lr: [8.784853345454547e-06] - Loss total: 4.007373809814453, Last rpr Loss: 1.060344934463501, Last lagvar Loss: 1.1070852279663086\n",
      "Step 1302/10000- lr: [8.78384324848485e-06] - Loss total: 4.0052900314331055, Last rpr Loss: 1.0545122623443604, Last lagvar Loss: 1.1109395027160645\n",
      "Step 1303/10000- lr: [8.782833151515152e-06] - Loss total: 4.006676197052002, Last rpr Loss: 0.9332306385040283, Last lagvar Loss: 1.2326189279556274\n",
      "Step 1304/10000- lr: [8.781823054545455e-06] - Loss total: 4.004615783691406, Last rpr Loss: 0.9394229650497437, Last lagvar Loss: 1.2245447635650635\n",
      "Step 1305/10000- lr: [8.780812957575758e-06] - Loss total: 4.0026068687438965, Last rpr Loss: 1.06308114528656, Last lagvar Loss: 1.1006579399108887\n",
      "Step 1306/10000- lr: [8.779802860606061e-06] - Loss total: 4.000502109527588, Last rpr Loss: 1.0525034666061401, Last lagvar Loss: 1.1089632511138916\n",
      "Step 1307/10000- lr: [8.778792763636365e-06] - Loss total: 4.002309322357178, Last rpr Loss: 0.9293832778930664, Last lagvar Loss: 1.233116626739502\n",
      "Step 1308/10000- lr: [8.777782666666668e-06] - Loss total: 4.000175476074219, Last rpr Loss: 0.9349847435951233, Last lagvar Loss: 1.2255659103393555\n",
      "Step 1309/10000- lr: [8.77677256969697e-06] - Loss total: 3.9979183673858643, Last rpr Loss: 1.0596373081207275, Last lagvar Loss: 1.1000757217407227\n",
      "Step 1310/10000- lr: [8.775762472727273e-06] - Loss total: 3.9957966804504395, Last rpr Loss: 1.0514525175094604, Last lagvar Loss: 1.106064796447754\n",
      "Step 1311/10000- lr: [8.774752375757576e-06] - Loss total: 3.997715473175049, Last rpr Loss: 0.9308715462684631, Last lagvar Loss: 1.2276830673217773\n",
      "Step 1312/10000- lr: [8.77374227878788e-06] - Loss total: 3.9954867362976074, Last rpr Loss: 0.9373434782028198, Last lagvar Loss: 1.2191176414489746\n",
      "Step 1313/10000- lr: [8.772732181818183e-06] - Loss total: 3.9933671951293945, Last rpr Loss: 1.0614490509033203, Last lagvar Loss: 1.0944989919662476\n",
      "Step 1314/10000- lr: [8.771722084848486e-06] - Loss total: 3.9911673069000244, Last rpr Loss: 1.0505943298339844, Last lagvar Loss: 1.1028972864151\n",
      "Step 1315/10000- lr: [8.77071198787879e-06] - Loss total: 3.9931678771972656, Last rpr Loss: 0.9284560680389404, Last lagvar Loss: 1.226380705833435\n",
      "Step 1316/10000- lr: [8.769701890909092e-06] - Loss total: 3.990938901901245, Last rpr Loss: 0.9350681304931641, Last lagvar Loss: 1.2176072597503662\n",
      "Step 1317/10000- lr: [8.768691793939394e-06] - Loss total: 3.9886720180511475, Last rpr Loss: 1.0609304904937744, Last lagvar Loss: 1.0907275676727295\n",
      "Step 1318/10000- lr: [8.767681696969697e-06] - Loss total: 3.986537456512451, Last rpr Loss: 1.053209662437439, Last lagvar Loss: 1.096305251121521\n",
      "Step 1319/10000- lr: [8.7666716e-06] - Loss total: 3.988525390625, Last rpr Loss: 0.9307364821434021, Last lagvar Loss: 1.2200978994369507\n",
      "Step 1320/10000- lr: [8.765661503030304e-06] - Loss total: 3.9863781929016113, Last rpr Loss: 0.9357782602310181, Last lagvar Loss: 1.2130498886108398\n",
      "Step 1321/10000- lr: [8.764651406060607e-06] - Loss total: 3.983922004699707, Last rpr Loss: 1.0599702596664429, Last lagvar Loss: 1.0878098011016846\n",
      "Step 1322/10000- lr: [8.76364130909091e-06] - Loss total: 3.9819047451019287, Last rpr Loss: 1.052182912826538, Last lagvar Loss: 1.0935745239257812\n",
      "Step 1323/10000- lr: [8.762631212121212e-06] - Loss total: 3.98386812210083, Last rpr Loss: 0.9297711849212646, Last lagvar Loss: 1.217236876487732\n",
      "Step 1324/10000- lr: [8.761621115151515e-06] - Loss total: 3.9818050861358643, Last rpr Loss: 0.935005247592926, Last lagvar Loss: 1.210154414176941\n",
      "Step 1325/10000- lr: [8.760611018181819e-06] - Loss total: 3.9791035652160645, Last rpr Loss: 1.0584912300109863, Last lagvar Loss: 1.085242748260498\n",
      "Step 1326/10000- lr: [8.759600921212122e-06] - Loss total: 3.9771206378936768, Last rpr Loss: 1.0512421131134033, Last lagvar Loss: 1.0905253887176514\n",
      "Step 1327/10000- lr: [8.758590824242425e-06] - Loss total: 3.979281187057495, Last rpr Loss: 0.9289276599884033, Last lagvar Loss: 1.2144157886505127\n",
      "Step 1328/10000- lr: [8.757580727272728e-06] - Loss total: 3.977207660675049, Last rpr Loss: 0.9335929155349731, Last lagvar Loss: 1.207833170890808\n",
      "Step 1329/10000- lr: [8.756570630303032e-06] - Loss total: 3.97426700592041, Last rpr Loss: 1.056476354598999, Last lagvar Loss: 1.0831984281539917\n",
      "Step 1330/10000- lr: [8.755560533333335e-06] - Loss total: 3.9722774028778076, Last rpr Loss: 1.0499320030212402, Last lagvar Loss: 1.0878300666809082\n",
      "Step 1331/10000- lr: [8.754550436363637e-06] - Loss total: 3.974735736846924, Last rpr Loss: 0.928766131401062, Last lagvar Loss: 1.21083664894104\n",
      "Step 1332/10000- lr: [8.75354033939394e-06] - Loss total: 3.972642660140991, Last rpr Loss: 0.933220624923706, Last lagvar Loss: 1.2044880390167236\n",
      "Step 1333/10000- lr: [8.752530242424243e-06] - Loss total: 3.969393014907837, Last rpr Loss: 1.0547642707824707, Last lagvar Loss: 1.0807956457138062\n",
      "Step 1334/10000- lr: [8.751520145454546e-06] - Loss total: 3.967414140701294, Last rpr Loss: 1.0478930473327637, Last lagvar Loss: 1.085750699043274\n",
      "Step 1335/10000- lr: [8.75051004848485e-06] - Loss total: 3.97017765045166, Last rpr Loss: 0.9282011985778809, Last lagvar Loss: 1.207763671875\n",
      "Step 1336/10000- lr: [8.749499951515151e-06] - Loss total: 3.968048572540283, Last rpr Loss: 0.9335542917251587, Last lagvar Loss: 1.2004401683807373\n",
      "Step 1337/10000- lr: [8.748489854545454e-06] - Loss total: 3.964568614959717, Last rpr Loss: 1.055009126663208, Last lagvar Loss: 1.0766022205352783\n",
      "Step 1338/10000- lr: [8.747479757575758e-06] - Loss total: 3.962613821029663, Last rpr Loss: 1.047459363937378, Last lagvar Loss: 1.0822062492370605\n",
      "Step 1339/10000- lr: [8.746469660606061e-06] - Loss total: 3.965529203414917, Last rpr Loss: 0.9275535345077515, Last lagvar Loss: 1.2046774625778198\n",
      "Step 1340/10000- lr: [8.745459563636364e-06] - Loss total: 3.9633877277374268, Last rpr Loss: 0.9325083494186401, Last lagvar Loss: 1.1977438926696777\n",
      "Step 1341/10000- lr: [8.744449466666668e-06] - Loss total: 3.959744691848755, Last rpr Loss: 1.0533095598220825, Last lagvar Loss: 1.0741713047027588\n",
      "Step 1342/10000- lr: [8.743439369696971e-06] - Loss total: 3.957789897918701, Last rpr Loss: 1.0458285808563232, Last lagvar Loss: 1.0796924829483032\n",
      "Step 1343/10000- lr: [8.742429272727274e-06] - Loss total: 3.960859537124634, Last rpr Loss: 0.92693030834198, Last lagvar Loss: 1.201453447341919\n",
      "Step 1344/10000- lr: [8.741419175757576e-06] - Loss total: 3.958696126937866, Last rpr Loss: 0.9318282604217529, Last lagvar Loss: 1.1945244073867798\n",
      "Step 1345/10000- lr: [8.740409078787879e-06] - Loss total: 3.954906463623047, Last rpr Loss: 1.051778793334961, Last lagvar Loss: 1.071468710899353\n",
      "Step 1346/10000- lr: [8.739398981818182e-06] - Loss total: 3.9529473781585693, Last rpr Loss: 1.0446500778198242, Last lagvar Loss: 1.07666015625\n",
      "Step 1347/10000- lr: [8.738388884848486e-06] - Loss total: 3.95617413520813, Last rpr Loss: 0.9276041984558105, Last lagvar Loss: 1.1967853307724\n",
      "Step 1348/10000- lr: [8.737378787878789e-06] - Loss total: 3.9539761543273926, Last rpr Loss: 0.9334585666656494, Last lagvar Loss: 1.1888031959533691\n",
      "Step 1349/10000- lr: [8.736368690909092e-06] - Loss total: 3.950127124786377, Last rpr Loss: 1.0533838272094727, Last lagvar Loss: 1.0659106969833374\n",
      "Step 1350/10000- lr: [8.735358593939394e-06] - Loss total: 3.9481730461120605, Last rpr Loss: 1.0451282262802124, Last lagvar Loss: 1.0722274780273438\n",
      "Step 1351/10000- lr: [8.734348496969697e-06] - Loss total: 3.951503276824951, Last rpr Loss: 0.9266529083251953, Last lagvar Loss: 1.193812370300293\n",
      "Step 1352/10000- lr: [8.7333384e-06] - Loss total: 3.949335813522339, Last rpr Loss: 0.931182861328125, Last lagvar Loss: 1.1872797012329102\n",
      "Step 1353/10000- lr: [8.732328303030304e-06] - Loss total: 3.9453537464141846, Last rpr Loss: 1.0504074096679688, Last lagvar Loss: 1.0650564432144165\n",
      "Step 1354/10000- lr: [8.731318206060607e-06] - Loss total: 3.943450927734375, Last rpr Loss: 1.0435669422149658, Last lagvar Loss: 1.070097804069519\n",
      "Step 1355/10000- lr: [8.73030810909091e-06] - Loss total: 3.946873188018799, Last rpr Loss: 0.926925778388977, Last lagvar Loss: 1.1897882223129272\n",
      "Step 1356/10000- lr: [8.729298012121213e-06] - Loss total: 3.9447224140167236, Last rpr Loss: 0.9322012066841125, Last lagvar Loss: 1.1825381517410278\n",
      "Step 1357/10000- lr: [8.728287915151517e-06] - Loss total: 3.940678119659424, Last rpr Loss: 1.0510896444320679, Last lagvar Loss: 1.0609309673309326\n",
      "Step 1358/10000- lr: [8.727277818181818e-06] - Loss total: 3.938791513442993, Last rpr Loss: 1.043395757675171, Last lagvar Loss: 1.066719651222229\n",
      "Step 1359/10000- lr: [8.726267721212122e-06] - Loss total: 3.942336320877075, Last rpr Loss: 0.9263808727264404, Last lagvar Loss: 1.1868292093276978\n",
      "Step 1360/10000- lr: [8.725257624242425e-06] - Loss total: 3.940213918685913, Last rpr Loss: 0.9314111471176147, Last lagvar Loss: 1.1798958778381348\n",
      "Step 1361/10000- lr: [8.724247527272728e-06] - Loss total: 3.9360225200653076, Last rpr Loss: 1.0495400428771973, Last lagvar Loss: 1.0586291551589966\n",
      "Step 1362/10000- lr: [8.723237430303031e-06] - Loss total: 3.934168577194214, Last rpr Loss: 1.0418407917022705, Last lagvar Loss: 1.0645198822021484\n",
      "Step 1363/10000- lr: [8.722227333333335e-06] - Loss total: 3.937859535217285, Last rpr Loss: 0.9256763458251953, Last lagvar Loss: 1.1842460632324219\n",
      "Step 1364/10000- lr: [8.721217236363636e-06] - Loss total: 3.935729503631592, Last rpr Loss: 0.93116295337677, Last lagvar Loss: 1.1768357753753662\n",
      "Step 1365/10000- lr: [8.72020713939394e-06] - Loss total: 3.9314515590667725, Last rpr Loss: 1.0494513511657715, Last lagvar Loss: 1.0551351308822632\n",
      "Step 1366/10000- lr: [8.719197042424243e-06] - Loss total: 3.929600715637207, Last rpr Loss: 1.0418938398361206, Last lagvar Loss: 1.060949683189392\n",
      "Step 1367/10000- lr: [8.718186945454546e-06] - Loss total: 3.933467149734497, Last rpr Loss: 0.9254356622695923, Last lagvar Loss: 1.181278944015503\n",
      "Step 1368/10000- lr: [8.71717684848485e-06] - Loss total: 3.931361675262451, Last rpr Loss: 0.9298385381698608, Last lagvar Loss: 1.1750110387802124\n",
      "Step 1369/10000- lr: [8.716166751515153e-06] - Loss total: 3.926849842071533, Last rpr Loss: 1.0468740463256836, Last lagvar Loss: 1.0541558265686035\n",
      "Step 1370/10000- lr: [8.715156654545456e-06] - Loss total: 3.9250271320343018, Last rpr Loss: 1.0400769710540771, Last lagvar Loss: 1.0592749118804932\n",
      "Step 1371/10000- lr: [8.714146557575759e-06] - Loss total: 3.9291152954101562, Last rpr Loss: 0.9259802103042603, Last lagvar Loss: 1.1775288581848145\n",
      "Step 1372/10000- lr: [8.71313646060606e-06] - Loss total: 3.9269859790802, Last rpr Loss: 0.9315699338912964, Last lagvar Loss: 1.1699984073638916\n",
      "Step 1373/10000- lr: [8.712126363636364e-06] - Loss total: 3.922330617904663, Last rpr Loss: 1.0482747554779053, Last lagvar Loss: 1.0494459867477417\n",
      "Step 1374/10000- lr: [8.711116266666667e-06] - Loss total: 3.920522451400757, Last rpr Loss: 1.0397493839263916, Last lagvar Loss: 1.0562562942504883\n",
      "Step 1375/10000- lr: [8.71010616969697e-06] - Loss total: 3.9247729778289795, Last rpr Loss: 0.924613356590271, Last lagvar Loss: 1.175776720046997\n",
      "Step 1376/10000- lr: [8.709096072727274e-06] - Loss total: 3.922656536102295, Last rpr Loss: 0.9295520782470703, Last lagvar Loss: 1.1689517498016357\n",
      "Step 1377/10000- lr: [8.708085975757577e-06] - Loss total: 3.917823076248169, Last rpr Loss: 1.045772671699524, Last lagvar Loss: 1.0485267639160156\n",
      "Step 1378/10000- lr: [8.707075878787879e-06] - Loss total: 3.916046619415283, Last rpr Loss: 1.038125991821289, Last lagvar Loss: 1.0544936656951904\n",
      "Step 1379/10000- lr: [8.706065781818182e-06] - Loss total: 3.920438528060913, Last rpr Loss: 0.9244826436042786, Last lagvar Loss: 1.17281174659729\n",
      "Step 1380/10000- lr: [8.705055684848485e-06] - Loss total: 3.9183197021484375, Last rpr Loss: 0.9300190806388855, Last lagvar Loss: 1.165360927581787\n",
      "Step 1381/10000- lr: [8.704045587878789e-06] - Loss total: 3.9133644104003906, Last rpr Loss: 1.0460097789764404, Last lagvar Loss: 1.0450040102005005\n",
      "Step 1382/10000- lr: [8.703035490909092e-06] - Loss total: 3.9115993976593018, Last rpr Loss: 1.037792444229126, Last lagvar Loss: 1.051583170890808\n",
      "Step 1383/10000- lr: [8.702025393939395e-06] - Loss total: 3.91614031791687, Last rpr Loss: 0.9236835241317749, Last lagvar Loss: 1.1705764532089233\n",
      "Step 1384/10000- lr: [8.701015296969698e-06] - Loss total: 3.914018392562866, Last rpr Loss: 0.9283647537231445, Last lagvar Loss: 1.1640244722366333\n",
      "Step 1385/10000- lr: [8.7000052e-06] - Loss total: 3.9089343547821045, Last rpr Loss: 1.0435429811477661, Last lagvar Loss: 1.0442092418670654\n",
      "Step 1386/10000- lr: [8.698995103030303e-06] - Loss total: 3.9071977138519287, Last rpr Loss: 1.036433458328247, Last lagvar Loss: 1.0497443675994873\n",
      "Step 1387/10000- lr: [8.697985006060606e-06] - Loss total: 3.911773681640625, Last rpr Loss: 0.9246554374694824, Last lagvar Loss: 1.1664719581604004\n",
      "Step 1388/10000- lr: [8.69697490909091e-06] - Loss total: 3.9096179008483887, Last rpr Loss: 0.9305975437164307, Last lagvar Loss: 1.1585569381713867\n",
      "Step 1389/10000- lr: [8.695964812121213e-06] - Loss total: 3.904618978500366, Last rpr Loss: 1.0459609031677246, Last lagvar Loss: 1.0388047695159912\n",
      "Step 1390/10000- lr: [8.694954715151516e-06] - Loss total: 3.9028728008270264, Last rpr Loss: 1.0373635292053223, Last lagvar Loss: 1.045807957649231\n",
      "Step 1391/10000- lr: [8.693944618181818e-06] - Loss total: 3.9073970317840576, Last rpr Loss: 0.9242413640022278, Last lagvar Loss: 1.1637775897979736\n",
      "Step 1392/10000- lr: [8.692934521212121e-06] - Loss total: 3.9052488803863525, Last rpr Loss: 0.9292206168174744, Last lagvar Loss: 1.1569056510925293\n",
      "Step 1393/10000- lr: [8.691924424242424e-06] - Loss total: 3.9003334045410156, Last rpr Loss: 1.0442144870758057, Last lagvar Loss: 1.0375175476074219\n",
      "Step 1394/10000- lr: [8.690914327272728e-06] - Loss total: 3.898607015609741, Last rpr Loss: 1.0368421077728271, Last lagvar Loss: 1.0433200597763062\n",
      "Step 1395/10000- lr: [8.689904230303031e-06] - Loss total: 3.9029436111450195, Last rpr Loss: 0.9260424375534058, Last lagvar Loss: 1.1587765216827393\n",
      "Step 1396/10000- lr: [8.688894133333334e-06] - Loss total: 3.900773763656616, Last rpr Loss: 0.9323960542678833, Last lagvar Loss: 1.1504387855529785\n",
      "Step 1397/10000- lr: [8.687884036363638e-06] - Loss total: 3.896193742752075, Last rpr Loss: 1.0476939678192139, Last lagvar Loss: 1.0312687158584595\n",
      "Step 1398/10000- lr: [8.686873939393941e-06] - Loss total: 3.894451141357422, Last rpr Loss: 1.0385799407958984, Last lagvar Loss: 1.0387723445892334\n",
      "Step 1399/10000- lr: [8.685863842424242e-06] - Loss total: 3.8984673023223877, Last rpr Loss: 0.9262601137161255, Last lagvar Loss: 1.1553617715835571\n",
      "Step 1400/10000- lr: [8.684853745454546e-06] - Loss total: 3.8963093757629395, Last rpr Loss: 0.9317193031311035, Last lagvar Loss: 1.1480141878128052\n",
      "Step 1401/10000- lr: [8.683843648484849e-06] - Loss total: 3.8921501636505127, Last rpr Loss: 1.046968698501587, Last lagvar Loss: 1.0292249917984009\n",
      "Step 1402/10000- lr: [8.682833551515152e-06] - Loss total: 3.8904144763946533, Last rpr Loss: 1.039029598236084, Last lagvar Loss: 1.0355409383773804\n",
      "Step 1403/10000- lr: [8.681823454545456e-06] - Loss total: 3.8938913345336914, Last rpr Loss: 0.9291979074478149, Last lagvar Loss: 1.1490696668624878\n",
      "Step 1404/10000- lr: [8.680813357575759e-06] - Loss total: 3.891711711883545, Last rpr Loss: 0.9367014765739441, Last lagvar Loss: 1.1395387649536133\n",
      "Step 1405/10000- lr: [8.67980326060606e-06] - Loss total: 3.8883485794067383, Last rpr Loss: 1.0532057285308838, Last lagvar Loss: 1.0205920934677124\n",
      "Step 1406/10000- lr: [8.678793163636364e-06] - Loss total: 3.8865749835968018, Last rpr Loss: 1.0435166358947754, Last lagvar Loss: 1.0285937786102295\n",
      "Step 1407/10000- lr: [8.677783066666667e-06] - Loss total: 3.88930082321167, Last rpr Loss: 0.9308534264564514, Last lagvar Loss: 1.1440454721450806\n",
      "Step 1408/10000- lr: [8.67677296969697e-06] - Loss total: 3.8871634006500244, Last rpr Loss: 0.9370843172073364, Last lagvar Loss: 1.135960578918457\n",
      "Step 1409/10000- lr: [8.675762872727274e-06] - Loss total: 3.884697437286377, Last rpr Loss: 1.054324746131897, Last lagvar Loss: 1.0170964002609253\n",
      "Step 1410/10000- lr: [8.674752775757577e-06] - Loss total: 3.882899522781372, Last rpr Loss: 1.0461864471435547, Last lagvar Loss: 1.02350652217865\n",
      "Step 1411/10000- lr: [8.67374267878788e-06] - Loss total: 3.884742021560669, Last rpr Loss: 0.9348007440567017, Last lagvar Loss: 1.136842966079712\n",
      "Step 1412/10000- lr: [8.672732581818183e-06] - Loss total: 3.8826420307159424, Last rpr Loss: 0.9423724412918091, Last lagvar Loss: 1.127336025238037\n",
      "Step 1413/10000- lr: [8.671722484848485e-06] - Loss total: 3.8812408447265625, Last rpr Loss: 1.0611299276351929, Last lagvar Loss: 1.008294701576233\n",
      "Step 1414/10000- lr: [8.670712387878788e-06] - Loss total: 3.8793728351593018, Last rpr Loss: 1.0520374774932861, Last lagvar Loss: 1.0156241655349731\n",
      "Step 1415/10000- lr: [8.669702290909091e-06] - Loss total: 3.8803722858428955, Last rpr Loss: 0.9373059272766113, Last lagvar Loss: 1.1312901973724365\n",
      "Step 1416/10000- lr: [8.668692193939395e-06] - Loss total: 3.878382444381714, Last rpr Loss: 0.9427703619003296, Last lagvar Loss: 1.124145269393921\n",
      "Step 1417/10000- lr: [8.667682096969698e-06] - Loss total: 3.877715587615967, Last rpr Loss: 1.0617876052856445, Last lagvar Loss: 1.0055397748947144\n",
      "Step 1418/10000- lr: [8.666672000000001e-06] - Loss total: 3.8757858276367188, Last rpr Loss: 1.0535719394683838, Last lagvar Loss: 1.0118879079818726\n",
      "Step 1419/10000- lr: [8.665661903030303e-06] - Loss total: 3.876288890838623, Last rpr Loss: 0.9392759799957275, Last lagvar Loss: 1.126731514930725\n",
      "Step 1420/10000- lr: [8.664651806060606e-06] - Loss total: 3.874377727508545, Last rpr Loss: 0.9451489448547363, Last lagvar Loss: 1.1191329956054688\n",
      "Step 1421/10000- lr: [8.66364170909091e-06] - Loss total: 3.8740828037261963, Last rpr Loss: 1.0644593238830566, Last lagvar Loss: 1.0007412433624268\n",
      "Step 1422/10000- lr: [8.662631612121213e-06] - Loss total: 3.87213134765625, Last rpr Loss: 1.055787205696106, Last lagvar Loss: 1.0075874328613281\n",
      "Step 1423/10000- lr: [8.661621515151516e-06] - Loss total: 3.8724398612976074, Last rpr Loss: 0.9396851062774658, Last lagvar Loss: 1.1238465309143066\n",
      "Step 1424/10000- lr: [8.66061141818182e-06] - Loss total: 3.8706271648406982, Last rpr Loss: 0.9442489147186279, Last lagvar Loss: 1.1177692413330078\n",
      "Step 1425/10000- lr: [8.659601321212123e-06] - Loss total: 3.870271921157837, Last rpr Loss: 1.0631093978881836, Last lagvar Loss: 0.9997692108154297\n",
      "Step 1426/10000- lr: [8.658591224242424e-06] - Loss total: 3.868335008621216, Last rpr Loss: 1.0548642873764038, Last lagvar Loss: 1.0061612129211426\n",
      "Step 1427/10000- lr: [8.657581127272727e-06] - Loss total: 3.868839740753174, Last rpr Loss: 0.9390281438827515, Last lagvar Loss: 1.122450351715088\n",
      "Step 1428/10000- lr: [8.65657103030303e-06] - Loss total: 3.8670883178710938, Last rpr Loss: 0.9436420798301697, Last lagvar Loss: 1.1163322925567627\n",
      "Step 1429/10000- lr: [8.655560933333334e-06] - Loss total: 3.866360902786255, Last rpr Loss: 1.0612821578979492, Last lagvar Loss: 0.9990684390068054\n",
      "Step 1430/10000- lr: [8.654550836363637e-06] - Loss total: 3.8644964694976807, Last rpr Loss: 1.0531280040740967, Last lagvar Loss: 1.00552499294281\n",
      "Step 1431/10000- lr: [8.65354073939394e-06] - Loss total: 3.865351438522339, Last rpr Loss: 0.9375755786895752, Last lagvar Loss: 1.1218059062957764\n",
      "Step 1432/10000- lr: [8.652530642424242e-06] - Loss total: 3.863642930984497, Last rpr Loss: 0.9423169493675232, Last lagvar Loss: 1.1156576871871948\n",
      "Step 1433/10000- lr: [8.651520545454545e-06] - Loss total: 3.8624424934387207, Last rpr Loss: 1.059281826019287, Last lagvar Loss: 0.9985804557800293\n",
      "Step 1434/10000- lr: [8.650510448484849e-06] - Loss total: 3.86063551902771, Last rpr Loss: 1.0512919425964355, Last lagvar Loss: 1.0049058198928833\n",
      "Step 1435/10000- lr: [8.649500351515152e-06] - Loss total: 3.8619987964630127, Last rpr Loss: 0.9358534812927246, Last lagvar Loss: 1.1217015981674194\n",
      "Step 1436/10000- lr: [8.648490254545455e-06] - Loss total: 3.860323190689087, Last rpr Loss: 0.9403500556945801, Last lagvar Loss: 1.115821123123169\n",
      "Step 1437/10000- lr: [8.647480157575758e-06] - Loss total: 3.85849928855896, Last rpr Loss: 1.0557196140289307, Last lagvar Loss: 0.9994832277297974\n",
      "Step 1438/10000- lr: [8.646470060606062e-06] - Loss total: 3.8567886352539062, Last rpr Loss: 1.0484377145767212, Last lagvar Loss: 1.0052870512008667\n",
      "Step 1439/10000- lr: [8.645459963636365e-06] - Loss total: 3.8586642742156982, Last rpr Loss: 0.9343627691268921, Last lagvar Loss: 1.1212483644485474\n",
      "Step 1440/10000- lr: [8.644449866666667e-06] - Loss total: 3.8569881916046143, Last rpr Loss: 0.9393332004547119, Last lagvar Loss: 1.1149179935455322\n",
      "Step 1441/10000- lr: [8.64343976969697e-06] - Loss total: 3.8546383380889893, Last rpr Loss: 1.0539426803588867, Last lagvar Loss: 0.9988131523132324\n",
      "Step 1442/10000- lr: [8.642429672727273e-06] - Loss total: 3.8529858589172363, Last rpr Loss: 1.0466499328613281, Last lagvar Loss: 1.0046718120574951\n",
      "Step 1443/10000- lr: [8.641419575757576e-06] - Loss total: 3.8553690910339355, Last rpr Loss: 0.9326432943344116, Last lagvar Loss: 1.1211957931518555\n",
      "Step 1444/10000- lr: [8.64040947878788e-06] - Loss total: 3.853700876235962, Last rpr Loss: 0.9371757507324219, Last lagvar Loss: 1.1153242588043213\n",
      "Step 1445/10000- lr: [8.639399381818183e-06] - Loss total: 3.850789785385132, Last rpr Loss: 1.050290584564209, Last lagvar Loss: 0.9999092221260071\n",
      "Step 1446/10000- lr: [8.638389284848486e-06] - Loss total: 3.8492252826690674, Last rpr Loss: 1.0440664291381836, Last lagvar Loss: 1.0048857927322388\n",
      "Step 1447/10000- lr: [8.637379187878788e-06] - Loss total: 3.8519952297210693, Last rpr Loss: 0.9318206310272217, Last lagvar Loss: 1.1200754642486572\n",
      "Step 1448/10000- lr: [8.636369090909091e-06] - Loss total: 3.850297212600708, Last rpr Loss: 0.9371346831321716, Last lagvar Loss: 1.1134042739868164\n",
      "Step 1449/10000- lr: [8.635358993939394e-06] - Loss total: 3.8470683097839355, Last rpr Loss: 1.0497153997421265, Last lagvar Loss: 0.998238205909729\n",
      "Step 1450/10000- lr: [8.634348896969698e-06] - Loss total: 3.8455440998077393, Last rpr Loss: 1.043154001235962, Last lagvar Loss: 1.003584384918213\n",
      "Step 1451/10000- lr: [8.633338800000001e-06] - Loss total: 3.8485705852508545, Last rpr Loss: 0.930627703666687, Last lagvar Loss: 1.119390845298767\n",
      "Step 1452/10000- lr: [8.632328703030304e-06] - Loss total: 3.8468737602233887, Last rpr Loss: 0.9357256889343262, Last lagvar Loss: 1.1129688024520874\n",
      "Step 1453/10000- lr: [8.631318606060608e-06] - Loss total: 3.8433799743652344, Last rpr Loss: 1.0474789142608643, Last lagvar Loss: 0.998159646987915\n",
      "Step 1454/10000- lr: [8.630308509090909e-06] - Loss total: 3.84193754196167, Last rpr Loss: 1.0424250364303589, Last lagvar Loss: 1.0021991729736328\n",
      "Step 1455/10000- lr: [8.629298412121212e-06] - Loss total: 3.844970226287842, Last rpr Loss: 0.9313146471977234, Last lagvar Loss: 1.1165646314620972\n",
      "Step 1456/10000- lr: [8.628288315151516e-06] - Loss total: 3.8432514667510986, Last rpr Loss: 0.9373741745948792, Last lagvar Loss: 1.109192132949829\n",
      "Step 1457/10000- lr: [8.627278218181819e-06] - Loss total: 3.8398654460906982, Last rpr Loss: 1.0488998889923096, Last lagvar Loss: 0.9947870969772339\n",
      "Step 1458/10000- lr: [8.626268121212122e-06] - Loss total: 3.838456153869629, Last rpr Loss: 1.0432531833648682, Last lagvar Loss: 0.999464750289917\n",
      "Step 1459/10000- lr: [8.625258024242426e-06] - Loss total: 3.841266632080078, Last rpr Loss: 0.9311641454696655, Last lagvar Loss: 1.1145951747894287\n",
      "Step 1460/10000- lr: [8.624247927272727e-06] - Loss total: 3.8395919799804688, Last rpr Loss: 0.9375745058059692, Last lagvar Loss: 1.1069715023040771\n",
      "Step 1461/10000- lr: [8.62323783030303e-06] - Loss total: 3.8364098072052, Last rpr Loss: 1.048925757408142, Last lagvar Loss: 0.9927630424499512\n",
      "Step 1462/10000- lr: [8.622227733333334e-06] - Loss total: 3.8350906372070312, Last rpr Loss: 1.0449007749557495, Last lagvar Loss: 0.9960728287696838\n",
      "Step 1463/10000- lr: [8.621217636363637e-06] - Loss total: 3.8373897075653076, Last rpr Loss: 0.9333215951919556, Last lagvar Loss: 1.1100468635559082\n",
      "Step 1464/10000- lr: [8.62020753939394e-06] - Loss total: 3.83575177192688, Last rpr Loss: 0.9410519003868103, Last lagvar Loss: 1.1011626720428467\n",
      "Step 1465/10000- lr: [8.619197442424243e-06] - Loss total: 3.833153247833252, Last rpr Loss: 1.0529117584228516, Last lagvar Loss: 0.9871526956558228\n",
      "Step 1466/10000- lr: [8.618187345454547e-06] - Loss total: 3.8318774700164795, Last rpr Loss: 1.0479966402053833, Last lagvar Loss: 0.9914219379425049\n",
      "Step 1467/10000- lr: [8.61717724848485e-06] - Loss total: 3.833491086959839, Last rpr Loss: 0.9339686632156372, Last lagvar Loss: 1.1071200370788574\n",
      "Step 1468/10000- lr: [8.616167151515152e-06] - Loss total: 3.831925630569458, Last rpr Loss: 0.9412927627563477, Last lagvar Loss: 1.098644495010376\n",
      "Step 1469/10000- lr: [8.615157054545455e-06] - Loss total: 3.829972267150879, Last rpr Loss: 1.0553501844406128, Last lagvar Loss: 0.9830067157745361\n",
      "Step 1470/10000- lr: [8.614146957575758e-06] - Loss total: 3.8288066387176514, Last rpr Loss: 1.053192138671875, Last lagvar Loss: 0.9847455024719238\n",
      "Step 1471/10000- lr: [8.613136860606061e-06] - Loss total: 3.8293869495391846, Last rpr Loss: 0.9386659860610962, Last lagvar Loss: 1.099638819694519\n",
      "Step 1472/10000- lr: [8.612126763636365e-06] - Loss total: 3.8278579711914062, Last rpr Loss: 0.9449036717414856, Last lagvar Loss: 1.0922553539276123\n",
      "Step 1473/10000- lr: [8.611116666666666e-06] - Loss total: 3.827103853225708, Last rpr Loss: 1.0604219436645508, Last lagvar Loss: 0.9766359329223633\n",
      "Step 1474/10000- lr: [8.61010656969697e-06] - Loss total: 3.8258790969848633, Last rpr Loss: 1.058558464050293, Last lagvar Loss: 0.9779067039489746\n",
      "Step 1475/10000- lr: [8.609096472727273e-06] - Loss total: 3.82535719871521, Last rpr Loss: 0.9429165124893188, Last lagvar Loss: 1.0926681756973267\n",
      "Step 1476/10000- lr: [8.608086375757576e-06] - Loss total: 3.8239259719848633, Last rpr Loss: 0.9470705986022949, Last lagvar Loss: 1.0874435901641846\n",
      "Step 1477/10000- lr: [8.60707627878788e-06] - Loss total: 3.824144124984741, Last rpr Loss: 1.0623493194580078, Last lagvar Loss: 0.9730777740478516\n",
      "Step 1478/10000- lr: [8.606066181818183e-06] - Loss total: 3.822781801223755, Last rpr Loss: 1.06114661693573, Last lagvar Loss: 0.9735203385353088\n",
      "Step 1479/10000- lr: [8.605056084848486e-06] - Loss total: 3.82163667678833, Last rpr Loss: 0.9470599889755249, Last lagvar Loss: 1.0860490798950195\n",
      "Step 1480/10000- lr: [8.60404598787879e-06] - Loss total: 3.8202617168426514, Last rpr Loss: 0.9503661394119263, Last lagvar Loss: 1.0817046165466309\n",
      "Step 1481/10000- lr: [8.60303589090909e-06] - Loss total: 3.8209478855133057, Last rpr Loss: 1.064001441001892, Last lagvar Loss: 0.9696403741836548\n",
      "Step 1482/10000- lr: [8.602025793939394e-06] - Loss total: 3.8193886280059814, Last rpr Loss: 1.0605605840682983, Last lagvar Loss: 0.9719552993774414\n",
      "Step 1483/10000- lr: [8.601015696969697e-06] - Loss total: 3.8183603286743164, Last rpr Loss: 0.946452260017395, Last lagvar Loss: 1.084867000579834\n",
      "Step 1484/10000- lr: [8.6000056e-06] - Loss total: 3.817011594772339, Last rpr Loss: 0.9487266540527344, Last lagvar Loss: 1.0815479755401611\n",
      "Step 1485/10000- lr: [8.598995503030304e-06] - Loss total: 3.8173916339874268, Last rpr Loss: 1.0610053539276123, Last lagvar Loss: 0.9703681468963623\n",
      "Step 1486/10000- lr: [8.597985406060607e-06] - Loss total: 3.8157904148101807, Last rpr Loss: 1.0577592849731445, Last lagvar Loss: 0.9724396467208862\n",
      "Step 1487/10000- lr: [8.59697530909091e-06] - Loss total: 3.8152835369110107, Last rpr Loss: 0.9460203647613525, Last lagvar Loss: 1.0836405754089355\n",
      "Step 1488/10000- lr: [8.595965212121212e-06] - Loss total: 3.8139102458953857, Last rpr Loss: 0.9485098123550415, Last lagvar Loss: 1.0800886154174805\n",
      "Step 1489/10000- lr: [8.594955115151515e-06] - Loss total: 3.8137919902801514, Last rpr Loss: 1.0586881637573242, Last lagvar Loss: 0.9704952836036682\n",
      "Step 1490/10000- lr: [8.593945018181819e-06] - Loss total: 3.812181234359741, Last rpr Loss: 1.0539283752441406, Last lagvar Loss: 0.9739988446235657\n",
      "Step 1491/10000- lr: [8.592934921212122e-06] - Loss total: 3.81233549118042, Last rpr Loss: 0.9435257911682129, Last lagvar Loss: 1.084770917892456\n",
      "Step 1492/10000- lr: [8.591924824242425e-06] - Loss total: 3.8109211921691895, Last rpr Loss: 0.9465492367744446, Last lagvar Loss: 1.0806242227554321\n",
      "Step 1493/10000- lr: [8.590914727272728e-06] - Loss total: 3.810216188430786, Last rpr Loss: 1.055655598640442, Last lagvar Loss: 0.9713523387908936\n",
      "Step 1494/10000- lr: [8.589904630303032e-06] - Loss total: 3.8086438179016113, Last rpr Loss: 1.0504612922668457, Last lagvar Loss: 0.9753331542015076\n",
      "Step 1495/10000- lr: [8.588894533333333e-06] - Loss total: 3.809380054473877, Last rpr Loss: 0.9420214891433716, Last lagvar Loss: 1.0848264694213867\n",
      "Step 1496/10000- lr: [8.587884436363637e-06] - Loss total: 3.807908296585083, Last rpr Loss: 0.946303129196167, Last lagvar Loss: 1.0793408155441284\n",
      "Step 1497/10000- lr: [8.58687433939394e-06] - Loss total: 3.8067588806152344, Last rpr Loss: 1.055130958557129, Last lagvar Loss: 0.9699645042419434\n",
      "Step 1498/10000- lr: [8.585864242424243e-06] - Loss total: 3.8051888942718506, Last rpr Loss: 1.048400640487671, Last lagvar Loss: 0.9754199981689453\n",
      "Step 1499/10000- lr: [8.584854145454546e-06] - Loss total: 3.806452989578247, Last rpr Loss: 0.939805269241333, Last lagvar Loss: 1.0857141017913818\n",
      "Step 1500/10000- lr: [8.58384404848485e-06] - Loss total: 3.804946184158325, Last rpr Loss: 0.9439870119094849, Last lagvar Loss: 1.0803264379501343\n",
      "Step 1501/10000- lr: [8.582833951515151e-06] - Loss total: 3.8033158779144287, Last rpr Loss: 1.052559494972229, Last lagvar Loss: 0.9705665111541748\n",
      "Step 1502/10000- lr: [8.581823854545455e-06] - Loss total: 3.8017773628234863, Last rpr Loss: 1.0459933280944824, Last lagvar Loss: 0.9759169220924377\n",
      "Step 1503/10000- lr: [8.580813757575758e-06] - Loss total: 3.8035027980804443, Last rpr Loss: 0.9384877681732178, Last lagvar Loss: 1.085632562637329\n",
      "Step 1504/10000- lr: [8.579803660606061e-06] - Loss total: 3.80195951461792, Last rpr Loss: 0.9430090188980103, Last lagvar Loss: 1.0799059867858887\n",
      "Step 1505/10000- lr: [8.578793563636364e-06] - Loss total: 3.7999234199523926, Last rpr Loss: 1.0510368347167969, Last lagvar Loss: 0.9702534079551697\n",
      "Step 1506/10000- lr: [8.577783466666668e-06] - Loss total: 3.7983932495117188, Last rpr Loss: 1.0439119338989258, Last lagvar Loss: 0.9761602878570557\n",
      "Step 1507/10000- lr: [8.576773369696971e-06] - Loss total: 3.800568103790283, Last rpr Loss: 0.9369714260101318, Last lagvar Loss: 1.0858427286148071\n",
      "Step 1508/10000- lr: [8.575763272727274e-06] - Loss total: 3.79899263381958, Last rpr Loss: 0.9413807392120361, Last lagvar Loss: 1.0802303552627563\n",
      "Step 1509/10000- lr: [8.574753175757576e-06] - Loss total: 3.7965385913848877, Last rpr Loss: 1.0486125946044922, Last lagvar Loss: 0.9708393812179565\n",
      "Step 1510/10000- lr: [8.573743078787879e-06] - Loss total: 3.795032501220703, Last rpr Loss: 1.0415313243865967, Last lagvar Loss: 0.976747989654541\n",
      "Step 1511/10000- lr: [8.572732981818182e-06] - Loss total: 3.7975828647613525, Last rpr Loss: 0.9362257122993469, Last lagvar Loss: 1.0852041244506836\n",
      "Step 1512/10000- lr: [8.571722884848486e-06] - Loss total: 3.79595947265625, Last rpr Loss: 0.9412811994552612, Last lagvar Loss: 1.0789003372192383\n",
      "Step 1513/10000- lr: [8.570712787878789e-06] - Loss total: 3.7932140827178955, Last rpr Loss: 1.04795241355896, Last lagvar Loss: 0.9698207378387451\n",
      "Step 1514/10000- lr: [8.569702690909092e-06] - Loss total: 3.791717529296875, Last rpr Loss: 1.0398743152618408, Last lagvar Loss: 0.9767033457756042\n",
      "Step 1515/10000- lr: [8.568692593939394e-06] - Loss total: 3.794532299041748, Last rpr Loss: 0.9353103637695312, Last lagvar Loss: 1.0847415924072266\n",
      "Step 1516/10000- lr: [8.567682496969697e-06] - Loss total: 3.7928624153137207, Last rpr Loss: 0.9405837655067444, Last lagvar Loss: 1.0781902074813843\n",
      "Step 1517/10000- lr: [8.5666724e-06] - Loss total: 3.7899487018585205, Last rpr Loss: 1.0467727184295654, Last lagvar Loss: 0.969350278377533\n",
      "Step 1518/10000- lr: [8.565662303030304e-06] - Loss total: 3.7884814739227295, Last rpr Loss: 1.0386512279510498, Last lagvar Loss: 0.9763206839561462\n",
      "Step 1519/10000- lr: [8.564652206060607e-06] - Loss total: 3.79130482673645, Last rpr Loss: 0.9357838034629822, Last lagvar Loss: 1.0826774835586548\n",
      "Step 1520/10000- lr: [8.56364210909091e-06] - Loss total: 3.7895829677581787, Last rpr Loss: 0.9420313835144043, Last lagvar Loss: 1.0751011371612549\n",
      "Step 1521/10000- lr: [8.562632012121213e-06] - Loss total: 3.786830425262451, Last rpr Loss: 1.0480294227600098, Last lagvar Loss: 0.9666663408279419\n",
      "Step 1522/10000- lr: [8.561621915151515e-06] - Loss total: 3.7853729724884033, Last rpr Loss: 1.038994550704956, Last lagvar Loss: 0.9745349884033203\n",
      "Step 1523/10000- lr: [8.560611818181818e-06] - Loss total: 3.7878940105438232, Last rpr Loss: 0.9368244409561157, Last lagvar Loss: 1.07990562915802\n",
      "Step 1524/10000- lr: [8.559601721212122e-06] - Loss total: 3.7861361503601074, Last rpr Loss: 0.9437490701675415, Last lagvar Loss: 1.0716344118118286\n",
      "Step 1525/10000- lr: [8.558591624242425e-06] - Loss total: 3.7838897705078125, Last rpr Loss: 1.0498173236846924, Last lagvar Loss: 0.9636005163192749\n",
      "Step 1526/10000- lr: [8.557581527272728e-06] - Loss total: 3.782442808151245, Last rpr Loss: 1.0407941341400146, Last lagvar Loss: 0.9714770317077637\n",
      "Step 1527/10000- lr: [8.556571430303031e-06] - Loss total: 3.7842822074890137, Last rpr Loss: 0.9396106004714966, Last lagvar Loss: 1.075127124786377\n",
      "Step 1528/10000- lr: [8.555561333333335e-06] - Loss total: 3.7825136184692383, Last rpr Loss: 0.9478276968002319, Last lagvar Loss: 1.0655572414398193\n",
      "Step 1529/10000- lr: [8.554551236363636e-06] - Loss total: 3.7811920642852783, Last rpr Loss: 1.0544180870056152, Last lagvar Loss: 0.9580414891242981\n",
      "Step 1530/10000- lr: [8.55354113939394e-06] - Loss total: 3.7796995639801025, Last rpr Loss: 1.0443835258483887, Last lagvar Loss: 0.966825008392334\n",
      "Step 1531/10000- lr: [8.552531042424243e-06] - Loss total: 3.780636787414551, Last rpr Loss: 0.9423562288284302, Last lagvar Loss: 1.0704007148742676\n",
      "Step 1532/10000- lr: [8.551520945454546e-06] - Loss total: 3.7789034843444824, Last rpr Loss: 0.9510297775268555, Last lagvar Loss: 1.0604087114334106\n",
      "Step 1533/10000- lr: [8.55051084848485e-06] - Loss total: 3.778613567352295, Last rpr Loss: 1.0584033727645874, Last lagvar Loss: 0.9531770348548889\n",
      "Step 1534/10000- lr: [8.549500751515153e-06] - Loss total: 3.7770321369171143, Last rpr Loss: 1.0480247735977173, Last lagvar Loss: 0.9621696472167969\n",
      "Step 1535/10000- lr: [8.548490654545456e-06] - Loss total: 3.7771246433258057, Last rpr Loss: 0.9452653527259827, Last lagvar Loss: 1.0656166076660156\n",
      "Step 1536/10000- lr: [8.54748055757576e-06] - Loss total: 3.7754626274108887, Last rpr Loss: 0.9542068243026733, Last lagvar Loss: 1.0554051399230957\n",
      "Step 1537/10000- lr: [8.54647046060606e-06] - Loss total: 3.7759382724761963, Last rpr Loss: 1.0619089603424072, Last lagvar Loss: 0.9487335681915283\n",
      "Step 1538/10000- lr: [8.545460363636364e-06] - Loss total: 3.7742130756378174, Last rpr Loss: 1.050039529800415, Last lagvar Loss: 0.9589775800704956\n",
      "Step 1539/10000- lr: [8.544450266666667e-06] - Loss total: 3.773932933807373, Last rpr Loss: 0.9459498524665833, Last lagvar Loss: 1.06342613697052\n",
      "Step 1540/10000- lr: [8.54344016969697e-06] - Loss total: 3.7723257541656494, Last rpr Loss: 0.9546297192573547, Last lagvar Loss: 1.0534693002700806\n",
      "Step 1541/10000- lr: [8.542430072727274e-06] - Loss total: 3.772969961166382, Last rpr Loss: 1.062633752822876, Last lagvar Loss: 0.9467164278030396\n",
      "Step 1542/10000- lr: [8.541419975757575e-06] - Loss total: 3.771158456802368, Last rpr Loss: 1.0498322248458862, Last lagvar Loss: 0.9577547311782837\n",
      "Step 1543/10000- lr: [8.540409878787879e-06] - Loss total: 3.7710037231445312, Last rpr Loss: 0.9451083540916443, Last lagvar Loss: 1.0629899501800537\n",
      "Step 1544/10000- lr: [8.539399781818182e-06] - Loss total: 3.7694146633148193, Last rpr Loss: 0.9536833763122559, Last lagvar Loss: 1.0531094074249268\n",
      "Step 1545/10000- lr: [8.538389684848485e-06] - Loss total: 3.7698051929473877, Last rpr Loss: 1.0622096061706543, Last lagvar Loss: 0.9456312656402588\n",
      "Step 1546/10000- lr: [8.537379587878789e-06] - Loss total: 3.7679834365844727, Last rpr Loss: 1.0486958026885986, Last lagvar Loss: 0.9573237299919128\n",
      "Step 1547/10000- lr: [8.536369490909092e-06] - Loss total: 3.7681851387023926, Last rpr Loss: 0.9434126019477844, Last lagvar Loss: 1.0635367631912231\n",
      "Step 1548/10000- lr: [8.535359393939395e-06] - Loss total: 3.7665627002716064, Last rpr Loss: 0.9517958164215088, Last lagvar Loss: 1.0537693500518799\n",
      "Step 1549/10000- lr: [8.534349296969698e-06] - Loss total: 3.7666773796081543, Last rpr Loss: 1.061357021331787, Last lagvar Loss: 0.9449710845947266\n",
      "Step 1550/10000- lr: [8.5333392e-06] - Loss total: 3.764901876449585, Last rpr Loss: 1.0483806133270264, Last lagvar Loss: 0.9561585187911987\n",
      "Step 1551/10000- lr: [8.532329103030303e-06] - Loss total: 3.7652647495269775, Last rpr Loss: 0.9429197907447815, Last lagvar Loss: 1.062716007232666\n",
      "Step 1552/10000- lr: [8.531319006060607e-06] - Loss total: 3.7636053562164307, Last rpr Loss: 0.9512369632720947, Last lagvar Loss: 1.0529594421386719\n",
      "Step 1553/10000- lr: [8.53030890909091e-06] - Loss total: 3.7637083530426025, Last rpr Loss: 1.0617706775665283, Last lagvar Loss: 0.9431962370872498\n",
      "Step 1554/10000- lr: [8.529298812121213e-06] - Loss total: 3.761953115463257, Last rpr Loss: 1.0491856336593628, Last lagvar Loss: 0.9539821147918701\n",
      "Step 1555/10000- lr: [8.528288715151516e-06] - Loss total: 3.762237548828125, Last rpr Loss: 0.9429212212562561, Last lagvar Loss: 1.0612735748291016\n",
      "Step 1556/10000- lr: [8.527278618181818e-06] - Loss total: 3.7605574131011963, Last rpr Loss: 0.951167106628418, Last lagvar Loss: 1.0515415668487549\n",
      "Step 1557/10000- lr: [8.526268521212121e-06] - Loss total: 3.7608652114868164, Last rpr Loss: 1.0629470348358154, Last lagvar Loss: 0.9407566785812378\n",
      "Step 1558/10000- lr: [8.525258424242425e-06] - Loss total: 3.7591090202331543, Last rpr Loss: 1.051121711730957, Last lagvar Loss: 0.9507675170898438\n",
      "Step 1559/10000- lr: [8.524248327272728e-06] - Loss total: 3.759150266647339, Last rpr Loss: 0.9436590671539307, Last lagvar Loss: 1.0589581727981567\n",
      "Step 1560/10000- lr: [8.523238230303031e-06] - Loss total: 3.757493019104004, Last rpr Loss: 0.951375424861908, Last lagvar Loss: 1.0497822761535645\n",
      "Step 1561/10000- lr: [8.522228133333334e-06] - Loss total: 3.758023500442505, Last rpr Loss: 1.0640099048614502, Last lagvar Loss: 0.9383786916732788\n",
      "Step 1562/10000- lr: [8.521218036363638e-06] - Loss total: 3.7562477588653564, Last rpr Loss: 1.0527606010437012, Last lagvar Loss: 0.9477820992469788\n",
      "Step 1563/10000- lr: [8.52020793939394e-06] - Loss total: 3.756113290786743, Last rpr Loss: 0.9441530704498291, Last lagvar Loss: 1.0568890571594238\n",
      "Step 1564/10000- lr: [8.519197842424242e-06] - Loss total: 3.7544920444488525, Last rpr Loss: 0.951113224029541, Last lagvar Loss: 1.0485057830810547\n",
      "Step 1565/10000- lr: [8.518187745454546e-06] - Loss total: 3.7551066875457764, Last rpr Loss: 1.0641672611236572, Last lagvar Loss: 0.9367731809616089\n",
      "Step 1566/10000- lr: [8.517177648484849e-06] - Loss total: 3.7533295154571533, Last rpr Loss: 1.0535805225372314, Last lagvar Loss: 0.9455347657203674\n",
      "Step 1567/10000- lr: [8.516167551515152e-06] - Loss total: 3.75315260887146, Last rpr Loss: 0.944351077079773, Last lagvar Loss: 1.0551615953445435\n",
      "Step 1568/10000- lr: [8.515157454545456e-06] - Loss total: 3.7515764236450195, Last rpr Loss: 0.9506878852844238, Last lagvar Loss: 1.0474659204483032\n",
      "Step 1569/10000- lr: [8.514147357575757e-06] - Loss total: 3.7520968914031982, Last rpr Loss: 1.0635778903961182, Last lagvar Loss: 0.9357943534851074\n",
      "Step 1570/10000- lr: [8.51313726060606e-06] - Loss total: 3.750340461730957, Last rpr Loss: 1.0533215999603271, Last lagvar Loss: 0.9442947506904602\n",
      "Step 1571/10000- lr: [8.512127163636364e-06] - Loss total: 3.750279664993286, Last rpr Loss: 0.9437394142150879, Last lagvar Loss: 1.0543887615203857\n",
      "Step 1572/10000- lr: [8.511117066666667e-06] - Loss total: 3.748739004135132, Last rpr Loss: 0.9498030543327332, Last lagvar Loss: 1.04701828956604\n",
      "Step 1573/10000- lr: [8.51010696969697e-06] - Loss total: 3.7490413188934326, Last rpr Loss: 1.0624570846557617, Last lagvar Loss: 0.9353160858154297\n",
      "Step 1574/10000- lr: [8.509096872727274e-06] - Loss total: 3.7473323345184326, Last rpr Loss: 1.0526940822601318, Last lagvar Loss: 0.943438708782196\n",
      "Step 1575/10000- lr: [8.508086775757577e-06] - Loss total: 3.7474586963653564, Last rpr Loss: 0.9429761171340942, Last lagvar Loss: 1.0538784265518188\n",
      "Step 1576/10000- lr: [8.50707667878788e-06] - Loss total: 3.7459521293640137, Last rpr Loss: 0.9487066268920898, Last lagvar Loss: 1.0469025373458862\n",
      "Step 1577/10000- lr: [8.506066581818183e-06] - Loss total: 3.745967388153076, Last rpr Loss: 1.0608913898468018, Last lagvar Loss: 0.9352774620056152\n",
      "Step 1578/10000- lr: [8.505056484848485e-06] - Loss total: 3.744314432144165, Last rpr Loss: 1.0516921281814575, Last lagvar Loss: 0.9429618120193481\n",
      "Step 1579/10000- lr: [8.504046387878788e-06] - Loss total: 3.7446839809417725, Last rpr Loss: 0.9421120882034302, Last lagvar Loss: 1.053553581237793\n",
      "Step 1580/10000- lr: [8.503036290909092e-06] - Loss total: 3.7432053089141846, Last rpr Loss: 0.9475535154342651, Last lagvar Loss: 1.0469099283218384\n",
      "Step 1581/10000- lr: [8.502026193939395e-06] - Loss total: 3.7428970336914062, Last rpr Loss: 1.05912446975708, Last lagvar Loss: 0.9354733228683472\n",
      "Step 1582/10000- lr: [8.501016096969698e-06] - Loss total: 3.7412991523742676, Last rpr Loss: 1.0504894256591797, Last lagvar Loss: 0.9427111148834229\n",
      "Step 1583/10000- lr: [8.500006000000001e-06] - Loss total: 3.741954803466797, Last rpr Loss: 0.9412287473678589, Last lagvar Loss: 1.0533058643341064\n",
      "Step 1584/10000- lr: [8.498995903030303e-06] - Loss total: 3.7404980659484863, Last rpr Loss: 0.9463986158370972, Last lagvar Loss: 1.0469756126403809\n",
      "Step 1585/10000- lr: [8.497985806060606e-06] - Loss total: 3.7398293018341064, Last rpr Loss: 1.0572092533111572, Last lagvar Loss: 0.9358429908752441\n",
      "Step 1586/10000- lr: [8.49697570909091e-06] - Loss total: 3.7382824420928955, Last rpr Loss: 1.0490412712097168, Last lagvar Loss: 0.9427161812782288\n",
      "Step 1587/10000- lr: [8.495965612121213e-06] - Loss total: 3.7392725944519043, Last rpr Loss: 0.9402023553848267, Last lagvar Loss: 1.0532547235488892\n",
      "Step 1588/10000- lr: [8.494955515151516e-06] - Loss total: 3.737828493118286, Last rpr Loss: 0.9451119899749756, Last lagvar Loss: 1.0472112894058228\n",
      "Step 1589/10000- lr: [8.49394541818182e-06] - Loss total: 3.7367701530456543, Last rpr Loss: 1.055185317993164, Last lagvar Loss: 0.9363598227500916\n",
      "Step 1590/10000- lr: [8.492935321212123e-06] - Loss total: 3.735274076461792, Last rpr Loss: 1.0475587844848633, Last lagvar Loss: 0.9427850246429443\n",
      "Step 1591/10000- lr: [8.491925224242424e-06] - Loss total: 3.736626148223877, Last rpr Loss: 0.939211368560791, Last lagvar Loss: 1.053209900856018\n",
      "Step 1592/10000- lr: [8.490915127272727e-06] - Loss total: 3.735189199447632, Last rpr Loss: 0.9437805414199829, Last lagvar Loss: 1.0475337505340576\n",
      "Step 1593/10000- lr: [8.48990503030303e-06] - Loss total: 3.733719825744629, Last rpr Loss: 1.0529911518096924, Last lagvar Loss: 0.9370719194412231\n",
      "Step 1594/10000- lr: [8.488894933333334e-06] - Loss total: 3.7322731018066406, Last rpr Loss: 1.0458993911743164, Last lagvar Loss: 0.9430503845214844\n",
      "Step 1595/10000- lr: [8.487884836363637e-06] - Loss total: 3.734002113342285, Last rpr Loss: 0.938130259513855, Last lagvar Loss: 1.0532782077789307\n",
      "Step 1596/10000- lr: [8.48687473939394e-06] - Loss total: 3.73256516456604, Last rpr Loss: 0.9424376487731934, Last lagvar Loss: 1.0478755235671997\n",
      "Step 1597/10000- lr: [8.485864642424242e-06] - Loss total: 3.7306840419769287, Last rpr Loss: 1.0507993698120117, Last lagvar Loss: 0.9378125667572021\n",
      "Step 1598/10000- lr: [8.484854545454545e-06] - Loss total: 3.7292840480804443, Last rpr Loss: 1.0442054271697998, Last lagvar Loss: 0.9433708190917969\n",
      "Step 1599/10000- lr: [8.483844448484849e-06] - Loss total: 3.73138427734375, Last rpr Loss: 0.9369911551475525, Last lagvar Loss: 1.053410291671753\n",
      "Step 1600/10000- lr: [8.482834351515152e-06] - Loss total: 3.7299418449401855, Last rpr Loss: 0.9411352276802063, Last lagvar Loss: 1.0481765270233154\n",
      "Step 1601/10000- lr: [8.481824254545455e-06] - Loss total: 3.727666139602661, Last rpr Loss: 1.048759937286377, Last lagvar Loss: 0.9384172558784485\n",
      "Step 1602/10000- lr: [8.480814157575759e-06] - Loss total: 3.726313352584839, Last rpr Loss: 1.0426685810089111, Last lagvar Loss: 0.9435464143753052\n",
      "Step 1603/10000- lr: [8.479804060606062e-06] - Loss total: 3.728747844696045, Last rpr Loss: 0.9358794093132019, Last lagvar Loss: 1.0534894466400146\n",
      "Step 1604/10000- lr: [8.478793963636365e-06] - Loss total: 3.7272965908050537, Last rpr Loss: 0.9399129152297974, Last lagvar Loss: 1.0483661890029907\n",
      "Step 1605/10000- lr: [8.477783866666667e-06] - Loss total: 3.724679708480835, Last rpr Loss: 1.0470340251922607, Last lagvar Loss: 0.9387302398681641\n",
      "Step 1606/10000- lr: [8.47677376969697e-06] - Loss total: 3.723374366760254, Last rpr Loss: 1.041585087776184, Last lagvar Loss: 0.9432933330535889\n",
      "Step 1607/10000- lr: [8.475763672727273e-06] - Loss total: 3.726067066192627, Last rpr Loss: 0.9350210428237915, Last lagvar Loss: 1.053284764289856\n",
      "Step 1608/10000- lr: [8.474753575757577e-06] - Loss total: 3.724604368209839, Last rpr Loss: 0.9389587640762329, Last lagvar Loss: 1.0482642650604248\n",
      "Step 1609/10000- lr: [8.47374347878788e-06] - Loss total: 3.7217423915863037, Last rpr Loss: 1.0458507537841797, Last lagvar Loss: 0.938549816608429\n",
      "Step 1610/10000- lr: [8.472733381818181e-06] - Loss total: 3.720489978790283, Last rpr Loss: 1.041156530380249, Last lagvar Loss: 0.942457914352417\n",
      "Step 1611/10000- lr: [8.471723284848485e-06] - Loss total: 3.7232987880706787, Last rpr Loss: 0.9344998598098755, Last lagvar Loss: 1.0526814460754395\n",
      "Step 1612/10000- lr: [8.470713187878788e-06] - Loss total: 3.7218246459960938, Last rpr Loss: 0.9384210109710693, Last lagvar Loss: 1.0476877689361572\n",
      "Step 1613/10000- lr: [8.469703090909091e-06] - Loss total: 3.71889066696167, Last rpr Loss: 1.045598030090332, Last lagvar Loss: 0.9375596642494202\n",
      "Step 1614/10000- lr: [8.468692993939394e-06] - Loss total: 3.717695951461792, Last rpr Loss: 1.041832685470581, Last lagvar Loss: 0.9406611919403076\n",
      "Step 1615/10000- lr: [8.467682896969698e-06] - Loss total: 3.7203967571258545, Last rpr Loss: 0.9346961379051208, Last lagvar Loss: 1.0512571334838867\n",
      "Step 1616/10000- lr: [8.466672800000001e-06] - Loss total: 3.7189183235168457, Last rpr Loss: 0.9387023448944092, Last lagvar Loss: 1.0462021827697754\n",
      "Step 1617/10000- lr: [8.465662703030304e-06] - Loss total: 3.716174364089966, Last rpr Loss: 1.0467420816421509, Last lagvar Loss: 0.9353444576263428\n",
      "Step 1618/10000- lr: [8.464652606060608e-06] - Loss total: 3.715043306350708, Last rpr Loss: 1.0439834594726562, Last lagvar Loss: 0.9375842809677124\n",
      "Step 1619/10000- lr: [8.46364250909091e-06] - Loss total: 3.7173097133636475, Last rpr Loss: 0.9359700679779053, Last lagvar Loss: 1.048567771911621\n",
      "Step 1620/10000- lr: [8.462632412121212e-06] - Loss total: 3.7158424854278564, Last rpr Loss: 0.9401425123214722, Last lagvar Loss: 1.0433838367462158\n",
      "Step 1621/10000- lr: [8.461622315151516e-06] - Loss total: 3.713657855987549, Last rpr Loss: 1.0496900081634521, Last lagvar Loss: 0.9315587282180786\n",
      "Step 1622/10000- lr: [8.460612218181819e-06] - Loss total: 3.712590456008911, Last rpr Loss: 1.0479567050933838, Last lagvar Loss: 0.9329201579093933\n",
      "Step 1623/10000- lr: [8.459602121212122e-06] - Loss total: 3.7140285968780518, Last rpr Loss: 0.9388139247894287, Last lagvar Loss: 1.0440843105316162\n",
      "Step 1624/10000- lr: [8.458592024242426e-06] - Loss total: 3.712603807449341, Last rpr Loss: 0.9430550336837769, Last lagvar Loss: 1.0388997793197632\n",
      "Step 1625/10000- lr: [8.457581927272727e-06] - Loss total: 3.711379289627075, Last rpr Loss: 1.054380178451538, Last lagvar Loss: 0.92628014087677\n",
      "Step 1626/10000- lr: [8.45657183030303e-06] - Loss total: 3.7103428840637207, Last rpr Loss: 1.053282380104065, Last lagvar Loss: 0.9271016120910645\n",
      "Step 1627/10000- lr: [8.455561733333334e-06] - Loss total: 3.7106540203094482, Last rpr Loss: 0.9429161548614502, Last lagvar Loss: 1.0382049083709717\n",
      "Step 1628/10000- lr: [8.454551636363637e-06] - Loss total: 3.7093145847320557, Last rpr Loss: 0.9468601942062378, Last lagvar Loss: 1.033416748046875\n",
      "Step 1629/10000- lr: [8.45354153939394e-06] - Loss total: 3.709254741668701, Last rpr Loss: 1.0596222877502441, Last lagvar Loss: 0.9205996990203857\n",
      "Step 1630/10000- lr: [8.452531442424244e-06] - Loss total: 3.7081828117370605, Last rpr Loss: 1.058590054512024, Last lagvar Loss: 0.9213455319404602\n",
      "Step 1631/10000- lr: [8.451521345454547e-06] - Loss total: 3.7073864936828613, Last rpr Loss: 0.94718998670578, Last lagvar Loss: 1.0322482585906982\n",
      "Step 1632/10000- lr: [8.450511248484848e-06] - Loss total: 3.70615553855896, Last rpr Loss: 0.950403094291687, Last lagvar Loss: 1.0283074378967285\n",
      "Step 1633/10000- lr: [8.449501151515152e-06] - Loss total: 3.7070741653442383, Last rpr Loss: 1.0636643171310425, Last lagvar Loss: 0.9160394668579102\n",
      "Step 1634/10000- lr: [8.448491054545455e-06] - Loss total: 3.705907106399536, Last rpr Loss: 1.062082290649414, Last lagvar Loss: 0.9172359108924866\n",
      "Step 1635/10000- lr: [8.447480957575758e-06] - Loss total: 3.7043750286102295, Last rpr Loss: 0.9499605894088745, Last lagvar Loss: 1.0280711650848389\n",
      "Step 1636/10000- lr: [8.446470860606062e-06] - Loss total: 3.703240394592285, Last rpr Loss: 0.9523698091506958, Last lagvar Loss: 1.025031566619873\n",
      "Step 1637/10000- lr: [8.445460763636365e-06] - Loss total: 3.704637289047241, Last rpr Loss: 1.0652989149093628, Last lagvar Loss: 0.9136109352111816\n",
      "Step 1638/10000- lr: [8.444450666666666e-06] - Loss total: 3.7033703327178955, Last rpr Loss: 1.0631132125854492, Last lagvar Loss: 0.9153019189834595\n",
      "Step 1639/10000- lr: [8.44344056969697e-06] - Loss total: 3.7016420364379883, Last rpr Loss: 0.9507880210876465, Last lagvar Loss: 1.0261452198028564\n",
      "Step 1640/10000- lr: [8.442430472727273e-06] - Loss total: 3.7005646228790283, Last rpr Loss: 0.9525653719902039, Last lagvar Loss: 1.023796796798706\n",
      "Step 1641/10000- lr: [8.441420375757576e-06] - Loss total: 3.7019059658050537, Last rpr Loss: 1.0644625425338745, Last lagvar Loss: 0.9133366942405701\n",
      "Step 1642/10000- lr: [8.44041027878788e-06] - Loss total: 3.700589418411255, Last rpr Loss: 1.0619502067565918, Last lagvar Loss: 0.9152994155883789\n",
      "Step 1643/10000- lr: [8.439400181818183e-06] - Loss total: 3.699108123779297, Last rpr Loss: 0.9500449895858765, Last lagvar Loss: 1.0260019302368164\n",
      "Step 1644/10000- lr: [8.438390084848486e-06] - Loss total: 3.698046922683716, Last rpr Loss: 0.9514789581298828, Last lagvar Loss: 1.0240111351013184\n",
      "Step 1645/10000- lr: [8.43737998787879e-06] - Loss total: 3.6990034580230713, Last rpr Loss: 1.0620977878570557, Last lagvar Loss: 0.9144046902656555\n",
      "Step 1646/10000- lr: [8.436369890909091e-06] - Loss total: 3.6976940631866455, Last rpr Loss: 1.0597937107086182, Last lagvar Loss: 0.9161686897277832\n",
      "Step 1647/10000- lr: [8.435359793939394e-06] - Loss total: 3.696657419204712, Last rpr Loss: 0.9488778710365295, Last lagvar Loss: 1.0263440608978271\n",
      "Step 1648/10000- lr: [8.434349696969697e-06] - Loss total: 3.695577383041382, Last rpr Loss: 0.95017009973526, Last lagvar Loss: 1.0244688987731934\n",
      "Step 1649/10000- lr: [8.4333396e-06] - Loss total: 3.6960954666137695, Last rpr Loss: 1.059529423713684, Last lagvar Loss: 0.9156658053398132\n",
      "Step 1650/10000- lr: [8.432329503030304e-06] - Loss total: 3.6948235034942627, Last rpr Loss: 1.057647466659546, Last lagvar Loss: 0.9170374870300293\n",
      "Step 1651/10000- lr: [8.431319406060607e-06] - Loss total: 3.694182872772217, Last rpr Loss: 0.947866678237915, Last lagvar Loss: 1.0264421701431274\n",
      "Step 1652/10000- lr: [8.430309309090909e-06] - Loss total: 3.693066120147705, Last rpr Loss: 0.9492172002792358, Last lagvar Loss: 1.0244556665420532\n",
      "Step 1653/10000- lr: [8.429299212121212e-06] - Loss total: 3.6932928562164307, Last rpr Loss: 1.0577987432479858, Last lagvar Loss: 0.9161760807037354\n",
      "Step 1654/10000- lr: [8.428289115151515e-06] - Loss total: 3.6920597553253174, Last rpr Loss: 1.0563874244689941, Last lagvar Loss: 0.9170840978622437\n",
      "Step 1655/10000- lr: [8.427279018181819e-06] - Loss total: 3.691622018814087, Last rpr Loss: 0.9475377798080444, Last lagvar Loss: 1.0256606340408325\n",
      "Step 1656/10000- lr: [8.426268921212122e-06] - Loss total: 3.6904666423797607, Last rpr Loss: 0.9489903450012207, Last lagvar Loss: 1.0235118865966797\n",
      "Step 1657/10000- lr: [8.425258824242425e-06] - Loss total: 3.6906301975250244, Last rpr Loss: 1.057255506515503, Last lagvar Loss: 0.9155676364898682\n",
      "Step 1658/10000- lr: [8.424248727272729e-06] - Loss total: 3.689415454864502, Last rpr Loss: 1.0561027526855469, Last lagvar Loss: 0.9161680936813354\n",
      "Step 1659/10000- lr: [8.423238630303032e-06] - Loss total: 3.688971996307373, Last rpr Loss: 0.9479066133499146, Last lagvar Loss: 1.0239856243133545\n",
      "Step 1660/10000- lr: [8.422228533333333e-06] - Loss total: 3.687795400619507, Last rpr Loss: 0.9493627548217773, Last lagvar Loss: 1.021798849105835\n",
      "Step 1661/10000- lr: [8.421218436363637e-06] - Loss total: 3.688067674636841, Last rpr Loss: 1.0574231147766113, Last lagvar Loss: 0.9142183065414429\n",
      "Step 1662/10000- lr: [8.42020833939394e-06] - Loss total: 3.6868486404418945, Last rpr Loss: 1.0563604831695557, Last lagvar Loss: 0.9146637916564941\n",
      "Step 1663/10000- lr: [8.419198242424243e-06] - Loss total: 3.686284303665161, Last rpr Loss: 0.9487781524658203, Last lagvar Loss: 1.0217581987380981\n",
      "Step 1664/10000- lr: [8.418188145454546e-06] - Loss total: 3.685105323791504, Last rpr Loss: 0.9501813650131226, Last lagvar Loss: 1.0196244716644287\n",
      "Step 1665/10000- lr: [8.41717804848485e-06] - Loss total: 3.685551881790161, Last rpr Loss: 1.057939887046814, Last lagvar Loss: 0.9125128984451294\n",
      "Step 1666/10000- lr: [8.416167951515151e-06] - Loss total: 3.6843178272247314, Last rpr Loss: 1.056769609451294, Last lagvar Loss: 0.913043737411499\n",
      "Step 1667/10000- lr: [8.415157854545455e-06] - Loss total: 3.683610200881958, Last rpr Loss: 0.9496307969093323, Last lagvar Loss: 1.019633173942566\n",
      "Step 1668/10000- lr: [8.414147757575758e-06] - Loss total: 3.6824426651000977, Last rpr Loss: 0.9509835839271545, Last lagvar Loss: 1.017561912536621\n",
      "Step 1669/10000- lr: [8.413137660606061e-06] - Loss total: 3.6830379962921143, Last rpr Loss: 1.0584683418273926, Last lagvar Loss: 0.9108392596244812\n",
      "Step 1670/10000- lr: [8.412127563636364e-06] - Loss total: 3.6817855834960938, Last rpr Loss: 1.0571293830871582, Last lagvar Loss: 0.9115268588066101\n",
      "Step 1671/10000- lr: [8.411117466666668e-06] - Loss total: 3.6809871196746826, Last rpr Loss: 0.9502480030059814, Last lagvar Loss: 1.0178471803665161\n",
      "Step 1672/10000- lr: [8.410107369696971e-06] - Loss total: 3.679837226867676, Last rpr Loss: 0.9514270424842834, Last lagvar Loss: 1.0159673690795898\n",
      "Step 1673/10000- lr: [8.409097272727274e-06] - Loss total: 3.680485963821411, Last rpr Loss: 1.058422327041626, Last lagvar Loss: 0.9097198843955994\n",
      "Step 1674/10000- lr: [8.408087175757576e-06] - Loss total: 3.6792194843292236, Last rpr Loss: 1.0569292306900024, Last lagvar Loss: 0.9105565547943115\n",
      "Step 1675/10000- lr: [8.407077078787879e-06] - Loss total: 3.6784286499023438, Last rpr Loss: 0.950415313243866, Last lagvar Loss: 1.016608476638794\n",
      "Step 1676/10000- lr: [8.406066981818182e-06] - Loss total: 3.677290678024292, Last rpr Loss: 0.951513409614563, Last lagvar Loss: 1.0148212909698486\n",
      "Step 1677/10000- lr: [8.405056884848486e-06] - Loss total: 3.677894115447998, Last rpr Loss: 1.0579197406768799, Last lagvar Loss: 0.909042239189148\n",
      "Step 1678/10000- lr: [8.404046787878789e-06] - Loss total: 3.6766231060028076, Last rpr Loss: 1.0563228130340576, Last lagvar Loss: 0.9099899530410767\n",
      "Step 1679/10000- lr: [8.40303669090909e-06] - Loss total: 3.6759212017059326, Last rpr Loss: 0.9503144025802612, Last lagvar Loss: 1.0157105922698975\n",
      "Step 1680/10000- lr: [8.402026593939394e-06] - Loss total: 3.6747848987579346, Last rpr Loss: 0.9514459371566772, Last lagvar Loss: 1.0138899087905884\n",
      "Step 1681/10000- lr: [8.401016496969697e-06] - Loss total: 3.675286293029785, Last rpr Loss: 1.057242512702942, Last lagvar Loss: 0.9085642099380493\n",
      "Step 1682/10000- lr: [8.4000064e-06] - Loss total: 3.6740150451660156, Last rpr Loss: 1.055505633354187, Last lagvar Loss: 0.9096543192863464\n",
      "Step 1683/10000- lr: [8.398996303030304e-06] - Loss total: 3.673444986343384, Last rpr Loss: 0.9500243663787842, Last lagvar Loss: 1.015048861503601\n",
      "Step 1684/10000- lr: [8.397986206060607e-06] - Loss total: 3.672301769256592, Last rpr Loss: 0.9512683153152466, Last lagvar Loss: 1.013106107711792\n",
      "Step 1685/10000- lr: [8.39697610909091e-06] - Loss total: 3.6726791858673096, Last rpr Loss: 1.0564939975738525, Last lagvar Loss: 0.9081830978393555\n",
      "Step 1686/10000- lr: [8.395966012121213e-06] - Loss total: 3.6714107990264893, Last rpr Loss: 1.0545933246612549, Last lagvar Loss: 0.9094346761703491\n",
      "Step 1687/10000- lr: [8.394955915151515e-06] - Loss total: 3.6709816455841064, Last rpr Loss: 0.9496298432350159, Last lagvar Loss: 1.0145163536071777\n",
      "Step 1688/10000- lr: [8.393945818181818e-06] - Loss total: 3.669825792312622, Last rpr Loss: 0.9510663747787476, Last lagvar Loss: 1.0123624801635742\n",
      "Step 1689/10000- lr: [8.392935721212122e-06] - Loss total: 3.670088052749634, Last rpr Loss: 1.0558578968048096, Last lagvar Loss: 0.907724142074585\n",
      "Step 1690/10000- lr: [8.391925624242425e-06] - Loss total: 3.6688232421875, Last rpr Loss: 1.0537796020507812, Last lagvar Loss: 0.9091485738754272\n",
      "Step 1691/10000- lr: [8.390915527272728e-06] - Loss total: 3.668515920639038, Last rpr Loss: 0.9492506980895996, Last lagvar Loss: 1.0139706134796143\n",
      "Step 1692/10000- lr: [8.389905430303031e-06] - Loss total: 3.667346477508545, Last rpr Loss: 0.9508866667747498, Last lagvar Loss: 1.0115976333618164\n",
      "Step 1693/10000- lr: [8.388895333333333e-06] - Loss total: 3.6675198078155518, Last rpr Loss: 1.0553827285766602, Last lagvar Loss: 0.9071439504623413\n",
      "Step 1694/10000- lr: [8.387885236363636e-06] - Loss total: 3.666259765625, Last rpr Loss: 1.0531513690948486, Last lagvar Loss: 0.9087173938751221\n",
      "Step 1695/10000- lr: [8.38687513939394e-06] - Loss total: 3.666043281555176, Last rpr Loss: 0.9489800930023193, Last lagvar Loss: 1.0133060216903687\n",
      "Step 1696/10000- lr: [8.385865042424243e-06] - Loss total: 3.6648647785186768, Last rpr Loss: 0.9508211612701416, Last lagvar Loss: 1.010713815689087\n",
      "Step 1697/10000- lr: [8.384854945454546e-06] - Loss total: 3.6649811267852783, Last rpr Loss: 1.055119276046753, Last lagvar Loss: 0.9063957929611206\n",
      "Step 1698/10000- lr: [8.38384484848485e-06] - Loss total: 3.6637251377105713, Last rpr Loss: 1.0526889562606812, Last lagvar Loss: 0.9081610441207886\n",
      "Step 1699/10000- lr: [8.382834751515153e-06] - Loss total: 3.663573741912842, Last rpr Loss: 0.948750376701355, Last lagvar Loss: 1.012603521347046\n",
      "Step 1700/10000- lr: [8.381824654545456e-06] - Loss total: 3.662391185760498, Last rpr Loss: 0.9507923722267151, Last lagvar Loss: 1.0098028182983398\n",
      "Step 1701/10000- lr: [8.380814557575758e-06] - Loss total: 3.662464141845703, Last rpr Loss: 1.0549588203430176, Last lagvar Loss: 0.9055711030960083\n",
      "Step 1702/10000- lr: [8.379804460606061e-06] - Loss total: 3.6612112522125244, Last rpr Loss: 1.052272081375122, Last lagvar Loss: 0.9075839519500732\n",
      "Step 1703/10000- lr: [8.378794363636364e-06] - Loss total: 3.661119222640991, Last rpr Loss: 0.9484459161758423, Last lagvar Loss: 1.0119972229003906\n",
      "Step 1704/10000- lr: [8.377784266666667e-06] - Loss total: 3.65993595123291, Last rpr Loss: 0.9506537914276123, Last lagvar Loss: 1.0090267658233643\n",
      "Step 1705/10000- lr: [8.37677416969697e-06] - Loss total: 3.659958839416504, Last rpr Loss: 1.0547206401824951, Last lagvar Loss: 0.9048338532447815\n",
      "Step 1706/10000- lr: [8.375764072727274e-06] - Loss total: 3.6587092876434326, Last rpr Loss: 1.0518264770507812, Last lagvar Loss: 0.907050609588623\n",
      "Step 1707/10000- lr: [8.374753975757576e-06] - Loss total: 3.6586854457855225, Last rpr Loss: 0.9481040239334106, Last lagvar Loss: 1.01145339012146\n",
      "Step 1708/10000- lr: [8.373743878787879e-06] - Loss total: 3.6575028896331787, Last rpr Loss: 0.9504599571228027, Last lagvar Loss: 1.0083320140838623\n",
      "Step 1709/10000- lr: [8.372733781818182e-06] - Loss total: 3.657461404800415, Last rpr Loss: 1.0544366836547852, Last lagvar Loss: 0.9041590690612793\n",
      "Step 1710/10000- lr: [8.371723684848485e-06] - Loss total: 3.656216621398926, Last rpr Loss: 1.0513739585876465, Last lagvar Loss: 0.9065443873405457\n",
      "Step 1711/10000- lr: [8.370713587878789e-06] - Loss total: 3.6562724113464355, Last rpr Loss: 0.9477771520614624, Last lagvar Loss: 1.010914921760559\n",
      "Step 1712/10000- lr: [8.369703490909092e-06] - Loss total: 3.655088186264038, Last rpr Loss: 0.9503030180931091, Last lagvar Loss: 1.0076196193695068\n",
      "Step 1713/10000- lr: [8.368693393939395e-06] - Loss total: 3.654975414276123, Last rpr Loss: 1.0542172193527222, Last lagvar Loss: 0.903447151184082\n",
      "Step 1714/10000- lr: [8.367683296969698e-06] - Loss total: 3.6537349224090576, Last rpr Loss: 1.050970435142517, Last lagvar Loss: 0.9060143232345581\n",
      "Step 1715/10000- lr: [8.3666732e-06] - Loss total: 3.6538755893707275, Last rpr Loss: 0.9474633932113647, Last lagvar Loss: 1.0103851556777954\n",
      "Step 1716/10000- lr: [8.365663103030303e-06] - Loss total: 3.65268874168396, Last rpr Loss: 0.9501609206199646, Last lagvar Loss: 1.0069142580032349\n",
      "Step 1717/10000- lr: [8.364653006060607e-06] - Loss total: 3.652503252029419, Last rpr Loss: 1.054038643836975, Last lagvar Loss: 0.9027184844017029\n",
      "Step 1718/10000- lr: [8.36364290909091e-06] - Loss total: 3.6512668132781982, Last rpr Loss: 1.0505836009979248, Last lagvar Loss: 0.905490517616272\n",
      "Step 1719/10000- lr: [8.362632812121213e-06] - Loss total: 3.6514930725097656, Last rpr Loss: 0.9471138715744019, Last lagvar Loss: 1.0099174976348877\n",
      "Step 1720/10000- lr: [8.361622715151516e-06] - Loss total: 3.6503021717071533, Last rpr Loss: 0.9499616622924805, Last lagvar Loss: 1.0062929391860962\n",
      "Step 1721/10000- lr: [8.360612618181818e-06] - Loss total: 3.6500439643859863, Last rpr Loss: 1.0538177490234375, Last lagvar Loss: 0.9020520448684692\n",
      "Step 1722/10000- lr: [8.359602521212121e-06] - Loss total: 3.6488122940063477, Last rpr Loss: 1.0501649379730225, Last lagvar Loss: 0.9050191640853882\n",
      "Step 1723/10000- lr: [8.358592424242425e-06] - Loss total: 3.6491219997406006, Last rpr Loss: 0.9467167854309082, Last lagvar Loss: 1.0095241069793701\n",
      "Step 1724/10000- lr: [8.357582327272728e-06] - Loss total: 3.6479275226593018, Last rpr Loss: 0.9496971368789673, Last lagvar Loss: 1.0057625770568848\n",
      "Step 1725/10000- lr: [8.356572230303031e-06] - Loss total: 3.647597074508667, Last rpr Loss: 1.0535633563995361, Last lagvar Loss: 0.901439905166626\n",
      "Step 1726/10000- lr: [8.355562133333334e-06] - Loss total: 3.6463704109191895, Last rpr Loss: 1.0497653484344482, Last lagvar Loss: 0.9045515656471252\n",
      "Step 1727/10000- lr: [8.354552036363638e-06] - Loss total: 3.6467623710632324, Last rpr Loss: 0.9463337659835815, Last lagvar Loss: 1.0091357231140137\n",
      "Step 1728/10000- lr: [8.35354193939394e-06] - Loss total: 3.6455650329589844, Last rpr Loss: 0.9494277238845825, Last lagvar Loss: 1.0052554607391357\n",
      "Step 1729/10000- lr: [8.352531842424243e-06] - Loss total: 3.645162343978882, Last rpr Loss: 1.0533173084259033, Last lagvar Loss: 0.900840163230896\n",
      "Step 1730/10000- lr: [8.351521745454546e-06] - Loss total: 3.6439409255981445, Last rpr Loss: 1.049414873123169, Last lagvar Loss: 0.9040582180023193\n",
      "Step 1731/10000- lr: [8.350511648484849e-06] - Loss total: 3.644413948059082, Last rpr Loss: 0.945988655090332, Last lagvar Loss: 1.0087218284606934\n",
      "Step 1732/10000- lr: [8.349501551515152e-06] - Loss total: 3.6432135105133057, Last rpr Loss: 0.9491685628890991, Last lagvar Loss: 1.004752278327942\n",
      "Step 1733/10000- lr: [8.348491454545456e-06] - Loss total: 3.6427388191223145, Last rpr Loss: 1.0530791282653809, Last lagvar Loss: 0.9002512693405151\n",
      "Step 1734/10000- lr: [8.347481357575757e-06] - Loss total: 3.641523599624634, Last rpr Loss: 1.049094319343567, Last lagvar Loss: 0.9035562872886658\n",
      "Step 1735/10000- lr: [8.34647126060606e-06] - Loss total: 3.6420741081237793, Last rpr Loss: 0.9456444978713989, Last lagvar Loss: 1.0083190202713013\n",
      "Step 1736/10000- lr: [8.345461163636364e-06] - Loss total: 3.64087176322937, Last rpr Loss: 0.9489037990570068, Last lagvar Loss: 1.0042675733566284\n",
      "Step 1737/10000- lr: [8.344451066666667e-06] - Loss total: 3.6403279304504395, Last rpr Loss: 1.0528762340545654, Last lagvar Loss: 0.8996457457542419\n",
      "Step 1738/10000- lr: [8.34344096969697e-06] - Loss total: 3.6391212940216064, Last rpr Loss: 1.0488507747650146, Last lagvar Loss: 0.9029989838600159\n",
      "Step 1739/10000- lr: [8.342430872727274e-06] - Loss total: 3.639739990234375, Last rpr Loss: 0.9453275203704834, Last lagvar Loss: 1.0078989267349243\n",
      "Step 1740/10000- lr: [8.341420775757577e-06] - Loss total: 3.6385371685028076, Last rpr Loss: 0.9486309289932251, Last lagvar Loss: 1.0038036108016968\n",
      "Step 1741/10000- lr: [8.34041067878788e-06] - Loss total: 3.6379313468933105, Last rpr Loss: 1.052697777748108, Last lagvar Loss: 0.8990316390991211\n",
      "Step 1742/10000- lr: [8.339400581818183e-06] - Loss total: 3.6367344856262207, Last rpr Loss: 1.0486979484558105, Last lagvar Loss: 0.9023715257644653\n",
      "Step 1743/10000- lr: [8.338390484848485e-06] - Loss total: 3.63740873336792, Last rpr Loss: 0.9450682997703552, Last lagvar Loss: 1.0074273347854614\n",
      "Step 1744/10000- lr: [8.337380387878788e-06] - Loss total: 3.6362059116363525, Last rpr Loss: 0.9483891725540161, Last lagvar Loss: 1.00331711769104\n",
      "Step 1745/10000- lr: [8.336370290909092e-06] - Loss total: 3.635551929473877, Last rpr Loss: 1.0525755882263184, Last lagvar Loss: 0.8983772397041321\n",
      "Step 1746/10000- lr: [8.335360193939395e-06] - Loss total: 3.6343672275543213, Last rpr Loss: 1.0486630201339722, Last lagvar Loss: 0.9016475677490234\n",
      "Step 1747/10000- lr: [8.334350096969698e-06] - Loss total: 3.6350746154785156, Last rpr Loss: 0.9448963403701782, Last lagvar Loss: 1.0068702697753906\n",
      "Step 1748/10000- lr: [8.33334e-06] - Loss total: 3.6338729858398438, Last rpr Loss: 0.9482215642929077, Last lagvar Loss: 1.002760410308838\n",
      "Step 1749/10000- lr: [8.332329903030303e-06] - Loss total: 3.6331961154937744, Last rpr Loss: 1.0525791645050049, Last lagvar Loss: 0.8976173400878906\n",
      "Step 1750/10000- lr: [8.331319806060606e-06] - Loss total: 3.632025957107544, Last rpr Loss: 1.0488070249557495, Last lagvar Loss: 0.9007715582847595\n",
      "Step 1751/10000- lr: [8.33030970909091e-06] - Loss total: 3.6327319145202637, Last rpr Loss: 0.9448394775390625, Last lagvar Loss: 1.0061938762664795\n",
      "Step 1752/10000- lr: [8.329299612121213e-06] - Loss total: 3.6315340995788574, Last rpr Loss: 0.9481537342071533, Last lagvar Loss: 1.0021034479141235\n",
      "Step 1753/10000- lr: [8.328289515151516e-06] - Loss total: 3.6308679580688477, Last rpr Loss: 1.052761435508728, Last lagvar Loss: 0.8967038989067078\n",
      "Step 1754/10000- lr: [8.32727941818182e-06] - Loss total: 3.629713773727417, Last rpr Loss: 1.0491877794265747, Last lagvar Loss: 0.899691641330719\n",
      "Step 1755/10000- lr: [8.326269321212123e-06] - Loss total: 3.6303741931915283, Last rpr Loss: 0.9449387788772583, Last lagvar Loss: 1.00534987449646\n",
      "Step 1756/10000- lr: [8.325259224242424e-06] - Loss total: 3.629183053970337, Last rpr Loss: 0.9482278823852539, Last lagvar Loss: 1.0012974739074707\n",
      "Step 1757/10000- lr: [8.324249127272728e-06] - Loss total: 3.6285760402679443, Last rpr Loss: 1.0531824827194214, Last lagvar Loss: 0.8955845832824707\n",
      "Step 1758/10000- lr: [8.32323903030303e-06] - Loss total: 3.6274402141571045, Last rpr Loss: 1.0498632192611694, Last lagvar Loss: 0.8983581066131592\n",
      "Step 1759/10000- lr: [8.322228933333334e-06] - Loss total: 3.627995014190674, Last rpr Loss: 0.9452488422393799, Last lagvar Loss: 1.0042754411697388\n",
      "Step 1760/10000- lr: [8.321218836363637e-06] - Loss total: 3.626814126968384, Last rpr Loss: 0.9484973549842834, Last lagvar Loss: 1.0002820491790771\n",
      "Step 1761/10000- lr: [8.32020873939394e-06] - Loss total: 3.6263267993927, Last rpr Loss: 1.0539066791534424, Last lagvar Loss: 0.8942033052444458\n",
      "Step 1762/10000- lr: [8.319198642424242e-06] - Loss total: 3.625209331512451, Last rpr Loss: 1.05086350440979, Last lagvar Loss: 0.8967478275299072\n",
      "Step 1763/10000- lr: [8.318188545454546e-06] - Loss total: 3.6255908012390137, Last rpr Loss: 0.945789635181427, Last lagvar Loss: 1.0029445886611938\n",
      "Step 1764/10000- lr: [8.317178448484849e-06] - Loss total: 3.6244261264801025, Last rpr Loss: 0.9489903450012207, Last lagvar Loss: 0.9990236759185791\n",
      "Step 1765/10000- lr: [8.316168351515152e-06] - Loss total: 3.624124765396118, Last rpr Loss: 1.0549637079238892, Last lagvar Loss: 0.8925361633300781\n",
      "Step 1766/10000- lr: [8.315158254545455e-06] - Loss total: 3.62302565574646, Last rpr Loss: 1.052189826965332, Last lagvar Loss: 0.8948631286621094\n",
      "Step 1767/10000- lr: [8.314148157575759e-06] - Loss total: 3.623164653778076, Last rpr Loss: 0.9465688467025757, Last lagvar Loss: 1.0013481378555298\n",
      "Step 1768/10000- lr: [8.313138060606062e-06] - Loss total: 3.6220223903656006, Last rpr Loss: 0.9497091770172119, Last lagvar Loss: 0.9975195527076721\n",
      "Step 1769/10000- lr: [8.312127963636363e-06] - Loss total: 3.6219677925109863, Last rpr Loss: 1.0563275814056396, Last lagvar Loss: 0.8906089067459106\n",
      "Step 1770/10000- lr: [8.311117866666667e-06] - Loss total: 3.620882272720337, Last rpr Loss: 1.0537763833999634, Last lagvar Loss: 0.8927645087242126\n",
      "Step 1771/10000- lr: [8.31010776969697e-06] - Loss total: 3.6207263469696045, Last rpr Loss: 0.9475277662277222, Last lagvar Loss: 0.9995531439781189\n",
      "Step 1772/10000- lr: [8.309097672727273e-06] - Loss total: 3.6196136474609375, Last rpr Loss: 0.9505774974822998, Last lagvar Loss: 0.995854914188385\n",
      "Step 1773/10000- lr: [8.308087575757577e-06] - Loss total: 3.619842529296875, Last rpr Loss: 1.0578736066818237, Last lagvar Loss: 0.8885346055030823\n",
      "Step 1774/10000- lr: [8.30707747878788e-06] - Loss total: 3.6187667846679688, Last rpr Loss: 1.0554826259613037, Last lagvar Loss: 0.890578031539917\n",
      "Step 1775/10000- lr: [8.306067381818181e-06] - Loss total: 3.618293285369873, Last rpr Loss: 0.9485478401184082, Last lagvar Loss: 0.9976951479911804\n",
      "Step 1776/10000- lr: [8.305057284848485e-06] - Loss total: 3.6172163486480713, Last rpr Loss: 0.9514728784561157, Last lagvar Loss: 0.9941685795783997\n",
      "Step 1777/10000- lr: [8.304047187878788e-06] - Loss total: 3.617727518081665, Last rpr Loss: 1.0594059228897095, Last lagvar Loss: 0.8864843845367432\n",
      "Step 1778/10000- lr: [8.303037090909091e-06] - Loss total: 3.6166555881500244, Last rpr Loss: 1.0571010112762451, Last lagvar Loss: 0.8884862661361694\n",
      "Step 1779/10000- lr: [8.302026993939395e-06] - Loss total: 3.6158862113952637, Last rpr Loss: 0.9494563341140747, Last lagvar Loss: 0.995966911315918\n",
      "Step 1780/10000- lr: [8.301016896969698e-06] - Loss total: 3.614849090576172, Last rpr Loss: 0.952237069606781, Last lagvar Loss: 0.9926360249519348\n",
      "Step 1781/10000- lr: [8.300006800000001e-06] - Loss total: 3.615593910217285, Last rpr Loss: 1.060714840888977, Last lagvar Loss: 0.8846350908279419\n",
      "Step 1782/10000- lr: [8.298996703030304e-06] - Loss total: 3.6145265102386475, Last rpr Loss: 1.0584580898284912, Last lagvar Loss: 0.8866352438926697\n",
      "Step 1783/10000- lr: [8.297986606060606e-06] - Loss total: 3.613520383834839, Last rpr Loss: 0.9501132965087891, Last lagvar Loss: 0.9945191144943237\n",
      "Step 1784/10000- lr: [8.29697650909091e-06] - Loss total: 3.6125247478485107, Last rpr Loss: 0.9527488946914673, Last lagvar Loss: 0.9913865923881531\n",
      "Step 1785/10000- lr: [8.295966412121213e-06] - Loss total: 3.6134181022644043, Last rpr Loss: 1.0616437196731567, Last lagvar Loss: 0.883108377456665\n",
      "Step 1786/10000- lr: [8.294956315151516e-06] - Loss total: 3.612361431121826, Last rpr Loss: 1.0594362020492554, Last lagvar Loss: 0.885114848613739\n",
      "Step 1787/10000- lr: [8.293946218181819e-06] - Loss total: 3.6112005710601807, Last rpr Loss: 0.9504321813583374, Last lagvar Loss: 0.9934308528900146\n",
      "Step 1788/10000- lr: [8.292936121212122e-06] - Loss total: 3.6102447509765625, Last rpr Loss: 0.9529500007629395, Last lagvar Loss: 0.9904657602310181\n",
      "Step 1789/10000- lr: [8.291926024242426e-06] - Loss total: 3.6111934185028076, Last rpr Loss: 1.0621423721313477, Last lagvar Loss: 0.8819242715835571\n",
      "Step 1790/10000- lr: [8.290915927272727e-06] - Loss total: 3.610159158706665, Last rpr Loss: 1.0600537061691284, Last lagvar Loss: 0.8838876485824585\n",
      "Step 1791/10000- lr: [8.28990583030303e-06] - Loss total: 3.608917236328125, Last rpr Loss: 0.9504682421684265, Last lagvar Loss: 0.9926074147224426\n",
      "Step 1792/10000- lr: [8.288895733333334e-06] - Loss total: 3.6080000400543213, Last rpr Loss: 0.9529294371604919, Last lagvar Loss: 0.989743709564209\n",
      "Step 1793/10000- lr: [8.287885636363637e-06] - Loss total: 3.6089298725128174, Last rpr Loss: 1.0623506307601929, Last lagvar Loss: 0.8809391260147095\n",
      "Step 1794/10000- lr: [8.28687553939394e-06] - Loss total: 3.607937812805176, Last rpr Loss: 1.0604722499847412, Last lagvar Loss: 0.8828039169311523\n",
      "Step 1795/10000- lr: [8.285865442424244e-06] - Loss total: 3.6066486835479736, Last rpr Loss: 0.9503685235977173, Last lagvar Loss: 0.9918578863143921\n",
      "Step 1796/10000- lr: [8.284855345454547e-06] - Loss total: 3.605771064758301, Last rpr Loss: 0.952886164188385, Last lagvar Loss: 0.9889922738075256\n",
      "Step 1797/10000- lr: [8.283845248484848e-06] - Loss total: 3.606661558151245, Last rpr Loss: 1.0625665187835693, Last lagvar Loss: 0.8799216747283936\n",
      "Step 1798/10000- lr: [8.282835151515152e-06] - Loss total: 3.6057276725769043, Last rpr Loss: 1.0609261989593506, Last lagvar Loss: 0.8817075490951538\n",
      "Step 1799/10000- lr: [8.281825054545455e-06] - Loss total: 3.6043777465820312, Last rpr Loss: 0.9502898454666138, Last lagvar Loss: 0.9910519123077393\n",
      "Step 1800/10000- lr: [8.280814957575758e-06] - Loss total: 3.6035444736480713, Last rpr Loss: 0.9529633522033691, Last lagvar Loss: 0.9881158471107483\n",
      "Step 1801/10000- lr: [8.279804860606062e-06] - Loss total: 3.6044108867645264, Last rpr Loss: 1.0628743171691895, Last lagvar Loss: 0.8788501024246216\n",
      "Step 1802/10000- lr: [8.278794763636365e-06] - Loss total: 3.6035428047180176, Last rpr Loss: 1.0613205432891846, Last lagvar Loss: 0.8807220458984375\n",
      "Step 1803/10000- lr: [8.277784666666666e-06] - Loss total: 3.602104663848877, Last rpr Loss: 0.9501099586486816, Last lagvar Loss: 0.9903663396835327\n",
      "Step 1804/10000- lr: [8.27677456969697e-06] - Loss total: 3.601325511932373, Last rpr Loss: 0.9530425667762756, Last lagvar Loss: 0.9872738122940063\n",
      "Step 1805/10000- lr: [8.275764472727273e-06] - Loss total: 3.602161407470703, Last rpr Loss: 1.063058853149414, Last lagvar Loss: 0.8778908252716064\n",
      "Step 1806/10000- lr: [8.274754375757576e-06] - Loss total: 3.6013598442077637, Last rpr Loss: 1.0614405870437622, Last lagvar Loss: 0.8800015449523926\n",
      "Step 1807/10000- lr: [8.27374427878788e-06] - Loss total: 3.599841356277466, Last rpr Loss: 0.9497650265693665, Last lagvar Loss: 0.9898717403411865\n",
      "Step 1808/10000- lr: [8.272734181818183e-06] - Loss total: 3.599128246307373, Last rpr Loss: 0.9531353712081909, Last lagvar Loss: 0.9864630699157715\n",
      "Step 1809/10000- lr: [8.271724084848486e-06] - Loss total: 3.599879503250122, Last rpr Loss: 1.0630192756652832, Last lagvar Loss: 0.877106785774231\n",
      "Step 1810/10000- lr: [8.27071398787879e-06] - Loss total: 3.5991508960723877, Last rpr Loss: 1.0611910820007324, Last lagvar Loss: 0.879623293876648\n",
      "Step 1811/10000- lr: [8.269703890909091e-06] - Loss total: 3.597602128982544, Last rpr Loss: 0.949253499507904, Last lagvar Loss: 0.9895755052566528\n",
      "Step 1812/10000- lr: [8.268693793939394e-06] - Loss total: 3.5969624519348145, Last rpr Loss: 0.9532804489135742, Last lagvar Loss: 0.9856486916542053\n",
      "Step 1813/10000- lr: [8.267683696969698e-06] - Loss total: 3.5975358486175537, Last rpr Loss: 1.0626330375671387, Last lagvar Loss: 0.8766121864318848\n",
      "Step 1814/10000- lr: [8.2666736e-06] - Loss total: 3.5968899726867676, Last rpr Loss: 1.0603606700897217, Last lagvar Loss: 0.8797757625579834\n",
      "Step 1815/10000- lr: [8.265663503030304e-06] - Loss total: 3.5953640937805176, Last rpr Loss: 0.9485082030296326, Last lagvar Loss: 0.9894591569900513\n",
      "Step 1816/10000- lr: [8.264653406060606e-06] - Loss total: 3.5947892665863037, Last rpr Loss: 0.9535976052284241, Last lagvar Loss: 0.9845758676528931\n",
      "Step 1817/10000- lr: [8.263643309090909e-06] - Loss total: 3.595086097717285, Last rpr Loss: 1.0619854927062988, Last lagvar Loss: 0.8761820793151855\n",
      "Step 1818/10000- lr: [8.262633212121212e-06] - Loss total: 3.594508409500122, Last rpr Loss: 1.0588467121124268, Last lagvar Loss: 0.8803096413612366\n",
      "Step 1819/10000- lr: [8.261623115151515e-06] - Loss total: 3.593043088912964, Last rpr Loss: 0.9476836323738098, Last lagvar Loss: 0.9890413880348206\n",
      "Step 1820/10000- lr: [8.260613018181819e-06] - Loss total: 3.592529773712158, Last rpr Loss: 0.9544702768325806, Last lagvar Loss: 0.9825292825698853\n",
      "Step 1821/10000- lr: [8.259602921212122e-06] - Loss total: 3.5924923419952393, Last rpr Loss: 1.0612027645111084, Last lagvar Loss: 0.8754550814628601\n",
      "Step 1822/10000- lr: [8.258592824242425e-06] - Loss total: 3.592021942138672, Last rpr Loss: 1.0567785501480103, Last lagvar Loss: 0.8811894655227661\n",
      "Step 1823/10000- lr: [8.257582727272729e-06] - Loss total: 3.590672492980957, Last rpr Loss: 0.947460412979126, Last lagvar Loss: 0.9880281686782837\n",
      "Step 1824/10000- lr: [8.25657263030303e-06] - Loss total: 3.5902187824249268, Last rpr Loss: 0.9567899703979492, Last lagvar Loss: 0.979108452796936\n",
      "Step 1825/10000- lr: [8.255562533333333e-06] - Loss total: 3.589948892593384, Last rpr Loss: 1.0607435703277588, Last lagvar Loss: 0.8747565746307373\n",
      "Step 1826/10000- lr: [8.254552436363637e-06] - Loss total: 3.5894525051116943, Last rpr Loss: 1.0530824661254883, Last lagvar Loss: 0.8837159872055054\n",
      "Step 1827/10000- lr: [8.25354233939394e-06] - Loss total: 3.588434934616089, Last rpr Loss: 0.9466379880905151, Last lagvar Loss: 0.9880108833312988\n",
      "Step 1828/10000- lr: [8.252532242424243e-06] - Loss total: 3.588029146194458, Last rpr Loss: 0.9586941003799438, Last lagvar Loss: 0.9765145778656006\n",
      "Step 1829/10000- lr: [8.251522145454547e-06] - Loss total: 3.5872230529785156, Last rpr Loss: 1.0571337938308716, Last lagvar Loss: 0.8771809935569763\n",
      "Step 1830/10000- lr: [8.25051204848485e-06] - Loss total: 3.5866262912750244, Last rpr Loss: 1.0444974899291992, Last lagvar Loss: 0.8908272981643677\n",
      "Step 1831/10000- lr: [8.249501951515151e-06] - Loss total: 3.5864381790161133, Last rpr Loss: 0.9450870752334595, Last lagvar Loss: 0.9895017147064209\n",
      "Step 1832/10000- lr: [8.248491854545455e-06] - Loss total: 3.5858209133148193, Last rpr Loss: 0.960853099822998, Last lagvar Loss: 0.973975658416748\n",
      "Step 1833/10000- lr: [8.247481757575758e-06] - Loss total: 3.584791898727417, Last rpr Loss: 1.053358793258667, Last lagvar Loss: 0.8807635307312012\n",
      "Step 1834/10000- lr: [8.246471660606061e-06] - Loss total: 3.583875894546509, Last rpr Loss: 1.036980152130127, Last lagvar Loss: 0.8973757028579712\n",
      "Step 1835/10000- lr: [8.245461563636365e-06] - Loss total: 3.5845537185668945, Last rpr Loss: 0.9480663537979126, Last lagvar Loss: 0.9870139956474304\n",
      "Step 1836/10000- lr: [8.244451466666668e-06] - Loss total: 3.5835444927215576, Last rpr Loss: 0.9641733169555664, Last lagvar Loss: 0.9704606533050537\n",
      "Step 1837/10000- lr: [8.243441369696971e-06] - Loss total: 3.5825560092926025, Last rpr Loss: 1.0485639572143555, Last lagvar Loss: 0.8861844539642334\n",
      "Step 1838/10000- lr: [8.242431272727273e-06] - Loss total: 3.581224203109741, Last rpr Loss: 1.0313665866851807, Last lagvar Loss: 0.9023800492286682\n",
      "Step 1839/10000- lr: [8.241421175757576e-06] - Loss total: 3.582667112350464, Last rpr Loss: 0.9531935453414917, Last lagvar Loss: 0.9824416637420654\n",
      "Step 1840/10000- lr: [8.24041107878788e-06] - Loss total: 3.581272602081299, Last rpr Loss: 0.9634596109390259, Last lagvar Loss: 0.9708817005157471\n",
      "Step 1841/10000- lr: [8.239400981818182e-06] - Loss total: 3.5801517963409424, Last rpr Loss: 1.0410795211791992, Last lagvar Loss: 0.8930504322052002\n",
      "Step 1842/10000- lr: [8.238390884848486e-06] - Loss total: 3.5786709785461426, Last rpr Loss: 1.0310842990875244, Last lagvar Loss: 0.901496171951294\n",
      "Step 1843/10000- lr: [8.237380787878789e-06] - Loss total: 3.5802714824676514, Last rpr Loss: 0.9602546691894531, Last lagvar Loss: 0.9746721386909485\n",
      "Step 1844/10000- lr: [8.23637069090909e-06] - Loss total: 3.5787599086761475, Last rpr Loss: 0.9629517793655396, Last lagvar Loss: 0.9704235196113586\n",
      "Step 1845/10000- lr: [8.235360593939394e-06] - Loss total: 3.5775108337402344, Last rpr Loss: 1.0378239154815674, Last lagvar Loss: 0.8950835466384888\n",
      "Step 1846/10000- lr: [8.234350496969697e-06] - Loss total: 3.5759968757629395, Last rpr Loss: 1.0338082313537598, Last lagvar Loss: 0.8975041508674622\n",
      "Step 1847/10000- lr: [8.2333404e-06] - Loss total: 3.577664613723755, Last rpr Loss: 0.9619513154029846, Last lagvar Loss: 0.9719064831733704\n",
      "Step 1848/10000- lr: [8.232330303030304e-06] - Loss total: 3.576138734817505, Last rpr Loss: 0.9609028697013855, Last lagvar Loss: 0.9714690446853638\n",
      "Step 1849/10000- lr: [8.231320206060607e-06] - Loss total: 3.5747294425964355, Last rpr Loss: 1.0377558469772339, Last lagvar Loss: 0.8939030170440674\n",
      "Step 1850/10000- lr: [8.23031010909091e-06] - Loss total: 3.5731921195983887, Last rpr Loss: 1.0339075326919556, Last lagvar Loss: 0.8961520195007324\n",
      "Step 1851/10000- lr: [8.229300012121214e-06] - Loss total: 3.575141429901123, Last rpr Loss: 0.958712100982666, Last lagvar Loss: 0.9744243621826172\n",
      "Step 1852/10000- lr: [8.228289915151515e-06] - Loss total: 3.573650360107422, Last rpr Loss: 0.9601045250892639, Last lagvar Loss: 0.9716351628303528\n",
      "Step 1853/10000- lr: [8.227279818181818e-06] - Loss total: 3.5718579292297363, Last rpr Loss: 1.0386347770690918, Last lagvar Loss: 0.8917281627655029\n",
      "Step 1854/10000- lr: [8.226269721212122e-06] - Loss total: 3.570441484451294, Last rpr Loss: 1.0315622091293335, Last lagvar Loss: 0.8974759578704834\n",
      "Step 1855/10000- lr: [8.225259624242425e-06] - Loss total: 3.572434425354004, Last rpr Loss: 0.9576526284217834, Last lagvar Loss: 0.9745732545852661\n",
      "Step 1856/10000- lr: [8.224249527272728e-06] - Loss total: 3.570910692214966, Last rpr Loss: 0.9628883004188538, Last lagvar Loss: 0.967902660369873\n",
      "Step 1857/10000- lr: [8.223239430303032e-06] - Loss total: 3.5693702697753906, Last rpr Loss: 1.040015697479248, Last lagvar Loss: 0.8897337913513184\n",
      "Step 1858/10000- lr: [8.222229333333333e-06] - Loss total: 3.5680880546569824, Last rpr Loss: 1.0310792922973633, Last lagvar Loss: 0.897612452507019\n",
      "Step 1859/10000- lr: [8.221219236363636e-06] - Loss total: 3.569422483444214, Last rpr Loss: 0.9602246284484863, Last lagvar Loss: 0.9706668257713318\n",
      "Step 1860/10000- lr: [8.22020913939394e-06] - Loss total: 3.56795334815979, Last rpr Loss: 0.9663978815078735, Last lagvar Loss: 0.9631307125091553\n",
      "Step 1861/10000- lr: [8.219199042424243e-06] - Loss total: 3.567004680633545, Last rpr Loss: 1.0387595891952515, Last lagvar Loss: 0.8906344175338745\n",
      "Step 1862/10000- lr: [8.218188945454546e-06] - Loss total: 3.565638303756714, Last rpr Loss: 1.0302444696426392, Last lagvar Loss: 0.8979403972625732\n",
      "Step 1863/10000- lr: [8.21717884848485e-06] - Loss total: 3.5665581226348877, Last rpr Loss: 0.9633708000183105, Last lagvar Loss: 0.9663909077644348\n",
      "Step 1864/10000- lr: [8.216168751515153e-06] - Loss total: 3.56510853767395, Last rpr Loss: 0.9670778512954712, Last lagvar Loss: 0.9613648653030396\n",
      "Step 1865/10000- lr: [8.215158654545454e-06] - Loss total: 3.564487934112549, Last rpr Loss: 1.03684663772583, Last lagvar Loss: 0.8919423818588257\n",
      "Step 1866/10000- lr: [8.214148557575758e-06] - Loss total: 3.563070058822632, Last rpr Loss: 1.0310821533203125, Last lagvar Loss: 0.8964101672172546\n",
      "Step 1867/10000- lr: [8.213138460606061e-06] - Loss total: 3.563767433166504, Last rpr Loss: 0.9654844999313354, Last lagvar Loss: 0.96323561668396\n",
      "Step 1868/10000- lr: [8.212128363636364e-06] - Loss total: 3.5623562335968018, Last rpr Loss: 0.9669089913368225, Last lagvar Loss: 0.9605669379234314\n",
      "Step 1869/10000- lr: [8.211118266666667e-06] - Loss total: 3.5618045330047607, Last rpr Loss: 1.036670446395874, Last lagvar Loss: 0.8912814259529114\n",
      "Step 1870/10000- lr: [8.21010816969697e-06] - Loss total: 3.560368537902832, Last rpr Loss: 1.0313022136688232, Last lagvar Loss: 0.8953204154968262\n",
      "Step 1871/10000- lr: [8.209098072727274e-06] - Loss total: 3.561086416244507, Last rpr Loss: 0.9651758074760437, Last lagvar Loss: 0.9627296924591064\n",
      "Step 1872/10000- lr: [8.208087975757576e-06] - Loss total: 3.55971360206604, Last rpr Loss: 0.9671090841293335, Last lagvar Loss: 0.9596210718154907\n",
      "Step 1873/10000- lr: [8.207077878787879e-06] - Loss total: 3.5590176582336426, Last rpr Loss: 1.0358680486679077, Last lagvar Loss: 0.8910797834396362\n",
      "Step 1874/10000- lr: [8.206067781818182e-06] - Loss total: 3.5576095581054688, Last rpr Loss: 1.029339075088501, Last lagvar Loss: 0.8963344097137451\n",
      "Step 1875/10000- lr: [8.205057684848485e-06] - Loss total: 3.558458089828491, Last rpr Loss: 0.9653061628341675, Last lagvar Loss: 0.9619461297988892\n",
      "Step 1876/10000- lr: [8.204047587878789e-06] - Loss total: 3.557095766067505, Last rpr Loss: 0.9679728746414185, Last lagvar Loss: 0.9581047296524048\n",
      "Step 1877/10000- lr: [8.203037490909092e-06] - Loss total: 3.556230306625366, Last rpr Loss: 1.0340707302093506, Last lagvar Loss: 0.8919471502304077\n",
      "Step 1878/10000- lr: [8.202027393939395e-06] - Loss total: 3.5548393726348877, Last rpr Loss: 1.0277653932571411, Last lagvar Loss: 0.8970029354095459\n",
      "Step 1879/10000- lr: [8.201017296969699e-06] - Loss total: 3.55556058883667, Last rpr Loss: 0.9674853682518005, Last lagvar Loss: 0.9587469100952148\n",
      "Step 1880/10000- lr: [8.2000072e-06] - Loss total: 3.5539913177490234, Last rpr Loss: 0.9700407981872559, Last lagvar Loss: 0.954725444316864\n",
      "Step 1881/10000- lr: [8.198997103030303e-06] - Loss total: 3.5534820556640625, Last rpr Loss: 1.0331933498382568, Last lagvar Loss: 0.8919944763183594\n",
      "Step 1882/10000- lr: [8.197987006060607e-06] - Loss total: 3.551729917526245, Last rpr Loss: 1.0247329473495483, Last lagvar Loss: 0.8986812233924866\n",
      "Step 1883/10000- lr: [8.19697690909091e-06] - Loss total: 3.5524399280548096, Last rpr Loss: 0.9700899124145508, Last lagvar Loss: 0.9548345804214478\n",
      "Step 1884/10000- lr: [8.195966812121213e-06] - Loss total: 3.5502994060516357, Last rpr Loss: 0.9745677709579468, Last lagvar Loss: 0.9481039047241211\n",
      "Step 1885/10000- lr: [8.194956715151515e-06] - Loss total: 3.550529956817627, Last rpr Loss: 1.0322654247283936, Last lagvar Loss: 0.8918201327323914\n",
      "Step 1886/10000- lr: [8.193946618181818e-06] - Loss total: 3.5479633808135986, Last rpr Loss: 1.015241265296936, Last lagvar Loss: 0.9059063792228699\n",
      "Step 1887/10000- lr: [8.192936521212121e-06] - Loss total: 3.5489282608032227, Last rpr Loss: 0.9746379256248474, Last lagvar Loss: 0.9484694004058838\n",
      "Step 1888/10000- lr: [8.191926424242425e-06] - Loss total: 3.5465595722198486, Last rpr Loss: 0.9816545248031616, Last lagvar Loss: 0.9389113783836365\n",
      "Step 1889/10000- lr: [8.190916327272728e-06] - Loss total: 3.5472710132598877, Last rpr Loss: 1.0287582874298096, Last lagvar Loss: 0.8938596844673157\n",
      "Step 1890/10000- lr: [8.189906230303031e-06] - Loss total: 3.544431686401367, Last rpr Loss: 1.0048270225524902, Last lagvar Loss: 0.9144437313079834\n",
      "Step 1891/10000- lr: [8.188896133333334e-06] - Loss total: 3.545419692993164, Last rpr Loss: 0.9792596101760864, Last lagvar Loss: 0.9420954585075378\n",
      "Step 1892/10000- lr: [8.187886036363638e-06] - Loss total: 3.543062925338745, Last rpr Loss: 0.9898855090141296, Last lagvar Loss: 0.9289820194244385\n",
      "Step 1893/10000- lr: [8.18687593939394e-06] - Loss total: 3.543915033340454, Last rpr Loss: 1.0247735977172852, Last lagvar Loss: 0.8962876200675964\n",
      "Step 1894/10000- lr: [8.185865842424243e-06] - Loss total: 3.541459321975708, Last rpr Loss: 0.9981954097747803, Last lagvar Loss: 0.9200637340545654\n",
      "Step 1895/10000- lr: [8.184855745454546e-06] - Loss total: 3.542088508605957, Last rpr Loss: 0.981695294380188, Last lagvar Loss: 0.9382116794586182\n",
      "Step 1896/10000- lr: [8.18384564848485e-06] - Loss total: 3.5400819778442383, Last rpr Loss: 0.9973320364952087, Last lagvar Loss: 0.9206054210662842\n",
      "Step 1897/10000- lr: [8.182835551515152e-06] - Loss total: 3.5405895709991455, Last rpr Loss: 1.0203638076782227, Last lagvar Loss: 0.8992296457290649\n",
      "Step 1898/10000- lr: [8.181825454545456e-06] - Loss total: 3.5387487411499023, Last rpr Loss: 0.9931926727294922, Last lagvar Loss: 0.9244967103004456\n",
      "Step 1899/10000- lr: [8.180815357575757e-06] - Loss total: 3.5388689041137695, Last rpr Loss: 0.9842996597290039, Last lagvar Loss: 0.9343571066856384\n",
      "Step 1900/10000- lr: [8.17980526060606e-06] - Loss total: 3.5373620986938477, Last rpr Loss: 1.00316321849823, Last lagvar Loss: 0.914259672164917\n",
      "Step 1901/10000- lr: [8.178795163636364e-06] - Loss total: 3.537318706512451, Last rpr Loss: 1.015128493309021, Last lagvar Loss: 0.9031409025192261\n",
      "Step 1902/10000- lr: [8.177785066666667e-06] - Loss total: 3.5360939502716064, Last rpr Loss: 0.9914976358413696, Last lagvar Loss: 0.9257591366767883\n",
      "Step 1903/10000- lr: [8.17677496969697e-06] - Loss total: 3.535712957382202, Last rpr Loss: 0.9874429702758789, Last lagvar Loss: 0.9301015138626099\n",
      "Step 1904/10000- lr: [8.175764872727274e-06] - Loss total: 3.5347092151641846, Last rpr Loss: 1.0063488483428955, Last lagvar Loss: 0.910714328289032\n",
      "Step 1905/10000- lr: [8.174754775757577e-06] - Loss total: 3.5341484546661377, Last rpr Loss: 1.009883165359497, Last lagvar Loss: 0.9072537422180176\n",
      "Step 1906/10000- lr: [8.173744678787879e-06] - Loss total: 3.533390522003174, Last rpr Loss: 0.9910781979560852, Last lagvar Loss: 0.9257391691207886\n",
      "Step 1907/10000- lr: [8.172734581818182e-06] - Loss total: 3.532642126083374, Last rpr Loss: 0.991138219833374, Last lagvar Loss: 0.9254661202430725\n",
      "Step 1908/10000- lr: [8.171724484848485e-06] - Loss total: 3.532010078430176, Last rpr Loss: 1.0082950592041016, Last lagvar Loss: 0.9083647131919861\n",
      "Step 1909/10000- lr: [8.170714387878788e-06] - Loss total: 3.531137228012085, Last rpr Loss: 1.0045576095581055, Last lagvar Loss: 0.9116770029067993\n",
      "Step 1910/10000- lr: [8.169704290909092e-06] - Loss total: 3.5306246280670166, Last rpr Loss: 0.9914191365242004, Last lagvar Loss: 0.9248663187026978\n",
      "Step 1911/10000- lr: [8.168694193939395e-06] - Loss total: 3.529712438583374, Last rpr Loss: 0.9955654144287109, Last lagvar Loss: 0.9202743172645569\n",
      "Step 1912/10000- lr: [8.167684096969698e-06] - Loss total: 3.529235601425171, Last rpr Loss: 1.0076990127563477, Last lagvar Loss: 0.9083814024925232\n",
      "Step 1913/10000- lr: [8.166674e-06] - Loss total: 3.5282974243164062, Last rpr Loss: 0.9995615482330322, Last lagvar Loss: 0.9159566164016724\n",
      "Step 1914/10000- lr: [8.165663903030303e-06] - Loss total: 3.5278091430664062, Last rpr Loss: 0.9922682642936707, Last lagvar Loss: 0.9233599901199341\n",
      "Step 1915/10000- lr: [8.164653806060606e-06] - Loss total: 3.526918649673462, Last rpr Loss: 0.9992333054542542, Last lagvar Loss: 0.9159801006317139\n",
      "Step 1916/10000- lr: [8.16364370909091e-06] - Loss total: 3.5263967514038086, Last rpr Loss: 1.0059157609939575, Last lagvar Loss: 0.9094236493110657\n",
      "Step 1917/10000- lr: [8.162633612121213e-06] - Loss total: 3.525559663772583, Last rpr Loss: 0.99658203125, Last lagvar Loss: 0.9183391332626343\n",
      "Step 1918/10000- lr: [8.161623515151516e-06] - Loss total: 3.5249669551849365, Last rpr Loss: 0.9938058853149414, Last lagvar Loss: 0.9210949540138245\n",
      "Step 1919/10000- lr: [8.16061341818182e-06] - Loss total: 3.5241997241973877, Last rpr Loss: 1.0023871660232544, Last lagvar Loss: 0.9122775197029114\n",
      "Step 1920/10000- lr: [8.159603321212123e-06] - Loss total: 3.523550033569336, Last rpr Loss: 1.0036840438842773, Last lagvar Loss: 0.9108906984329224\n",
      "Step 1921/10000- lr: [8.158593224242424e-06] - Loss total: 3.5228474140167236, Last rpr Loss: 0.9952125549316406, Last lagvar Loss: 0.9191497564315796\n",
      "Step 1922/10000- lr: [8.157583127272728e-06] - Loss total: 3.522144317626953, Last rpr Loss: 0.9962468147277832, Last lagvar Loss: 0.9179471731185913\n",
      "Step 1923/10000- lr: [8.156573030303031e-06] - Loss total: 3.5214853286743164, Last rpr Loss: 1.003861427307129, Last lagvar Loss: 0.9102524518966675\n",
      "Step 1924/10000- lr: [8.155562933333334e-06] - Loss total: 3.5207486152648926, Last rpr Loss: 1.000964879989624, Last lagvar Loss: 0.9129149913787842\n",
      "Step 1925/10000- lr: [8.154552836363637e-06] - Loss total: 3.5201141834259033, Last rpr Loss: 0.9952051639556885, Last lagvar Loss: 0.9185730814933777\n",
      "Step 1926/10000- lr: [8.15354273939394e-06] - Loss total: 3.519368886947632, Last rpr Loss: 0.9986608624458313, Last lagvar Loss: 0.9148948192596436\n",
      "Step 1927/10000- lr: [8.152532642424242e-06] - Loss total: 3.518737316131592, Last rpr Loss: 1.0035979747772217, Last lagvar Loss: 0.9099064469337463\n",
      "Step 1928/10000- lr: [8.151522545454546e-06] - Loss total: 3.5179972648620605, Last rpr Loss: 0.9988400936126709, Last lagvar Loss: 0.9144130945205688\n",
      "Step 1929/10000- lr: [8.150512448484849e-06] - Loss total: 3.517350673675537, Last rpr Loss: 0.9960013031959534, Last lagvar Loss: 0.9171438813209534\n",
      "Step 1930/10000- lr: [8.149502351515152e-06] - Loss total: 3.5166289806365967, Last rpr Loss: 1.0007236003875732, Last lagvar Loss: 0.9122295379638672\n",
      "Step 1931/10000- lr: [8.148492254545455e-06] - Loss total: 3.5159623622894287, Last rpr Loss: 1.0023263692855835, Last lagvar Loss: 0.9104978442192078\n",
      "Step 1932/10000- lr: [8.147482157575759e-06] - Loss total: 3.515261173248291, Last rpr Loss: 0.9973691701889038, Last lagvar Loss: 0.9152432680130005\n",
      "Step 1933/10000- lr: [8.146472060606062e-06] - Loss total: 3.5145716667175293, Last rpr Loss: 0.9973741173744202, Last lagvar Loss: 0.9150529503822327\n",
      "Step 1934/10000- lr: [8.145461963636364e-06] - Loss total: 3.513887405395508, Last rpr Loss: 1.0017932653427124, Last lagvar Loss: 0.9104641675949097\n",
      "Step 1935/10000- lr: [8.144451866666667e-06] - Loss total: 3.5131824016571045, Last rpr Loss: 1.0005477666854858, Last lagvar Loss: 0.9114707708358765\n",
      "Step 1936/10000- lr: [8.14344176969697e-06] - Loss total: 3.5125083923339844, Last rpr Loss: 0.9971815347671509, Last lagvar Loss: 0.9146192073822021\n",
      "Step 1937/10000- lr: [8.142431672727273e-06] - Loss total: 3.5117998123168945, Last rpr Loss: 0.9991722106933594, Last lagvar Loss: 0.9123820066452026\n",
      "Step 1938/10000- lr: [8.141421575757577e-06] - Loss total: 3.51112961769104, Last rpr Loss: 1.0019340515136719, Last lagvar Loss: 0.9094371199607849\n",
      "Step 1939/10000- lr: [8.14041147878788e-06] - Loss total: 3.5104260444641113, Last rpr Loss: 0.9993407130241394, Last lagvar Loss: 0.9117605090141296\n",
      "Step 1940/10000- lr: [8.139401381818182e-06] - Loss total: 3.509752035140991, Last rpr Loss: 0.9978684782981873, Last lagvar Loss: 0.9130183458328247\n",
      "Step 1941/10000- lr: [8.138391284848485e-06] - Loss total: 3.509058952331543, Last rpr Loss: 1.000502586364746, Last lagvar Loss: 0.9101763367652893\n",
      "Step 1942/10000- lr: [8.137381187878788e-06] - Loss total: 3.50837779045105, Last rpr Loss: 1.000847578048706, Last lagvar Loss: 0.9096261858940125\n",
      "Step 1943/10000- lr: [8.136371090909091e-06] - Loss total: 3.5076935291290283, Last rpr Loss: 0.9980453252792358, Last lagvar Loss: 0.9121979475021362\n",
      "Step 1944/10000- lr: [8.135360993939395e-06] - Loss total: 3.507007598876953, Last rpr Loss: 0.9983755350112915, Last lagvar Loss: 0.9116613864898682\n",
      "Step 1945/10000- lr: [8.134350896969698e-06] - Loss total: 3.506331443786621, Last rpr Loss: 1.0004339218139648, Last lagvar Loss: 0.909427285194397\n",
      "Step 1946/10000- lr: [8.133340800000001e-06] - Loss total: 3.5056445598602295, Last rpr Loss: 0.9990483522415161, Last lagvar Loss: 0.9106054306030273\n",
      "Step 1947/10000- lr: [8.132330703030304e-06] - Loss total: 3.5049726963043213, Last rpr Loss: 0.9975847601890564, Last lagvar Loss: 0.9118909239768982\n",
      "Step 1948/10000- lr: [8.131320606060606e-06] - Loss total: 3.504289150238037, Last rpr Loss: 0.9992777705192566, Last lagvar Loss: 0.9100247621536255\n",
      "Step 1949/10000- lr: [8.13031050909091e-06] - Loss total: 3.503618001937866, Last rpr Loss: 1.0002214908599854, Last lagvar Loss: 0.908928394317627\n",
      "Step 1950/10000- lr: [8.129300412121213e-06] - Loss total: 3.502939224243164, Last rpr Loss: 0.9984626770019531, Last lagvar Loss: 0.9105162620544434\n",
      "Step 1951/10000- lr: [8.128290315151516e-06] - Loss total: 3.5022664070129395, Last rpr Loss: 0.9983850717544556, Last lagvar Loss: 0.9104437828063965\n",
      "Step 1952/10000- lr: [8.127280218181819e-06] - Loss total: 3.501593589782715, Last rpr Loss: 1.0002171993255615, Last lagvar Loss: 0.9084739685058594\n",
      "Step 1953/10000- lr: [8.12627012121212e-06] - Loss total: 3.5009191036224365, Last rpr Loss: 0.9997856616973877, Last lagvar Loss: 0.9087594151496887\n",
      "Step 1954/10000- lr: [8.125260024242424e-06] - Loss total: 3.5002501010894775, Last rpr Loss: 0.9983550906181335, Last lagvar Loss: 0.910049319267273\n",
      "Step 1955/10000- lr: [8.124249927272727e-06] - Loss total: 3.4995765686035156, Last rpr Loss: 0.9992865920066833, Last lagvar Loss: 0.9089826345443726\n",
      "Step 1956/10000- lr: [8.12323983030303e-06] - Loss total: 3.498908519744873, Last rpr Loss: 1.0003042221069336, Last lagvar Loss: 0.9078422784805298\n",
      "Step 1957/10000- lr: [8.122229733333334e-06] - Loss total: 3.498236656188965, Last rpr Loss: 0.9991390705108643, Last lagvar Loss: 0.9088691473007202\n",
      "Step 1958/10000- lr: [8.121219636363637e-06] - Loss total: 3.4975688457489014, Last rpr Loss: 0.9986895322799683, Last lagvar Loss: 0.9091916084289551\n",
      "Step 1959/10000- lr: [8.12020953939394e-06] - Loss total: 3.4968998432159424, Last rpr Loss: 0.9998396635055542, Last lagvar Loss: 0.907920777797699\n",
      "Step 1960/10000- lr: [8.119199442424244e-06] - Loss total: 3.4962315559387207, Last rpr Loss: 0.999788761138916, Last lagvar Loss: 0.9078476428985596\n",
      "Step 1961/10000- lr: [8.118189345454547e-06] - Loss total: 3.4955644607543945, Last rpr Loss: 0.9986896514892578, Last lagvar Loss: 0.9088211059570312\n",
      "Step 1962/10000- lr: [8.117179248484849e-06] - Loss total: 3.4948956966400146, Last rpr Loss: 0.9990316033363342, Last lagvar Loss: 0.9083589911460876\n",
      "Step 1963/10000- lr: [8.116169151515152e-06] - Loss total: 3.494230031967163, Last rpr Loss: 0.9997658729553223, Last lagvar Loss: 0.9075107574462891\n",
      "Step 1964/10000- lr: [8.115159054545455e-06] - Loss total: 3.493560791015625, Last rpr Loss: 0.9990487098693848, Last lagvar Loss: 0.9081047773361206\n",
      "Step 1965/10000- lr: [8.114148957575758e-06] - Loss total: 3.492894172668457, Last rpr Loss: 0.9986482858657837, Last lagvar Loss: 0.9083881974220276\n",
      "Step 1966/10000- lr: [8.113138860606062e-06] - Loss total: 3.4922256469726562, Last rpr Loss: 0.999474048614502, Last lagvar Loss: 0.9074503183364868\n",
      "Step 1967/10000- lr: [8.112128763636365e-06] - Loss total: 3.4915575981140137, Last rpr Loss: 0.9995778799057007, Last lagvar Loss: 0.9072336554527283\n",
      "Step 1968/10000- lr: [8.111118666666666e-06] - Loss total: 3.490889549255371, Last rpr Loss: 0.9989343285560608, Last lagvar Loss: 0.9077625274658203\n",
      "Step 1969/10000- lr: [8.11010856969697e-06] - Loss total: 3.490220785140991, Last rpr Loss: 0.9992601275444031, Last lagvar Loss: 0.9073269367218018\n",
      "Step 1970/10000- lr: [8.109098472727273e-06] - Loss total: 3.4895541667938232, Last rpr Loss: 0.9998399019241333, Last lagvar Loss: 0.9066418409347534\n",
      "Step 1971/10000- lr: [8.108088375757576e-06] - Loss total: 3.488886594772339, Last rpr Loss: 0.999374270439148, Last lagvar Loss: 0.9069962501525879\n",
      "Step 1972/10000- lr: [8.10707827878788e-06] - Loss total: 3.4882214069366455, Last rpr Loss: 0.9990794658660889, Last lagvar Loss: 0.9071824550628662\n",
      "Step 1973/10000- lr: [8.106068181818183e-06] - Loss total: 3.4875571727752686, Last rpr Loss: 0.9996075630187988, Last lagvar Loss: 0.9065476655960083\n",
      "Step 1974/10000- lr: [8.105058084848486e-06] - Loss total: 3.486893892288208, Last rpr Loss: 0.999570369720459, Last lagvar Loss: 0.9064759016036987\n",
      "Step 1975/10000- lr: [8.104047987878788e-06] - Loss total: 3.486232280731201, Last rpr Loss: 0.9989804625511169, Last lagvar Loss: 0.9069546461105347\n",
      "Step 1976/10000- lr: [8.103037890909091e-06] - Loss total: 3.4855711460113525, Last rpr Loss: 0.9991244077682495, Last lagvar Loss: 0.906700849533081\n",
      "Step 1977/10000- lr: [8.102027793939394e-06] - Loss total: 3.4849114418029785, Last rpr Loss: 0.9994550943374634, Last lagvar Loss: 0.9062610864639282\n",
      "Step 1978/10000- lr: [8.101017696969698e-06] - Loss total: 3.4842522144317627, Last rpr Loss: 0.9990530014038086, Last lagvar Loss: 0.9065515398979187\n",
      "Step 1979/10000- lr: [8.1000076e-06] - Loss total: 3.4835941791534424, Last rpr Loss: 0.9988496899604797, Last lagvar Loss: 0.906644344329834\n",
      "Step 1980/10000- lr: [8.098997503030304e-06] - Loss total: 3.4829373359680176, Last rpr Loss: 0.9992656707763672, Last lagvar Loss: 0.906119167804718\n",
      "Step 1981/10000- lr: [8.097987406060606e-06] - Loss total: 3.4822804927825928, Last rpr Loss: 0.9992833137512207, Last lagvar Loss: 0.9059921503067017\n",
      "Step 1982/10000- lr: [8.096977309090909e-06] - Loss total: 3.4816253185272217, Last rpr Loss: 0.9989509582519531, Last lagvar Loss: 0.9062154293060303\n",
      "Step 1983/10000- lr: [8.095967212121212e-06] - Loss total: 3.480970621109009, Last rpr Loss: 0.9991531372070312, Last lagvar Loss: 0.9059056639671326\n",
      "Step 1984/10000- lr: [8.094957115151516e-06] - Loss total: 3.4803168773651123, Last rpr Loss: 0.9994334578514099, Last lagvar Loss: 0.9055194854736328\n",
      "Step 1985/10000- lr: [8.093947018181819e-06] - Loss total: 3.479663610458374, Last rpr Loss: 0.9991883635520935, Last lagvar Loss: 0.9056588411331177\n",
      "Step 1986/10000- lr: [8.092936921212122e-06] - Loss total: 3.4790117740631104, Last rpr Loss: 0.9991220235824585, Last lagvar Loss: 0.9056212902069092\n",
      "Step 1987/10000- lr: [8.091926824242425e-06] - Loss total: 3.4783599376678467, Last rpr Loss: 0.999423623085022, Last lagvar Loss: 0.905217707157135\n",
      "Step 1988/10000- lr: [8.090916727272729e-06] - Loss total: 3.4777088165283203, Last rpr Loss: 0.9993969202041626, Last lagvar Loss: 0.9051428437232971\n",
      "Step 1989/10000- lr: [8.08990663030303e-06] - Loss total: 3.4770588874816895, Last rpr Loss: 0.9992011785507202, Last lagvar Loss: 0.9052377939224243\n",
      "Step 1990/10000- lr: [8.088896533333333e-06] - Loss total: 3.4764091968536377, Last rpr Loss: 0.9993560314178467, Last lagvar Loss: 0.9049838185310364\n",
      "Step 1991/10000- lr: [8.087886436363637e-06] - Loss total: 3.4757606983184814, Last rpr Loss: 0.9994986653327942, Last lagvar Loss: 0.9047428369522095\n",
      "Step 1992/10000- lr: [8.08687633939394e-06] - Loss total: 3.4751126766204834, Last rpr Loss: 0.9992920160293579, Last lagvar Loss: 0.904850959777832\n",
      "Step 1993/10000- lr: [8.085866242424243e-06] - Loss total: 3.4744656085968018, Last rpr Loss: 0.9992589950561523, Last lagvar Loss: 0.9047864675521851\n",
      "Step 1994/10000- lr: [8.084856145454545e-06] - Loss total: 3.4738192558288574, Last rpr Loss: 0.9994373321533203, Last lagvar Loss: 0.9045114517211914\n",
      "Step 1995/10000- lr: [8.083846048484848e-06] - Loss total: 3.4731733798980713, Last rpr Loss: 0.9993276596069336, Last lagvar Loss: 0.9045242071151733\n",
      "Step 1996/10000- lr: [8.082835951515151e-06] - Loss total: 3.4725282192230225, Last rpr Loss: 0.9991955757141113, Last lagvar Loss: 0.9045596718788147\n",
      "Step 1997/10000- lr: [8.081825854545455e-06] - Loss total: 3.471883535385132, Last rpr Loss: 0.9993415474891663, Last lagvar Loss: 0.9043177962303162\n",
      "Step 1998/10000- lr: [8.080815757575758e-06] - Loss total: 3.471240282058716, Last rpr Loss: 0.9993937015533447, Last lagvar Loss: 0.9041699767112732\n",
      "Step 1999/10000- lr: [8.079805660606061e-06] - Loss total: 3.4705967903137207, Last rpr Loss: 0.9992700815200806, Last lagvar Loss: 0.9041980504989624\n",
      "Step 2000/10000- lr: [8.078795563636365e-06] - Loss total: 3.469954490661621, Last rpr Loss: 0.9993228912353516, Last lagvar Loss: 0.9040505290031433\n",
      "Step 2001/10000- lr: [8.077785466666668e-06] - Loss total: 3.4693121910095215, Last rpr Loss: 0.9994702935218811, Last lagvar Loss: 0.9038088321685791\n",
      "Step 2002/10000- lr: [8.076775369696971e-06] - Loss total: 3.4686710834503174, Last rpr Loss: 0.9993857145309448, Last lagvar Loss: 0.9037991762161255\n",
      "Step 2003/10000- lr: [8.075765272727274e-06] - Loss total: 3.4680306911468506, Last rpr Loss: 0.9993230104446411, Last lagvar Loss: 0.9037683010101318\n",
      "Step 2004/10000- lr: [8.074755175757576e-06] - Loss total: 3.467390298843384, Last rpr Loss: 0.9994401335716248, Last lagvar Loss: 0.9035581350326538\n",
      "Step 2005/10000- lr: [8.07374507878788e-06] - Loss total: 3.4667508602142334, Last rpr Loss: 0.9994237422943115, Last lagvar Loss: 0.9034817814826965\n",
      "Step 2006/10000- lr: [8.072734981818183e-06] - Loss total: 3.466111421585083, Last rpr Loss: 0.9993199110031128, Last lagvar Loss: 0.9034929275512695\n",
      "Step 2007/10000- lr: [8.071724884848486e-06] - Loss total: 3.465472459793091, Last rpr Loss: 0.9993654489517212, Last lagvar Loss: 0.9033551216125488\n",
      "Step 2008/10000- lr: [8.070714787878789e-06] - Loss total: 3.464834213256836, Last rpr Loss: 0.9994258284568787, Last lagvar Loss: 0.9032025933265686\n",
      "Step 2009/10000- lr: [8.06970469090909e-06] - Loss total: 3.4641971588134766, Last rpr Loss: 0.9993478059768677, Last lagvar Loss: 0.9031885862350464\n",
      "Step 2010/10000- lr: [8.068694593939394e-06] - Loss total: 3.46355938911438, Last rpr Loss: 0.9993416666984558, Last lagvar Loss: 0.9031026363372803\n",
      "Step 2011/10000- lr: [8.067684496969697e-06] - Loss total: 3.4629225730895996, Last rpr Loss: 0.9994285106658936, Last lagvar Loss: 0.9029237627983093\n",
      "Step 2012/10000- lr: [8.0666744e-06] - Loss total: 3.4622855186462402, Last rpr Loss: 0.9993956089019775, Last lagvar Loss: 0.9028643369674683\n",
      "Step 2013/10000- lr: [8.065664303030304e-06] - Loss total: 3.4616498947143555, Last rpr Loss: 0.9993506669998169, Last lagvar Loss: 0.902816653251648\n",
      "Step 2014/10000- lr: [8.064654206060607e-06] - Loss total: 3.4610133171081543, Last rpr Loss: 0.9994139671325684, Last lagvar Loss: 0.9026604294776917\n",
      "Step 2015/10000- lr: [8.06364410909091e-06] - Loss total: 3.4603779315948486, Last rpr Loss: 0.9994325637817383, Last lagvar Loss: 0.9025486707687378\n",
      "Step 2016/10000- lr: [8.062634012121214e-06] - Loss total: 3.4597420692443848, Last rpr Loss: 0.9993716478347778, Last lagvar Loss: 0.9025158882141113\n",
      "Step 2017/10000- lr: [8.061623915151515e-06] - Loss total: 3.4591064453125, Last rpr Loss: 0.9993897080421448, Last lagvar Loss: 0.9024034738540649\n",
      "Step 2018/10000- lr: [8.060613818181818e-06] - Loss total: 3.4584720134735107, Last rpr Loss: 0.9994387626647949, Last lagvar Loss: 0.9022597074508667\n",
      "Step 2019/10000- lr: [8.059603721212122e-06] - Loss total: 3.457836627960205, Last rpr Loss: 0.999392032623291, Last lagvar Loss: 0.9022111892700195\n",
      "Step 2020/10000- lr: [8.058593624242425e-06] - Loss total: 3.4572017192840576, Last rpr Loss: 0.9993866086006165, Last lagvar Loss: 0.90212082862854\n",
      "Step 2021/10000- lr: [8.057583527272728e-06] - Loss total: 3.4565670490264893, Last rpr Loss: 0.9994417428970337, Last lagvar Loss: 0.9019695520401001\n",
      "Step 2022/10000- lr: [8.05657343030303e-06] - Loss total: 3.455933094024658, Last rpr Loss: 0.999427318572998, Last lagvar Loss: 0.9018871784210205\n",
      "Step 2023/10000- lr: [8.055563333333333e-06] - Loss total: 3.455298662185669, Last rpr Loss: 0.9994043707847595, Last lagvar Loss: 0.9018129110336304\n",
      "Step 2024/10000- lr: [8.054553236363636e-06] - Loss total: 3.454664945602417, Last rpr Loss: 0.9994335770606995, Last lagvar Loss: 0.9016862511634827\n",
      "Step 2025/10000- lr: [8.05354313939394e-06] - Loss total: 3.4540317058563232, Last rpr Loss: 0.9994614124298096, Last lagvar Loss: 0.9015607833862305\n",
      "Step 2026/10000- lr: [8.052533042424243e-06] - Loss total: 3.4533984661102295, Last rpr Loss: 0.9994158148765564, Last lagvar Loss: 0.9015089273452759\n",
      "Step 2027/10000- lr: [8.051522945454546e-06] - Loss total: 3.452765941619873, Last rpr Loss: 0.9994295239448547, Last lagvar Loss: 0.9013980031013489\n",
      "Step 2028/10000- lr: [8.05051284848485e-06] - Loss total: 3.4521336555480957, Last rpr Loss: 0.9994601011276245, Last lagvar Loss: 0.9012706279754639\n",
      "Step 2029/10000- lr: [8.049502751515153e-06] - Loss total: 3.4515023231506348, Last rpr Loss: 0.9994274973869324, Last lagvar Loss: 0.9012069702148438\n",
      "Step 2030/10000- lr: [8.048492654545454e-06] - Loss total: 3.450871706008911, Last rpr Loss: 0.9994264841079712, Last lagvar Loss: 0.9011126160621643\n",
      "Step 2031/10000- lr: [8.047482557575758e-06] - Loss total: 3.4502410888671875, Last rpr Loss: 0.9994490146636963, Last lagvar Loss: 0.9009956121444702\n",
      "Step 2032/10000- lr: [8.046472460606061e-06] - Loss total: 3.4496119022369385, Last rpr Loss: 0.9994475841522217, Last lagvar Loss: 0.900903582572937\n",
      "Step 2033/10000- lr: [8.045462363636364e-06] - Loss total: 3.4489829540252686, Last rpr Loss: 0.9994252920150757, Last lagvar Loss: 0.9008333683013916\n",
      "Step 2034/10000- lr: [8.044452266666668e-06] - Loss total: 3.448354482650757, Last rpr Loss: 0.9994411468505859, Last lagvar Loss: 0.9007260799407959\n",
      "Step 2035/10000- lr: [8.043442169696969e-06] - Loss total: 3.4477274417877197, Last rpr Loss: 0.9994519352912903, Last lagvar Loss: 0.9006248712539673\n",
      "Step 2036/10000- lr: [8.042432072727272e-06] - Loss total: 3.4471004009246826, Last rpr Loss: 0.999428391456604, Last lagvar Loss: 0.9005589485168457\n",
      "Step 2037/10000- lr: [8.041421975757576e-06] - Loss total: 3.446474075317383, Last rpr Loss: 0.9994379281997681, Last lagvar Loss: 0.900460958480835\n",
      "Step 2038/10000- lr: [8.040411878787879e-06] - Loss total: 3.445848226547241, Last rpr Loss: 0.9994472861289978, Last lagvar Loss: 0.9003638029098511\n",
      "Step 2039/10000- lr: [8.039401781818182e-06] - Loss total: 3.445223093032837, Last rpr Loss: 0.9994394779205322, Last lagvar Loss: 0.9002847671508789\n",
      "Step 2040/10000- lr: [8.038391684848485e-06] - Loss total: 3.4445981979370117, Last rpr Loss: 0.9994299411773682, Last lagvar Loss: 0.9002083539962769\n",
      "Step 2041/10000- lr: [8.037381587878789e-06] - Loss total: 3.443974256515503, Last rpr Loss: 0.9994508624076843, Last lagvar Loss: 0.9001021385192871\n",
      "Step 2042/10000- lr: [8.036371490909092e-06] - Loss total: 3.4433507919311523, Last rpr Loss: 0.9994472861289978, Last lagvar Loss: 0.9000211358070374\n",
      "Step 2043/10000- lr: [8.035361393939395e-06] - Loss total: 3.4427266120910645, Last rpr Loss: 0.9994306564331055, Last lagvar Loss: 0.8999537229537964\n",
      "Step 2044/10000- lr: [8.034351296969699e-06] - Loss total: 3.4421043395996094, Last rpr Loss: 0.9994508028030396, Last lagvar Loss: 0.8998504281044006\n",
      "Step 2045/10000- lr: [8.0333412e-06] - Loss total: 3.441480875015259, Last rpr Loss: 0.9994356036186218, Last lagvar Loss: 0.8997831344604492\n",
      "Step 2046/10000- lr: [8.032331103030303e-06] - Loss total: 3.4408586025238037, Last rpr Loss: 0.9994345307350159, Last lagvar Loss: 0.8997020721435547\n",
      "Step 2047/10000- lr: [8.031321006060607e-06] - Loss total: 3.4402365684509277, Last rpr Loss: 0.9994251728057861, Last lagvar Loss: 0.8996299505233765\n",
      "Step 2048/10000- lr: [8.03031090909091e-06] - Loss total: 3.43961501121521, Last rpr Loss: 0.9994440078735352, Last lagvar Loss: 0.899530291557312\n",
      "Step 2049/10000- lr: [8.029300812121213e-06] - Loss total: 3.4389936923980713, Last rpr Loss: 0.9994239807128906, Last lagvar Loss: 0.8994699716567993\n",
      "Step 2050/10000- lr: [8.028290715151515e-06] - Loss total: 3.4383723735809326, Last rpr Loss: 0.9994312524795532, Last lagvar Loss: 0.8993827104568481\n",
      "Step 2051/10000- lr: [8.027280618181818e-06] - Loss total: 3.437751054763794, Last rpr Loss: 0.9994404315948486, Last lagvar Loss: 0.8992939591407776\n",
      "Step 2052/10000- lr: [8.026270521212121e-06] - Loss total: 3.437130928039551, Last rpr Loss: 0.999432384967804, Last lagvar Loss: 0.899222731590271\n",
      "Step 2053/10000- lr: [8.025260424242425e-06] - Loss total: 3.4365100860595703, Last rpr Loss: 0.9994364976882935, Last lagvar Loss: 0.8991394639015198\n",
      "Step 2054/10000- lr: [8.024250327272728e-06] - Loss total: 3.435889720916748, Last rpr Loss: 0.9994345903396606, Last lagvar Loss: 0.89906245470047\n",
      "Step 2055/10000- lr: [8.023240230303031e-06] - Loss total: 3.435269594192505, Last rpr Loss: 0.9994543790817261, Last lagvar Loss: 0.8989636898040771\n",
      "Step 2056/10000- lr: [8.022230133333335e-06] - Loss total: 3.4346492290496826, Last rpr Loss: 0.9994324445724487, Last lagvar Loss: 0.8989067077636719\n",
      "Step 2057/10000- lr: [8.021220036363638e-06] - Loss total: 3.4340291023254395, Last rpr Loss: 0.9994560480117798, Last lagvar Loss: 0.8988037705421448\n",
      "Step 2058/10000- lr: [8.02020993939394e-06] - Loss total: 3.433408737182617, Last rpr Loss: 0.9994476437568665, Last lagvar Loss: 0.8987327814102173\n",
      "Step 2059/10000- lr: [8.019199842424243e-06] - Loss total: 3.432788848876953, Last rpr Loss: 0.999446451663971, Last lagvar Loss: 0.8986539244651794\n",
      "Step 2060/10000- lr: [8.018189745454546e-06] - Loss total: 3.432168483734131, Last rpr Loss: 0.9994500875473022, Last lagvar Loss: 0.8985700607299805\n",
      "Step 2061/10000- lr: [8.01717964848485e-06] - Loss total: 3.4315481185913086, Last rpr Loss: 0.9994528889656067, Last lagvar Loss: 0.8984862565994263\n",
      "Step 2062/10000- lr: [8.016169551515153e-06] - Loss total: 3.4309277534484863, Last rpr Loss: 0.9994545578956604, Last lagvar Loss: 0.8984031081199646\n",
      "Step 2063/10000- lr: [8.015159454545454e-06] - Loss total: 3.430307626724243, Last rpr Loss: 0.9994497299194336, Last lagvar Loss: 0.8983259201049805\n",
      "Step 2064/10000- lr: [8.014149357575757e-06] - Loss total: 3.4296865463256836, Last rpr Loss: 0.9994655847549438, Last lagvar Loss: 0.8982278108596802\n",
      "Step 2065/10000- lr: [8.01313926060606e-06] - Loss total: 3.4290661811828613, Last rpr Loss: 0.9994568824768066, Last lagvar Loss: 0.898154079914093\n",
      "Step 2066/10000- lr: [8.012129163636364e-06] - Loss total: 3.4284451007843018, Last rpr Loss: 0.9994666576385498, Last lagvar Loss: 0.8980619311332703\n",
      "Step 2067/10000- lr: [8.011119066666667e-06] - Loss total: 3.427824020385742, Last rpr Loss: 0.9994652271270752, Last lagvar Loss: 0.8979814648628235\n",
      "Step 2068/10000- lr: [8.01010896969697e-06] - Loss total: 3.4272031784057617, Last rpr Loss: 0.9994763135910034, Last lagvar Loss: 0.8978890776634216\n",
      "Step 2069/10000- lr: [8.009098872727274e-06] - Loss total: 3.4265811443328857, Last rpr Loss: 0.9994761943817139, Last lagvar Loss: 0.8978086709976196\n",
      "Step 2070/10000- lr: [8.008088775757577e-06] - Loss total: 3.425960063934326, Last rpr Loss: 0.999482274055481, Last lagvar Loss: 0.8977231383323669\n",
      "Step 2071/10000- lr: [8.00707867878788e-06] - Loss total: 3.4253387451171875, Last rpr Loss: 0.9994856715202332, Last lagvar Loss: 0.8976410627365112\n",
      "Step 2072/10000- lr: [8.006068581818182e-06] - Loss total: 3.4247171878814697, Last rpr Loss: 0.9994838237762451, Last lagvar Loss: 0.897565484046936\n",
      "Step 2073/10000- lr: [8.005058484848485e-06] - Loss total: 3.424095630645752, Last rpr Loss: 0.9994852542877197, Last lagvar Loss: 0.8974875211715698\n",
      "Step 2074/10000- lr: [8.004048387878788e-06] - Loss total: 3.423473834991455, Last rpr Loss: 0.9994760751724243, Last lagvar Loss: 0.8974207639694214\n",
      "Step 2075/10000- lr: [8.003038290909092e-06] - Loss total: 3.422852039337158, Last rpr Loss: 0.9994722008705139, Last lagvar Loss: 0.8973496556282043\n",
      "Step 2076/10000- lr: [8.002028193939395e-06] - Loss total: 3.4222302436828613, Last rpr Loss: 0.9994682669639587, Last lagvar Loss: 0.8972790241241455\n",
      "Step 2077/10000- lr: [8.001018096969697e-06] - Loss total: 3.4216084480285645, Last rpr Loss: 0.9994593262672424, Last lagvar Loss: 0.8972136974334717\n",
      "Step 2078/10000- lr: [8.000008e-06] - Loss total: 3.4209866523742676, Last rpr Loss: 0.9994476437568665, Last lagvar Loss: 0.8971514701843262\n",
      "Step 2079/10000- lr: [7.998997903030303e-06] - Loss total: 3.4203646183013916, Last rpr Loss: 0.9994512796401978, Last lagvar Loss: 0.8970739841461182\n",
      "Step 2080/10000- lr: [7.997987806060606e-06] - Loss total: 3.4197428226470947, Last rpr Loss: 0.999432384967804, Last lagvar Loss: 0.8970189094543457\n",
      "Step 2081/10000- lr: [7.99697770909091e-06] - Loss total: 3.4191200733184814, Last rpr Loss: 0.9994428753852844, Last lagvar Loss: 0.8969341516494751\n",
      "Step 2082/10000- lr: [7.995967612121213e-06] - Loss total: 3.418497323989868, Last rpr Loss: 0.9994251728057861, Last lagvar Loss: 0.8968769311904907\n",
      "Step 2083/10000- lr: [7.994957515151516e-06] - Loss total: 3.4178738594055176, Last rpr Loss: 0.9994478225708008, Last lagvar Loss: 0.8967784643173218\n",
      "Step 2084/10000- lr: [7.99394741818182e-06] - Loss total: 3.417249917984009, Last rpr Loss: 0.9994292855262756, Last lagvar Loss: 0.8967198133468628\n",
      "Step 2085/10000- lr: [7.992937321212123e-06] - Loss total: 3.4166252613067627, Last rpr Loss: 0.9994567632675171, Last lagvar Loss: 0.8966129422187805\n",
      "Step 2086/10000- lr: [7.991927224242424e-06] - Loss total: 3.415998697280884, Last rpr Loss: 0.9994375705718994, Last lagvar Loss: 0.8965494632720947\n",
      "Step 2087/10000- lr: [7.990917127272728e-06] - Loss total: 3.415369749069214, Last rpr Loss: 0.9994737505912781, Last lagvar Loss: 0.8964254856109619\n",
      "Step 2088/10000- lr: [7.989907030303031e-06] - Loss total: 3.414738893508911, Last rpr Loss: 0.999451756477356, Last lagvar Loss: 0.8963519334793091\n",
      "Step 2089/10000- lr: [7.988896933333334e-06] - Loss total: 3.4141042232513428, Last rpr Loss: 0.9994837641716003, Last lagvar Loss: 0.8962130546569824\n",
      "Step 2090/10000- lr: [7.987886836363637e-06] - Loss total: 3.4134652614593506, Last rpr Loss: 0.9994520545005798, Last lagvar Loss: 0.8961209058761597\n",
      "Step 2091/10000- lr: [7.986876739393939e-06] - Loss total: 3.4128217697143555, Last rpr Loss: 0.9994663000106812, Last lagvar Loss: 0.8959593772888184\n",
      "Step 2092/10000- lr: [7.985866642424242e-06] - Loss total: 3.412172794342041, Last rpr Loss: 0.9994066953659058, Last lagvar Loss: 0.895843505859375\n",
      "Step 2093/10000- lr: [7.984856545454546e-06] - Loss total: 3.4115209579467773, Last rpr Loss: 0.9994052052497864, Last lagvar Loss: 0.8956447243690491\n",
      "Step 2094/10000- lr: [7.983846448484849e-06] - Loss total: 3.41086745262146, Last rpr Loss: 0.9993292689323425, Last lagvar Loss: 0.8955094814300537\n",
      "Step 2095/10000- lr: [7.982836351515152e-06] - Loss total: 3.410217046737671, Last rpr Loss: 0.9993557929992676, Last lagvar Loss: 0.8952814340591431\n",
      "Step 2096/10000- lr: [7.981826254545455e-06] - Loss total: 3.4095699787139893, Last rpr Loss: 0.9993179440498352, Last lagvar Loss: 0.895139217376709\n",
      "Step 2097/10000- lr: [7.980816157575759e-06] - Loss total: 3.4089252948760986, Last rpr Loss: 0.9994441270828247, Last lagvar Loss: 0.8948566317558289\n",
      "Step 2098/10000- lr: [7.979806060606062e-06] - Loss total: 3.408283233642578, Last rpr Loss: 0.9994839429855347, Last lagvar Loss: 0.8946782350540161\n",
      "Step 2099/10000- lr: [7.978795963636364e-06] - Loss total: 3.4076426029205322, Last rpr Loss: 0.9997004270553589, Last lagvar Loss: 0.8943372964859009\n",
      "Step 2100/10000- lr: [7.977785866666667e-06] - Loss total: 3.4070029258728027, Last rpr Loss: 0.9997233748435974, Last lagvar Loss: 0.8941981792449951\n",
      "Step 2101/10000- lr: [7.97677576969697e-06] - Loss total: 3.4063656330108643, Last rpr Loss: 0.9999102354049683, Last lagvar Loss: 0.8939020037651062\n",
      "Step 2102/10000- lr: [7.975765672727273e-06] - Loss total: 3.405729293823242, Last rpr Loss: 0.9997330904006958, Last lagvar Loss: 0.8939722776412964\n",
      "Step 2103/10000- lr: [7.974755575757577e-06] - Loss total: 3.405095338821411, Last rpr Loss: 0.9998281002044678, Last lagvar Loss: 0.8937734365463257\n",
      "Step 2104/10000- lr: [7.973745478787878e-06] - Loss total: 3.4044628143310547, Last rpr Loss: 0.9994506239891052, Last lagvar Loss: 0.894046425819397\n",
      "Step 2105/10000- lr: [7.972735381818182e-06] - Loss total: 3.403832197189331, Last rpr Loss: 0.999630868434906, Last lagvar Loss: 0.8937637209892273\n",
      "Step 2106/10000- lr: [7.971725284848485e-06] - Loss total: 3.403202533721924, Last rpr Loss: 0.9991219639778137, Last lagvar Loss: 0.8941682577133179\n",
      "Step 2107/10000- lr: [7.970715187878788e-06] - Loss total: 3.402573823928833, Last rpr Loss: 0.9996113777160645, Last lagvar Loss: 0.8935773968696594\n",
      "Step 2108/10000- lr: [7.969705090909091e-06] - Loss total: 3.4019463062286377, Last rpr Loss: 0.9988924264907837, Last lagvar Loss: 0.8941924571990967\n",
      "Step 2109/10000- lr: [7.968694993939395e-06] - Loss total: 3.4013187885284424, Last rpr Loss: 0.9998740553855896, Last lagvar Loss: 0.8931131362915039\n",
      "Step 2110/10000- lr: [7.967684896969698e-06] - Loss total: 3.4006917476654053, Last rpr Loss: 0.9986515045166016, Last lagvar Loss: 0.8942333459854126\n",
      "Step 2111/10000- lr: [7.966674800000001e-06] - Loss total: 3.4000656604766846, Last rpr Loss: 1.000463843345642, Last lagvar Loss: 0.8923304080963135\n",
      "Step 2112/10000- lr: [7.965664703030305e-06] - Loss total: 3.399439811706543, Last rpr Loss: 0.9981902241706848, Last lagvar Loss: 0.8945024609565735\n",
      "Step 2113/10000- lr: [7.964654606060606e-06] - Loss total: 3.398815393447876, Last rpr Loss: 1.0015184879302979, Last lagvar Loss: 0.8910955190658569\n",
      "Step 2114/10000- lr: [7.96364450909091e-06] - Loss total: 3.398193120956421, Last rpr Loss: 0.9970760345458984, Last lagvar Loss: 0.8954364061355591\n",
      "Step 2115/10000- lr: [7.962634412121213e-06] - Loss total: 3.3975746631622314, Last rpr Loss: 1.0033597946166992, Last lagvar Loss: 0.8890981674194336\n",
      "Step 2116/10000- lr: [7.961624315151516e-06] - Loss total: 3.396965980529785, Last rpr Loss: 0.9945175647735596, Last lagvar Loss: 0.8978431224822998\n",
      "Step 2117/10000- lr: [7.96061421818182e-06] - Loss total: 3.3963732719421387, Last rpr Loss: 1.0068795680999756, Last lagvar Loss: 0.8854843974113464\n",
      "Step 2118/10000- lr: [7.95960412121212e-06] - Loss total: 3.3958239555358887, Last rpr Loss: 0.9891153573989868, Last lagvar Loss: 0.9031908512115479\n",
      "Step 2119/10000- lr: [7.958594024242424e-06] - Loss total: 3.395343542098999, Last rpr Loss: 1.0143396854400635, Last lagvar Loss: 0.8781399726867676\n",
      "Step 2120/10000- lr: [7.957583927272727e-06] - Loss total: 3.3950722217559814, Last rpr Loss: 0.978043794631958, Last lagvar Loss: 0.9146195650100708\n",
      "Step 2121/10000- lr: [7.95657383030303e-06] - Loss total: 3.3950488567352295, Last rpr Loss: 1.0304205417633057, Last lagvar Loss: 0.8630000948905945\n",
      "Step 2122/10000- lr: [7.955563733333334e-06] - Loss total: 3.3949978351593018, Last rpr Loss: 0.9641796350479126, Last lagvar Loss: 0.9295613169670105\n",
      "Step 2123/10000- lr: [7.954553636363637e-06] - Loss total: 3.3929123878479004, Last rpr Loss: 1.015782117843628, Last lagvar Loss: 0.8764843940734863\n",
      "Step 2124/10000- lr: [7.95354353939394e-06] - Loss total: 3.391929864883423, Last rpr Loss: 0.9979068040847778, Last lagvar Loss: 0.8938480615615845\n",
      "Step 2125/10000- lr: [7.952533442424244e-06] - Loss total: 3.3914847373962402, Last rpr Loss: 0.9886165261268616, Last lagvar Loss: 0.9032179117202759\n",
      "Step 2126/10000- lr: [7.951523345454547e-06] - Loss total: 3.3915181159973145, Last rpr Loss: 1.024770975112915, Last lagvar Loss: 0.8678218126296997\n",
      "Step 2127/10000- lr: [7.950513248484849e-06] - Loss total: 3.392559051513672, Last rpr Loss: 0.9589465856552124, Last lagvar Loss: 0.9351255893707275\n",
      "Step 2128/10000- lr: [7.949503151515152e-06] - Loss total: 3.3895957469940186, Last rpr Loss: 1.0088086128234863, Last lagvar Loss: 0.882846474647522\n",
      "Step 2129/10000- lr: [7.948493054545455e-06] - Loss total: 3.3893556594848633, Last rpr Loss: 1.0184215307235718, Last lagvar Loss: 0.8736041784286499\n",
      "Step 2130/10000- lr: [7.947482957575758e-06] - Loss total: 3.3914663791656494, Last rpr Loss: 0.9537312984466553, Last lagvar Loss: 0.9408921599388123\n",
      "Step 2131/10000- lr: [7.946472860606062e-06] - Loss total: 3.3876891136169434, Last rpr Loss: 1.0026850700378418, Last lagvar Loss: 0.8886446356773376\n",
      "Step 2132/10000- lr: [7.945462763636363e-06] - Loss total: 3.389146089553833, Last rpr Loss: 1.039792537689209, Last lagvar Loss: 0.8538050651550293\n",
      "Step 2133/10000- lr: [7.944452666666667e-06] - Loss total: 3.3891520500183105, Last rpr Loss: 0.9576419591903687, Last lagvar Loss: 0.9362179040908813\n",
      "Step 2134/10000- lr: [7.94344256969697e-06] - Loss total: 3.386000156402588, Last rpr Loss: 0.9938642978668213, Last lagvar Loss: 0.8972939848899841\n",
      "Step 2135/10000- lr: [7.942432472727273e-06] - Loss total: 3.3891665935516357, Last rpr Loss: 1.0547313690185547, Last lagvar Loss: 0.8406062722206116\n",
      "Step 2136/10000- lr: [7.941422375757576e-06] - Loss total: 3.3850598335266113, Last rpr Loss: 0.9876036643981934, Last lagvar Loss: 0.9036027193069458\n",
      "Step 2137/10000- lr: [7.94041227878788e-06] - Loss total: 3.38494873046875, Last rpr Loss: 0.9788814187049866, Last lagvar Loss: 0.9127073884010315\n",
      "Step 2138/10000- lr: [7.939402181818183e-06] - Loss total: 3.3877930641174316, Last rpr Loss: 1.0564172267913818, Last lagvar Loss: 0.8389962315559387\n",
      "Step 2139/10000- lr: [7.938392084848486e-06] - Loss total: 3.3832802772521973, Last rpr Loss: 1.0047836303710938, Last lagvar Loss: 0.8861709833145142\n",
      "Step 2140/10000- lr: [7.93738198787879e-06] - Loss total: 3.3873913288116455, Last rpr Loss: 0.945170521736145, Last lagvar Loss: 0.9504608511924744\n",
      "Step 2141/10000- lr: [7.936371890909091e-06] - Loss total: 3.3822391033172607, Last rpr Loss: 0.9944671988487244, Last lagvar Loss: 0.8963523507118225\n",
      "Step 2142/10000- lr: [7.935361793939394e-06] - Loss total: 3.3880767822265625, Last rpr Loss: 1.071402668952942, Last lagvar Loss: 0.8265851140022278\n",
      "Step 2143/10000- lr: [7.934351696969698e-06] - Loss total: 3.381577730178833, Last rpr Loss: 1.0143721103668213, Last lagvar Loss: 0.8768797516822815\n",
      "Step 2144/10000- lr: [7.933341600000001e-06] - Loss total: 3.391989231109619, Last rpr Loss: 0.9203747510910034, Last lagvar Loss: 0.9822174906730652\n",
      "Step 2145/10000- lr: [7.932331503030304e-06] - Loss total: 3.3887298107147217, Last rpr Loss: 0.9330353736877441, Last lagvar Loss: 0.9668964147567749\n",
      "Step 2146/10000- lr: [7.931321406060606e-06] - Loss total: 3.3828670978546143, Last rpr Loss: 1.04837167263031, Last lagvar Loss: 0.8455382585525513\n",
      "Step 2147/10000- lr: [7.930311309090909e-06] - Loss total: 3.38309907913208, Last rpr Loss: 1.0478737354278564, Last lagvar Loss: 0.8474169969558716\n",
      "Step 2148/10000- lr: [7.929301212121212e-06] - Loss total: 3.383892297744751, Last rpr Loss: 0.940413236618042, Last lagvar Loss: 0.955256462097168\n",
      "Step 2149/10000- lr: [7.928291115151516e-06] - Loss total: 3.381779909133911, Last rpr Loss: 0.9564074873924255, Last lagvar Loss: 0.9375464916229248\n",
      "Step 2150/10000- lr: [7.927281018181819e-06] - Loss total: 3.3863115310668945, Last rpr Loss: 1.0856772661209106, Last lagvar Loss: 0.8136671781539917\n",
      "Step 2151/10000- lr: [7.926270921212122e-06] - Loss total: 3.3857903480529785, Last rpr Loss: 1.083167314529419, Last lagvar Loss: 0.8160902261734009\n",
      "Step 2152/10000- lr: [7.925260824242425e-06] - Loss total: 3.379284143447876, Last rpr Loss: 0.9620156288146973, Last lagvar Loss: 0.9304422736167908\n",
      "Step 2153/10000- lr: [7.924250727272729e-06] - Loss total: 3.3780834674835205, Last rpr Loss: 0.9727102518081665, Last lagvar Loss: 0.91878342628479\n",
      "Step 2154/10000- lr: [7.92324063030303e-06] - Loss total: 3.3877182006835938, Last rpr Loss: 1.0998793840408325, Last lagvar Loss: 0.8023950457572937\n",
      "Step 2155/10000- lr: [7.922230533333334e-06] - Loss total: 3.3856282234191895, Last rpr Loss: 1.0895745754241943, Last lagvar Loss: 0.8108497858047485\n",
      "Step 2156/10000- lr: [7.921220436363637e-06] - Loss total: 3.3775131702423096, Last rpr Loss: 0.9623242020606995, Last lagvar Loss: 0.9296838641166687\n",
      "Step 2157/10000- lr: [7.92021033939394e-06] - Loss total: 3.3766396045684814, Last rpr Loss: 0.9704153537750244, Last lagvar Loss: 0.9210177659988403\n",
      "Step 2158/10000- lr: [7.919200242424243e-06] - Loss total: 3.3854312896728516, Last rpr Loss: 1.096057415008545, Last lagvar Loss: 0.8053585290908813\n",
      "Step 2159/10000- lr: [7.918190145454545e-06] - Loss total: 3.3832626342773438, Last rpr Loss: 1.0851882696151733, Last lagvar Loss: 0.8142052888870239\n",
      "Step 2160/10000- lr: [7.917180048484848e-06] - Loss total: 3.3763341903686523, Last rpr Loss: 0.9597977995872498, Last lagvar Loss: 0.9324044585227966\n",
      "Step 2161/10000- lr: [7.916169951515152e-06] - Loss total: 3.375415802001953, Last rpr Loss: 0.9678624868392944, Last lagvar Loss: 0.9237165451049805\n",
      "Step 2162/10000- lr: [7.915159854545455e-06] - Loss total: 3.3828890323638916, Last rpr Loss: 1.0914826393127441, Last lagvar Loss: 0.808722734451294\n",
      "Step 2163/10000- lr: [7.914149757575758e-06] - Loss total: 3.3807175159454346, Last rpr Loss: 1.0795598030090332, Last lagvar Loss: 0.8185278177261353\n",
      "Step 2164/10000- lr: [7.913139660606061e-06] - Loss total: 3.3753654956817627, Last rpr Loss: 0.9553134441375732, Last lagvar Loss: 0.9372996091842651\n",
      "Step 2165/10000- lr: [7.912129563636365e-06] - Loss total: 3.374394416809082, Last rpr Loss: 0.9624813795089722, Last lagvar Loss: 0.9294158220291138\n",
      "Step 2166/10000- lr: [7.911119466666668e-06] - Loss total: 3.3802709579467773, Last rpr Loss: 1.0863823890686035, Last lagvar Loss: 0.8125495910644531\n",
      "Step 2167/10000- lr: [7.91010936969697e-06] - Loss total: 3.3782155513763428, Last rpr Loss: 1.0757904052734375, Last lagvar Loss: 0.8211096525192261\n",
      "Step 2168/10000- lr: [7.909099272727273e-06] - Loss total: 3.374502658843994, Last rpr Loss: 0.9528301954269409, Last lagvar Loss: 0.940207839012146\n",
      "Step 2169/10000- lr: [7.908089175757576e-06] - Loss total: 3.3734934329986572, Last rpr Loss: 0.9573534727096558, Last lagvar Loss: 0.9349379539489746\n",
      "Step 2170/10000- lr: [7.90707907878788e-06] - Loss total: 3.3778014183044434, Last rpr Loss: 1.079270362854004, Last lagvar Loss: 0.8183424472808838\n",
      "Step 2171/10000- lr: [7.906068981818183e-06] - Loss total: 3.3759849071502686, Last rpr Loss: 1.070068120956421, Last lagvar Loss: 0.825851321220398\n",
      "Step 2172/10000- lr: [7.905058884848486e-06] - Loss total: 3.373595714569092, Last rpr Loss: 0.9491100311279297, Last lagvar Loss: 0.9442658424377441\n",
      "Step 2173/10000- lr: [7.904048787878787e-06] - Loss total: 3.3725881576538086, Last rpr Loss: 0.9530704021453857, Last lagvar Loss: 0.9395933747291565\n",
      "Step 2174/10000- lr: [7.90303869090909e-06] - Loss total: 3.3755908012390137, Last rpr Loss: 1.0732096433639526, Last lagvar Loss: 0.8232585191726685\n",
      "Step 2175/10000- lr: [7.902028593939394e-06] - Loss total: 3.3740053176879883, Last rpr Loss: 1.0659348964691162, Last lagvar Loss: 0.829242467880249\n",
      "Step 2176/10000- lr: [7.901018496969697e-06] - Loss total: 3.372628688812256, Last rpr Loss: 0.9476782083511353, Last lagvar Loss: 0.9458670616149902\n",
      "Step 2177/10000- lr: [7.9000084e-06] - Loss total: 3.371622323989868, Last rpr Loss: 0.9515649080276489, Last lagvar Loss: 0.9413048624992371\n",
      "Step 2178/10000- lr: [7.898998303030304e-06] - Loss total: 3.373605728149414, Last rpr Loss: 1.068701982498169, Last lagvar Loss: 0.8268717527389526\n",
      "Step 2179/10000- lr: [7.897988206060607e-06] - Loss total: 3.3721556663513184, Last rpr Loss: 1.061288595199585, Last lagvar Loss: 0.8331617116928101\n",
      "Step 2180/10000- lr: [7.89697810909091e-06] - Loss total: 3.3716483116149902, Last rpr Loss: 0.9452678561210632, Last lagvar Loss: 0.948472797870636\n",
      "Step 2181/10000- lr: [7.895968012121214e-06] - Loss total: 3.370609760284424, Last rpr Loss: 0.949718713760376, Last lagvar Loss: 0.943303108215332\n",
      "Step 2182/10000- lr: [7.894957915151515e-06] - Loss total: 3.371772050857544, Last rpr Loss: 1.0650463104248047, Last lagvar Loss: 0.8297991752624512\n",
      "Step 2183/10000- lr: [7.893947818181819e-06] - Loss total: 3.370389461517334, Last rpr Loss: 1.057369351387024, Last lagvar Loss: 0.836396336555481\n",
      "Step 2184/10000- lr: [7.892937721212122e-06] - Loss total: 3.370654821395874, Last rpr Loss: 0.9435344934463501, Last lagvar Loss: 0.9503730535507202\n",
      "Step 2185/10000- lr: [7.891927624242425e-06] - Loss total: 3.369548797607422, Last rpr Loss: 0.9489507675170898, Last lagvar Loss: 0.9441343545913696\n",
      "Step 2186/10000- lr: [7.890917527272728e-06] - Loss total: 3.370103120803833, Last rpr Loss: 1.0633684396743774, Last lagvar Loss: 0.8310002684593201\n",
      "Step 2187/10000- lr: [7.88990743030303e-06] - Loss total: 3.3687527179718018, Last rpr Loss: 1.0546143054962158, Last lagvar Loss: 0.8386276960372925\n",
      "Step 2188/10000- lr: [7.888897333333333e-06] - Loss total: 3.3696353435516357, Last rpr Loss: 0.9413066506385803, Last lagvar Loss: 0.9527726769447327\n",
      "Step 2189/10000- lr: [7.887887236363637e-06] - Loss total: 3.3684802055358887, Last rpr Loss: 0.9469461441040039, Last lagvar Loss: 0.9462526440620422\n",
      "Step 2190/10000- lr: [7.88687713939394e-06] - Loss total: 3.368516206741333, Last rpr Loss: 1.061314582824707, Last lagvar Loss: 0.8326379060745239\n",
      "Step 2191/10000- lr: [7.885867042424243e-06] - Loss total: 3.3671984672546387, Last rpr Loss: 1.0526950359344482, Last lagvar Loss: 0.8401410579681396\n",
      "Step 2192/10000- lr: [7.884856945454546e-06] - Loss total: 3.368584632873535, Last rpr Loss: 0.9398800730705261, Last lagvar Loss: 0.9543231725692749\n",
      "Step 2193/10000- lr: [7.88384684848485e-06] - Loss total: 3.3673977851867676, Last rpr Loss: 0.9453116059303284, Last lagvar Loss: 0.9479768872261047\n",
      "Step 2194/10000- lr: [7.882836751515153e-06] - Loss total: 3.3669731616973877, Last rpr Loss: 1.059445858001709, Last lagvar Loss: 0.8341397047042847\n",
      "Step 2195/10000- lr: [7.881826654545454e-06] - Loss total: 3.365696430206299, Last rpr Loss: 1.051433801651001, Last lagvar Loss: 0.8410696387290955\n",
      "Step 2196/10000- lr: [7.880816557575758e-06] - Loss total: 3.3674936294555664, Last rpr Loss: 0.9391396641731262, Last lagvar Loss: 0.9551349878311157\n",
      "Step 2197/10000- lr: [7.879806460606061e-06] - Loss total: 3.366288900375366, Last rpr Loss: 0.9440701007843018, Last lagvar Loss: 0.9492819309234619\n",
      "Step 2198/10000- lr: [7.878796363636364e-06] - Loss total: 3.3654608726501465, Last rpr Loss: 1.0574713945388794, Last lagvar Loss: 0.8357547521591187\n",
      "Step 2199/10000- lr: [7.877786266666668e-06] - Loss total: 3.3642308712005615, Last rpr Loss: 1.0502125024795532, Last lagvar Loss: 0.842009425163269\n",
      "Step 2200/10000- lr: [7.87677616969697e-06] - Loss total: 3.3663580417633057, Last rpr Loss: 0.93870609998703, Last lagvar Loss: 0.9555834531784058\n",
      "Step 2201/10000- lr: [7.875766072727272e-06] - Loss total: 3.3651514053344727, Last rpr Loss: 0.9432541728019714, Last lagvar Loss: 0.950127124786377\n",
      "Step 2202/10000- lr: [7.874755975757576e-06] - Loss total: 3.3639602661132812, Last rpr Loss: 1.0555346012115479, Last lagvar Loss: 0.8373438119888306\n",
      "Step 2203/10000- lr: [7.873745878787879e-06] - Loss total: 3.362776041030884, Last rpr Loss: 1.0487103462219238, Last lagvar Loss: 0.8432374000549316\n",
      "Step 2204/10000- lr: [7.872735781818182e-06] - Loss total: 3.3651933670043945, Last rpr Loss: 0.9382596015930176, Last lagvar Loss: 0.9560297727584839\n",
      "Step 2205/10000- lr: [7.871725684848486e-06] - Loss total: 3.363982915878296, Last rpr Loss: 0.9427329301834106, Last lagvar Loss: 0.9506557583808899\n",
      "Step 2206/10000- lr: [7.870715587878789e-06] - Loss total: 3.362473249435425, Last rpr Loss: 1.0537925958633423, Last lagvar Loss: 0.838756263256073\n",
      "Step 2207/10000- lr: [7.869705490909092e-06] - Loss total: 3.361321449279785, Last rpr Loss: 1.0468730926513672, Last lagvar Loss: 0.8447966575622559\n",
      "Step 2208/10000- lr: [7.868695393939395e-06] - Loss total: 3.3640148639678955, Last rpr Loss: 0.9375403523445129, Last lagvar Loss: 0.9567501544952393\n",
      "Step 2209/10000- lr: [7.867685296969697e-06] - Loss total: 3.3627960681915283, Last rpr Loss: 0.9423264265060425, Last lagvar Loss: 0.9510539174079895\n",
      "Step 2210/10000- lr: [7.8666752e-06] - Loss total: 3.3609893321990967, Last rpr Loss: 1.0525579452514648, Last lagvar Loss: 0.8396995067596436\n",
      "Step 2211/10000- lr: [7.865665103030304e-06] - Loss total: 3.359860420227051, Last rpr Loss: 1.045287847518921, Last lagvar Loss: 0.8461122512817383\n",
      "Step 2212/10000- lr: [7.864655006060607e-06] - Loss total: 3.362826108932495, Last rpr Loss: 0.9367750883102417, Last lagvar Loss: 0.9575233459472656\n",
      "Step 2213/10000- lr: [7.86364490909091e-06] - Loss total: 3.3615903854370117, Last rpr Loss: 0.9418062567710876, Last lagvar Loss: 0.9515625238418579\n",
      "Step 2214/10000- lr: [7.862634812121213e-06] - Loss total: 3.35951566696167, Last rpr Loss: 1.0514768362045288, Last lagvar Loss: 0.8405115604400635\n",
      "Step 2215/10000- lr: [7.861624715151515e-06] - Loss total: 3.358403444290161, Last rpr Loss: 1.0439541339874268, Last lagvar Loss: 0.8471912145614624\n",
      "Step 2216/10000- lr: [7.860614618181818e-06] - Loss total: 3.3616156578063965, Last rpr Loss: 0.9361025094985962, Last lagvar Loss: 0.9581912755966187\n",
      "Step 2217/10000- lr: [7.859604521212121e-06] - Loss total: 3.360363721847534, Last rpr Loss: 0.9412898421287537, Last lagvar Loss: 0.9520561099052429\n",
      "Step 2218/10000- lr: [7.858594424242425e-06] - Loss total: 3.358044385910034, Last rpr Loss: 1.050516963005066, Last lagvar Loss: 0.8412247896194458\n",
      "Step 2219/10000- lr: [7.857584327272728e-06] - Loss total: 3.3569469451904297, Last rpr Loss: 1.042799711227417, Last lagvar Loss: 0.8481025695800781\n",
      "Step 2220/10000- lr: [7.856574230303031e-06] - Loss total: 3.360382556915283, Last rpr Loss: 0.9354190230369568, Last lagvar Loss: 0.9588676691055298\n",
      "Step 2221/10000- lr: [7.855564133333335e-06] - Loss total: 3.3591129779815674, Last rpr Loss: 0.9406114816665649, Last lagvar Loss: 0.9527121782302856\n",
      "Step 2222/10000- lr: [7.854554036363638e-06] - Loss total: 3.356577157974243, Last rpr Loss: 1.049448013305664, Last lagvar Loss: 0.8420519828796387\n",
      "Step 2223/10000- lr: [7.85354393939394e-06] - Loss total: 3.355494499206543, Last rpr Loss: 1.041805624961853, Last lagvar Loss: 0.8488693237304688\n",
      "Step 2224/10000- lr: [7.852533842424243e-06] - Loss total: 3.3591220378875732, Last rpr Loss: 0.9349319934844971, Last lagvar Loss: 0.9593253135681152\n",
      "Step 2225/10000- lr: [7.851523745454546e-06] - Loss total: 3.3578405380249023, Last rpr Loss: 0.9401187896728516, Last lagvar Loss: 0.9531641006469727\n",
      "Step 2226/10000- lr: [7.85051364848485e-06] - Loss total: 3.3551084995269775, Last rpr Loss: 1.0485780239105225, Last lagvar Loss: 0.8426992893218994\n",
      "Step 2227/10000- lr: [7.849503551515153e-06] - Loss total: 3.3540408611297607, Last rpr Loss: 1.041056513786316, Last lagvar Loss: 0.8494077324867249\n",
      "Step 2228/10000- lr: [7.848493454545454e-06] - Loss total: 3.3578336238861084, Last rpr Loss: 0.9345638751983643, Last lagvar Loss: 0.9596493244171143\n",
      "Step 2229/10000- lr: [7.847483357575757e-06] - Loss total: 3.3565428256988525, Last rpr Loss: 0.9396000504493713, Last lagvar Loss: 0.9536370038986206\n",
      "Step 2230/10000- lr: [7.84647326060606e-06] - Loss total: 3.3536384105682373, Last rpr Loss: 1.0475733280181885, Last lagvar Loss: 0.8434785604476929\n",
      "Step 2231/10000- lr: [7.845463163636364e-06] - Loss total: 3.3525843620300293, Last rpr Loss: 1.040280818939209, Last lagvar Loss: 0.8499765396118164\n",
      "Step 2232/10000- lr: [7.844453066666667e-06] - Loss total: 3.356522798538208, Last rpr Loss: 0.9343284964561462, Last lagvar Loss: 0.9598298072814941\n",
      "Step 2233/10000- lr: [7.84344296969697e-06] - Loss total: 3.355225086212158, Last rpr Loss: 0.939298689365387, Last lagvar Loss: 0.9538803100585938\n",
      "Step 2234/10000- lr: [7.842432872727274e-06] - Loss total: 3.3521628379821777, Last rpr Loss: 1.0467497110366821, Last lagvar Loss: 0.8440895676612854\n",
      "Step 2235/10000- lr: [7.841422775757577e-06] - Loss total: 3.3511223793029785, Last rpr Loss: 1.0395418405532837, Last lagvar Loss: 0.8505150675773621\n",
      "Step 2236/10000- lr: [7.840412678787879e-06] - Loss total: 3.355189561843872, Last rpr Loss: 0.9340565800666809, Last lagvar Loss: 0.9600452780723572\n",
      "Step 2237/10000- lr: [7.839402581818182e-06] - Loss total: 3.353883981704712, Last rpr Loss: 0.9389348030090332, Last lagvar Loss: 0.9541865587234497\n",
      "Step 2238/10000- lr: [7.838392484848485e-06] - Loss total: 3.3506851196289062, Last rpr Loss: 1.0458542108535767, Last lagvar Loss: 0.8447706699371338\n",
      "Step 2239/10000- lr: [7.837382387878789e-06] - Loss total: 3.3496546745300293, Last rpr Loss: 1.0387871265411377, Last lagvar Loss: 0.8510739207267761\n",
      "Step 2240/10000- lr: [7.836372290909092e-06] - Loss total: 3.353834629058838, Last rpr Loss: 0.9339383840560913, Last lagvar Loss: 0.960090160369873\n",
      "Step 2241/10000- lr: [7.835362193939393e-06] - Loss total: 3.3525216579437256, Last rpr Loss: 0.9388668537139893, Last lagvar Loss: 0.954173743724823\n",
      "Step 2242/10000- lr: [7.834352096969697e-06] - Loss total: 3.3492040634155273, Last rpr Loss: 1.0452990531921387, Last lagvar Loss: 0.8451362252235413\n",
      "Step 2243/10000- lr: [7.833342e-06] - Loss total: 3.3481838703155518, Last rpr Loss: 1.0381381511688232, Last lagvar Loss: 0.851538360118866\n",
      "Step 2244/10000- lr: [7.832331903030303e-06] - Loss total: 3.3524558544158936, Last rpr Loss: 0.9337417483329773, Last lagvar Loss: 0.9602112174034119\n",
      "Step 2245/10000- lr: [7.831321806060606e-06] - Loss total: 3.3511345386505127, Last rpr Loss: 0.9386509656906128, Last lagvar Loss: 0.9543111324310303\n",
      "Step 2246/10000- lr: [7.83031170909091e-06] - Loss total: 3.3477232456207275, Last rpr Loss: 1.044617772102356, Last lagvar Loss: 0.8456255197525024\n",
      "Step 2247/10000- lr: [7.829301612121213e-06] - Loss total: 3.346710205078125, Last rpr Loss: 1.037480354309082, Last lagvar Loss: 0.8520181179046631\n",
      "Step 2248/10000- lr: [7.828291515151516e-06] - Loss total: 3.351050615310669, Last rpr Loss: 0.9337149858474731, Last lagvar Loss: 0.9601405262947083\n",
      "Step 2249/10000- lr: [7.82728141818182e-06] - Loss total: 3.349722385406494, Last rpr Loss: 0.9387553930282593, Last lagvar Loss: 0.9540985226631165\n",
      "Step 2250/10000- lr: [7.826271321212121e-06] - Loss total: 3.3462436199188232, Last rpr Loss: 1.0443397760391235, Last lagvar Loss: 0.8457432985305786\n",
      "Step 2251/10000- lr: [7.825261224242424e-06] - Loss total: 3.345236301422119, Last rpr Loss: 1.036996603012085, Last lagvar Loss: 0.8523392677307129\n",
      "Step 2252/10000- lr: [7.824251127272728e-06] - Loss total: 3.3496181964874268, Last rpr Loss: 0.9336212873458862, Last lagvar Loss: 0.96012943983078\n",
      "Step 2253/10000- lr: [7.823241030303031e-06] - Loss total: 3.348280906677246, Last rpr Loss: 0.9386916160583496, Last lagvar Loss: 0.9540520310401917\n",
      "Step 2254/10000- lr: [7.822230933333334e-06] - Loss total: 3.3447697162628174, Last rpr Loss: 1.0439385175704956, Last lagvar Loss: 0.8459857702255249\n",
      "Step 2255/10000- lr: [7.821220836363638e-06] - Loss total: 3.3437654972076416, Last rpr Loss: 1.0365924835205078, Last lagvar Loss: 0.8525930643081665\n",
      "Step 2256/10000- lr: [7.820210739393939e-06] - Loss total: 3.348154306411743, Last rpr Loss: 0.9338058233261108, Last lagvar Loss: 0.9598072171211243\n",
      "Step 2257/10000- lr: [7.819200642424242e-06] - Loss total: 3.3468105792999268, Last rpr Loss: 0.9390518069267273, Last lagvar Loss: 0.9535425901412964\n",
      "Step 2258/10000- lr: [7.818190545454546e-06] - Loss total: 3.3433029651641846, Last rpr Loss: 1.0440258979797363, Last lagvar Loss: 0.845778226852417\n",
      "Step 2259/10000- lr: [7.817180448484849e-06] - Loss total: 3.3423008918762207, Last rpr Loss: 1.036400318145752, Last lagvar Loss: 0.8526541590690613\n",
      "Step 2260/10000- lr: [7.816170351515152e-06] - Loss total: 3.3466553688049316, Last rpr Loss: 0.9338947534561157, Last lagvar Loss: 0.9595690965652466\n",
      "Step 2261/10000- lr: [7.815160254545456e-06] - Loss total: 3.3453030586242676, Last rpr Loss: 0.9391950368881226, Last lagvar Loss: 0.9532444477081299\n",
      "Step 2262/10000- lr: [7.814150157575759e-06] - Loss total: 3.341853141784668, Last rpr Loss: 1.0439797639846802, Last lagvar Loss: 0.8457096815109253\n",
      "Step 2263/10000- lr: [7.813140060606062e-06] - Loss total: 3.3408493995666504, Last rpr Loss: 1.0363686084747314, Last lagvar Loss: 0.8525738716125488\n",
      "Step 2264/10000- lr: [7.812129963636364e-06] - Loss total: 3.345118761062622, Last rpr Loss: 0.9343663454055786, Last lagvar Loss: 0.958902895450592\n",
      "Step 2265/10000- lr: [7.811119866666667e-06] - Loss total: 3.3437609672546387, Last rpr Loss: 0.9398964643478394, Last lagvar Loss: 0.9523364305496216\n",
      "Step 2266/10000- lr: [7.81010976969697e-06] - Loss total: 3.340421199798584, Last rpr Loss: 1.0445876121520996, Last lagvar Loss: 0.845038652420044\n",
      "Step 2267/10000- lr: [7.809099672727273e-06] - Loss total: 3.3394148349761963, Last rpr Loss: 1.0366657972335815, Last lagvar Loss: 0.852192759513855\n",
      "Step 2268/10000- lr: [7.808089575757577e-06] - Loss total: 3.3435401916503906, Last rpr Loss: 0.9347108006477356, Last lagvar Loss: 0.9583481550216675\n",
      "Step 2269/10000- lr: [7.807079478787878e-06] - Loss total: 3.3421785831451416, Last rpr Loss: 0.9402813911437988, Last lagvar Loss: 0.9517385363578796\n",
      "Step 2270/10000- lr: [7.806069381818182e-06] - Loss total: 3.3390185832977295, Last rpr Loss: 1.045009732246399, Last lagvar Loss: 0.844560980796814\n",
      "Step 2271/10000- lr: [7.805059284848485e-06] - Loss total: 3.338005304336548, Last rpr Loss: 1.0372341871261597, Last lagvar Loss: 0.8515673875808716\n",
      "Step 2272/10000- lr: [7.804049187878788e-06] - Loss total: 3.3419253826141357, Last rpr Loss: 0.9355526566505432, Last lagvar Loss: 0.9572436809539795\n",
      "Step 2273/10000- lr: [7.803039090909091e-06] - Loss total: 3.3405661582946777, Last rpr Loss: 0.941328763961792, Last lagvar Loss: 0.9504235982894897\n",
      "Step 2274/10000- lr: [7.802028993939395e-06] - Loss total: 3.3376410007476807, Last rpr Loss: 1.046173334121704, Last lagvar Loss: 0.8433995246887207\n",
      "Step 2275/10000- lr: [7.801018896969698e-06] - Loss total: 3.3366196155548096, Last rpr Loss: 1.0381815433502197, Last lagvar Loss: 0.850594699382782\n",
      "Step 2276/10000- lr: [7.800008800000001e-06] - Loss total: 3.3402822017669678, Last rpr Loss: 0.9361697435379028, Last lagvar Loss: 0.956360936164856\n",
      "Step 2277/10000- lr: [7.798998703030305e-06] - Loss total: 3.3389313220977783, Last rpr Loss: 0.941864013671875, Last lagvar Loss: 0.9496334791183472\n",
      "Step 2278/10000- lr: [7.797988606060606e-06] - Loss total: 3.3362910747528076, Last rpr Loss: 1.0469424724578857, Last lagvar Loss: 0.8426252603530884\n",
      "Step 2279/10000- lr: [7.79697850909091e-06] - Loss total: 3.3352577686309814, Last rpr Loss: 1.0393304824829102, Last lagvar Loss: 0.8494411706924438\n",
      "Step 2280/10000- lr: [7.795968412121213e-06] - Loss total: 3.3386306762695312, Last rpr Loss: 0.9372991323471069, Last lagvar Loss: 0.9549322128295898\n",
      "Step 2281/10000- lr: [7.794958315151516e-06] - Loss total: 3.337299346923828, Last rpr Loss: 0.9430526494979858, Last lagvar Loss: 0.9481596350669861\n",
      "Step 2282/10000- lr: [7.79394821818182e-06] - Loss total: 3.334949254989624, Last rpr Loss: 1.0483112335205078, Last lagvar Loss: 0.841289222240448\n",
      "Step 2283/10000- lr: [7.79293812121212e-06] - Loss total: 3.3339052200317383, Last rpr Loss: 1.040634274482727, Last lagvar Loss: 0.8481470942497253\n",
      "Step 2284/10000- lr: [7.791928024242424e-06] - Loss total: 3.336991548538208, Last rpr Loss: 0.9379948973655701, Last lagvar Loss: 0.9539705514907837\n",
      "Step 2285/10000- lr: [7.790917927272727e-06] - Loss total: 3.3356854915618896, Last rpr Loss: 0.9434534311294556, Last lagvar Loss: 0.9475263357162476\n",
      "Step 2286/10000- lr: [7.78990783030303e-06] - Loss total: 3.3336055278778076, Last rpr Loss: 1.0488712787628174, Last lagvar Loss: 0.8407134413719177\n",
      "Step 2287/10000- lr: [7.788897733333334e-06] - Loss total: 3.332551956176758, Last rpr Loss: 1.0417652130126953, Last lagvar Loss: 0.8470174074172974\n",
      "Step 2288/10000- lr: [7.787887636363637e-06] - Loss total: 3.335385799407959, Last rpr Loss: 0.9390944838523865, Last lagvar Loss: 0.9526040554046631\n",
      "Step 2289/10000- lr: [7.78687753939394e-06] - Loss total: 3.334113359451294, Last rpr Loss: 0.9444634914398193, Last lagvar Loss: 0.9462834000587463\n",
      "Step 2290/10000- lr: [7.785867442424244e-06] - Loss total: 3.33223557472229, Last rpr Loss: 1.0498018264770508, Last lagvar Loss: 0.8397725820541382\n",
      "Step 2291/10000- lr: [7.784857345454545e-06] - Loss total: 3.3311774730682373, Last rpr Loss: 1.0426669120788574, Last lagvar Loss: 0.8460994958877563\n",
      "Step 2292/10000- lr: [7.783847248484849e-06] - Loss total: 3.3338253498077393, Last rpr Loss: 0.9395349621772766, Last lagvar Loss: 0.951960563659668\n",
      "Step 2293/10000- lr: [7.782837151515152e-06] - Loss total: 3.332583427429199, Last rpr Loss: 0.9445228576660156, Last lagvar Loss: 0.9460651278495789\n",
      "Step 2294/10000- lr: [7.781827054545455e-06] - Loss total: 3.3308393955230713, Last rpr Loss: 1.0496928691864014, Last lagvar Loss: 0.8397963643074036\n",
      "Step 2295/10000- lr: [7.780816957575758e-06] - Loss total: 3.329780101776123, Last rpr Loss: 1.0431195497512817, Last lagvar Loss: 0.8455966114997864\n",
      "Step 2296/10000- lr: [7.779806860606062e-06] - Loss total: 3.332310914993286, Last rpr Loss: 0.940300464630127, Last lagvar Loss: 0.9510049819946289\n",
      "Step 2297/10000- lr: [7.778796763636363e-06] - Loss total: 3.3310978412628174, Last rpr Loss: 0.9452303647994995, Last lagvar Loss: 0.945199728012085\n",
      "Step 2298/10000- lr: [7.777786666666667e-06] - Loss total: 3.3294060230255127, Last rpr Loss: 1.0499680042266846, Last lagvar Loss: 0.8394380211830139\n",
      "Step 2299/10000- lr: [7.77677656969697e-06] - Loss total: 3.32835054397583, Last rpr Loss: 1.0432357788085938, Last lagvar Loss: 0.8454002141952515\n",
      "Step 2300/10000- lr: [7.775766472727273e-06] - Loss total: 3.3308398723602295, Last rpr Loss: 0.9403270483016968, Last lagvar Loss: 0.9508548974990845\n",
      "Step 2301/10000- lr: [7.774756375757576e-06] - Loss total: 3.3296444416046143, Last rpr Loss: 0.9449810981750488, Last lagvar Loss: 0.9453563690185547\n",
      "Step 2302/10000- lr: [7.77374627878788e-06] - Loss total: 3.327949047088623, Last rpr Loss: 1.049299955368042, Last lagvar Loss: 0.8399596214294434\n",
      "Step 2303/10000- lr: [7.772736181818183e-06] - Loss total: 3.3268990516662598, Last rpr Loss: 1.0429675579071045, Last lagvar Loss: 0.845557451248169\n",
      "Step 2304/10000- lr: [7.771726084848486e-06] - Loss total: 3.3293979167938232, Last rpr Loss: 0.9407151937484741, Last lagvar Loss: 0.9503471851348877\n",
      "Step 2305/10000- lr: [7.770715987878788e-06] - Loss total: 3.328216552734375, Last rpr Loss: 0.9454565644264221, Last lagvar Loss: 0.9447744488716125\n",
      "Step 2306/10000- lr: [7.769705890909091e-06] - Loss total: 3.3264682292938232, Last rpr Loss: 1.0491979122161865, Last lagvar Loss: 0.8399355411529541\n",
      "Step 2307/10000- lr: [7.768695793939394e-06] - Loss total: 3.3254241943359375, Last rpr Loss: 1.0425280332565308, Last lagvar Loss: 0.8458688259124756\n",
      "Step 2308/10000- lr: [7.767685696969698e-06] - Loss total: 3.3279786109924316, Last rpr Loss: 0.9404293298721313, Last lagvar Loss: 0.9505653381347656\n",
      "Step 2309/10000- lr: [7.766675600000001e-06] - Loss total: 3.3267998695373535, Last rpr Loss: 0.9450311660766602, Last lagvar Loss: 0.9451438188552856\n",
      "Step 2310/10000- lr: [7.765665503030303e-06] - Loss total: 3.324977159500122, Last rpr Loss: 1.0483129024505615, Last lagvar Loss: 0.8406513333320618\n",
      "Step 2311/10000- lr: [7.764655406060606e-06] - Loss total: 3.323939323425293, Last rpr Loss: 1.0418927669525146, Last lagvar Loss: 0.8463619351387024\n",
      "Step 2312/10000- lr: [7.763645309090909e-06] - Loss total: 3.326568841934204, Last rpr Loss: 0.9405853748321533, Last lagvar Loss: 0.9503309726715088\n",
      "Step 2313/10000- lr: [7.762635212121212e-06] - Loss total: 3.325392246246338, Last rpr Loss: 0.9453753232955933, Last lagvar Loss: 0.9447181224822998\n",
      "Step 2314/10000- lr: [7.761625115151516e-06] - Loss total: 3.3234729766845703, Last rpr Loss: 1.0481098890304565, Last lagvar Loss: 0.8407188653945923\n",
      "Step 2315/10000- lr: [7.760615018181819e-06] - Loss total: 3.3224422931671143, Last rpr Loss: 1.0412604808807373, Last lagvar Loss: 0.8468506336212158\n",
      "Step 2316/10000- lr: [7.759604921212122e-06] - Loss total: 3.325162649154663, Last rpr Loss: 0.9401665329933167, Last lagvar Loss: 0.9507077932357788\n",
      "Step 2317/10000- lr: [7.758594824242425e-06] - Loss total: 3.3239803314208984, Last rpr Loss: 0.9448752403259277, Last lagvar Loss: 0.9451766610145569\n",
      "Step 2318/10000- lr: [7.757584727272729e-06] - Loss total: 3.3219690322875977, Last rpr Loss: 1.0472047328948975, Last lagvar Loss: 0.8414572477340698\n",
      "Step 2319/10000- lr: [7.75657463030303e-06] - Loss total: 3.320943832397461, Last rpr Loss: 1.0405638217926025, Last lagvar Loss: 0.8474026918411255\n",
      "Step 2320/10000- lr: [7.755564533333334e-06] - Loss total: 3.3237507343292236, Last rpr Loss: 0.9402745366096497, Last lagvar Loss: 0.9505338668823242\n",
      "Step 2321/10000- lr: [7.754554436363637e-06] - Loss total: 3.3225655555725098, Last rpr Loss: 0.9452018737792969, Last lagvar Loss: 0.9447745084762573\n",
      "Step 2322/10000- lr: [7.75354433939394e-06] - Loss total: 3.32045841217041, Last rpr Loss: 1.0470473766326904, Last lagvar Loss: 0.8414881229400635\n",
      "Step 2323/10000- lr: [7.752534242424243e-06] - Loss total: 3.3194401264190674, Last rpr Loss: 1.039961338043213, Last lagvar Loss: 0.8478679060935974\n",
      "Step 2324/10000- lr: [7.751524145454545e-06] - Loss total: 3.3223297595977783, Last rpr Loss: 0.9398639798164368, Last lagvar Loss: 0.9509034156799316\n",
      "Step 2325/10000- lr: [7.750514048484848e-06] - Loss total: 3.321136951446533, Last rpr Loss: 0.9447168111801147, Last lagvar Loss: 0.945216178894043\n",
      "Step 2326/10000- lr: [7.749503951515152e-06] - Loss total: 3.318953037261963, Last rpr Loss: 1.0462183952331543, Last lagvar Loss: 0.8421648740768433\n",
      "Step 2327/10000- lr: [7.748493854545455e-06] - Loss total: 3.3179399967193604, Last rpr Loss: 1.0393730401992798, Last lagvar Loss: 0.8483253121376038\n",
      "Step 2328/10000- lr: [7.747483757575758e-06] - Loss total: 3.3208954334259033, Last rpr Loss: 0.9400591850280762, Last lagvar Loss: 0.9506338834762573\n",
      "Step 2329/10000- lr: [7.746473660606061e-06] - Loss total: 3.319697856903076, Last rpr Loss: 0.9451289772987366, Last lagvar Loss: 0.9447194337844849\n",
      "Step 2330/10000- lr: [7.745463563636365e-06] - Loss total: 3.317445993423462, Last rpr Loss: 1.0461854934692383, Last lagvar Loss: 0.8420895934104919\n",
      "Step 2331/10000- lr: [7.744453466666668e-06] - Loss total: 3.3164384365081787, Last rpr Loss: 1.0389012098312378, Last lagvar Loss: 0.8486773371696472\n",
      "Step 2332/10000- lr: [7.74344336969697e-06] - Loss total: 3.319443941116333, Last rpr Loss: 0.939741313457489, Last lagvar Loss: 0.9508965015411377\n",
      "Step 2333/10000- lr: [7.742433272727273e-06] - Loss total: 3.3182384967803955, Last rpr Loss: 0.944736659526825, Last lagvar Loss: 0.9450544714927673\n",
      "Step 2334/10000- lr: [7.741423175757576e-06] - Loss total: 3.3159472942352295, Last rpr Loss: 1.0455033779144287, Last lagvar Loss: 0.8426418304443359\n",
      "Step 2335/10000- lr: [7.74041307878788e-06] - Loss total: 3.314943313598633, Last rpr Loss: 1.038489818572998, Last lagvar Loss: 0.848979115486145\n",
      "Step 2336/10000- lr: [7.739402981818183e-06] - Loss total: 3.3179726600646973, Last rpr Loss: 0.9400919079780579, Last lagvar Loss: 0.9504517316818237\n",
      "Step 2337/10000- lr: [7.738392884848484e-06] - Loss total: 3.3167648315429688, Last rpr Loss: 0.9453092813491821, Last lagvar Loss: 0.9443790912628174\n",
      "Step 2338/10000- lr: [7.737382787878788e-06] - Loss total: 3.314448833465576, Last rpr Loss: 1.0456609725952148, Last lagvar Loss: 0.8424019813537598\n",
      "Step 2339/10000- lr: [7.73637269090909e-06] - Loss total: 3.3134491443634033, Last rpr Loss: 1.0381853580474854, Last lagvar Loss: 0.8491873741149902\n",
      "Step 2340/10000- lr: [7.735362593939394e-06] - Loss total: 3.316481590270996, Last rpr Loss: 0.9399003982543945, Last lagvar Loss: 0.9505670070648193\n",
      "Step 2341/10000- lr: [7.734352496969697e-06] - Loss total: 3.3152668476104736, Last rpr Loss: 0.945061206817627, Last lagvar Loss: 0.9445501565933228\n",
      "Step 2342/10000- lr: [7.7333424e-06] - Loss total: 3.312962532043457, Last rpr Loss: 1.0451884269714355, Last lagvar Loss: 0.8427746295928955\n",
      "Step 2343/10000- lr: [7.732332303030304e-06] - Loss total: 3.3119630813598633, Last rpr Loss: 1.0379958152770996, Last lagvar Loss: 0.8492952585220337\n",
      "Step 2344/10000- lr: [7.731322206060607e-06] - Loss total: 3.3149683475494385, Last rpr Loss: 0.9404373168945312, Last lagvar Loss: 0.9499126076698303\n",
      "Step 2345/10000- lr: [7.73031210909091e-06] - Loss total: 3.313751459121704, Last rpr Loss: 0.9458395838737488, Last lagvar Loss: 0.9436481595039368\n",
      "Step 2346/10000- lr: [7.729302012121214e-06] - Loss total: 3.3114774227142334, Last rpr Loss: 1.045598030090332, Last lagvar Loss: 0.8423177599906921\n",
      "Step 2347/10000- lr: [7.728291915151515e-06] - Loss total: 3.310478687286377, Last rpr Loss: 1.0379019975662231, Last lagvar Loss: 0.8493244647979736\n",
      "Step 2348/10000- lr: [7.727281818181819e-06] - Loss total: 3.313429117202759, Last rpr Loss: 0.9403890371322632, Last lagvar Loss: 0.949864387512207\n",
      "Step 2349/10000- lr: [7.726271721212122e-06] - Loss total: 3.3122072219848633, Last rpr Loss: 0.945770263671875, Last lagvar Loss: 0.943621814250946\n",
      "Step 2350/10000- lr: [7.725261624242425e-06] - Loss total: 3.310006856918335, Last rpr Loss: 1.0454076528549194, Last lagvar Loss: 0.8424495458602905\n",
      "Step 2351/10000- lr: [7.724251527272728e-06] - Loss total: 3.309004068374634, Last rpr Loss: 1.0379927158355713, Last lagvar Loss: 0.8491913080215454\n",
      "Step 2352/10000- lr: [7.72324143030303e-06] - Loss total: 3.3118650913238525, Last rpr Loss: 0.9411312341690063, Last lagvar Loss: 0.9489855170249939\n",
      "Step 2353/10000- lr: [7.722231333333333e-06] - Loss total: 3.3106443881988525, Last rpr Loss: 0.9467880725860596, Last lagvar Loss: 0.9424645900726318\n",
      "Step 2354/10000- lr: [7.721221236363637e-06] - Loss total: 3.308539628982544, Last rpr Loss: 1.0461430549621582, Last lagvar Loss: 0.8417141437530518\n",
      "Step 2355/10000- lr: [7.72021113939394e-06] - Loss total: 3.3075339794158936, Last rpr Loss: 1.0381821393966675, Last lagvar Loss: 0.8489797115325928\n",
      "Step 2356/10000- lr: [7.719201042424243e-06] - Loss total: 3.3102774620056152, Last rpr Loss: 0.9412450790405273, Last lagvar Loss: 0.9487597942352295\n",
      "Step 2357/10000- lr: [7.718190945454546e-06] - Loss total: 3.3090550899505615, Last rpr Loss: 0.9469085335731506, Last lagvar Loss: 0.9422349333763123\n",
      "Step 2358/10000- lr: [7.71718084848485e-06] - Loss total: 3.307093858718872, Last rpr Loss: 1.0462679862976074, Last lagvar Loss: 0.8415755033493042\n",
      "Step 2359/10000- lr: [7.716170751515153e-06] - Loss total: 3.3060812950134277, Last rpr Loss: 1.0386046171188354, Last lagvar Loss: 0.848555862903595\n",
      "Step 2360/10000- lr: [7.715160654545455e-06] - Loss total: 3.3086726665496826, Last rpr Loss: 0.9421614408493042, Last lagvar Loss: 0.9476901292800903\n",
      "Step 2361/10000- lr: [7.714150557575758e-06] - Loss total: 3.3074567317962646, Last rpr Loss: 0.9480801820755005, Last lagvar Loss: 0.9409103989601135\n",
      "Step 2362/10000- lr: [7.713140460606061e-06] - Loss total: 3.305651903152466, Last rpr Loss: 1.0472513437271118, Last lagvar Loss: 0.8406299948692322\n",
      "Step 2363/10000- lr: [7.712130363636364e-06] - Loss total: 3.304633378982544, Last rpr Loss: 1.0390790700912476, Last lagvar Loss: 0.8480936884880066\n",
      "Step 2364/10000- lr: [7.711120266666668e-06] - Loss total: 3.3070521354675293, Last rpr Loss: 0.9423717260360718, Last lagvar Loss: 0.9473528861999512\n",
      "Step 2365/10000- lr: [7.71011016969697e-06] - Loss total: 3.3058393001556396, Last rpr Loss: 0.9482771158218384, Last lagvar Loss: 0.9405940771102905\n",
      "Step 2366/10000- lr: [7.709100072727273e-06] - Loss total: 3.3042237758636475, Last rpr Loss: 1.0476213693618774, Last lagvar Loss: 0.8402808904647827\n",
      "Step 2367/10000- lr: [7.708089975757576e-06] - Loss total: 3.303194761276245, Last rpr Loss: 1.039842128753662, Last lagvar Loss: 0.8473630547523499\n",
      "Step 2368/10000- lr: [7.707079878787879e-06] - Loss total: 3.305424928665161, Last rpr Loss: 0.9434244632720947, Last lagvar Loss: 0.9461350440979004\n",
      "Step 2369/10000- lr: [7.706069781818182e-06] - Loss total: 3.304227113723755, Last rpr Loss: 0.9495196342468262, Last lagvar Loss: 0.9391931891441345\n",
      "Step 2370/10000- lr: [7.705059684848486e-06] - Loss total: 3.3027987480163574, Last rpr Loss: 1.0487682819366455, Last lagvar Loss: 0.839187502861023\n",
      "Step 2371/10000- lr: [7.704049587878789e-06] - Loss total: 3.3017685413360596, Last rpr Loss: 1.040592074394226, Last lagvar Loss: 0.8466359376907349\n",
      "Step 2372/10000- lr: [7.703039490909092e-06] - Loss total: 3.303807497024536, Last rpr Loss: 0.9437549114227295, Last lagvar Loss: 0.9456485509872437\n",
      "Step 2373/10000- lr: [7.702029393939394e-06] - Loss total: 3.3026232719421387, Last rpr Loss: 0.9497271776199341, Last lagvar Loss: 0.9388372898101807\n",
      "Step 2374/10000- lr: [7.701019296969697e-06] - Loss total: 3.301403760910034, Last rpr Loss: 1.0491325855255127, Last lagvar Loss: 0.8388148546218872\n",
      "Step 2375/10000- lr: [7.7000092e-06] - Loss total: 3.3003671169281006, Last rpr Loss: 1.0413925647735596, Last lagvar Loss: 0.8458377122879028\n",
      "Step 2376/10000- lr: [7.698999103030304e-06] - Loss total: 3.3022077083587646, Last rpr Loss: 0.9447039365768433, Last lagvar Loss: 0.9444955587387085\n",
      "Step 2377/10000- lr: [7.697989006060607e-06] - Loss total: 3.3010449409484863, Last rpr Loss: 0.9507777690887451, Last lagvar Loss: 0.9375928640365601\n",
      "Step 2378/10000- lr: [7.696978909090908e-06] - Loss total: 3.300006151199341, Last rpr Loss: 1.050147294998169, Last lagvar Loss: 0.837809681892395\n",
      "Step 2379/10000- lr: [7.695968812121212e-06] - Loss total: 3.2989649772644043, Last rpr Loss: 1.0421857833862305, Last lagvar Loss: 0.8450382947921753\n",
      "Step 2380/10000- lr: [7.694958715151515e-06] - Loss total: 3.300629138946533, Last rpr Loss: 0.9450390338897705, Last lagvar Loss: 0.9439796209335327\n",
      "Step 2381/10000- lr: [7.693948618181818e-06] - Loss total: 3.299482822418213, Last rpr Loss: 0.9509713053703308, Last lagvar Loss: 0.9372363090515137\n",
      "Step 2382/10000- lr: [7.692938521212122e-06] - Loss total: 3.2986130714416504, Last rpr Loss: 1.0506110191345215, Last lagvar Loss: 0.8373318910598755\n",
      "Step 2383/10000- lr: [7.691928424242425e-06] - Loss total: 3.2975666522979736, Last rpr Loss: 1.0431485176086426, Last lagvar Loss: 0.8440746068954468\n",
      "Step 2384/10000- lr: [7.690918327272728e-06] - Loss total: 3.2990710735321045, Last rpr Loss: 0.9459872841835022, Last lagvar Loss: 0.9428336024284363\n",
      "Step 2385/10000- lr: [7.689908230303031e-06] - Loss total: 3.297945261001587, Last rpr Loss: 0.9517748355865479, Last lagvar Loss: 0.9362611770629883\n",
      "Step 2386/10000- lr: [7.688898133333335e-06] - Loss total: 3.297205686569214, Last rpr Loss: 1.0512017011642456, Last lagvar Loss: 0.8367261290550232\n",
      "Step 2387/10000- lr: [7.687888036363638e-06] - Loss total: 3.2961578369140625, Last rpr Loss: 1.0435703992843628, Last lagvar Loss: 0.8436213731765747\n",
      "Step 2388/10000- lr: [7.68687793939394e-06] - Loss total: 3.297534465789795, Last rpr Loss: 0.9460701942443848, Last lagvar Loss: 0.9426093101501465\n",
      "Step 2389/10000- lr: [7.685867842424243e-06] - Loss total: 3.29642391204834, Last rpr Loss: 0.9516421556472778, Last lagvar Loss: 0.9362733960151672\n",
      "Step 2390/10000- lr: [7.684857745454546e-06] - Loss total: 3.2957956790924072, Last rpr Loss: 1.0511704683303833, Last lagvar Loss: 0.8366986513137817\n",
      "Step 2391/10000- lr: [7.68384764848485e-06] - Loss total: 3.2947452068328857, Last rpr Loss: 1.0440640449523926, Last lagvar Loss: 0.843086838722229\n",
      "Step 2392/10000- lr: [7.682837551515153e-06] - Loss total: 3.296020746231079, Last rpr Loss: 0.9467707276344299, Last lagvar Loss: 0.9417533874511719\n",
      "Step 2393/10000- lr: [7.681827454545454e-06] - Loss total: 3.2949271202087402, Last rpr Loss: 0.9522618651390076, Last lagvar Loss: 0.9355146288871765\n",
      "Step 2394/10000- lr: [7.680817357575757e-06] - Loss total: 3.2943649291992188, Last rpr Loss: 1.0515391826629639, Last lagvar Loss: 0.8362792134284973\n",
      "Step 2395/10000- lr: [7.67980726060606e-06] - Loss total: 3.293313503265381, Last rpr Loss: 1.044323444366455, Last lagvar Loss: 0.8427696824073792\n",
      "Step 2396/10000- lr: [7.678797163636364e-06] - Loss total: 3.2945311069488525, Last rpr Loss: 0.9468514919281006, Last lagvar Loss: 0.9415546655654907\n",
      "Step 2397/10000- lr: [7.677787066666667e-06] - Loss total: 3.293450117111206, Last rpr Loss: 0.9521037340164185, Last lagvar Loss: 0.9355736970901489\n",
      "Step 2398/10000- lr: [7.67677696969697e-06] - Loss total: 3.292919635772705, Last rpr Loss: 1.0512723922729492, Last lagvar Loss: 0.8364593386650085\n",
      "Step 2399/10000- lr: [7.675766872727274e-06] - Loss total: 3.291867971420288, Last rpr Loss: 1.0444201231002808, Last lagvar Loss: 0.8426002264022827\n",
      "Step 2400/10000- lr: [7.674756775757577e-06] - Loss total: 3.2930660247802734, Last rpr Loss: 0.9472464323043823, Last lagvar Loss: 0.9410462379455566\n",
      "Step 2401/10000- lr: [7.673746678787879e-06] - Loss total: 3.291997194290161, Last rpr Loss: 0.9523807764053345, Last lagvar Loss: 0.9351980686187744\n",
      "Step 2402/10000- lr: [7.672736581818182e-06] - Loss total: 3.2914505004882812, Last rpr Loss: 1.0511149168014526, Last lagvar Loss: 0.8365244269371033\n",
      "Step 2403/10000- lr: [7.671726484848485e-06] - Loss total: 3.29040265083313, Last rpr Loss: 1.044152855873108, Last lagvar Loss: 0.8427716493606567\n",
      "Step 2404/10000- lr: [7.670716387878789e-06] - Loss total: 3.291620969772339, Last rpr Loss: 0.9470847249031067, Last lagvar Loss: 0.9411335587501526\n",
      "Step 2405/10000- lr: [7.669706290909092e-06] - Loss total: 3.290557622909546, Last rpr Loss: 0.9520819187164307, Last lagvar Loss: 0.9354332089424133\n",
      "Step 2406/10000- lr: [7.668696193939393e-06] - Loss total: 3.289970874786377, Last rpr Loss: 1.0505828857421875, Last lagvar Loss: 0.8369392156600952\n",
      "Step 2407/10000- lr: [7.667686096969697e-06] - Loss total: 3.2889270782470703, Last rpr Loss: 1.0439181327819824, Last lagvar Loss: 0.8429045677185059\n",
      "Step 2408/10000- lr: [7.666676e-06] - Loss total: 3.290189027786255, Last rpr Loss: 0.9472898840904236, Last lagvar Loss: 0.9408504366874695\n",
      "Step 2409/10000- lr: [7.665665903030303e-06] - Loss total: 3.2891311645507812, Last rpr Loss: 0.9522169828414917, Last lagvar Loss: 0.9352278709411621\n",
      "Step 2410/10000- lr: [7.664655806060607e-06] - Loss total: 3.288475275039673, Last rpr Loss: 1.0502251386642456, Last lagvar Loss: 0.8371785283088684\n",
      "Step 2411/10000- lr: [7.66364570909091e-06] - Loss total: 3.2874388694763184, Last rpr Loss: 1.0434719324111938, Last lagvar Loss: 0.8432341814041138\n",
      "Step 2412/10000- lr: [7.662635612121213e-06] - Loss total: 3.2887661457061768, Last rpr Loss: 0.9470836520195007, Last lagvar Loss: 0.9410060048103333\n",
      "Step 2413/10000- lr: [7.661625515151516e-06] - Loss total: 3.2877097129821777, Last rpr Loss: 0.9518867135047913, Last lagvar Loss: 0.935513973236084\n",
      "Step 2414/10000- lr: [7.66061541818182e-06] - Loss total: 3.2869741916656494, Last rpr Loss: 1.0495342016220093, Last lagvar Loss: 0.8377339243888855\n",
      "Step 2415/10000- lr: [7.659605321212121e-06] - Loss total: 3.2859442234039307, Last rpr Loss: 1.0430068969726562, Last lagvar Loss: 0.8435791730880737\n",
      "Step 2416/10000- lr: [7.658595224242425e-06] - Loss total: 3.287348747253418, Last rpr Loss: 0.9471379518508911, Last lagvar Loss: 0.9408979415893555\n",
      "Step 2417/10000- lr: [7.657585127272728e-06] - Loss total: 3.2862930297851562, Last rpr Loss: 0.9518882036209106, Last lagvar Loss: 0.9354612827301025\n",
      "Step 2418/10000- lr: [7.656575030303031e-06] - Loss total: 3.285463333129883, Last rpr Loss: 1.0489962100982666, Last lagvar Loss: 0.8381407260894775\n",
      "Step 2419/10000- lr: [7.655564933333334e-06] - Loss total: 3.284442186355591, Last rpr Loss: 1.0424115657806396, Last lagvar Loss: 0.8440488576889038\n",
      "Step 2420/10000- lr: [7.654554836363636e-06] - Loss total: 3.2859320640563965, Last rpr Loss: 0.946923553943634, Last lagvar Loss: 0.9410736560821533\n",
      "Step 2421/10000- lr: [7.65354473939394e-06] - Loss total: 3.2848739624023438, Last rpr Loss: 0.9516032934188843, Last lagvar Loss: 0.9357089996337891\n",
      "Step 2422/10000- lr: [7.652534642424242e-06] - Loss total: 3.2839512825012207, Last rpr Loss: 1.0482749938964844, Last lagvar Loss: 0.8387248516082764\n",
      "Step 2423/10000- lr: [7.651524545454546e-06] - Loss total: 3.282937526702881, Last rpr Loss: 1.0418330430984497, Last lagvar Loss: 0.8445038199424744\n",
      "Step 2424/10000- lr: [7.650514448484849e-06] - Loss total: 3.2845137119293213, Last rpr Loss: 0.946914792060852, Last lagvar Loss: 0.9410358667373657\n",
      "Step 2425/10000- lr: [7.649504351515152e-06] - Loss total: 3.2834534645080566, Last rpr Loss: 0.9515950679779053, Last lagvar Loss: 0.9356693029403687\n",
      "Step 2426/10000- lr: [7.648494254545456e-06] - Loss total: 3.2824337482452393, Last rpr Loss: 1.0477263927459717, Last lagvar Loss: 0.8391430377960205\n",
      "Step 2427/10000- lr: [7.647484157575759e-06] - Loss total: 3.281428813934326, Last rpr Loss: 1.0412027835845947, Last lagvar Loss: 0.8450087308883667\n",
      "Step 2428/10000- lr: [7.646474060606062e-06] - Loss total: 3.2830898761749268, Last rpr Loss: 0.9467155337333679, Last lagvar Loss: 0.9411948919296265\n",
      "Step 2429/10000- lr: [7.645463963636364e-06] - Loss total: 3.2820260524749756, Last rpr Loss: 0.9513757228851318, Last lagvar Loss: 0.9358464479446411\n",
      "Step 2430/10000- lr: [7.644453866666667e-06] - Loss total: 3.2809176445007324, Last rpr Loss: 1.047071099281311, Last lagvar Loss: 0.8396652340888977\n",
      "Step 2431/10000- lr: [7.64344376969697e-06] - Loss total: 3.279919147491455, Last rpr Loss: 1.0406277179718018, Last lagvar Loss: 0.8454610109329224\n",
      "Step 2432/10000- lr: [7.642433672727274e-06] - Loss total: 3.2816600799560547, Last rpr Loss: 0.9467098712921143, Last lagvar Loss: 0.941146969795227\n",
      "Step 2433/10000- lr: [7.641423575757577e-06] - Loss total: 3.280593156814575, Last rpr Loss: 0.951403796672821, Last lagvar Loss: 0.935760498046875\n",
      "Step 2434/10000- lr: [7.640413478787878e-06] - Loss total: 3.279398202896118, Last rpr Loss: 1.0465936660766602, Last lagvar Loss: 0.8400155305862427\n",
      "Step 2435/10000- lr: [7.639403381818182e-06] - Loss total: 3.278407335281372, Last rpr Loss: 1.0400574207305908, Last lagvar Loss: 0.8459078073501587\n",
      "Step 2436/10000- lr: [7.638393284848485e-06] - Loss total: 3.2802205085754395, Last rpr Loss: 0.9465920925140381, Last lagvar Loss: 0.9412078857421875\n",
      "Step 2437/10000- lr: [7.637383187878788e-06] - Loss total: 3.2791481018066406, Last rpr Loss: 0.9512950778007507, Last lagvar Loss: 0.9358079433441162\n",
      "Step 2438/10000- lr: [7.636373090909092e-06] - Loss total: 3.2778828144073486, Last rpr Loss: 1.0460482835769653, Last lagvar Loss: 0.8404306173324585\n",
      "Step 2439/10000- lr: [7.635362993939395e-06] - Loss total: 3.2768962383270264, Last rpr Loss: 1.0395317077636719, Last lagvar Loss: 0.846308708190918\n",
      "Step 2440/10000- lr: [7.634352896969698e-06] - Loss total: 3.2787678241729736, Last rpr Loss: 0.9466308355331421, Last lagvar Loss: 0.9410915970802307\n",
      "Step 2441/10000- lr: [7.633342800000001e-06] - Loss total: 3.277690887451172, Last rpr Loss: 0.9513964653015137, Last lagvar Loss: 0.9356213212013245\n",
      "Step 2442/10000- lr: [7.632332703030303e-06] - Loss total: 3.2763671875, Last rpr Loss: 1.0456678867340088, Last lagvar Loss: 0.8406818509101868\n",
      "Step 2443/10000- lr: [7.631322606060606e-06] - Loss total: 3.2753868103027344, Last rpr Loss: 1.0390338897705078, Last lagvar Loss: 0.8466771245002747\n",
      "Step 2444/10000- lr: [7.63031250909091e-06] - Loss total: 3.277299165725708, Last rpr Loss: 0.9466171264648438, Last lagvar Loss: 0.941009521484375\n",
      "Step 2445/10000- lr: [7.629302412121213e-06] - Loss total: 3.2762157917022705, Last rpr Loss: 0.9514490365982056, Last lagvar Loss: 0.9354647994041443\n",
      "Step 2446/10000- lr: [7.628292315151516e-06] - Loss total: 3.2748584747314453, Last rpr Loss: 1.0453110933303833, Last lagvar Loss: 0.8409019708633423\n",
      "Step 2447/10000- lr: [7.6272822181818185e-06] - Loss total: 3.273880958557129, Last rpr Loss: 1.038632869720459, Last lagvar Loss: 0.8469412326812744\n",
      "Step 2448/10000- lr: [7.626272121212122e-06] - Loss total: 3.275810718536377, Last rpr Loss: 0.9467854499816895, Last lagvar Loss: 0.9407111406326294\n",
      "Step 2449/10000- lr: [7.625262024242424e-06] - Loss total: 3.2747228145599365, Last rpr Loss: 0.9517382979393005, Last lagvar Loss: 0.9350360035896301\n",
      "Step 2450/10000- lr: [7.6242519272727275e-06] - Loss total: 3.2733535766601562, Last rpr Loss: 1.0451548099517822, Last lagvar Loss: 0.84091717004776\n",
      "Step 2451/10000- lr: [7.623241830303031e-06] - Loss total: 3.2723782062530518, Last rpr Loss: 1.038311243057251, Last lagvar Loss: 0.8471174836158752\n",
      "Step 2452/10000- lr: [7.622231733333334e-06] - Loss total: 3.2742996215820312, Last rpr Loss: 0.9469598531723022, Last lagvar Loss: 0.9403817057609558\n",
      "Step 2453/10000- lr: [7.621221636363637e-06] - Loss total: 3.2732057571411133, Last rpr Loss: 0.9520481824874878, Last lagvar Loss: 0.9345639944076538\n",
      "Step 2454/10000- lr: [7.62021153939394e-06] - Loss total: 3.271859645843506, Last rpr Loss: 1.045083999633789, Last lagvar Loss: 0.8408439755439758\n",
      "Step 2455/10000- lr: [7.619201442424243e-06] - Loss total: 3.2708847522735596, Last rpr Loss: 1.0381269454956055, Last lagvar Loss: 0.847156822681427\n",
      "Step 2456/10000- lr: [7.618191345454545e-06] - Loss total: 3.272761821746826, Last rpr Loss: 0.947323203086853, Last lagvar Loss: 0.9398340582847595\n",
      "Step 2457/10000- lr: [7.617181248484849e-06] - Loss total: 3.2716636657714844, Last rpr Loss: 0.9526013135910034, Last lagvar Loss: 0.9338209629058838\n",
      "Step 2458/10000- lr: [7.616171151515152e-06] - Loss total: 3.270378828048706, Last rpr Loss: 1.045259952545166, Last lagvar Loss: 0.8405406475067139\n",
      "Step 2459/10000- lr: [7.615161054545455e-06] - Loss total: 3.2694036960601807, Last rpr Loss: 1.038096308708191, Last lagvar Loss: 0.8470578789710999\n",
      "Step 2460/10000- lr: [7.6141509575757585e-06] - Loss total: 3.2711901664733887, Last rpr Loss: 0.9477532505989075, Last lagvar Loss: 0.9392014741897583\n",
      "Step 2461/10000- lr: [7.613140860606061e-06] - Loss total: 3.2700858116149902, Last rpr Loss: 0.9532529711723328, Last lagvar Loss: 0.9329643845558167\n",
      "Step 2462/10000- lr: [7.612130763636363e-06] - Loss total: 3.2689168453216553, Last rpr Loss: 1.045637607574463, Last lagvar Loss: 0.8400671482086182\n",
      "Step 2463/10000- lr: [7.611120666666667e-06] - Loss total: 3.267937660217285, Last rpr Loss: 1.0383312702178955, Last lagvar Loss: 0.8467279672622681\n",
      "Step 2464/10000- lr: [7.61011056969697e-06] - Loss total: 3.26957368850708, Last rpr Loss: 0.948431134223938, Last lagvar Loss: 0.9382998943328857\n",
      "Step 2465/10000- lr: [7.609100472727273e-06] - Loss total: 3.268463134765625, Last rpr Loss: 0.9541997909545898, Last lagvar Loss: 0.9317951798439026\n",
      "Step 2466/10000- lr: [7.6080903757575765e-06] - Loss total: 3.267470121383667, Last rpr Loss: 1.0463511943817139, Last lagvar Loss: 0.8393117189407349\n",
      "Step 2467/10000- lr: [7.60708027878788e-06] - Loss total: 3.266479969024658, Last rpr Loss: 1.0388582944869995, Last lagvar Loss: 0.8461575508117676\n",
      "Step 2468/10000- lr: [7.606070181818183e-06] - Loss total: 3.2678983211517334, Last rpr Loss: 0.94924396276474, Last lagvar Loss: 0.9372515678405762\n",
      "Step 2469/10000- lr: [7.6050600848484855e-06] - Loss total: 3.266787528991699, Last rpr Loss: 0.9552639126777649, Last lagvar Loss: 0.9304986000061035\n",
      "Step 2470/10000- lr: [7.604049987878788e-06] - Loss total: 3.266033887863159, Last rpr Loss: 1.0472564697265625, Last lagvar Loss: 0.8383981585502625\n",
      "Step 2471/10000- lr: [7.603039890909091e-06] - Loss total: 3.265035390853882, Last rpr Loss: 1.0396349430084229, Last lagvar Loss: 0.8453599214553833\n",
      "Step 2472/10000- lr: [7.6020297939393945e-06] - Loss total: 3.266187906265259, Last rpr Loss: 0.950162410736084, Last lagvar Loss: 0.9360494017601013\n",
      "Step 2473/10000- lr: [7.601019696969698e-06] - Loss total: 3.2650809288024902, Last rpr Loss: 0.9564736485481262, Last lagvar Loss: 0.9289826154708862\n",
      "Step 2474/10000- lr: [7.600009600000001e-06] - Loss total: 3.264620304107666, Last rpr Loss: 1.0484318733215332, Last lagvar Loss: 0.837120532989502\n",
      "Step 2475/10000- lr: [7.5989995030303035e-06] - Loss total: 3.2635998725891113, Last rpr Loss: 1.0406485795974731, Last lagvar Loss: 0.8441485166549683\n",
      "Step 2476/10000- lr: [7.597989406060607e-06] - Loss total: 3.2643978595733643, Last rpr Loss: 0.9512122869491577, Last lagvar Loss: 0.9344220161437988\n",
      "Step 2477/10000- lr: [7.596979309090909e-06] - Loss total: 3.2632641792297363, Last rpr Loss: 0.9579464197158813, Last lagvar Loss: 0.9267679452896118\n",
      "Step 2478/10000- lr: [7.5959692121212124e-06] - Loss total: 3.263165235519409, Last rpr Loss: 1.050203800201416, Last lagvar Loss: 0.8348262310028076\n",
      "Step 2479/10000- lr: [7.594959115151516e-06] - Loss total: 3.2620980739593506, Last rpr Loss: 1.0424071550369263, Last lagvar Loss: 0.841808557510376\n",
      "Step 2480/10000- lr: [7.593949018181819e-06] - Loss total: 3.262481927871704, Last rpr Loss: 0.9526562690734863, Last lagvar Loss: 0.9320284128189087\n",
      "Step 2481/10000- lr: [7.592938921212122e-06] - Loss total: 3.261366367340088, Last rpr Loss: 0.9595101475715637, Last lagvar Loss: 0.9243571758270264\n",
      "Step 2482/10000- lr: [7.591928824242425e-06] - Loss total: 3.261660575866699, Last rpr Loss: 1.051883578300476, Last lagvar Loss: 0.8328299522399902\n",
      "Step 2483/10000- lr: [7.590918727272728e-06] - Loss total: 3.2605700492858887, Last rpr Loss: 1.044044017791748, Last lagvar Loss: 0.8398792743682861\n",
      "Step 2484/10000- lr: [7.58990863030303e-06] - Loss total: 3.2605793476104736, Last rpr Loss: 0.9539927840232849, Last lagvar Loss: 0.9300013780593872\n",
      "Step 2485/10000- lr: [7.588898533333334e-06] - Loss total: 3.259490489959717, Last rpr Loss: 0.9610240459442139, Last lagvar Loss: 0.9222005605697632\n",
      "Step 2486/10000- lr: [7.587888436363637e-06] - Loss total: 3.2601537704467773, Last rpr Loss: 1.0533788204193115, Last lagvar Loss: 0.8311115503311157\n",
      "Step 2487/10000- lr: [7.58687833939394e-06] - Loss total: 3.2590489387512207, Last rpr Loss: 1.045309066772461, Last lagvar Loss: 0.8384155631065369\n",
      "Step 2488/10000- lr: [7.5858682424242435e-06] - Loss total: 3.2587544918060303, Last rpr Loss: 0.9548137187957764, Last lagvar Loss: 0.9287016987800598\n",
      "Step 2489/10000- lr: [7.584858145454546e-06] - Loss total: 3.2577221393585205, Last rpr Loss: 0.9617506861686707, Last lagvar Loss: 0.921095609664917\n",
      "Step 2490/10000- lr: [7.583848048484848e-06] - Loss total: 3.2586233615875244, Last rpr Loss: 1.0537869930267334, Last lagvar Loss: 0.830554723739624\n",
      "Step 2491/10000- lr: [7.582837951515152e-06] - Loss total: 3.2575008869171143, Last rpr Loss: 1.0456000566482544, Last lagvar Loss: 0.8379751443862915\n",
      "Step 2492/10000- lr: [7.581827854545455e-06] - Loss total: 3.2570812702178955, Last rpr Loss: 0.9551084041595459, Last lagvar Loss: 0.9281609058380127\n",
      "Step 2493/10000- lr: [7.580817757575758e-06] - Loss total: 3.2560925483703613, Last rpr Loss: 0.9621731042861938, Last lagvar Loss: 0.9204675555229187\n",
      "Step 2494/10000- lr: [7.5798076606060615e-06] - Loss total: 3.257009744644165, Last rpr Loss: 1.0540465116500854, Last lagvar Loss: 0.8300473690032959\n",
      "Step 2495/10000- lr: [7.578797563636364e-06] - Loss total: 3.2558770179748535, Last rpr Loss: 1.045844316482544, Last lagvar Loss: 0.8374825716018677\n",
      "Step 2496/10000- lr: [7.577787466666667e-06] - Loss total: 3.2555229663848877, Last rpr Loss: 0.9552843570709229, Last lagvar Loss: 0.9278230667114258\n",
      "Step 2497/10000- lr: [7.57677736969697e-06] - Loss total: 3.25455904006958, Last rpr Loss: 0.9617221355438232, Last lagvar Loss: 0.9207965135574341\n",
      "Step 2498/10000- lr: [7.575767272727273e-06] - Loss total: 3.255312442779541, Last rpr Loss: 1.052746295928955, Last lagvar Loss: 0.8309890031814575\n",
      "Step 2499/10000- lr: [7.574757175757576e-06] - Loss total: 3.254192352294922, Last rpr Loss: 1.044561743736267, Last lagvar Loss: 0.8384298086166382\n",
      "Step 2500/10000- lr: [7.5737470787878795e-06] - Loss total: 3.254021644592285, Last rpr Loss: 0.9546831846237183, Last lagvar Loss: 0.9283185601234436\n",
      "Step 2501/10000- lr: [7.572736981818183e-06] - Loss total: 3.253056526184082, Last rpr Loss: 0.9610657095909119, Last lagvar Loss: 0.921349048614502\n",
      "Step 2502/10000- lr: [7.571726884848485e-06] - Loss total: 3.253617286682129, Last rpr Loss: 1.0516397953033447, Last lagvar Loss: 0.8317919969558716\n",
      "Step 2503/10000- lr: [7.5707167878787884e-06] - Loss total: 3.2525248527526855, Last rpr Loss: 1.0437333583831787, Last lagvar Loss: 0.8389981985092163\n",
      "Step 2504/10000- lr: [7.569706690909091e-06] - Loss total: 3.252512216567993, Last rpr Loss: 0.9545666575431824, Last lagvar Loss: 0.928306519985199\n",
      "Step 2505/10000- lr: [7.568696593939394e-06] - Loss total: 3.2515451908111572, Last rpr Loss: 0.9608127474784851, Last lagvar Loss: 0.9214895963668823\n",
      "Step 2506/10000- lr: [7.567686496969697e-06] - Loss total: 3.2519471645355225, Last rpr Loss: 1.0506680011749268, Last lagvar Loss: 0.8325018882751465\n",
      "Step 2507/10000- lr: [7.566676400000001e-06] - Loss total: 3.250882625579834, Last rpr Loss: 1.0428789854049683, Last lagvar Loss: 0.8396295309066772\n",
      "Step 2508/10000- lr: [7.565666303030304e-06] - Loss total: 3.2509801387786865, Last rpr Loss: 0.9544790387153625, Last lagvar Loss: 0.9282760620117188\n",
      "Step 2509/10000- lr: [7.564656206060607e-06] - Loss total: 3.2500126361846924, Last rpr Loss: 0.9606522917747498, Last lagvar Loss: 0.9215582609176636\n",
      "Step 2510/10000- lr: [7.56364610909091e-06] - Loss total: 3.250309705734253, Last rpr Loss: 1.0496381521224976, Last lagvar Loss: 0.8332953453063965\n",
      "Step 2511/10000- lr: [7.562636012121212e-06] - Loss total: 3.249274492263794, Last rpr Loss: 1.0420364141464233, Last lagvar Loss: 0.8402913212776184\n",
      "Step 2512/10000- lr: [7.561625915151515e-06] - Loss total: 3.2494077682495117, Last rpr Loss: 0.954737663269043, Last lagvar Loss: 0.9278766512870789\n",
      "Step 2513/10000- lr: [7.560615818181819e-06] - Loss total: 3.248438596725464, Last rpr Loss: 0.9613460302352905, Last lagvar Loss: 0.9207356572151184\n",
      "Step 2514/10000- lr: [7.559605721212122e-06] - Loss total: 3.248720407485962, Last rpr Loss: 1.049668788909912, Last lagvar Loss: 0.8331312537193298\n",
      "Step 2515/10000- lr: [7.558595624242425e-06] - Loss total: 3.2477033138275146, Last rpr Loss: 1.0419052839279175, Last lagvar Loss: 0.8403230905532837\n",
      "Step 2516/10000- lr: [7.557585527272728e-06] - Loss total: 3.24780011177063, Last rpr Loss: 0.955120325088501, Last lagvar Loss: 0.9273363947868347\n",
      "Step 2517/10000- lr: [7.556575430303031e-06] - Loss total: 3.2468369007110596, Last rpr Loss: 0.9619300365447998, Last lagvar Loss: 0.9200207591056824\n",
      "Step 2518/10000- lr: [7.555565333333333e-06] - Loss total: 3.2471516132354736, Last rpr Loss: 1.0496113300323486, Last lagvar Loss: 0.8330880999565125\n",
      "Step 2519/10000- lr: [7.554555236363637e-06] - Loss total: 3.2461483478546143, Last rpr Loss: 1.0417612791061401, Last lagvar Loss: 0.8403984308242798\n",
      "Step 2520/10000- lr: [7.55354513939394e-06] - Loss total: 3.2461655139923096, Last rpr Loss: 0.9554757475852966, Last lagvar Loss: 0.9268230199813843\n",
      "Step 2521/10000- lr: [7.552535042424243e-06] - Loss total: 3.2452099323272705, Last rpr Loss: 0.9624409675598145, Last lagvar Loss: 0.9193800091743469\n",
      "Step 2522/10000- lr: [7.5515249454545465e-06] - Loss total: 3.245591878890991, Last rpr Loss: 1.049400806427002, Last lagvar Loss: 0.8332133293151855\n",
      "Step 2523/10000- lr: [7.550514848484849e-06] - Loss total: 3.244596242904663, Last rpr Loss: 1.0415010452270508, Last lagvar Loss: 0.8406017422676086\n",
      "Step 2524/10000- lr: [7.549504751515152e-06] - Loss total: 3.2445080280303955, Last rpr Loss: 0.9559100866317749, Last lagvar Loss: 0.9262263774871826\n",
      "Step 2525/10000- lr: [7.548494654545455e-06] - Loss total: 3.2435615062713623, Last rpr Loss: 0.9632551670074463, Last lagvar Loss: 0.9184223413467407\n",
      "Step 2526/10000- lr: [7.547484557575758e-06] - Loss total: 3.2440288066864014, Last rpr Loss: 1.0495585203170776, Last lagvar Loss: 0.8329929113388062\n",
      "Step 2527/10000- lr: [7.546474460606061e-06] - Loss total: 3.243035316467285, Last rpr Loss: 1.0415618419647217, Last lagvar Loss: 0.8404974937438965\n",
      "Step 2528/10000- lr: [7.5454643636363644e-06] - Loss total: 3.2428338527679443, Last rpr Loss: 0.9565409421920776, Last lagvar Loss: 0.9254106879234314\n",
      "Step 2529/10000- lr: [7.544454266666668e-06] - Loss total: 3.24189829826355, Last rpr Loss: 0.9640961289405823, Last lagvar Loss: 0.9174201488494873\n",
      "Step 2530/10000- lr: [7.54344416969697e-06] - Loss total: 3.242438554763794, Last rpr Loss: 1.0495505332946777, Last lagvar Loss: 0.8329184055328369\n",
      "Step 2531/10000- lr: [7.5424340727272726e-06] - Loss total: 3.241442918777466, Last rpr Loss: 1.0414334535598755, Last lagvar Loss: 0.8405548334121704\n",
      "Step 2532/10000- lr: [7.541423975757576e-06] - Loss total: 3.2411487102508545, Last rpr Loss: 0.957081139087677, Last lagvar Loss: 0.924653172492981\n",
      "Step 2533/10000- lr: [7.540413878787879e-06] - Loss total: 3.2402260303497314, Last rpr Loss: 0.964846134185791, Last lagvar Loss: 0.9164726734161377\n",
      "Step 2534/10000- lr: [7.539403781818182e-06] - Loss total: 3.2407939434051514, Last rpr Loss: 1.0493046045303345, Last lagvar Loss: 0.8330081701278687\n",
      "Step 2535/10000- lr: [7.538393684848486e-06] - Loss total: 3.2397944927215576, Last rpr Loss: 1.0410276651382446, Last lagvar Loss: 0.8408028483390808\n",
      "Step 2536/10000- lr: [7.537383587878788e-06] - Loss total: 3.239453077316284, Last rpr Loss: 0.9574837684631348, Last lagvar Loss: 0.9239637851715088\n",
      "Step 2537/10000- lr: [7.536373490909091e-06] - Loss total: 3.238542079925537, Last rpr Loss: 0.9654808640480042, Last lagvar Loss: 0.9155623912811279\n",
      "Step 2538/10000- lr: [7.535363393939394e-06] - Loss total: 3.2390687465667725, Last rpr Loss: 1.0487779378890991, Last lagvar Loss: 0.8332264423370361\n",
      "Step 2539/10000- lr: [7.534353296969697e-06] - Loss total: 3.2380709648132324, Last rpr Loss: 1.0403428077697754, Last lagvar Loss: 0.8411790132522583\n",
      "Step 2540/10000- lr: [7.5333432e-06] - Loss total: 3.2377517223358154, Last rpr Loss: 0.9578967094421387, Last lagvar Loss: 0.9231981039047241\n",
      "Step 2541/10000- lr: [7.532333103030304e-06] - Loss total: 3.2368581295013428, Last rpr Loss: 0.9661329388618469, Last lagvar Loss: 0.9146009683609009\n",
      "Step 2542/10000- lr: [7.531323006060607e-06] - Loss total: 3.237272024154663, Last rpr Loss: 1.0479085445404053, Last lagvar Loss: 0.8336589336395264\n",
      "Step 2543/10000- lr: [7.530312909090909e-06] - Loss total: 3.236294984817505, Last rpr Loss: 1.0392189025878906, Last lagvar Loss: 0.8419315814971924\n",
      "Step 2544/10000- lr: [7.529302812121213e-06] - Loss total: 3.236069679260254, Last rpr Loss: 0.9581162929534912, Last lagvar Loss: 0.9227077960968018\n",
      "Step 2545/10000- lr: [7.528292715151515e-06] - Loss total: 3.2351982593536377, Last rpr Loss: 0.9665753841400146, Last lagvar Loss: 0.9139485955238342\n",
      "Step 2546/10000- lr: [7.527282618181818e-06] - Loss total: 3.2354602813720703, Last rpr Loss: 1.0466796159744263, Last lagvar Loss: 0.8344919681549072\n",
      "Step 2547/10000- lr: [7.526272521212122e-06] - Loss total: 3.234520435333252, Last rpr Loss: 1.0377755165100098, Last lagvar Loss: 0.8430690169334412\n",
      "Step 2548/10000- lr: [7.525262424242425e-06] - Loss total: 3.234400987625122, Last rpr Loss: 0.9581441879272461, Last lagvar Loss: 0.9224765300750732\n",
      "Step 2549/10000- lr: [7.524252327272728e-06] - Loss total: 3.2335469722747803, Last rpr Loss: 0.9668476581573486, Last lagvar Loss: 0.9135240912437439\n",
      "Step 2550/10000- lr: [7.523242230303031e-06] - Loss total: 3.2336692810058594, Last rpr Loss: 1.045274019241333, Last lagvar Loss: 0.8355623483657837\n",
      "Step 2551/10000- lr: [7.522232133333334e-06] - Loss total: 3.2327730655670166, Last rpr Loss: 1.036329746246338, Last lagvar Loss: 0.8442655801773071\n",
      "Step 2552/10000- lr: [7.521222036363637e-06] - Loss total: 3.232720136642456, Last rpr Loss: 0.9583929777145386, Last lagvar Loss: 0.9220283031463623\n",
      "Step 2553/10000- lr: [7.52021193939394e-06] - Loss total: 3.231884002685547, Last rpr Loss: 0.9674431085586548, Last lagvar Loss: 0.9127877950668335\n",
      "Step 2554/10000- lr: [7.519201842424243e-06] - Loss total: 3.2319188117980957, Last rpr Loss: 1.0440800189971924, Last lagvar Loss: 0.8364852666854858\n",
      "Step 2555/10000- lr: [7.518191745454546e-06] - Loss total: 3.231066942214966, Last rpr Loss: 1.035165786743164, Last lagvar Loss: 0.845242440700531\n",
      "Step 2556/10000- lr: [7.517181648484849e-06] - Loss total: 3.231018543243408, Last rpr Loss: 0.9590743184089661, Last lagvar Loss: 0.9211499691009521\n",
      "Step 2557/10000- lr: [7.516171551515153e-06] - Loss total: 3.2302064895629883, Last rpr Loss: 0.9684919118881226, Last lagvar Loss: 0.9116107225418091\n",
      "Step 2558/10000- lr: [7.515161454545455e-06] - Loss total: 3.230214834213257, Last rpr Loss: 1.0430192947387695, Last lagvar Loss: 0.8373509645462036\n",
      "Step 2559/10000- lr: [7.5141513575757576e-06] - Loss total: 3.2294023036956787, Last rpr Loss: 1.0340113639831543, Last lagvar Loss: 0.8462809324264526\n",
      "Step 2560/10000- lr: [7.513141260606061e-06] - Loss total: 3.229311943054199, Last rpr Loss: 0.9598914980888367, Last lagvar Loss: 0.9201611280441284\n",
      "Step 2561/10000- lr: [7.512131163636364e-06] - Loss total: 3.2285337448120117, Last rpr Loss: 0.9697674512863159, Last lagvar Loss: 0.9102411270141602\n",
      "Step 2562/10000- lr: [7.511121066666667e-06] - Loss total: 3.2285399436950684, Last rpr Loss: 1.0419116020202637, Last lagvar Loss: 0.8383264541625977\n",
      "Step 2563/10000- lr: [7.510110969696971e-06] - Loss total: 3.2277603149414062, Last rpr Loss: 1.0327434539794922, Last lagvar Loss: 0.8474905490875244\n",
      "Step 2564/10000- lr: [7.509100872727273e-06] - Loss total: 3.227630853652954, Last rpr Loss: 0.9608287811279297, Last lagvar Loss: 0.9190968871116638\n",
      "Step 2565/10000- lr: [7.508090775757576e-06] - Loss total: 3.2268943786621094, Last rpr Loss: 0.9711958765983582, Last lagvar Loss: 0.9087743759155273\n",
      "Step 2566/10000- lr: [7.507080678787879e-06] - Loss total: 3.2268619537353516, Last rpr Loss: 1.0405786037445068, Last lagvar Loss: 0.8395462036132812\n",
      "Step 2567/10000- lr: [7.506070581818182e-06] - Loss total: 3.226111888885498, Last rpr Loss: 1.0311530828475952, Last lagvar Loss: 0.8490386605262756\n",
      "Step 2568/10000- lr: [7.505060484848485e-06] - Loss total: 3.225998640060425, Last rpr Loss: 0.961738109588623, Last lagvar Loss: 0.9181265830993652\n",
      "Step 2569/10000- lr: [7.504050387878789e-06] - Loss total: 3.2253055572509766, Last rpr Loss: 0.9725192189216614, Last lagvar Loss: 0.9074804782867432\n",
      "Step 2570/10000- lr: [7.503040290909092e-06] - Loss total: 3.2251644134521484, Last rpr Loss: 1.0388332605361938, Last lagvar Loss: 0.8411693572998047\n",
      "Step 2571/10000- lr: [7.502030193939394e-06] - Loss total: 3.2244508266448975, Last rpr Loss: 1.0291969776153564, Last lagvar Loss: 0.8509505391120911\n",
      "Step 2572/10000- lr: [7.501020096969698e-06] - Loss total: 3.2244086265563965, Last rpr Loss: 0.9626830220222473, Last lagvar Loss: 0.917177677154541\n",
      "Step 2573/10000- lr: [7.50001e-06] - Loss total: 3.223752737045288, Last rpr Loss: 0.9737853407859802, Last lagvar Loss: 0.9062929153442383\n",
      "Step 2574/10000- lr: [7.498999903030303e-06] - Loss total: 3.22346568107605, Last rpr Loss: 1.0368366241455078, Last lagvar Loss: 0.84305739402771\n",
      "Step 2575/10000- lr: [7.497989806060607e-06] - Loss total: 3.22279691696167, Last rpr Loss: 1.0271790027618408, Last lagvar Loss: 0.8529479503631592\n",
      "Step 2576/10000- lr: [7.49697970909091e-06] - Loss total: 3.222831964492798, Last rpr Loss: 0.9639202356338501, Last lagvar Loss: 0.9159626960754395\n",
      "Step 2577/10000- lr: [7.495969612121213e-06] - Loss total: 3.222205400466919, Last rpr Loss: 0.9752095341682434, Last lagvar Loss: 0.9049645662307739\n",
      "Step 2578/10000- lr: [7.494959515151516e-06] - Loss total: 3.2217936515808105, Last rpr Loss: 1.0347459316253662, Last lagvar Loss: 0.8450863361358643\n",
      "Step 2579/10000- lr: [7.493949418181818e-06] - Loss total: 3.2211720943450928, Last rpr Loss: 1.0252549648284912, Last lagvar Loss: 0.8548983931541443\n",
      "Step 2580/10000- lr: [7.492939321212121e-06] - Loss total: 3.221240520477295, Last rpr Loss: 0.9655421376228333, Last lagvar Loss: 0.9143639802932739\n",
      "Step 2581/10000- lr: [7.4919292242424246e-06] - Loss total: 3.220639944076538, Last rpr Loss: 0.9769327640533447, Last lagvar Loss: 0.903331458568573\n",
      "Step 2582/10000- lr: [7.490919127272728e-06] - Loss total: 3.220163583755493, Last rpr Loss: 1.0326566696166992, Last lagvar Loss: 0.8471776843070984\n",
      "Step 2583/10000- lr: [7.489909030303031e-06] - Loss total: 3.2195820808410645, Last rpr Loss: 1.023415207862854, Last lagvar Loss: 0.856816291809082\n",
      "Step 2584/10000- lr: [7.4888989333333335e-06] - Loss total: 3.2196295261383057, Last rpr Loss: 0.9674466848373413, Last lagvar Loss: 0.9124773740768433\n",
      "Step 2585/10000- lr: [7.487888836363637e-06] - Loss total: 3.219055414199829, Last rpr Loss: 0.9788925647735596, Last lagvar Loss: 0.9014496803283691\n",
      "Step 2586/10000- lr: [7.486878739393939e-06] - Loss total: 3.2185676097869873, Last rpr Loss: 1.0305507183074951, Last lagvar Loss: 0.8493399024009705\n",
      "Step 2587/10000- lr: [7.4858686424242425e-06] - Loss total: 3.2180116176605225, Last rpr Loss: 1.0215489864349365, Last lagvar Loss: 0.8587948679924011\n",
      "Step 2588/10000- lr: [7.484858545454546e-06] - Loss total: 3.218013048171997, Last rpr Loss: 0.9694928526878357, Last lagvar Loss: 0.9104599952697754\n",
      "Step 2589/10000- lr: [7.483848448484849e-06] - Loss total: 3.217463254928589, Last rpr Loss: 0.9808794260025024, Last lagvar Loss: 0.8995412588119507\n",
      "Step 2590/10000- lr: [7.482838351515152e-06] - Loss total: 3.2169837951660156, Last rpr Loss: 1.02828049659729, Last lagvar Loss: 0.8516978025436401\n",
      "Step 2591/10000- lr: [7.481828254545455e-06] - Loss total: 3.2164433002471924, Last rpr Loss: 1.0195692777633667, Last lagvar Loss: 0.8608982563018799\n",
      "Step 2592/10000- lr: [7.480818157575758e-06] - Loss total: 3.2164041996002197, Last rpr Loss: 0.9716843366622925, Last lagvar Loss: 0.9083234071731567\n",
      "Step 2593/10000- lr: [7.4798080606060605e-06] - Loss total: 3.215869426727295, Last rpr Loss: 0.9827883243560791, Last lagvar Loss: 0.8977147936820984\n",
      "Step 2594/10000- lr: [7.478797963636364e-06] - Loss total: 3.2154037952423096, Last rpr Loss: 1.0258080959320068, Last lagvar Loss: 0.8542801737785339\n",
      "Step 2595/10000- lr: [7.477787866666667e-06] - Loss total: 3.214871406555176, Last rpr Loss: 1.0175436735153198, Last lagvar Loss: 0.8630517721176147\n",
      "Step 2596/10000- lr: [7.47677776969697e-06] - Loss total: 3.214797258377075, Last rpr Loss: 0.9741013050079346, Last lagvar Loss: 0.9059833884239197\n",
      "Step 2597/10000- lr: [7.475767672727274e-06] - Loss total: 3.2142608165740967, Last rpr Loss: 0.9846378564834595, Last lagvar Loss: 0.8959393501281738\n",
      "Step 2598/10000- lr: [7.474757575757576e-06] - Loss total: 3.2138383388519287, Last rpr Loss: 1.023237943649292, Last lagvar Loss: 0.8569937944412231\n",
      "Step 2599/10000- lr: [7.4737474787878785e-06] - Loss total: 3.213305711746216, Last rpr Loss: 1.0156245231628418, Last lagvar Loss: 0.8651142120361328\n",
      "Step 2600/10000- lr: [7.472737381818182e-06] - Loss total: 3.2131683826446533, Last rpr Loss: 0.9767447710037231, Last lagvar Loss: 0.9034159183502197\n",
      "Step 2601/10000- lr: [7.471727284848485e-06] - Loss total: 3.212615728378296, Last rpr Loss: 0.986452043056488, Last lagvar Loss: 0.8941686153411865\n",
      "Step 2602/10000- lr: [7.470717187878788e-06] - Loss total: 3.2122995853424072, Last rpr Loss: 1.0207231044769287, Last lagvar Loss: 0.859699010848999\n",
      "Step 2603/10000- lr: [7.469707090909092e-06] - Loss total: 3.2117555141448975, Last rpr Loss: 1.0138990879058838, Last lagvar Loss: 0.8670101761817932\n",
      "Step 2604/10000- lr: [7.468696993939394e-06] - Loss total: 3.211503028869629, Last rpr Loss: 0.9794725179672241, Last lagvar Loss: 0.9007409811019897\n",
      "Step 2605/10000- lr: [7.467686896969697e-06] - Loss total: 3.2109270095825195, Last rpr Loss: 0.9881744384765625, Last lagvar Loss: 0.892451286315918\n",
      "Step 2606/10000- lr: [7.4666768e-06] - Loss total: 3.2107784748077393, Last rpr Loss: 1.0183137655258179, Last lagvar Loss: 0.862337052822113\n",
      "Step 2607/10000- lr: [7.465666703030303e-06] - Loss total: 3.210209608078003, Last rpr Loss: 1.012324571609497, Last lagvar Loss: 0.8687726259231567\n",
      "Step 2608/10000- lr: [7.464656606060606e-06] - Loss total: 3.209808111190796, Last rpr Loss: 0.9821547269821167, Last lagvar Loss: 0.898094654083252\n",
      "Step 2609/10000- lr: [7.4636465090909095e-06] - Loss total: 3.209207057952881, Last rpr Loss: 0.9896917939186096, Last lagvar Loss: 0.89091557264328\n",
      "Step 2610/10000- lr: [7.462636412121213e-06] - Loss total: 3.2092459201812744, Last rpr Loss: 1.015982747077942, Last lagvar Loss: 0.8649038076400757\n",
      "Step 2611/10000- lr: [7.461626315151515e-06] - Loss total: 3.2086379528045654, Last rpr Loss: 1.0108857154846191, Last lagvar Loss: 0.8703858256340027\n",
      "Step 2612/10000- lr: [7.4606162181818185e-06] - Loss total: 3.208106279373169, Last rpr Loss: 0.9847595691680908, Last lagvar Loss: 0.8955358266830444\n",
      "Step 2613/10000- lr: [7.459606121212121e-06] - Loss total: 3.207474946975708, Last rpr Loss: 0.990821361541748, Last lagvar Loss: 0.8897656798362732\n",
      "Step 2614/10000- lr: [7.458596024242424e-06] - Loss total: 3.2076711654663086, Last rpr Loss: 1.0137131214141846, Last lagvar Loss: 0.8673801422119141\n",
      "Step 2615/10000- lr: [7.4575859272727275e-06] - Loss total: 3.207015037536621, Last rpr Loss: 1.0097017288208008, Last lagvar Loss: 0.8716988563537598\n",
      "Step 2616/10000- lr: [7.456575830303031e-06] - Loss total: 3.206404209136963, Last rpr Loss: 0.9872713685035706, Last lagvar Loss: 0.8930952548980713\n",
      "Step 2617/10000- lr: [7.455565733333334e-06] - Loss total: 3.205732583999634, Last rpr Loss: 0.9914071559906006, Last lagvar Loss: 0.8891667723655701\n",
      "Step 2618/10000- lr: [7.454555636363637e-06] - Loss total: 3.2060387134552, Last rpr Loss: 1.0116541385650635, Last lagvar Loss: 0.8695929646492004\n",
      "Step 2619/10000- lr: [7.453545539393941e-06] - Loss total: 3.2053329944610596, Last rpr Loss: 1.0089938640594482, Last lagvar Loss: 0.8724807500839233\n",
      "Step 2620/10000- lr: [7.452535442424243e-06] - Loss total: 3.204692840576172, Last rpr Loss: 0.9894990921020508, Last lagvar Loss: 0.8909488916397095\n",
      "Step 2621/10000- lr: [7.451525345454546e-06] - Loss total: 3.20397686958313, Last rpr Loss: 0.9914168119430542, Last lagvar Loss: 0.8891535997390747\n",
      "Step 2622/10000- lr: [7.450515248484849e-06] - Loss total: 3.204336404800415, Last rpr Loss: 1.0100436210632324, Last lagvar Loss: 0.8712873458862305\n",
      "Step 2623/10000- lr: [7.449505151515152e-06] - Loss total: 3.203587770462036, Last rpr Loss: 1.008829116821289, Last lagvar Loss: 0.8726649880409241\n",
      "Step 2624/10000- lr: [7.448495054545455e-06] - Loss total: 3.202962636947632, Last rpr Loss: 0.9911428689956665, Last lagvar Loss: 0.8893859386444092\n",
      "Step 2625/10000- lr: [7.447484957575759e-06] - Loss total: 3.2022147178649902, Last rpr Loss: 0.9909953474998474, Last lagvar Loss: 0.889599084854126\n",
      "Step 2626/10000- lr: [7.446474860606062e-06] - Loss total: 3.2025527954101562, Last rpr Loss: 1.0090198516845703, Last lagvar Loss: 0.8723111748695374\n",
      "Step 2627/10000- lr: [7.445464763636364e-06] - Loss total: 3.2017722129821777, Last rpr Loss: 1.009060263633728, Last lagvar Loss: 0.8723970651626587\n",
      "Step 2628/10000- lr: [7.444454666666667e-06] - Loss total: 3.2012245655059814, Last rpr Loss: 0.9920685291290283, Last lagvar Loss: 0.8885605335235596\n",
      "Step 2629/10000- lr: [7.44344456969697e-06] - Loss total: 3.200455904006958, Last rpr Loss: 0.990365743637085, Last lagvar Loss: 0.8903023600578308\n",
      "Step 2630/10000- lr: [7.442434472727273e-06] - Loss total: 3.2005817890167236, Last rpr Loss: 1.0081796646118164, Last lagvar Loss: 0.8729345798492432\n",
      "Step 2631/10000- lr: [7.4414243757575766e-06] - Loss total: 3.1997127532958984, Last rpr Loss: 1.0091962814331055, Last lagvar Loss: 0.8719260692596436\n",
      "Step 2632/10000- lr: [7.44041427878788e-06] - Loss total: 3.1997334957122803, Last rpr Loss: 0.9929744601249695, Last lagvar Loss: 0.8881733417510986\n",
      "Step 2633/10000- lr: [7.439404181818182e-06] - Loss total: 3.198920488357544, Last rpr Loss: 0.9888107776641846, Last lagvar Loss: 0.8922926783561707\n",
      "Step 2634/10000- lr: [7.4383940848484855e-06] - Loss total: 3.1985256671905518, Last rpr Loss: 1.0068433284759521, Last lagvar Loss: 0.8739839792251587\n",
      "Step 2635/10000- lr: [7.437383987878788e-06] - Loss total: 3.1977736949920654, Last rpr Loss: 1.0104095935821533, Last lagvar Loss: 0.8705912828445435\n",
      "Step 2636/10000- lr: [7.436373890909091e-06] - Loss total: 3.197836399078369, Last rpr Loss: 0.9927434921264648, Last lagvar Loss: 0.888385534286499\n",
      "Step 2637/10000- lr: [7.4353637939393945e-06] - Loss total: 3.1969172954559326, Last rpr Loss: 0.9881929755210876, Last lagvar Loss: 0.8927441835403442\n",
      "Step 2638/10000- lr: [7.434353696969698e-06] - Loss total: 3.1964809894561768, Last rpr Loss: 1.0080595016479492, Last lagvar Loss: 0.8725529909133911\n",
      "Step 2639/10000- lr: [7.433343600000001e-06] - Loss total: 3.195462226867676, Last rpr Loss: 1.0098016262054443, Last lagvar Loss: 0.8705527782440186\n",
      "Step 2640/10000- lr: [7.4323335030303035e-06] - Loss total: 3.195854902267456, Last rpr Loss: 0.9925699234008789, Last lagvar Loss: 0.8885475397109985\n",
      "Step 2641/10000- lr: [7.431323406060607e-06] - Loss total: 3.194446563720703, Last rpr Loss: 0.9882035851478577, Last lagvar Loss: 0.8919193744659424\n",
      "Step 2642/10000- lr: [7.430313309090909e-06] - Loss total: 3.1942715644836426, Last rpr Loss: 1.0090584754943848, Last lagvar Loss: 0.8712271451950073\n",
      "Step 2643/10000- lr: [7.4293032121212125e-06] - Loss total: 3.192509889602661, Last rpr Loss: 1.0061707496643066, Last lagvar Loss: 0.8725200891494751\n",
      "Step 2644/10000- lr: [7.428293115151516e-06] - Loss total: 3.1931796073913574, Last rpr Loss: 0.995113730430603, Last lagvar Loss: 0.8850718140602112\n",
      "Step 2645/10000- lr: [7.427283018181819e-06] - Loss total: 3.191295623779297, Last rpr Loss: 0.989922046661377, Last lagvar Loss: 0.8883060812950134\n",
      "Step 2646/10000- lr: [7.426272921212122e-06] - Loss total: 3.1917402744293213, Last rpr Loss: 1.0090452432632446, Last lagvar Loss: 0.8705196380615234\n",
      "Step 2647/10000- lr: [7.425262824242425e-06] - Loss total: 3.1896791458129883, Last rpr Loss: 1.003248929977417, Last lagvar Loss: 0.8739187121391296\n",
      "Step 2648/10000- lr: [7.424252727272727e-06] - Loss total: 3.1904664039611816, Last rpr Loss: 0.9964856505393982, Last lagvar Loss: 0.8826879262924194\n",
      "Step 2649/10000- lr: [7.4232426303030305e-06] - Loss total: 3.188616991043091, Last rpr Loss: 0.9911353588104248, Last lagvar Loss: 0.8858954906463623\n",
      "Step 2650/10000- lr: [7.422232533333334e-06] - Loss total: 3.189230442047119, Last rpr Loss: 1.0082485675811768, Last lagvar Loss: 0.8705635070800781\n",
      "Step 2651/10000- lr: [7.421222436363637e-06] - Loss total: 3.1872897148132324, Last rpr Loss: 1.001671314239502, Last lagvar Loss: 0.8747648000717163\n",
      "Step 2652/10000- lr: [7.42021233939394e-06] - Loss total: 3.1879360675811768, Last rpr Loss: 0.9967357516288757, Last lagvar Loss: 0.881594181060791\n",
      "Step 2653/10000- lr: [7.419202242424243e-06] - Loss total: 3.1862709522247314, Last rpr Loss: 0.9936578869819641, Last lagvar Loss: 0.8827364444732666\n",
      "Step 2654/10000- lr: [7.418192145454546e-06] - Loss total: 3.1867926120758057, Last rpr Loss: 1.0075833797454834, Last lagvar Loss: 0.8704930543899536\n",
      "Step 2655/10000- lr: [7.4171820484848484e-06] - Loss total: 3.1851613521575928, Last rpr Loss: 0.9998270273208618, Last lagvar Loss: 0.8763600587844849\n",
      "Step 2656/10000- lr: [7.416171951515152e-06] - Loss total: 3.1855270862579346, Last rpr Loss: 0.9969719648361206, Last lagvar Loss: 0.8806577324867249\n",
      "Step 2657/10000- lr: [7.415161854545455e-06] - Loss total: 3.184152364730835, Last rpr Loss: 0.9968536496162415, Last lagvar Loss: 0.8793118000030518\n",
      "Step 2658/10000- lr: [7.414151757575758e-06] - Loss total: 3.184401273727417, Last rpr Loss: 1.0054869651794434, Last lagvar Loss: 0.871904730796814\n",
      "Step 2659/10000- lr: [7.4131416606060615e-06] - Loss total: 3.1831512451171875, Last rpr Loss: 0.9985010027885437, Last lagvar Loss: 0.8776565790176392\n",
      "Step 2660/10000- lr: [7.412131563636364e-06] - Loss total: 3.18320894241333, Last rpr Loss: 0.9979016780853271, Last lagvar Loss: 0.8791735172271729\n",
      "Step 2661/10000- lr: [7.411121466666667e-06] - Loss total: 3.1821396350860596, Last rpr Loss: 0.9987972378730774, Last lagvar Loss: 0.8773370981216431\n",
      "Step 2662/10000- lr: [7.41011136969697e-06] - Loss total: 3.1820950508117676, Last rpr Loss: 1.0030230283737183, Last lagvar Loss: 0.8738377690315247\n",
      "Step 2663/10000- lr: [7.409101272727273e-06] - Loss total: 3.1811561584472656, Last rpr Loss: 0.9982807636260986, Last lagvar Loss: 0.8778834342956543\n",
      "Step 2664/10000- lr: [7.408091175757576e-06] - Loss total: 3.1809699535369873, Last rpr Loss: 0.9985184669494629, Last lagvar Loss: 0.878143310546875\n",
      "Step 2665/10000- lr: [7.4070810787878795e-06] - Loss total: 3.1801464557647705, Last rpr Loss: 0.9997581243515015, Last lagvar Loss: 0.8763896226882935\n",
      "Step 2666/10000- lr: [7.406070981818183e-06] - Loss total: 3.179875612258911, Last rpr Loss: 1.0018219947814941, Last lagvar Loss: 0.8746767044067383\n",
      "Step 2667/10000- lr: [7.405060884848485e-06] - Loss total: 3.1791584491729736, Last rpr Loss: 0.9984109401702881, Last lagvar Loss: 0.8777569532394409\n",
      "Step 2668/10000- lr: [7.404050787878788e-06] - Loss total: 3.1787898540496826, Last rpr Loss: 0.9985851645469666, Last lagvar Loss: 0.877784013748169\n",
      "Step 2669/10000- lr: [7.403040690909091e-06] - Loss total: 3.178154468536377, Last rpr Loss: 1.000643253326416, Last lagvar Loss: 0.8755160570144653\n",
      "Step 2670/10000- lr: [7.402030593939394e-06] - Loss total: 3.1777162551879883, Last rpr Loss: 1.001039981842041, Last lagvar Loss: 0.875214159488678\n",
      "Step 2671/10000- lr: [7.4010204969696975e-06] - Loss total: 3.1771583557128906, Last rpr Loss: 0.9983201026916504, Last lagvar Loss: 0.877845287322998\n",
      "Step 2672/10000- lr: [7.400010400000001e-06] - Loss total: 3.176658868789673, Last rpr Loss: 0.9988788366317749, Last lagvar Loss: 0.8772907257080078\n",
      "Step 2673/10000- lr: [7.399000303030303e-06] - Loss total: 3.1761512756347656, Last rpr Loss: 1.001194953918457, Last lagvar Loss: 0.8749574422836304\n",
      "Step 2674/10000- lr: [7.3979902060606065e-06] - Loss total: 3.175610065460205, Last rpr Loss: 1.0001704692840576, Last lagvar Loss: 0.8759258389472961\n",
      "Step 2675/10000- lr: [7.396980109090909e-06] - Loss total: 3.175143003463745, Last rpr Loss: 0.9984361529350281, Last lagvar Loss: 0.8777068853378296\n",
      "Step 2676/10000- lr: [7.395970012121212e-06] - Loss total: 3.1745779514312744, Last rpr Loss: 0.9992862939834595, Last lagvar Loss: 0.87675940990448\n",
      "Step 2677/10000- lr: [7.3949599151515154e-06] - Loss total: 3.174128770828247, Last rpr Loss: 1.0012199878692627, Last lagvar Loss: 0.874897837638855\n",
      "Step 2678/10000- lr: [7.393949818181819e-06] - Loss total: 3.1735520362854004, Last rpr Loss: 0.9997470378875732, Last lagvar Loss: 0.876257061958313\n",
      "Step 2679/10000- lr: [7.392939721212122e-06] - Loss total: 3.1731112003326416, Last rpr Loss: 0.9986411929130554, Last lagvar Loss: 0.8774548768997192\n",
      "Step 2680/10000- lr: [7.3919296242424244e-06] - Loss total: 3.172536611557007, Last rpr Loss: 0.999561071395874, Last lagvar Loss: 0.8764141798019409\n",
      "Step 2681/10000- lr: [7.390919527272728e-06] - Loss total: 3.172093629837036, Last rpr Loss: 1.001174807548523, Last lagvar Loss: 0.8748886585235596\n",
      "Step 2682/10000- lr: [7.38990943030303e-06] - Loss total: 3.1715247631073, Last rpr Loss: 0.9994066953659058, Last lagvar Loss: 0.8765478134155273\n",
      "Step 2683/10000- lr: [7.388899333333333e-06] - Loss total: 3.1710739135742188, Last rpr Loss: 0.9985334873199463, Last lagvar Loss: 0.8775017857551575\n",
      "Step 2684/10000- lr: [7.387889236363637e-06] - Loss total: 3.1705172061920166, Last rpr Loss: 1.0000370740890503, Last lagvar Loss: 0.8759003281593323\n",
      "Step 2685/10000- lr: [7.38687913939394e-06] - Loss total: 3.1700572967529297, Last rpr Loss: 1.0011072158813477, Last lagvar Loss: 0.8748948574066162\n",
      "Step 2686/10000- lr: [7.385869042424243e-06] - Loss total: 3.169512987136841, Last rpr Loss: 0.9989281296730042, Last lagvar Loss: 0.8770007491111755\n",
      "Step 2687/10000- lr: [7.384858945454546e-06] - Loss total: 3.169039487838745, Last rpr Loss: 0.9986809492111206, Last lagvar Loss: 0.877291202545166\n",
      "Step 2688/10000- lr: [7.383848848484848e-06] - Loss total: 3.1685097217559814, Last rpr Loss: 1.0006071329116821, Last lagvar Loss: 0.875309944152832\n",
      "Step 2689/10000- lr: [7.382838751515151e-06] - Loss total: 3.1680243015289307, Last rpr Loss: 1.0006390810012817, Last lagvar Loss: 0.8753025531768799\n",
      "Step 2690/10000- lr: [7.381828654545455e-06] - Loss total: 3.167508363723755, Last rpr Loss: 0.998643159866333, Last lagvar Loss: 0.8772696852684021\n",
      "Step 2691/10000- lr: [7.380818557575758e-06] - Loss total: 3.167011260986328, Last rpr Loss: 0.9991194605827332, Last lagvar Loss: 0.8767955303192139\n",
      "Step 2692/10000- lr: [7.379808460606061e-06] - Loss total: 3.166506052017212, Last rpr Loss: 1.000812292098999, Last lagvar Loss: 0.8750882148742676\n",
      "Step 2693/10000- lr: [7.3787983636363645e-06] - Loss total: 3.1660008430480957, Last rpr Loss: 1.0001168251037598, Last lagvar Loss: 0.8757734298706055\n",
      "Step 2694/10000- lr: [7.377788266666667e-06] - Loss total: 3.165503740310669, Last rpr Loss: 0.9987239837646484, Last lagvar Loss: 0.8771690130233765\n",
      "Step 2695/10000- lr: [7.376778169696969e-06] - Loss total: 3.1649932861328125, Last rpr Loss: 0.9995355606079102, Last lagvar Loss: 0.8763347268104553\n",
      "Step 2696/10000- lr: [7.375768072727273e-06] - Loss total: 3.1645007133483887, Last rpr Loss: 1.0007939338684082, Last lagvar Loss: 0.8750834465026855\n",
      "Step 2697/10000- lr: [7.374757975757576e-06] - Loss total: 3.1639881134033203, Last rpr Loss: 0.999743640422821, Last lagvar Loss: 0.8761100769042969\n",
      "Step 2698/10000- lr: [7.373747878787879e-06] - Loss total: 3.163496494293213, Last rpr Loss: 0.9987965822219849, Last lagvar Loss: 0.8770683407783508\n",
      "Step 2699/10000- lr: [7.3727377818181825e-06] - Loss total: 3.162984609603882, Last rpr Loss: 0.9998573064804077, Last lagvar Loss: 0.8759817481040955\n",
      "Step 2700/10000- lr: [7.371727684848485e-06] - Loss total: 3.162492275238037, Last rpr Loss: 1.0006675720214844, Last lagvar Loss: 0.8751794099807739\n",
      "Step 2701/10000- lr: [7.370717587878788e-06] - Loss total: 3.1619815826416016, Last rpr Loss: 0.9994226694107056, Last lagvar Loss: 0.8764042854309082\n",
      "Step 2702/10000- lr: [7.3697074909090914e-06] - Loss total: 3.161486864089966, Last rpr Loss: 0.9989797472953796, Last lagvar Loss: 0.8768524527549744\n",
      "Step 2703/10000- lr: [7.368697393939395e-06] - Loss total: 3.1609787940979004, Last rpr Loss: 1.0001351833343506, Last lagvar Loss: 0.8756787776947021\n",
      "Step 2704/10000- lr: [7.367687296969697e-06] - Loss total: 3.1604816913604736, Last rpr Loss: 1.0003654956817627, Last lagvar Loss: 0.8754485249519348\n",
      "Step 2705/10000- lr: [7.3666772000000004e-06] - Loss total: 3.1599762439727783, Last rpr Loss: 0.9992707967758179, Last lagvar Loss: 0.8765320777893066\n",
      "Step 2706/10000- lr: [7.365667103030304e-06] - Loss total: 3.1594760417938232, Last rpr Loss: 0.9992660880088806, Last lagvar Loss: 0.8765321373939514\n",
      "Step 2707/10000- lr: [7.364657006060607e-06] - Loss total: 3.158973217010498, Last rpr Loss: 1.0001802444458008, Last lagvar Loss: 0.8756077885627747\n",
      "Step 2708/10000- lr: [7.36364690909091e-06] - Loss total: 3.1584701538085938, Last rpr Loss: 1.0000731945037842, Last lagvar Loss: 0.8757062554359436\n",
      "Step 2709/10000- lr: [7.362636812121213e-06] - Loss total: 3.157968282699585, Last rpr Loss: 0.9993019104003906, Last lagvar Loss: 0.876471757888794\n",
      "Step 2710/10000- lr: [7.361626715151516e-06] - Loss total: 3.157463550567627, Last rpr Loss: 0.9994795322418213, Last lagvar Loss: 0.8762805461883545\n",
      "Step 2711/10000- lr: [7.360616618181818e-06] - Loss total: 3.1569619178771973, Last rpr Loss: 1.0001726150512695, Last lagvar Loss: 0.8755776882171631\n",
      "Step 2712/10000- lr: [7.359606521212122e-06] - Loss total: 3.156454086303711, Last rpr Loss: 0.9998970627784729, Last lagvar Loss: 0.8758350610733032\n",
      "Step 2713/10000- lr: [7.358596424242425e-06] - Loss total: 3.155949354171753, Last rpr Loss: 0.9993307590484619, Last lagvar Loss: 0.8763868808746338\n",
      "Step 2714/10000- lr: [7.357586327272728e-06] - Loss total: 3.15543794631958, Last rpr Loss: 0.9996826648712158, Last lagvar Loss: 0.8760046362876892\n",
      "Step 2715/10000- lr: [7.3565762303030315e-06] - Loss total: 3.1549274921417236, Last rpr Loss: 1.000169038772583, Last lagvar Loss: 0.8754857778549194\n",
      "Step 2716/10000- lr: [7.355566133333334e-06] - Loss total: 3.1544106006622314, Last rpr Loss: 0.9997372627258301, Last lagvar Loss: 0.87586909532547\n",
      "Step 2717/10000- lr: [7.354556036363636e-06] - Loss total: 3.1538937091827393, Last rpr Loss: 0.9994207620620728, Last lagvar Loss: 0.8761336207389832\n",
      "Step 2718/10000- lr: [7.35354593939394e-06] - Loss total: 3.153374433517456, Last rpr Loss: 0.9998703598976135, Last lagvar Loss: 0.875628650188446\n",
      "Step 2719/10000- lr: [7.352535842424243e-06] - Loss total: 3.152857542037964, Last rpr Loss: 1.0000439882278442, Last lagvar Loss: 0.8754101395606995\n",
      "Step 2720/10000- lr: [7.351525745454546e-06] - Loss total: 3.1523425579071045, Last rpr Loss: 0.9995758533477783, Last lagvar Loss: 0.8758431077003479\n",
      "Step 2721/10000- lr: [7.3505156484848495e-06] - Loss total: 3.151829957962036, Last rpr Loss: 0.9994838237762451, Last lagvar Loss: 0.875909686088562\n",
      "Step 2722/10000- lr: [7.349505551515152e-06] - Loss total: 3.151320457458496, Last rpr Loss: 0.9998817443847656, Last lagvar Loss: 0.8754923343658447\n",
      "Step 2723/10000- lr: [7.348495454545455e-06] - Loss total: 3.1508121490478516, Last rpr Loss: 0.9998791217803955, Last lagvar Loss: 0.87547767162323\n",
      "Step 2724/10000- lr: [7.347485357575758e-06] - Loss total: 3.150306463241577, Last rpr Loss: 0.99955153465271, Last lagvar Loss: 0.8757928609848022\n",
      "Step 2725/10000- lr: [7.346475260606061e-06] - Loss total: 3.14980149269104, Last rpr Loss: 0.9996083378791809, Last lagvar Loss: 0.8757224678993225\n",
      "Step 2726/10000- lr: [7.345465163636364e-06] - Loss total: 3.1492984294891357, Last rpr Loss: 0.9998265504837036, Last lagvar Loss: 0.8754926919937134\n",
      "Step 2727/10000- lr: [7.3444550666666674e-06] - Loss total: 3.1487951278686523, Last rpr Loss: 0.9996023178100586, Last lagvar Loss: 0.8757046461105347\n",
      "Step 2728/10000- lr: [7.343444969696971e-06] - Loss total: 3.1482937335968018, Last rpr Loss: 0.9993531703948975, Last lagvar Loss: 0.8759427070617676\n",
      "Step 2729/10000- lr: [7.342434872727273e-06] - Loss total: 3.147792100906372, Last rpr Loss: 0.9995504021644592, Last lagvar Loss: 0.8757301568984985\n",
      "Step 2730/10000- lr: [7.3414247757575764e-06] - Loss total: 3.147292137145996, Last rpr Loss: 0.9997329115867615, Last lagvar Loss: 0.8755329251289368\n",
      "Step 2731/10000- lr: [7.340414678787879e-06] - Loss total: 3.146791696548462, Last rpr Loss: 0.9996055364608765, Last lagvar Loss: 0.8756451606750488\n",
      "Step 2732/10000- lr: [7.339404581818182e-06] - Loss total: 3.146291732788086, Last rpr Loss: 0.9996631741523743, Last lagvar Loss: 0.8755719065666199\n",
      "Step 2733/10000- lr: [7.338394484848485e-06] - Loss total: 3.145792245864868, Last rpr Loss: 0.9999287724494934, Last lagvar Loss: 0.87529057264328\n",
      "Step 2734/10000- lr: [7.337384387878789e-06] - Loss total: 3.1452934741973877, Last rpr Loss: 0.9999117851257324, Last lagvar Loss: 0.8752922415733337\n",
      "Step 2735/10000- lr: [7.336374290909092e-06] - Loss total: 3.1447949409484863, Last rpr Loss: 0.9997402429580688, Last lagvar Loss: 0.875449538230896\n",
      "Step 2736/10000- lr: [7.335364193939394e-06] - Loss total: 3.144296646118164, Last rpr Loss: 0.9997779130935669, Last lagvar Loss: 0.8753975033760071\n",
      "Step 2737/10000- lr: [7.334354096969697e-06] - Loss total: 3.143799066543579, Last rpr Loss: 0.9998348951339722, Last lagvar Loss: 0.875327467918396\n",
      "Step 2738/10000- lr: [7.333344e-06] - Loss total: 3.1433019638061523, Last rpr Loss: 0.9997007846832275, Last lagvar Loss: 0.87544846534729\n",
      "Step 2739/10000- lr: [7.332333903030303e-06] - Loss total: 3.1428050994873047, Last rpr Loss: 0.9996294975280762, Last lagvar Loss: 0.8755075931549072\n",
      "Step 2740/10000- lr: [7.331323806060607e-06] - Loss total: 3.1423087120056152, Last rpr Loss: 0.9997422695159912, Last lagvar Loss: 0.8753824234008789\n",
      "Step 2741/10000- lr: [7.33031370909091e-06] - Loss total: 3.141812562942505, Last rpr Loss: 0.9997765421867371, Last lagvar Loss: 0.8753368258476257\n",
      "Step 2742/10000- lr: [7.329303612121212e-06] - Loss total: 3.1413164138793945, Last rpr Loss: 0.9996805191040039, Last lagvar Loss: 0.8754218816757202\n",
      "Step 2743/10000- lr: [7.328293515151516e-06] - Loss total: 3.1408209800720215, Last rpr Loss: 0.9997093081474304, Last lagvar Loss: 0.8753821849822998\n",
      "Step 2744/10000- lr: [7.327283418181818e-06] - Loss total: 3.1403260231018066, Last rpr Loss: 0.999813437461853, Last lagvar Loss: 0.8752675652503967\n",
      "Step 2745/10000- lr: [7.326273321212121e-06] - Loss total: 3.1398305892944336, Last rpr Loss: 0.9997662901878357, Last lagvar Loss: 0.8753044605255127\n",
      "Step 2746/10000- lr: [7.325263224242425e-06] - Loss total: 3.139336109161377, Last rpr Loss: 0.9997189044952393, Last lagvar Loss: 0.875342071056366\n",
      "Step 2747/10000- lr: [7.324253127272728e-06] - Loss total: 3.138841390609741, Last rpr Loss: 0.9998182654380798, Last lagvar Loss: 0.875232994556427\n",
      "Step 2748/10000- lr: [7.323243030303031e-06] - Loss total: 3.1383471488952637, Last rpr Loss: 0.9998573064804077, Last lagvar Loss: 0.8751848936080933\n",
      "Step 2749/10000- lr: [7.322232933333334e-06] - Loss total: 3.1378533840179443, Last rpr Loss: 0.9997576475143433, Last lagvar Loss: 0.875275731086731\n",
      "Step 2750/10000- lr: [7.321222836363637e-06] - Loss total: 3.137359619140625, Last rpr Loss: 0.9997192025184631, Last lagvar Loss: 0.8753057718276978\n",
      "Step 2751/10000- lr: [7.320212739393939e-06] - Loss total: 3.1368658542633057, Last rpr Loss: 0.9997715950012207, Last lagvar Loss: 0.8752450942993164\n",
      "Step 2752/10000- lr: [7.319202642424243e-06] - Loss total: 3.1363728046417236, Last rpr Loss: 0.9997373223304749, Last lagvar Loss: 0.8752716779708862\n",
      "Step 2753/10000- lr: [7.318192545454546e-06] - Loss total: 3.1358792781829834, Last rpr Loss: 0.9996551871299744, Last lagvar Loss: 0.8753464818000793\n",
      "Step 2754/10000- lr: [7.317182448484849e-06] - Loss total: 3.1353867053985596, Last rpr Loss: 0.9996866583824158, Last lagvar Loss: 0.8753076791763306\n",
      "Step 2755/10000- lr: [7.3161723515151524e-06] - Loss total: 3.134894371032715, Last rpr Loss: 0.9997588992118835, Last lagvar Loss: 0.8752281665802002\n",
      "Step 2756/10000- lr: [7.315162254545455e-06] - Loss total: 3.134401798248291, Last rpr Loss: 0.9997254610061646, Last lagvar Loss: 0.8752546906471252\n",
      "Step 2757/10000- lr: [7.314152157575758e-06] - Loss total: 3.1339097023010254, Last rpr Loss: 0.9996829032897949, Last lagvar Loss: 0.8752905130386353\n",
      "Step 2758/10000- lr: [7.3131420606060606e-06] - Loss total: 3.1334176063537598, Last rpr Loss: 0.9997354745864868, Last lagvar Loss: 0.8752313256263733\n",
      "Step 2759/10000- lr: [7.312131963636364e-06] - Loss total: 3.1329257488250732, Last rpr Loss: 0.9997607469558716, Last lagvar Loss: 0.8751994371414185\n",
      "Step 2760/10000- lr: [7.311121866666667e-06] - Loss total: 3.132434368133545, Last rpr Loss: 0.9996947050094604, Last lagvar Loss: 0.875259280204773\n",
      "Step 2761/10000- lr: [7.31011176969697e-06] - Loss total: 3.1319429874420166, Last rpr Loss: 0.9996858239173889, Last lagvar Loss: 0.8752619624137878\n",
      "Step 2762/10000- lr: [7.309101672727274e-06] - Loss total: 3.1314518451690674, Last rpr Loss: 0.9997550249099731, Last lagvar Loss: 0.8751865029335022\n",
      "Step 2763/10000- lr: [7.308091575757576e-06] - Loss total: 3.130960702896118, Last rpr Loss: 0.9997609853744507, Last lagvar Loss: 0.8751746416091919\n",
      "Step 2764/10000- lr: [7.3070814787878785e-06] - Loss total: 3.130469799041748, Last rpr Loss: 0.9997221231460571, Last lagvar Loss: 0.8752076625823975\n",
      "Step 2765/10000- lr: [7.306071381818182e-06] - Loss total: 3.129979372024536, Last rpr Loss: 0.999752402305603, Last lagvar Loss: 0.875171422958374\n",
      "Step 2766/10000- lr: [7.305061284848485e-06] - Loss total: 3.129488706588745, Last rpr Loss: 0.9997909069061279, Last lagvar Loss: 0.8751273155212402\n",
      "Step 2767/10000- lr: [7.304051187878788e-06] - Loss total: 3.1289985179901123, Last rpr Loss: 0.9997484087944031, Last lagvar Loss: 0.875164270401001\n",
      "Step 2768/10000- lr: [7.303041090909092e-06] - Loss total: 3.1285088062286377, Last rpr Loss: 0.9997081756591797, Last lagvar Loss: 0.8751992583274841\n",
      "Step 2769/10000- lr: [7.302030993939394e-06] - Loss total: 3.128018379211426, Last rpr Loss: 0.9997385740280151, Last lagvar Loss: 0.8751633167266846\n",
      "Step 2770/10000- lr: [7.301020896969697e-06] - Loss total: 3.1275289058685303, Last rpr Loss: 0.9997538328170776, Last lagvar Loss: 0.8751429319381714\n",
      "Step 2771/10000- lr: [7.3000108e-06] - Loss total: 3.1270394325256348, Last rpr Loss: 0.9997233152389526, Last lagvar Loss: 0.8751684427261353\n",
      "Step 2772/10000- lr: [7.299000703030303e-06] - Loss total: 3.126549482345581, Last rpr Loss: 0.999729573726654, Last lagvar Loss: 0.8751569390296936\n",
      "Step 2773/10000- lr: [7.297990606060606e-06] - Loss total: 3.126060724258423, Last rpr Loss: 0.9997735023498535, Last lagvar Loss: 0.875108003616333\n",
      "Step 2774/10000- lr: [7.29698050909091e-06] - Loss total: 3.1255710124969482, Last rpr Loss: 0.9997701048851013, Last lagvar Loss: 0.8751065135002136\n",
      "Step 2775/10000- lr: [7.295970412121213e-06] - Loss total: 3.125082492828369, Last rpr Loss: 0.9997479319572449, Last lagvar Loss: 0.8751237392425537\n",
      "Step 2776/10000- lr: [7.294960315151515e-06] - Loss total: 3.1245932579040527, Last rpr Loss: 0.9997783899307251, Last lagvar Loss: 0.8750883340835571\n",
      "Step 2777/10000- lr: [7.293950218181819e-06] - Loss total: 3.1241047382354736, Last rpr Loss: 0.9997954964637756, Last lagvar Loss: 0.875066339969635\n",
      "Step 2778/10000- lr: [7.292940121212121e-06] - Loss total: 3.1236162185668945, Last rpr Loss: 0.9997730255126953, Last lagvar Loss: 0.8750840425491333\n",
      "Step 2779/10000- lr: [7.291930024242424e-06] - Loss total: 3.1231276988983154, Last rpr Loss: 0.9997720718383789, Last lagvar Loss: 0.8750801086425781\n",
      "Step 2780/10000- lr: [7.290919927272728e-06] - Loss total: 3.1226396560668945, Last rpr Loss: 0.9997818470001221, Last lagvar Loss: 0.8750655651092529\n",
      "Step 2781/10000- lr: [7.289909830303031e-06] - Loss total: 3.1221516132354736, Last rpr Loss: 0.9997731447219849, Last lagvar Loss: 0.8750693798065186\n",
      "Step 2782/10000- lr: [7.288899733333334e-06] - Loss total: 3.1216633319854736, Last rpr Loss: 0.9997533559799194, Last lagvar Loss: 0.875084638595581\n",
      "Step 2783/10000- lr: [7.2878896363636366e-06] - Loss total: 3.121175527572632, Last rpr Loss: 0.9997445344924927, Last lagvar Loss: 0.8750886917114258\n",
      "Step 2784/10000- lr: [7.286879539393939e-06] - Loss total: 3.120687961578369, Last rpr Loss: 0.9997570514678955, Last lagvar Loss: 0.8750714063644409\n",
      "Step 2785/10000- lr: [7.285869442424242e-06] - Loss total: 3.1202003955841064, Last rpr Loss: 0.9997496604919434, Last lagvar Loss: 0.8750741481781006\n",
      "Step 2786/10000- lr: [7.2848593454545455e-06] - Loss total: 3.1197128295898438, Last rpr Loss: 0.9997467994689941, Last lagvar Loss: 0.8750723600387573\n",
      "Step 2787/10000- lr: [7.283849248484849e-06] - Loss total: 3.119225263595581, Last rpr Loss: 0.9997740983963013, Last lagvar Loss: 0.8750404715538025\n",
      "Step 2788/10000- lr: [7.282839151515152e-06] - Loss total: 3.118738889694214, Last rpr Loss: 0.9997764229774475, Last lagvar Loss: 0.8750334978103638\n",
      "Step 2789/10000- lr: [7.281829054545455e-06] - Loss total: 3.118251085281372, Last rpr Loss: 0.9997719526290894, Last lagvar Loss: 0.8750333786010742\n",
      "Step 2790/10000- lr: [7.280818957575759e-06] - Loss total: 3.117764472961426, Last rpr Loss: 0.9997808933258057, Last lagvar Loss: 0.8750197887420654\n",
      "Step 2791/10000- lr: [7.279808860606061e-06] - Loss total: 3.1172780990600586, Last rpr Loss: 0.9997775554656982, Last lagvar Loss: 0.8750185370445251\n",
      "Step 2792/10000- lr: [7.278798763636364e-06] - Loss total: 3.116791248321533, Last rpr Loss: 0.999767541885376, Last lagvar Loss: 0.8750239610671997\n",
      "Step 2793/10000- lr: [7.277788666666667e-06] - Loss total: 3.116304636001587, Last rpr Loss: 0.9997575283050537, Last lagvar Loss: 0.8750293850898743\n",
      "Step 2794/10000- lr: [7.27677856969697e-06] - Loss total: 3.1158182621002197, Last rpr Loss: 0.9997557997703552, Last lagvar Loss: 0.8750264644622803\n",
      "Step 2795/10000- lr: [7.275768472727273e-06] - Loss total: 3.1153321266174316, Last rpr Loss: 0.999756932258606, Last lagvar Loss: 0.8750208616256714\n",
      "Step 2796/10000- lr: [7.274758375757577e-06] - Loss total: 3.1148464679718018, Last rpr Loss: 0.9997437000274658, Last lagvar Loss: 0.875029444694519\n",
      "Step 2797/10000- lr: [7.27374827878788e-06] - Loss total: 3.1143600940704346, Last rpr Loss: 0.9997457265853882, Last lagvar Loss: 0.8750228881835938\n",
      "Step 2798/10000- lr: [7.272738181818182e-06] - Loss total: 3.1138744354248047, Last rpr Loss: 0.999754786491394, Last lagvar Loss: 0.875009298324585\n",
      "Step 2799/10000- lr: [7.271728084848486e-06] - Loss total: 3.113388776779175, Last rpr Loss: 0.9997520446777344, Last lagvar Loss: 0.8750075697898865\n",
      "Step 2800/10000- lr: [7.270717987878788e-06] - Loss total: 3.112903594970703, Last rpr Loss: 0.9997551441192627, Last lagvar Loss: 0.875\n",
      "Step 2801/10000- lr: [7.269707890909091e-06] - Loss total: 3.1124181747436523, Last rpr Loss: 0.9997689127922058, Last lagvar Loss: 0.8749818801879883\n",
      "Step 2802/10000- lr: [7.268697793939395e-06] - Loss total: 3.1119329929351807, Last rpr Loss: 0.9997686743736267, Last lagvar Loss: 0.8749776482582092\n",
      "Step 2803/10000- lr: [7.267687696969698e-06] - Loss total: 3.11144757270813, Last rpr Loss: 0.9997655749320984, Last lagvar Loss: 0.874976396560669\n",
      "Step 2804/10000- lr: [7.266677600000001e-06] - Loss total: 3.1109631061553955, Last rpr Loss: 0.9997730255126953, Last lagvar Loss: 0.8749645352363586\n",
      "Step 2805/10000- lr: [7.2656675030303036e-06] - Loss total: 3.110478639602661, Last rpr Loss: 0.9997696280479431, Last lagvar Loss: 0.8749635815620422\n",
      "Step 2806/10000- lr: [7.264657406060607e-06] - Loss total: 3.1099939346313477, Last rpr Loss: 0.9997736215591431, Last lagvar Loss: 0.8749552965164185\n",
      "Step 2807/10000- lr: [7.263647309090909e-06] - Loss total: 3.1095097064971924, Last rpr Loss: 0.99976646900177, Last lagvar Loss: 0.8749580383300781\n",
      "Step 2808/10000- lr: [7.2626372121212126e-06] - Loss total: 3.109025239944458, Last rpr Loss: 0.9997649192810059, Last lagvar Loss: 0.8749553561210632\n",
      "Step 2809/10000- lr: [7.261627115151516e-06] - Loss total: 3.108541488647461, Last rpr Loss: 0.9997733235359192, Last lagvar Loss: 0.8749426603317261\n",
      "Step 2810/10000- lr: [7.260617018181819e-06] - Loss total: 3.108057737350464, Last rpr Loss: 0.9997650980949402, Last lagvar Loss: 0.8749467134475708\n",
      "Step 2811/10000- lr: [7.259606921212122e-06] - Loss total: 3.107573986053467, Last rpr Loss: 0.9997649192810059, Last lagvar Loss: 0.8749426603317261\n",
      "Step 2812/10000- lr: [7.258596824242425e-06] - Loss total: 3.107090473175049, Last rpr Loss: 0.9997780323028564, Last lagvar Loss: 0.8749251961708069\n",
      "Step 2813/10000- lr: [7.257586727272727e-06] - Loss total: 3.1066067218780518, Last rpr Loss: 0.9997690916061401, Last lagvar Loss: 0.8749298453330994\n",
      "Step 2814/10000- lr: [7.2565766303030305e-06] - Loss total: 3.106123924255371, Last rpr Loss: 0.9997692108154297, Last lagvar Loss: 0.8749256134033203\n",
      "Step 2815/10000- lr: [7.255566533333334e-06] - Loss total: 3.1056408882141113, Last rpr Loss: 0.9997768998146057, Last lagvar Loss: 0.8749135732650757\n",
      "Step 2816/10000- lr: [7.254556436363637e-06] - Loss total: 3.1051580905914307, Last rpr Loss: 0.9997711181640625, Last lagvar Loss: 0.8749152421951294\n",
      "Step 2817/10000- lr: [7.25354633939394e-06] - Loss total: 3.104675531387329, Last rpr Loss: 0.9997723698616028, Last lagvar Loss: 0.8749098777770996\n",
      "Step 2818/10000- lr: [7.252536242424243e-06] - Loss total: 3.1041929721832275, Last rpr Loss: 0.9997786283493042, Last lagvar Loss: 0.8748993277549744\n",
      "Step 2819/10000- lr: [7.251526145454546e-06] - Loss total: 3.1037111282348633, Last rpr Loss: 0.9997749924659729, Last lagvar Loss: 0.8748988509178162\n",
      "Step 2820/10000- lr: [7.2505160484848485e-06] - Loss total: 3.10322904586792, Last rpr Loss: 0.9997813105583191, Last lagvar Loss: 0.8748883605003357\n",
      "Step 2821/10000- lr: [7.249505951515152e-06] - Loss total: 3.1027469635009766, Last rpr Loss: 0.9997774362564087, Last lagvar Loss: 0.8748880624771118\n",
      "Step 2822/10000- lr: [7.248495854545455e-06] - Loss total: 3.1022655963897705, Last rpr Loss: 0.9997754096984863, Last lagvar Loss: 0.8748860359191895\n",
      "Step 2823/10000- lr: [7.247485757575758e-06] - Loss total: 3.1017837524414062, Last rpr Loss: 0.9997830390930176, Last lagvar Loss: 0.8748742341995239\n",
      "Step 2824/10000- lr: [7.246475660606062e-06] - Loss total: 3.1013023853302, Last rpr Loss: 0.9997733235359192, Last lagvar Loss: 0.8748798370361328\n",
      "Step 2825/10000- lr: [7.245465563636364e-06] - Loss total: 3.1008214950561523, Last rpr Loss: 0.9997796416282654, Last lagvar Loss: 0.8748695850372314\n",
      "Step 2826/10000- lr: [7.244455466666667e-06] - Loss total: 3.1003401279449463, Last rpr Loss: 0.9997841715812683, Last lagvar Loss: 0.8748608827590942\n",
      "Step 2827/10000- lr: [7.24344536969697e-06] - Loss total: 3.0998597145080566, Last rpr Loss: 0.9997745156288147, Last lagvar Loss: 0.8748666048049927\n",
      "Step 2828/10000- lr: [7.242435272727273e-06] - Loss total: 3.099378824234009, Last rpr Loss: 0.9997818470001221, Last lagvar Loss: 0.8748551607131958\n",
      "Step 2829/10000- lr: [7.241425175757576e-06] - Loss total: 3.098898410797119, Last rpr Loss: 0.999783992767334, Last lagvar Loss: 0.8748490810394287\n",
      "Step 2830/10000- lr: [7.2404150787878796e-06] - Loss total: 3.0984184741973877, Last rpr Loss: 0.9997779130935669, Last lagvar Loss: 0.8748511075973511\n",
      "Step 2831/10000- lr: [7.239404981818183e-06] - Loss total: 3.097938299179077, Last rpr Loss: 0.9997851848602295, Last lagvar Loss: 0.8748399019241333\n",
      "Step 2832/10000- lr: [7.238394884848485e-06] - Loss total: 3.0974581241607666, Last rpr Loss: 0.999775767326355, Last lagvar Loss: 0.8748454451560974\n",
      "Step 2833/10000- lr: [7.237384787878788e-06] - Loss total: 3.0969784259796143, Last rpr Loss: 0.9997838139533997, Last lagvar Loss: 0.8748334646224976\n",
      "Step 2834/10000- lr: [7.236374690909091e-06] - Loss total: 3.096498727798462, Last rpr Loss: 0.9997884035110474, Last lagvar Loss: 0.8748250007629395\n",
      "Step 2835/10000- lr: [7.235364593939394e-06] - Loss total: 3.0960190296173096, Last rpr Loss: 0.9997802376747131, Last lagvar Loss: 0.8748292922973633\n",
      "Step 2836/10000- lr: [7.2343544969696975e-06] - Loss total: 3.0955400466918945, Last rpr Loss: 0.9997878074645996, Last lagvar Loss: 0.8748178482055664\n",
      "Step 2837/10000- lr: [7.233344400000001e-06] - Loss total: 3.0950610637664795, Last rpr Loss: 0.9997846484184265, Last lagvar Loss: 0.8748171925544739\n",
      "Step 2838/10000- lr: [7.232334303030303e-06] - Loss total: 3.0945816040039062, Last rpr Loss: 0.9997817873954773, Last lagvar Loss: 0.8748162388801575\n",
      "Step 2839/10000- lr: [7.2313242060606065e-06] - Loss total: 3.094102382659912, Last rpr Loss: 0.9997886419296265, Last lagvar Loss: 0.8748056292533875\n",
      "Step 2840/10000- lr: [7.230314109090909e-06] - Loss total: 3.0936238765716553, Last rpr Loss: 0.9997847676277161, Last lagvar Loss: 0.874805748462677\n",
      "Step 2841/10000- lr: [7.229304012121212e-06] - Loss total: 3.0931451320648193, Last rpr Loss: 0.9997850060462952, Last lagvar Loss: 0.874801754951477\n",
      "Step 2842/10000- lr: [7.2282939151515155e-06] - Loss total: 3.0926666259765625, Last rpr Loss: 0.9997889399528503, Last lagvar Loss: 0.8747940063476562\n",
      "Step 2843/10000- lr: [7.227283818181819e-06] - Loss total: 3.092188596725464, Last rpr Loss: 0.9997856616973877, Last lagvar Loss: 0.8747937679290771\n",
      "Step 2844/10000- lr: [7.226273721212122e-06] - Loss total: 3.091710329055786, Last rpr Loss: 0.9997920393943787, Last lagvar Loss: 0.8747836351394653\n",
      "Step 2845/10000- lr: [7.2252636242424245e-06] - Loss total: 3.09123158454895, Last rpr Loss: 0.9997889995574951, Last lagvar Loss: 0.8747830390930176\n",
      "Step 2846/10000- lr: [7.224253527272728e-06] - Loss total: 3.0907535552978516, Last rpr Loss: 0.9997904300689697, Last lagvar Loss: 0.8747779726982117\n",
      "Step 2847/10000- lr: [7.22324343030303e-06] - Loss total: 3.090275764465332, Last rpr Loss: 0.9997907280921936, Last lagvar Loss: 0.8747739791870117\n",
      "Step 2848/10000- lr: [7.2222333333333335e-06] - Loss total: 3.0897977352142334, Last rpr Loss: 0.9997847080230713, Last lagvar Loss: 0.8747763633728027\n",
      "Step 2849/10000- lr: [7.221223236363637e-06] - Loss total: 3.089320421218872, Last rpr Loss: 0.9997903108596802, Last lagvar Loss: 0.8747671842575073\n",
      "Step 2850/10000- lr: [7.22021313939394e-06] - Loss total: 3.0888426303863525, Last rpr Loss: 0.9997913837432861, Last lagvar Loss: 0.8747625946998596\n",
      "Step 2851/10000- lr: [7.219203042424243e-06] - Loss total: 3.088364839553833, Last rpr Loss: 0.9997881650924683, Last lagvar Loss: 0.874762237071991\n",
      "Step 2852/10000- lr: [7.218192945454546e-06] - Loss total: 3.087887763977051, Last rpr Loss: 0.9997957348823547, Last lagvar Loss: 0.8747512102127075\n",
      "Step 2853/10000- lr: [7.217182848484848e-06] - Loss total: 3.0874102115631104, Last rpr Loss: 0.9997918009757996, Last lagvar Loss: 0.8747515082359314\n",
      "Step 2854/10000- lr: [7.2161727515151514e-06] - Loss total: 3.086932897567749, Last rpr Loss: 0.9997918009757996, Last lagvar Loss: 0.8747479915618896\n",
      "Step 2855/10000- lr: [7.215162654545455e-06] - Loss total: 3.086456775665283, Last rpr Loss: 0.9997942447662354, Last lagvar Loss: 0.8747420310974121\n",
      "Step 2856/10000- lr: [7.214152557575758e-06] - Loss total: 3.0859792232513428, Last rpr Loss: 0.9997895956039429, Last lagvar Loss: 0.8747432231903076\n",
      "Step 2857/10000- lr: [7.213142460606061e-06] - Loss total: 3.085502862930298, Last rpr Loss: 0.9997946619987488, Last lagvar Loss: 0.8747346997261047\n",
      "Step 2858/10000- lr: [7.212132363636364e-06] - Loss total: 3.085026502609253, Last rpr Loss: 0.9997969269752502, Last lagvar Loss: 0.8747289180755615\n",
      "Step 2859/10000- lr: [7.211122266666667e-06] - Loss total: 3.08454966545105, Last rpr Loss: 0.9997918605804443, Last lagvar Loss: 0.8747305870056152\n",
      "Step 2860/10000- lr: [7.210112169696969e-06] - Loss total: 3.084073781967163, Last rpr Loss: 0.9997982382774353, Last lagvar Loss: 0.8747206926345825\n",
      "Step 2861/10000- lr: [7.209102072727273e-06] - Loss total: 3.0835981369018555, Last rpr Loss: 0.9997940063476562, Last lagvar Loss: 0.8747215270996094\n",
      "Step 2862/10000- lr: [7.208091975757576e-06] - Loss total: 3.0831217765808105, Last rpr Loss: 0.9997955560684204, Last lagvar Loss: 0.8747165203094482\n",
      "Step 2863/10000- lr: [7.207081878787879e-06] - Loss total: 3.082646369934082, Last rpr Loss: 0.9997990727424622, Last lagvar Loss: 0.8747094869613647\n",
      "Step 2864/10000- lr: [7.2060717818181825e-06] - Loss total: 3.0821712017059326, Last rpr Loss: 0.9997949600219727, Last lagvar Loss: 0.8747100830078125\n",
      "Step 2865/10000- lr: [7.205061684848485e-06] - Loss total: 3.081695795059204, Last rpr Loss: 0.9997982382774353, Last lagvar Loss: 0.8747035264968872\n",
      "Step 2866/10000- lr: [7.204051587878788e-06] - Loss total: 3.081221103668213, Last rpr Loss: 0.999799370765686, Last lagvar Loss: 0.8746989965438843\n",
      "Step 2867/10000- lr: [7.203041490909091e-06] - Loss total: 3.0807464122772217, Last rpr Loss: 0.9997953176498413, Last lagvar Loss: 0.8746995329856873\n",
      "Step 2868/10000- lr: [7.202031393939394e-06] - Loss total: 3.0802719593048096, Last rpr Loss: 0.9998008012771606, Last lagvar Loss: 0.8746907711029053\n",
      "Step 2869/10000- lr: [7.201021296969697e-06] - Loss total: 3.0797975063323975, Last rpr Loss: 0.9998010993003845, Last lagvar Loss: 0.8746869564056396\n",
      "Step 2870/10000- lr: [7.2000112000000005e-06] - Loss total: 3.0793237686157227, Last rpr Loss: 0.999799370765686, Last lagvar Loss: 0.8746852874755859\n",
      "Step 2871/10000- lr: [7.199001103030304e-06] - Loss total: 3.078850269317627, Last rpr Loss: 0.9998048543930054, Last lagvar Loss: 0.8746764659881592\n",
      "Step 2872/10000- lr: [7.197991006060607e-06] - Loss total: 3.078376531600952, Last rpr Loss: 0.9997989535331726, Last lagvar Loss: 0.8746789693832397\n",
      "Step 2873/10000- lr: [7.19698090909091e-06] - Loss total: 3.0779032707214355, Last rpr Loss: 0.9997996091842651, Last lagvar Loss: 0.8746748566627502\n",
      "Step 2874/10000- lr: [7.195970812121213e-06] - Loss total: 3.077430248260498, Last rpr Loss: 0.9998047351837158, Last lagvar Loss: 0.8746663331985474\n",
      "Step 2875/10000- lr: [7.194960715151516e-06] - Loss total: 3.076957941055298, Last rpr Loss: 0.9997998476028442, Last lagvar Loss: 0.8746678829193115\n",
      "Step 2876/10000- lr: [7.1939506181818185e-06] - Loss total: 3.0764853954315186, Last rpr Loss: 0.9998031854629517, Last lagvar Loss: 0.8746610879898071\n",
      "Step 2877/10000- lr: [7.192940521212122e-06] - Loss total: 3.0760130882263184, Last rpr Loss: 0.9998010993003845, Last lagvar Loss: 0.8746598362922668\n",
      "Step 2878/10000- lr: [7.191930424242425e-06] - Loss total: 3.0755417346954346, Last rpr Loss: 0.9998026490211487, Last lagvar Loss: 0.8746548891067505\n",
      "Step 2879/10000- lr: [7.190920327272728e-06] - Loss total: 3.0750696659088135, Last rpr Loss: 0.9998055696487427, Last lagvar Loss: 0.8746486306190491\n",
      "Step 2880/10000- lr: [7.1899102303030316e-06] - Loss total: 3.074598550796509, Last rpr Loss: 0.9998034238815308, Last lagvar Loss: 0.874647319316864\n",
      "Step 2881/10000- lr: [7.188900133333334e-06] - Loss total: 3.074127435684204, Last rpr Loss: 0.9998055696487427, Last lagvar Loss: 0.8746417760848999\n",
      "Step 2882/10000- lr: [7.1878900363636364e-06] - Loss total: 3.0736567974090576, Last rpr Loss: 0.999802827835083, Last lagvar Loss: 0.8746411204338074\n",
      "Step 2883/10000- lr: [7.18687993939394e-06] - Loss total: 3.073186159133911, Last rpr Loss: 0.9998041391372681, Last lagvar Loss: 0.8746364116668701\n",
      "Step 2884/10000- lr: [7.185869842424243e-06] - Loss total: 3.072716236114502, Last rpr Loss: 0.9998047351837158, Last lagvar Loss: 0.8746325373649597\n",
      "Step 2885/10000- lr: [7.184859745454546e-06] - Loss total: 3.0722458362579346, Last rpr Loss: 0.9998049139976501, Last lagvar Loss: 0.874629020690918\n",
      "Step 2886/10000- lr: [7.1838496484848495e-06] - Loss total: 3.0717761516571045, Last rpr Loss: 0.9998025894165039, Last lagvar Loss: 0.8746280670166016\n",
      "Step 2887/10000- lr: [7.182839551515152e-06] - Loss total: 3.0713067054748535, Last rpr Loss: 0.9998052716255188, Last lagvar Loss: 0.8746219277381897\n",
      "Step 2888/10000- lr: [7.181829454545455e-06] - Loss total: 3.0708377361297607, Last rpr Loss: 0.9998061656951904, Last lagvar Loss: 0.8746177554130554\n",
      "Step 2889/10000- lr: [7.180819357575758e-06] - Loss total: 3.070368528366089, Last rpr Loss: 0.999803364276886, Last lagvar Loss: 0.8746171593666077\n",
      "Step 2890/10000- lr: [7.179809260606061e-06] - Loss total: 3.069899559020996, Last rpr Loss: 0.9998048543930054, Last lagvar Loss: 0.8746122717857361\n",
      "Step 2891/10000- lr: [7.178799163636364e-06] - Loss total: 3.0694313049316406, Last rpr Loss: 0.9998041391372681, Last lagvar Loss: 0.8746097087860107\n",
      "Step 2892/10000- lr: [7.1777890666666675e-06] - Loss total: 3.068963050842285, Last rpr Loss: 0.9998059272766113, Last lagvar Loss: 0.8746045827865601\n",
      "Step 2893/10000- lr: [7.176778969696971e-06] - Loss total: 3.0684945583343506, Last rpr Loss: 0.9998056888580322, Last lagvar Loss: 0.8746014833450317\n",
      "Step 2894/10000- lr: [7.175768872727273e-06] - Loss total: 3.0680267810821533, Last rpr Loss: 0.9998077154159546, Last lagvar Loss: 0.8745960593223572\n",
      "Step 2895/10000- lr: [7.1747587757575765e-06] - Loss total: 3.0675594806671143, Last rpr Loss: 0.9998041391372681, Last lagvar Loss: 0.8745964765548706\n",
      "Step 2896/10000- lr: [7.173748678787879e-06] - Loss total: 3.067091703414917, Last rpr Loss: 0.9998092651367188, Last lagvar Loss: 0.8745880126953125\n",
      "Step 2897/10000- lr: [7.172738581818182e-06] - Loss total: 3.066624879837036, Last rpr Loss: 0.9998054504394531, Last lagvar Loss: 0.8745884895324707\n",
      "Step 2898/10000- lr: [7.1717284848484855e-06] - Loss total: 3.066157817840576, Last rpr Loss: 0.999801516532898, Last lagvar Loss: 0.8745890855789185\n",
      "Step 2899/10000- lr: [7.170718387878789e-06] - Loss total: 3.0656912326812744, Last rpr Loss: 0.9998080730438232, Last lagvar Loss: 0.8745793104171753\n",
      "Step 2900/10000- lr: [7.169708290909092e-06] - Loss total: 3.0652246475219727, Last rpr Loss: 0.9998074173927307, Last lagvar Loss: 0.8745765686035156\n",
      "Step 2901/10000- lr: [7.1686981939393945e-06] - Loss total: 3.06475830078125, Last rpr Loss: 0.9998071193695068, Last lagvar Loss: 0.8745735287666321\n",
      "Step 2902/10000- lr: [7.167688096969697e-06] - Loss total: 3.064291477203369, Last rpr Loss: 0.9998037815093994, Last lagvar Loss: 0.8745735287666321\n",
      "Step 2903/10000- lr: [7.166678e-06] - Loss total: 3.0638256072998047, Last rpr Loss: 0.9998098611831665, Last lagvar Loss: 0.8745641708374023\n",
      "Step 2904/10000- lr: [7.1656679030303034e-06] - Loss total: 3.063359498977661, Last rpr Loss: 0.9998084902763367, Last lagvar Loss: 0.8745623826980591\n",
      "Step 2905/10000- lr: [7.164657806060607e-06] - Loss total: 3.062894105911255, Last rpr Loss: 0.9998054504394531, Last lagvar Loss: 0.8745619654655457\n",
      "Step 2906/10000- lr: [7.16364770909091e-06] - Loss total: 3.0624284744262695, Last rpr Loss: 0.9998105764389038, Last lagvar Loss: 0.8745535612106323\n",
      "Step 2907/10000- lr: [7.1626376121212124e-06] - Loss total: 3.0619630813598633, Last rpr Loss: 0.9998102188110352, Last lagvar Loss: 0.8745505809783936\n",
      "Step 2908/10000- lr: [7.161627515151516e-06] - Loss total: 3.061497926712036, Last rpr Loss: 0.9998074769973755, Last lagvar Loss: 0.8745498657226562\n",
      "Step 2909/10000- lr: [7.160617418181818e-06] - Loss total: 3.061032772064209, Last rpr Loss: 0.9998045563697815, Last lagvar Loss: 0.8745496273040771\n",
      "Step 2910/10000- lr: [7.159607321212121e-06] - Loss total: 3.060567855834961, Last rpr Loss: 0.9998078346252441, Last lagvar Loss: 0.8745430111885071\n",
      "Step 2911/10000- lr: [7.158597224242425e-06] - Loss total: 3.060103178024292, Last rpr Loss: 0.9998089075088501, Last lagvar Loss: 0.8745384216308594\n",
      "Step 2912/10000- lr: [7.157587127272728e-06] - Loss total: 3.059638261795044, Last rpr Loss: 0.9998123049736023, Last lagvar Loss: 0.874531626701355\n",
      "Step 2913/10000- lr: [7.156577030303031e-06] - Loss total: 3.059173822402954, Last rpr Loss: 0.9998061060905457, Last lagvar Loss: 0.8745343685150146\n",
      "Step 2914/10000- lr: [7.155566933333334e-06] - Loss total: 3.0587093830108643, Last rpr Loss: 0.9998095035552979, Last lagvar Loss: 0.8745275735855103\n",
      "Step 2915/10000- lr: [7.154556836363637e-06] - Loss total: 3.0582449436187744, Last rpr Loss: 0.9998071193695068, Last lagvar Loss: 0.8745263814926147\n",
      "Step 2916/10000- lr: [7.153546739393939e-06] - Loss total: 3.0577807426452637, Last rpr Loss: 0.999808669090271, Last lagvar Loss: 0.8745212554931641\n",
      "Step 2917/10000- lr: [7.152536642424243e-06] - Loss total: 3.057316780090332, Last rpr Loss: 0.9998103976249695, Last lagvar Loss: 0.874515950679779\n",
      "Step 2918/10000- lr: [7.151526545454546e-06] - Loss total: 3.0568525791168213, Last rpr Loss: 0.9998072981834412, Last lagvar Loss: 0.8745152950286865\n",
      "Step 2919/10000- lr: [7.150516448484849e-06] - Loss total: 3.0563886165618896, Last rpr Loss: 0.9998064637184143, Last lagvar Loss: 0.8745123744010925\n",
      "Step 2920/10000- lr: [7.1495063515151525e-06] - Loss total: 3.055924892425537, Last rpr Loss: 0.9998065233230591, Last lagvar Loss: 0.8745083808898926\n",
      "Step 2921/10000- lr: [7.148496254545455e-06] - Loss total: 3.0554611682891846, Last rpr Loss: 0.9998060464859009, Last lagvar Loss: 0.8745048642158508\n",
      "Step 2922/10000- lr: [7.147486157575757e-06] - Loss total: 3.054997682571411, Last rpr Loss: 0.9998059272766113, Last lagvar Loss: 0.8745007514953613\n",
      "Step 2923/10000- lr: [7.146476060606061e-06] - Loss total: 3.0545337200164795, Last rpr Loss: 0.9998049736022949, Last lagvar Loss: 0.8744972348213196\n",
      "Step 2924/10000- lr: [7.145465963636364e-06] - Loss total: 3.054070472717285, Last rpr Loss: 0.9998056888580322, Last lagvar Loss: 0.8744919300079346\n",
      "Step 2925/10000- lr: [7.144455866666667e-06] - Loss total: 3.0536065101623535, Last rpr Loss: 0.9998020529747009, Last lagvar Loss: 0.8744906783103943\n",
      "Step 2926/10000- lr: [7.1434457696969705e-06] - Loss total: 3.0531437397003174, Last rpr Loss: 0.999803364276886, Last lagvar Loss: 0.8744841814041138\n",
      "Step 2927/10000- lr: [7.142435672727273e-06] - Loss total: 3.052680015563965, Last rpr Loss: 0.9997988343238831, Last lagvar Loss: 0.8744831085205078\n",
      "Step 2928/10000- lr: [7.141425575757576e-06] - Loss total: 3.0522167682647705, Last rpr Loss: 0.9997968673706055, Last lagvar Loss: 0.8744788765907288\n",
      "Step 2929/10000- lr: [7.140415478787879e-06] - Loss total: 3.051753282546997, Last rpr Loss: 0.9998003244400024, Last lagvar Loss: 0.8744689226150513\n",
      "Step 2930/10000- lr: [7.139405381818182e-06] - Loss total: 3.051290512084961, Last rpr Loss: 0.9997960925102234, Last lagvar Loss: 0.874465823173523\n",
      "Step 2931/10000- lr: [7.138395284848485e-06] - Loss total: 3.0508272647857666, Last rpr Loss: 0.999796986579895, Last lagvar Loss: 0.8744572401046753\n",
      "Step 2932/10000- lr: [7.1373851878787884e-06] - Loss total: 3.0503642559051514, Last rpr Loss: 0.9997936487197876, Last lagvar Loss: 0.8744519948959351\n",
      "Step 2933/10000- lr: [7.136375090909092e-06] - Loss total: 3.049901247024536, Last rpr Loss: 0.9997915029525757, Last lagvar Loss: 0.8744449615478516\n",
      "Step 2934/10000- lr: [7.135364993939394e-06] - Loss total: 3.0494384765625, Last rpr Loss: 0.9997944831848145, Last lagvar Loss: 0.8744325041770935\n",
      "Step 2935/10000- lr: [7.134354896969697e-06] - Loss total: 3.048976421356201, Last rpr Loss: 0.9997907876968384, Last lagvar Loss: 0.8744259476661682\n",
      "Step 2936/10000- lr: [7.1333448e-06] - Loss total: 3.048513889312744, Last rpr Loss: 0.9997950196266174, Last lagvar Loss: 0.8744114637374878\n",
      "Step 2937/10000- lr: [7.132334703030303e-06] - Loss total: 3.0480520725250244, Last rpr Loss: 0.9997923374176025, Last lagvar Loss: 0.874403715133667\n",
      "Step 2938/10000- lr: [7.131324606060606e-06] - Loss total: 3.047590494155884, Last rpr Loss: 0.9997953772544861, Last lagvar Loss: 0.8743906021118164\n",
      "Step 2939/10000- lr: [7.13031450909091e-06] - Loss total: 3.0471291542053223, Last rpr Loss: 0.9998009204864502, Last lagvar Loss: 0.8743753433227539\n",
      "Step 2940/10000- lr: [7.129304412121213e-06] - Loss total: 3.046668291091919, Last rpr Loss: 0.9998011589050293, Last lagvar Loss: 0.8743659257888794\n",
      "Step 2941/10000- lr: [7.128294315151515e-06] - Loss total: 3.046208143234253, Last rpr Loss: 0.9998019933700562, Last lagvar Loss: 0.8743564486503601\n",
      "Step 2942/10000- lr: [7.127284218181818e-06] - Loss total: 3.045748233795166, Last rpr Loss: 0.9998109340667725, Last lagvar Loss: 0.8743393421173096\n",
      "Step 2943/10000- lr: [7.126274121212121e-06] - Loss total: 3.0452888011932373, Last rpr Loss: 0.9998103380203247, Last lagvar Loss: 0.8743324279785156\n",
      "Step 2944/10000- lr: [7.125264024242424e-06] - Loss total: 3.0448296070098877, Last rpr Loss: 0.9998143911361694, Last lagvar Loss: 0.8743213415145874\n",
      "Step 2945/10000- lr: [7.124253927272728e-06] - Loss total: 3.044370174407959, Last rpr Loss: 0.9998189806938171, Last lagvar Loss: 0.8743101358413696\n",
      "Step 2946/10000- lr: [7.123243830303031e-06] - Loss total: 3.043912410736084, Last rpr Loss: 0.9998178482055664, Last lagvar Loss: 0.874305009841919\n",
      "Step 2947/10000- lr: [7.122233733333333e-06] - Loss total: 3.04345440864563, Last rpr Loss: 0.9998191595077515, Last lagvar Loss: 0.8742977380752563\n",
      "Step 2948/10000- lr: [7.121223636363637e-06] - Loss total: 3.042996644973755, Last rpr Loss: 0.999815821647644, Last lagvar Loss: 0.8742951154708862\n",
      "Step 2949/10000- lr: [7.120213539393939e-06] - Loss total: 3.04253888130188, Last rpr Loss: 0.999811053276062, Last lagvar Loss: 0.8742942810058594\n",
      "Step 2950/10000- lr: [7.119203442424242e-06] - Loss total: 3.0420823097229004, Last rpr Loss: 0.9998177289962769, Last lagvar Loss: 0.8742821216583252\n",
      "Step 2951/10000- lr: [7.118193345454546e-06] - Loss total: 3.0416252613067627, Last rpr Loss: 0.9998155832290649, Last lagvar Loss: 0.8742790222167969\n",
      "Step 2952/10000- lr: [7.117183248484849e-06] - Loss total: 3.0411691665649414, Last rpr Loss: 0.9998154640197754, Last lagvar Loss: 0.8742738366127014\n",
      "Step 2953/10000- lr: [7.116173151515152e-06] - Loss total: 3.0407135486602783, Last rpr Loss: 0.9998180866241455, Last lagvar Loss: 0.8742661476135254\n",
      "Step 2954/10000- lr: [7.115163054545455e-06] - Loss total: 3.040257692337036, Last rpr Loss: 0.9998180866241455, Last lagvar Loss: 0.8742609620094299\n",
      "Step 2955/10000- lr: [7.114152957575758e-06] - Loss total: 3.039801836013794, Last rpr Loss: 0.9998278617858887, Last lagvar Loss: 0.87424635887146\n",
      "Step 2956/10000- lr: [7.11314286060606e-06] - Loss total: 3.039346933364868, Last rpr Loss: 0.9998253583908081, Last lagvar Loss: 0.874243974685669\n",
      "Step 2957/10000- lr: [7.1121327636363636e-06] - Loss total: 3.0388920307159424, Last rpr Loss: 0.9998296499252319, Last lagvar Loss: 0.8742348551750183\n",
      "Step 2958/10000- lr: [7.111122666666667e-06] - Loss total: 3.038437843322754, Last rpr Loss: 0.9998348355293274, Last lagvar Loss: 0.8742249608039856\n",
      "Step 2959/10000- lr: [7.11011256969697e-06] - Loss total: 3.0379831790924072, Last rpr Loss: 0.9998281598091125, Last lagvar Loss: 0.8742269277572632\n",
      "Step 2960/10000- lr: [7.109102472727273e-06] - Loss total: 3.037529230117798, Last rpr Loss: 0.9998359084129333, Last lagvar Loss: 0.8742145299911499\n",
      "Step 2961/10000- lr: [7.108092375757577e-06] - Loss total: 3.0370757579803467, Last rpr Loss: 0.9998278617858887, Last lagvar Loss: 0.8742179870605469\n",
      "Step 2962/10000- lr: [7.10708227878788e-06] - Loss total: 3.0366225242614746, Last rpr Loss: 0.9998373985290527, Last lagvar Loss: 0.8742038607597351\n",
      "Step 2963/10000- lr: [7.106072181818182e-06] - Loss total: 3.0361695289611816, Last rpr Loss: 0.9998289346694946, Last lagvar Loss: 0.8742078542709351\n",
      "Step 2964/10000- lr: [7.105062084848486e-06] - Loss total: 3.0357162952423096, Last rpr Loss: 0.9998323917388916, Last lagvar Loss: 0.8741999864578247\n",
      "Step 2965/10000- lr: [7.104051987878788e-06] - Loss total: 3.035264492034912, Last rpr Loss: 0.9998313188552856, Last lagvar Loss: 0.8741965293884277\n",
      "Step 2966/10000- lr: [7.103041890909091e-06] - Loss total: 3.0348122119903564, Last rpr Loss: 0.9998225569725037, Last lagvar Loss: 0.874200701713562\n",
      "Step 2967/10000- lr: [7.102031793939395e-06] - Loss total: 3.03436017036438, Last rpr Loss: 0.9998332858085632, Last lagvar Loss: 0.8741858005523682\n",
      "Step 2968/10000- lr: [7.101021696969698e-06] - Loss total: 3.0339081287384033, Last rpr Loss: 0.9998207092285156, Last lagvar Loss: 0.8741939067840576\n",
      "Step 2969/10000- lr: [7.100011600000001e-06] - Loss total: 3.033456802368164, Last rpr Loss: 0.9998304843902588, Last lagvar Loss: 0.8741798400878906\n",
      "Step 2970/10000- lr: [7.099001503030304e-06] - Loss total: 3.033005714416504, Last rpr Loss: 0.9998242855072021, Last lagvar Loss: 0.8741816282272339\n",
      "Step 2971/10000- lr: [7.097991406060606e-06] - Loss total: 3.0325543880462646, Last rpr Loss: 0.9998286962509155, Last lagvar Loss: 0.8741729259490967\n",
      "Step 2972/10000- lr: [7.096981309090909e-06] - Loss total: 3.0321037769317627, Last rpr Loss: 0.9998350143432617, Last lagvar Loss: 0.8741622567176819\n",
      "Step 2973/10000- lr: [7.095971212121213e-06] - Loss total: 3.0316531658172607, Last rpr Loss: 0.9998327493667603, Last lagvar Loss: 0.8741602897644043\n",
      "Step 2974/10000- lr: [7.094961115151516e-06] - Loss total: 3.031203269958496, Last rpr Loss: 0.9998367428779602, Last lagvar Loss: 0.8741519451141357\n",
      "Step 2975/10000- lr: [7.093951018181819e-06] - Loss total: 3.0307531356811523, Last rpr Loss: 0.999836266040802, Last lagvar Loss: 0.8741481304168701\n",
      "Step 2976/10000- lr: [7.092940921212122e-06] - Loss total: 3.0303032398223877, Last rpr Loss: 0.9998388290405273, Last lagvar Loss: 0.8741410970687866\n",
      "Step 2977/10000- lr: [7.091930824242425e-06] - Loss total: 3.029853343963623, Last rpr Loss: 0.9998409748077393, Last lagvar Loss: 0.8741347193717957\n",
      "Step 2978/10000- lr: [7.090920727272727e-06] - Loss total: 3.0294039249420166, Last rpr Loss: 0.999836802482605, Last lagvar Loss: 0.8741345405578613\n",
      "Step 2979/10000- lr: [7.089910630303031e-06] - Loss total: 3.0289547443389893, Last rpr Loss: 0.9998374581336975, Last lagvar Loss: 0.8741293549537659\n",
      "Step 2980/10000- lr: [7.088900533333334e-06] - Loss total: 3.028505563735962, Last rpr Loss: 0.9998384118080139, Last lagvar Loss: 0.8741239309310913\n",
      "Step 2981/10000- lr: [7.087890436363637e-06] - Loss total: 3.0280566215515137, Last rpr Loss: 0.9998406767845154, Last lagvar Loss: 0.8741171360015869\n",
      "Step 2982/10000- lr: [7.08688033939394e-06] - Loss total: 3.0276079177856445, Last rpr Loss: 0.9998400211334229, Last lagvar Loss: 0.8741133809089661\n",
      "Step 2983/10000- lr: [7.085870242424243e-06] - Loss total: 3.0271592140197754, Last rpr Loss: 0.9998394250869751, Last lagvar Loss: 0.8741093873977661\n",
      "Step 2984/10000- lr: [7.084860145454546e-06] - Loss total: 3.0267105102539062, Last rpr Loss: 0.9998404383659363, Last lagvar Loss: 0.874103844165802\n",
      "Step 2985/10000- lr: [7.0838500484848486e-06] - Loss total: 3.0262627601623535, Last rpr Loss: 0.9998410940170288, Last lagvar Loss: 0.8740986585617065\n",
      "Step 2986/10000- lr: [7.082839951515152e-06] - Loss total: 3.0258147716522217, Last rpr Loss: 0.9998380541801453, Last lagvar Loss: 0.8740971088409424\n",
      "Step 2987/10000- lr: [7.081829854545455e-06] - Loss total: 3.025367021560669, Last rpr Loss: 0.9998438358306885, Last lagvar Loss: 0.8740867376327515\n",
      "Step 2988/10000- lr: [7.080819757575758e-06] - Loss total: 3.024918794631958, Last rpr Loss: 0.9998393654823303, Last lagvar Loss: 0.8740864992141724\n",
      "Step 2989/10000- lr: [7.079809660606062e-06] - Loss total: 3.0244715213775635, Last rpr Loss: 0.9998458027839661, Last lagvar Loss: 0.8740752935409546\n",
      "Step 2990/10000- lr: [7.078799563636364e-06] - Loss total: 3.024024248123169, Last rpr Loss: 0.9998397827148438, Last lagvar Loss: 0.8740767240524292\n",
      "Step 2991/10000- lr: [7.0777894666666665e-06] - Loss total: 3.0235767364501953, Last rpr Loss: 0.9998428821563721, Last lagvar Loss: 0.8740688562393188\n",
      "Step 2992/10000- lr: [7.07677936969697e-06] - Loss total: 3.02312970161438, Last rpr Loss: 0.9998430609703064, Last lagvar Loss: 0.8740638494491577\n",
      "Step 2993/10000- lr: [7.075769272727273e-06] - Loss total: 3.0226829051971436, Last rpr Loss: 0.9998378753662109, Last lagvar Loss: 0.8740642070770264\n",
      "Step 2994/10000- lr: [7.074759175757576e-06] - Loss total: 3.022235631942749, Last rpr Loss: 0.9998500943183899, Last lagvar Loss: 0.8740471601486206\n",
      "Step 2995/10000- lr: [7.07374907878788e-06] - Loss total: 3.0217888355255127, Last rpr Loss: 0.9998436570167542, Last lagvar Loss: 0.8740487098693848\n",
      "Step 2996/10000- lr: [7.072738981818182e-06] - Loss total: 3.0213425159454346, Last rpr Loss: 0.9998425245285034, Last lagvar Loss: 0.87404465675354\n",
      "Step 2997/10000- lr: [7.071728884848485e-06] - Loss total: 3.0208961963653564, Last rpr Loss: 0.9998422861099243, Last lagvar Loss: 0.8740398287773132\n",
      "Step 2998/10000- lr: [7.070718787878788e-06] - Loss total: 3.020449638366699, Last rpr Loss: 0.9998414516448975, Last lagvar Loss: 0.8740353584289551\n",
      "Step 2999/10000- lr: [7.069708690909091e-06] - Loss total: 3.0200035572052, Last rpr Loss: 0.9998431205749512, Last lagvar Loss: 0.8740284442901611\n",
      "Step 3000/10000- lr: [7.068698593939394e-06] - Loss total: 3.019557237625122, Last rpr Loss: 0.99984210729599, Last lagvar Loss: 0.8740240335464478\n",
      "Step 3001/10000- lr: [7.067688496969698e-06] - Loss total: 3.019111156463623, Last rpr Loss: 0.9998502135276794, Last lagvar Loss: 0.8740103244781494\n",
      "Step 3002/10000- lr: [7.066678400000001e-06] - Loss total: 3.0186657905578613, Last rpr Loss: 0.9998443722724915, Last lagvar Loss: 0.874010443687439\n",
      "Step 3003/10000- lr: [7.065668303030303e-06] - Loss total: 3.0182201862335205, Last rpr Loss: 0.9998410940170288, Last lagvar Loss: 0.8740078210830688\n",
      "Step 3004/10000- lr: [7.064658206060607e-06] - Loss total: 3.0177743434906006, Last rpr Loss: 0.9998466968536377, Last lagvar Loss: 0.8739961385726929\n",
      "Step 3005/10000- lr: [7.063648109090909e-06] - Loss total: 3.017329216003418, Last rpr Loss: 0.9998432397842407, Last lagvar Loss: 0.8739935159683228\n",
      "Step 3006/10000- lr: [7.062638012121212e-06] - Loss total: 3.0168840885162354, Last rpr Loss: 0.9998478889465332, Last lagvar Loss: 0.8739825487136841\n",
      "Step 3007/10000- lr: [7.0616279151515156e-06] - Loss total: 3.0164387226104736, Last rpr Loss: 0.9998431205749512, Last lagvar Loss: 0.8739807605743408\n",
      "Step 3008/10000- lr: [7.060617818181819e-06] - Loss total: 3.01599383354187, Last rpr Loss: 0.9998494386672974, Last lagvar Loss: 0.8739675879478455\n",
      "Step 3009/10000- lr: [7.059607721212122e-06] - Loss total: 3.0155489444732666, Last rpr Loss: 0.9998452067375183, Last lagvar Loss: 0.8739648461341858\n",
      "Step 3010/10000- lr: [7.0585976242424246e-06] - Loss total: 3.015103816986084, Last rpr Loss: 0.9998427033424377, Last lagvar Loss: 0.873960018157959\n",
      "Step 3011/10000- lr: [7.057587527272727e-06] - Loss total: 3.0146591663360596, Last rpr Loss: 0.9998519420623779, Last lagvar Loss: 0.8739433288574219\n",
      "Step 3012/10000- lr: [7.05657743030303e-06] - Loss total: 3.014214277267456, Last rpr Loss: 0.9998430609703064, Last lagvar Loss: 0.8739442825317383\n",
      "Step 3013/10000- lr: [7.0555673333333335e-06] - Loss total: 3.0137698650360107, Last rpr Loss: 0.9998517632484436, Last lagvar Loss: 0.8739273548126221\n",
      "Step 3014/10000- lr: [7.054557236363637e-06] - Loss total: 3.0133252143859863, Last rpr Loss: 0.9998507499694824, Last lagvar Loss: 0.8739197254180908\n",
      "Step 3015/10000- lr: [7.05354713939394e-06] - Loss total: 3.012880325317383, Last rpr Loss: 0.9998470544815063, Last lagvar Loss: 0.8739145994186401\n",
      "Step 3016/10000- lr: [7.0525370424242425e-06] - Loss total: 3.0124354362487793, Last rpr Loss: 0.9998626112937927, Last lagvar Loss: 0.8738895058631897\n",
      "Step 3017/10000- lr: [7.051526945454546e-06] - Loss total: 3.011990547180176, Last rpr Loss: 0.9998419880867004, Last lagvar Loss: 0.8738999366760254\n",
      "Step 3018/10000- lr: [7.050516848484848e-06] - Loss total: 3.011544942855835, Last rpr Loss: 0.9998673796653748, Last lagvar Loss: 0.8738635778427124\n",
      "Step 3019/10000- lr: [7.0495067515151515e-06] - Loss total: 3.011099338531494, Last rpr Loss: 0.9998558759689331, Last lagvar Loss: 0.8738631010055542\n",
      "Step 3020/10000- lr: [7.048496654545455e-06] - Loss total: 3.010653018951416, Last rpr Loss: 0.9998698234558105, Last lagvar Loss: 0.8738359212875366\n",
      "Step 3021/10000- lr: [7.047486557575758e-06] - Loss total: 3.0102059841156006, Last rpr Loss: 0.9998694062232971, Last lagvar Loss: 0.8738211393356323\n",
      "Step 3022/10000- lr: [7.046476460606061e-06] - Loss total: 3.009758234024048, Last rpr Loss: 0.9998717904090881, Last lagvar Loss: 0.87380051612854\n",
      "Step 3023/10000- lr: [7.045466363636364e-06] - Loss total: 3.0093095302581787, Last rpr Loss: 0.9998916387557983, Last lagvar Loss: 0.8737579584121704\n",
      "Step 3024/10000- lr: [7.044456266666667e-06] - Loss total: 3.008859634399414, Last rpr Loss: 0.9998762607574463, Last lagvar Loss: 0.8737438917160034\n",
      "Step 3025/10000- lr: [7.0434461696969695e-06] - Loss total: 3.008408784866333, Last rpr Loss: 0.9998998641967773, Last lagvar Loss: 0.8736798763275146\n",
      "Step 3026/10000- lr: [7.042436072727273e-06] - Loss total: 3.007955551147461, Last rpr Loss: 0.9998722076416016, Last lagvar Loss: 0.8736515045166016\n",
      "Step 3027/10000- lr: [7.041425975757576e-06] - Loss total: 3.0075016021728516, Last rpr Loss: 0.9998687505722046, Last lagvar Loss: 0.873579204082489\n",
      "Step 3028/10000- lr: [7.040415878787879e-06] - Loss total: 3.0070457458496094, Last rpr Loss: 0.999854564666748, Last lagvar Loss: 0.8734997510910034\n",
      "Step 3029/10000- lr: [7.039405781818183e-06] - Loss total: 3.0065910816192627, Last rpr Loss: 0.9998654723167419, Last lagvar Loss: 0.8733891844749451\n",
      "Step 3030/10000- lr: [7.038395684848485e-06] - Loss total: 3.0061380863189697, Last rpr Loss: 0.9998998641967773, Last lagvar Loss: 0.8732645511627197\n",
      "Step 3031/10000- lr: [7.0373855878787874e-06] - Loss total: 3.005687713623047, Last rpr Loss: 0.9999253153800964, Last lagvar Loss: 0.8731659650802612\n",
      "Step 3032/10000- lr: [7.036375490909091e-06] - Loss total: 3.0052402019500732, Last rpr Loss: 0.9999436140060425, Last lagvar Loss: 0.8730896711349487\n",
      "Step 3033/10000- lr: [7.035365393939394e-06] - Loss total: 3.0047929286956787, Last rpr Loss: 0.9999173879623413, Last lagvar Loss: 0.8730682134628296\n",
      "Step 3034/10000- lr: [7.034355296969697e-06] - Loss total: 3.004347324371338, Last rpr Loss: 0.9998716711997986, Last lagvar Loss: 0.87307208776474\n",
      "Step 3035/10000- lr: [7.0333452000000006e-06] - Loss total: 3.003901720046997, Last rpr Loss: 0.9998424053192139, Last lagvar Loss: 0.8730625510215759\n",
      "Step 3036/10000- lr: [7.032335103030303e-06] - Loss total: 3.0034563541412354, Last rpr Loss: 0.9998233318328857, Last lagvar Loss: 0.8730446100234985\n",
      "Step 3037/10000- lr: [7.031325006060606e-06] - Loss total: 3.0030112266540527, Last rpr Loss: 0.9998317956924438, Last lagvar Loss: 0.8730001449584961\n",
      "Step 3038/10000- lr: [7.030314909090909e-06] - Loss total: 3.002565622329712, Last rpr Loss: 0.9998440742492676, Last lagvar Loss: 0.8729523420333862\n",
      "Step 3039/10000- lr: [7.029304812121212e-06] - Loss total: 3.0021209716796875, Last rpr Loss: 0.999845027923584, Last lagvar Loss: 0.8729164600372314\n",
      "Step 3040/10000- lr: [7.028294715151515e-06] - Loss total: 3.001676082611084, Last rpr Loss: 0.9998399019241333, Last lagvar Loss: 0.8728868961334229\n",
      "Step 3041/10000- lr: [7.0272846181818185e-06] - Loss total: 3.0012311935424805, Last rpr Loss: 0.999822735786438, Last lagvar Loss: 0.8728697896003723\n",
      "Step 3042/10000- lr: [7.026274521212122e-06] - Loss total: 3.000786781311035, Last rpr Loss: 0.9998251795768738, Last lagvar Loss: 0.8728334903717041\n",
      "Step 3043/10000- lr: [7.025264424242425e-06] - Loss total: 3.0003421306610107, Last rpr Loss: 0.9998369812965393, Last lagvar Loss: 0.8727883100509644\n",
      "Step 3044/10000- lr: [7.024254327272728e-06] - Loss total: 2.9998979568481445, Last rpr Loss: 0.9998621344566345, Last lagvar Loss: 0.872730016708374\n",
      "Step 3045/10000- lr: [7.023244230303031e-06] - Loss total: 2.9994537830352783, Last rpr Loss: 0.9998776912689209, Last lagvar Loss: 0.8726819157600403\n",
      "Step 3046/10000- lr: [7.022234133333334e-06] - Loss total: 2.999009847640991, Last rpr Loss: 0.9998658895492554, Last lagvar Loss: 0.8726617097854614\n",
      "Step 3047/10000- lr: [7.0212240363636365e-06] - Loss total: 2.998565435409546, Last rpr Loss: 0.9998656511306763, Last lagvar Loss: 0.8726305365562439\n",
      "Step 3048/10000- lr: [7.02021393939394e-06] - Loss total: 2.9981210231781006, Last rpr Loss: 0.9998354911804199, Last lagvar Loss: 0.8726298213005066\n",
      "Step 3049/10000- lr: [7.019203842424243e-06] - Loss total: 2.9976775646209717, Last rpr Loss: 0.9998591542243958, Last lagvar Loss: 0.8725757598876953\n",
      "Step 3050/10000- lr: [7.018193745454546e-06] - Loss total: 2.9972331523895264, Last rpr Loss: 0.999863862991333, Last lagvar Loss: 0.8725409507751465\n",
      "Step 3051/10000- lr: [7.01718364848485e-06] - Loss total: 2.996788501739502, Last rpr Loss: 0.999912440776825, Last lagvar Loss: 0.872462272644043\n",
      "Step 3052/10000- lr: [7.016173551515152e-06] - Loss total: 2.9963436126708984, Last rpr Loss: 0.9999150037765503, Last lagvar Loss: 0.8724297285079956\n",
      "Step 3053/10000- lr: [7.015163454545455e-06] - Loss total: 2.9958994388580322, Last rpr Loss: 0.9999534487724304, Last lagvar Loss: 0.8723611831665039\n",
      "Step 3054/10000- lr: [7.014153357575758e-06] - Loss total: 2.9954545497894287, Last rpr Loss: 0.9999377131462097, Last lagvar Loss: 0.8723466396331787\n",
      "Step 3055/10000- lr: [7.013143260606061e-06] - Loss total: 2.995009660720825, Last rpr Loss: 0.9999488592147827, Last lagvar Loss: 0.8723049163818359\n",
      "Step 3056/10000- lr: [7.012133163636364e-06] - Loss total: 2.99456524848938, Last rpr Loss: 0.9999121427536011, Last lagvar Loss: 0.8723107576370239\n",
      "Step 3057/10000- lr: [7.0111230666666676e-06] - Loss total: 2.9941213130950928, Last rpr Loss: 0.9998985528945923, Last lagvar Loss: 0.8722929954528809\n",
      "Step 3058/10000- lr: [7.010112969696971e-06] - Loss total: 2.993677854537964, Last rpr Loss: 0.9998661875724792, Last lagvar Loss: 0.8722937107086182\n",
      "Step 3059/10000- lr: [7.009102872727273e-06] - Loss total: 2.993234395980835, Last rpr Loss: 0.9998657703399658, Last lagvar Loss: 0.8722617626190186\n",
      "Step 3060/10000- lr: [7.008092775757576e-06] - Loss total: 2.9927921295166016, Last rpr Loss: 0.9998809099197388, Last lagvar Loss: 0.8722137212753296\n",
      "Step 3061/10000- lr: [7.007082678787879e-06] - Loss total: 2.99234938621521, Last rpr Loss: 0.9998971819877625, Last lagvar Loss: 0.8721639513969421\n",
      "Step 3062/10000- lr: [7.006072581818182e-06] - Loss total: 2.991908073425293, Last rpr Loss: 0.9999284744262695, Last lagvar Loss: 0.8720986843109131\n",
      "Step 3063/10000- lr: [7.0050624848484855e-06] - Loss total: 2.991466760635376, Last rpr Loss: 0.9999206066131592, Last lagvar Loss: 0.8720722198486328\n",
      "Step 3064/10000- lr: [7.004052387878789e-06] - Loss total: 2.991025686264038, Last rpr Loss: 0.9999204277992249, Last lagvar Loss: 0.8720377683639526\n",
      "Step 3065/10000- lr: [7.003042290909091e-06] - Loss total: 2.9905858039855957, Last rpr Loss: 0.9998816251754761, Last lagvar Loss: 0.8720417022705078\n",
      "Step 3066/10000- lr: [7.0020321939393945e-06] - Loss total: 2.990145444869995, Last rpr Loss: 0.9998680949211121, Last lagvar Loss: 0.8720201849937439\n",
      "Step 3067/10000- lr: [7.001022096969697e-06] - Loss total: 2.989706039428711, Last rpr Loss: 0.9998456835746765, Last lagvar Loss: 0.8720076084136963\n",
      "Step 3068/10000- lr: [7.000012e-06] - Loss total: 2.989267110824585, Last rpr Loss: 0.9998475313186646, Last lagvar Loss: 0.8719708919525146\n",
      "Step 3069/10000- lr: [6.9990019030303035e-06] - Loss total: 2.9888291358947754, Last rpr Loss: 0.9998453259468079, Last lagvar Loss: 0.8719385862350464\n",
      "Step 3070/10000- lr: [6.997991806060607e-06] - Loss total: 2.988391160964966, Last rpr Loss: 0.9998629093170166, Last lagvar Loss: 0.8718870878219604\n",
      "Step 3071/10000- lr: [6.99698170909091e-06] - Loss total: 2.9879541397094727, Last rpr Loss: 0.9998674392700195, Last lagvar Loss: 0.8718493580818176\n",
      "Step 3072/10000- lr: [6.9959716121212125e-06] - Loss total: 2.9875175952911377, Last rpr Loss: 0.9998829364776611, Last lagvar Loss: 0.8718013763427734\n",
      "Step 3073/10000- lr: [6.994961515151516e-06] - Loss total: 2.987082004547119, Last rpr Loss: 0.999884843826294, Last lagvar Loss: 0.8717678189277649\n",
      "Step 3074/10000- lr: [6.993951418181818e-06] - Loss total: 2.986646890640259, Last rpr Loss: 0.9998923540115356, Last lagvar Loss: 0.8717295527458191\n",
      "Step 3075/10000- lr: [6.9929413212121215e-06] - Loss total: 2.9862122535705566, Last rpr Loss: 0.9998762607574463, Last lagvar Loss: 0.8717159032821655\n",
      "Step 3076/10000- lr: [6.991931224242425e-06] - Loss total: 2.9857780933380127, Last rpr Loss: 0.9998698830604553, Last lagvar Loss: 0.8716934323310852\n",
      "Step 3077/10000- lr: [6.990921127272728e-06] - Loss total: 2.9853451251983643, Last rpr Loss: 0.9998616576194763, Last lagvar Loss: 0.8716737031936646\n",
      "Step 3078/10000- lr: [6.989911030303031e-06] - Loss total: 2.984912872314453, Last rpr Loss: 0.9998574256896973, Last lagvar Loss: 0.8716508150100708\n",
      "Step 3079/10000- lr: [6.988900933333334e-06] - Loss total: 2.9844810962677, Last rpr Loss: 0.9998557567596436, Last lagvar Loss: 0.8716263175010681\n",
      "Step 3080/10000- lr: [6.987890836363636e-06] - Loss total: 2.9840500354766846, Last rpr Loss: 0.9998641014099121, Last lagvar Loss: 0.8715927600860596\n",
      "Step 3081/10000- lr: [6.9868807393939394e-06] - Loss total: 2.983619213104248, Last rpr Loss: 0.9998676776885986, Last lagvar Loss: 0.8715646266937256\n",
      "Step 3082/10000- lr: [6.985870642424243e-06] - Loss total: 2.983189105987549, Last rpr Loss: 0.9998652935028076, Last lagvar Loss: 0.8715434074401855\n",
      "Step 3083/10000- lr: [6.984860545454546e-06] - Loss total: 2.982760190963745, Last rpr Loss: 0.9998748302459717, Last lagvar Loss: 0.8715111017227173\n",
      "Step 3084/10000- lr: [6.983850448484849e-06] - Loss total: 2.9823315143585205, Last rpr Loss: 0.9998726844787598, Last lagvar Loss: 0.8714910745620728\n",
      "Step 3085/10000- lr: [6.982840351515152e-06] - Loss total: 2.981903553009033, Last rpr Loss: 0.999882698059082, Last lagvar Loss: 0.8714595437049866\n",
      "Step 3086/10000- lr: [6.981830254545455e-06] - Loss total: 2.981476306915283, Last rpr Loss: 0.9998749494552612, Last lagvar Loss: 0.8714466094970703\n",
      "Step 3087/10000- lr: [6.980820157575757e-06] - Loss total: 2.9810495376586914, Last rpr Loss: 0.9998897314071655, Last lagvar Loss: 0.8714118003845215\n",
      "Step 3088/10000- lr: [6.979810060606061e-06] - Loss total: 2.9806230068206787, Last rpr Loss: 0.9998740553855896, Last lagvar Loss: 0.8714080452919006\n",
      "Step 3089/10000- lr: [6.978799963636364e-06] - Loss total: 2.9801979064941406, Last rpr Loss: 0.999886155128479, Last lagvar Loss: 0.8713772296905518\n",
      "Step 3090/10000- lr: [6.977789866666667e-06] - Loss total: 2.9797725677490234, Last rpr Loss: 0.9998711347579956, Last lagvar Loss: 0.8713740706443787\n",
      "Step 3091/10000- lr: [6.9767797696969705e-06] - Loss total: 2.9793477058410645, Last rpr Loss: 0.9998781085014343, Last lagvar Loss: 0.871349573135376\n",
      "Step 3092/10000- lr: [6.975769672727273e-06] - Loss total: 2.97892427444458, Last rpr Loss: 0.9998589754104614, Last lagvar Loss: 0.8713517189025879\n",
      "Step 3093/10000- lr: [6.974759575757576e-06] - Loss total: 2.9785008430480957, Last rpr Loss: 0.9998718500137329, Last lagvar Loss: 0.871322512626648\n",
      "Step 3094/10000- lr: [6.973749478787879e-06] - Loss total: 2.9780776500701904, Last rpr Loss: 0.9998502731323242, Last lagvar Loss: 0.8713281154632568\n",
      "Step 3095/10000- lr: [6.972739381818182e-06] - Loss total: 2.9776551723480225, Last rpr Loss: 0.9998674392700195, Last lagvar Loss: 0.8712955713272095\n",
      "Step 3096/10000- lr: [6.971729284848485e-06] - Loss total: 2.977233648300171, Last rpr Loss: 0.9998481273651123, Last lagvar Loss: 0.8712999820709229\n",
      "Step 3097/10000- lr: [6.9707191878787885e-06] - Loss total: 2.9768121242523193, Last rpr Loss: 0.9998727440834045, Last lagvar Loss: 0.8712607622146606\n",
      "Step 3098/10000- lr: [6.969709090909092e-06] - Loss total: 2.976390838623047, Last rpr Loss: 0.9998445510864258, Last lagvar Loss: 0.8712749481201172\n",
      "Step 3099/10000- lr: [6.968698993939394e-06] - Loss total: 2.975970983505249, Last rpr Loss: 0.999875545501709, Last lagvar Loss: 0.8712301254272461\n",
      "Step 3100/10000- lr: [6.9676888969696975e-06] - Loss total: 2.975551128387451, Last rpr Loss: 0.9998345971107483, Last lagvar Loss: 0.8712577819824219\n",
      "Step 3101/10000- lr: [6.9666788e-06] - Loss total: 2.9751315116882324, Last rpr Loss: 0.9998795390129089, Last lagvar Loss: 0.8712000846862793\n",
      "Step 3102/10000- lr: [6.965668703030303e-06] - Loss total: 2.9747121334075928, Last rpr Loss: 0.9998257756233215, Last lagvar Loss: 0.8712415099143982\n",
      "Step 3103/10000- lr: [6.9646586060606065e-06] - Loss total: 2.9742939472198486, Last rpr Loss: 0.9998879432678223, Last lagvar Loss: 0.8711671829223633\n",
      "Step 3104/10000- lr: [6.96364850909091e-06] - Loss total: 2.9738762378692627, Last rpr Loss: 0.9998104572296143, Last lagvar Loss: 0.871232807636261\n",
      "Step 3105/10000- lr: [6.962638412121213e-06] - Loss total: 2.9734585285186768, Last rpr Loss: 0.9999059438705444, Last lagvar Loss: 0.8711258172988892\n",
      "Step 3106/10000- lr: [6.9616283151515154e-06] - Loss total: 2.9730417728424072, Last rpr Loss: 0.999783456325531, Last lagvar Loss: 0.87123703956604\n",
      "Step 3107/10000- lr: [6.960618218181818e-06] - Loss total: 2.9726247787475586, Last rpr Loss: 0.9999322891235352, Last lagvar Loss: 0.871077299118042\n",
      "Step 3108/10000- lr: [6.959608121212121e-06] - Loss total: 2.9722087383270264, Last rpr Loss: 0.9997437000274658, Last lagvar Loss: 0.8712553977966309\n",
      "Step 3109/10000- lr: [6.958598024242424e-06] - Loss total: 2.9717929363250732, Last rpr Loss: 0.9999808669090271, Last lagvar Loss: 0.8710078001022339\n",
      "Step 3110/10000- lr: [6.957587927272728e-06] - Loss total: 2.97137713432312, Last rpr Loss: 0.999674916267395, Last lagvar Loss: 0.8713036775588989\n",
      "Step 3111/10000- lr: [6.956577830303031e-06] - Loss total: 2.970961809158325, Last rpr Loss: 1.0000550746917725, Last lagvar Loss: 0.8709138035774231\n",
      "Step 3112/10000- lr: [6.955567733333333e-06] - Loss total: 2.9705467224121094, Last rpr Loss: 0.9995733499526978, Last lagvar Loss: 0.871385931968689\n",
      "Step 3113/10000- lr: [6.954557636363637e-06] - Loss total: 2.970132827758789, Last rpr Loss: 1.000199317932129, Last lagvar Loss: 0.8707505464553833\n",
      "Step 3114/10000- lr: [6.953547539393939e-06] - Loss total: 2.969719171524048, Last rpr Loss: 0.9993940591812134, Last lagvar Loss: 0.8715469241142273\n",
      "Step 3115/10000- lr: [6.952537442424242e-06] - Loss total: 2.9693057537078857, Last rpr Loss: 1.0004453659057617, Last lagvar Loss: 0.8704870343208313\n",
      "Step 3116/10000- lr: [6.951527345454546e-06] - Loss total: 2.9688923358917236, Last rpr Loss: 0.9990756511688232, Last lagvar Loss: 0.8718487024307251\n",
      "Step 3117/10000- lr: [6.950517248484849e-06] - Loss total: 2.9684793949127197, Last rpr Loss: 1.0008816719055176, Last lagvar Loss: 0.8700346946716309\n",
      "Step 3118/10000- lr: [6.949507151515152e-06] - Loss total: 2.9680674076080322, Last rpr Loss: 0.998503565788269, Last lagvar Loss: 0.8724064826965332\n",
      "Step 3119/10000- lr: [6.948497054545455e-06] - Loss total: 2.967656373977661, Last rpr Loss: 1.0016591548919678, Last lagvar Loss: 0.8692449927330017\n",
      "Step 3120/10000- lr: [6.947486957575758e-06] - Loss total: 2.967247247695923, Last rpr Loss: 0.997456431388855, Last lagvar Loss: 0.8734449148178101\n",
      "Step 3121/10000- lr: [6.94647686060606e-06] - Loss total: 2.966841220855713, Last rpr Loss: 1.0030758380889893, Last lagvar Loss: 0.867825448513031\n",
      "Step 3122/10000- lr: [6.945466763636364e-06] - Loss total: 2.9664413928985596, Last rpr Loss: 0.9955288171768188, Last lagvar Loss: 0.8753809928894043\n",
      "Step 3123/10000- lr: [6.944456666666667e-06] - Loss total: 2.966050863265991, Last rpr Loss: 1.0057127475738525, Last lagvar Loss: 0.8652157783508301\n",
      "Step 3124/10000- lr: [6.94344656969697e-06] - Loss total: 2.9656829833984375, Last rpr Loss: 0.9919317364692688, Last lagvar Loss: 0.8790439367294312\n",
      "Step 3125/10000- lr: [6.9424364727272735e-06] - Loss total: 2.965346574783325, Last rpr Loss: 1.0106697082519531, Last lagvar Loss: 0.8603874444961548\n",
      "Step 3126/10000- lr: [6.941426375757576e-06] - Loss total: 2.965099811553955, Last rpr Loss: 0.9851703643798828, Last lagvar Loss: 0.8860723972320557\n",
      "Step 3127/10000- lr: [6.940416278787878e-06] - Loss total: 2.964938163757324, Last rpr Loss: 1.0199899673461914, Last lagvar Loss: 0.8515388369560242\n",
      "Step 3128/10000- lr: [6.9394061818181825e-06] - Loss total: 2.965139627456665, Last rpr Loss: 0.9726462960243225, Last lagvar Loss: 0.899570107460022\n",
      "Step 3129/10000- lr: [6.938396084848485e-06] - Loss total: 2.965442180633545, Last rpr Loss: 1.0367684364318848, Last lagvar Loss: 0.8362808227539062\n",
      "Step 3130/10000- lr: [6.937385987878788e-06] - Loss total: 2.9637179374694824, Last rpr Loss: 0.9795757532119751, Last lagvar Loss: 0.8919427394866943\n",
      "Step 3131/10000- lr: [6.9363758909090914e-06] - Loss total: 2.9627575874328613, Last rpr Loss: 1.0067870616912842, Last lagvar Loss: 0.8641176223754883\n",
      "Step 3132/10000- lr: [6.935365793939395e-06] - Loss total: 2.9623260498046875, Last rpr Loss: 1.0055596828460693, Last lagvar Loss: 0.8653117418289185\n",
      "Step 3133/10000- lr: [6.934355696969698e-06] - Loss total: 2.9622745513916016, Last rpr Loss: 0.9841039180755615, Last lagvar Loss: 0.8871704339981079\n",
      "Step 3134/10000- lr: [6.9333456e-06] - Loss total: 2.9625420570373535, Last rpr Loss: 1.027342438697815, Last lagvar Loss: 0.8446675539016724\n",
      "Step 3135/10000- lr: [6.932335503030304e-06] - Loss total: 2.963641405105591, Last rpr Loss: 0.9606242775917053, Last lagvar Loss: 0.9130874872207642\n",
      "Step 3136/10000- lr: [6.931325406060606e-06] - Loss total: 2.9607772827148438, Last rpr Loss: 1.007434606552124, Last lagvar Loss: 0.8634889721870422\n",
      "Step 3137/10000- lr: [6.930315309090909e-06] - Loss total: 2.9609575271606445, Last rpr Loss: 1.0213215351104736, Last lagvar Loss: 0.8502633571624756\n",
      "Step 3138/10000- lr: [6.929305212121213e-06] - Loss total: 2.9637467861175537, Last rpr Loss: 0.9527256488800049, Last lagvar Loss: 0.9224344491958618\n",
      "Step 3139/10000- lr: [6.928295115151516e-06] - Loss total: 2.9595446586608887, Last rpr Loss: 0.9939885139465332, Last lagvar Loss: 0.8768541216850281\n",
      "Step 3140/10000- lr: [6.927285018181819e-06] - Loss total: 2.9645767211914062, Last rpr Loss: 1.0658044815063477, Last lagvar Loss: 0.8112542629241943\n",
      "Step 3141/10000- lr: [6.926274921212122e-06] - Loss total: 2.958761215209961, Last rpr Loss: 1.0031081438064575, Last lagvar Loss: 0.867701530456543\n",
      "Step 3142/10000- lr: [6.925264824242425e-06] - Loss total: 2.9632937908172607, Last rpr Loss: 0.9464865922927856, Last lagvar Loss: 0.9298558831214905\n",
      "Step 3143/10000- lr: [6.924254727272727e-06] - Loss total: 2.9580459594726562, Last rpr Loss: 0.9955078363418579, Last lagvar Loss: 0.8753054141998291\n",
      "Step 3144/10000- lr: [6.923244630303031e-06] - Loss total: 2.963383436203003, Last rpr Loss: 1.066717267036438, Last lagvar Loss: 0.8106471300125122\n",
      "Step 3145/10000- lr: [6.922234533333334e-06] - Loss total: 2.957352638244629, Last rpr Loss: 1.003127932548523, Last lagvar Loss: 0.8677041530609131\n",
      "Step 3146/10000- lr: [6.921224436363637e-06] - Loss total: 2.962103843688965, Last rpr Loss: 0.9473227262496948, Last lagvar Loss: 0.9294120073318481\n",
      "Step 3147/10000- lr: [6.9202143393939405e-06] - Loss total: 2.956779956817627, Last rpr Loss: 0.9952713251113892, Last lagvar Loss: 0.8757212162017822\n",
      "Step 3148/10000- lr: [6.919204242424243e-06] - Loss total: 2.9629733562469482, Last rpr Loss: 1.06989324092865, Last lagvar Loss: 0.8090219497680664\n",
      "Step 3149/10000- lr: [6.918194145454546e-06] - Loss total: 2.9564898014068604, Last rpr Loss: 1.0082030296325684, Last lagvar Loss: 0.8634054660797119\n",
      "Step 3150/10000- lr: [6.917184048484849e-06] - Loss total: 2.9647929668426514, Last rpr Loss: 0.9370100498199463, Last lagvar Loss: 0.9452069997787476\n",
      "Step 3151/10000- lr: [6.916173951515152e-06] - Loss total: 2.9602174758911133, Last rpr Loss: 0.9637852907180786, Last lagvar Loss: 0.9139003157615662\n",
      "Step 3152/10000- lr: [6.915163854545455e-06] - Loss total: 2.966768264770508, Last rpr Loss: 1.0912303924560547, Last lagvar Loss: 0.7933588027954102\n",
      "Step 3153/10000- lr: [6.9141537575757584e-06] - Loss total: 2.9714620113372803, Last rpr Loss: 1.0999797582626343, Last lagvar Loss: 0.7929868698120117\n",
      "Step 3154/10000- lr: [6.913143660606062e-06] - Loss total: 2.9566445350646973, Last rpr Loss: 0.9735075831413269, Last lagvar Loss: 0.9003816843032837\n",
      "Step 3155/10000- lr: [6.912133563636364e-06] - Loss total: 2.9632673263549805, Last rpr Loss: 0.9672131538391113, Last lagvar Loss: 0.9164466857910156\n",
      "Step 3156/10000- lr: [6.911123466666667e-06] - Loss total: 2.9615821838378906, Last rpr Loss: 1.019270420074463, Last lagvar Loss: 0.8624402284622192\n",
      "Step 3157/10000- lr: [6.91011336969697e-06] - Loss total: 2.956465482711792, Last rpr Loss: 1.0309605598449707, Last lagvar Loss: 0.8436821699142456\n",
      "Step 3158/10000- lr: [6.909103272727273e-06] - Loss total: 2.9604251384735107, Last rpr Loss: 0.9663642644882202, Last lagvar Loss: 0.9135376214981079\n",
      "Step 3159/10000- lr: [6.908093175757576e-06] - Loss total: 2.9562597274780273, Last rpr Loss: 0.9630193710327148, Last lagvar Loss: 0.9112628698348999\n",
      "Step 3160/10000- lr: [6.90708307878788e-06] - Loss total: 2.960275173187256, Last rpr Loss: 1.0659029483795166, Last lagvar Loss: 0.8133416175842285\n",
      "Step 3161/10000- lr: [6.906072981818182e-06] - Loss total: 2.9610607624053955, Last rpr Loss: 1.0626115798950195, Last lagvar Loss: 0.8178027868270874\n",
      "Step 3162/10000- lr: [6.905062884848485e-06] - Loss total: 2.9536430835723877, Last rpr Loss: 0.9660308361053467, Last lagvar Loss: 0.9064429402351379\n",
      "Step 3163/10000- lr: [6.904052787878788e-06] - Loss total: 2.955864667892456, Last rpr Loss: 1.0108921527862549, Last lagvar Loss: 0.8654637336730957\n",
      "Step 3164/10000- lr: [6.903042690909091e-06] - Loss total: 2.952202081680298, Last rpr Loss: 1.0168826580047607, Last lagvar Loss: 0.854455828666687\n",
      "Step 3165/10000- lr: [6.902032593939394e-06] - Loss total: 2.9549081325531006, Last rpr Loss: 0.9700086116790771, Last lagvar Loss: 0.9058492183685303\n",
      "Step 3166/10000- lr: [6.901022496969698e-06] - Loss total: 2.9516992568969727, Last rpr Loss: 1.0052587985992432, Last lagvar Loss: 0.8663169145584106\n",
      "Step 3167/10000- lr: [6.900012400000001e-06] - Loss total: 2.952253580093384, Last rpr Loss: 1.0106109380722046, Last lagvar Loss: 0.8621621131896973\n",
      "Step 3168/10000- lr: [6.899002303030303e-06] - Loss total: 2.9522545337677, Last rpr Loss: 0.9832838177680969, Last lagvar Loss: 0.889889657497406\n",
      "Step 3169/10000- lr: [6.897992206060607e-06] - Loss total: 2.951465606689453, Last rpr Loss: 1.016990065574646, Last lagvar Loss: 0.8550358414649963\n",
      "Step 3170/10000- lr: [6.896982109090909e-06] - Loss total: 2.9528281688690186, Last rpr Loss: 0.9777849912643433, Last lagvar Loss: 0.8961630463600159\n",
      "Step 3171/10000- lr: [6.895972012121212e-06] - Loss total: 2.94997501373291, Last rpr Loss: 1.0051615238189697, Last lagvar Loss: 0.8659589290618896\n",
      "Step 3172/10000- lr: [6.894961915151516e-06] - Loss total: 2.9533207416534424, Last rpr Loss: 1.0317943096160889, Last lagvar Loss: 0.843450129032135\n",
      "Step 3173/10000- lr: [6.893951818181819e-06] - Loss total: 2.9502670764923096, Last rpr Loss: 0.9798868298530579, Last lagvar Loss: 0.8927302360534668\n",
      "Step 3174/10000- lr: [6.892941721212122e-06] - Loss total: 2.9524662494659424, Last rpr Loss: 0.9990277886390686, Last lagvar Loss: 0.8766436576843262\n",
      "Step 3175/10000- lr: [6.891931624242425e-06] - Loss total: 2.949601650238037, Last rpr Loss: 1.020155668258667, Last lagvar Loss: 0.8521758317947388\n",
      "Step 3176/10000- lr: [6.890921527272727e-06] - Loss total: 2.9536921977996826, Last rpr Loss: 0.9788508415222168, Last lagvar Loss: 0.900039792060852\n",
      "Step 3177/10000- lr: [6.88991143030303e-06] - Loss total: 2.950169801712036, Last rpr Loss: 0.9732039570808411, Last lagvar Loss: 0.9010430574417114\n",
      "Step 3178/10000- lr: [6.888901333333334e-06] - Loss total: 2.9567623138427734, Last rpr Loss: 1.0594663619995117, Last lagvar Loss: 0.8250341415405273\n",
      "Step 3179/10000- lr: [6.887891236363637e-06] - Loss total: 2.95672869682312, Last rpr Loss: 1.0386989116668701, Last lagvar Loss: 0.8460906147956848\n",
      "Step 3180/10000- lr: [6.88688113939394e-06] - Loss total: 2.949127197265625, Last rpr Loss: 0.9562122821807861, Last lagvar Loss: 0.9169118404388428\n",
      "Step 3181/10000- lr: [6.885871042424243e-06] - Loss total: 2.9561991691589355, Last rpr Loss: 1.023809552192688, Last lagvar Loss: 0.8585983514785767\n",
      "Step 3182/10000- lr: [6.884860945454546e-06] - Loss total: 2.952430009841919, Last rpr Loss: 1.0252318382263184, Last lagvar Loss: 0.852662980556488\n",
      "Step 3183/10000- lr: [6.883850848484848e-06] - Loss total: 2.948533296585083, Last rpr Loss: 0.9712947010993958, Last lagvar Loss: 0.9016022682189941\n",
      "Step 3184/10000- lr: [6.8828407515151516e-06] - Loss total: 2.949887275695801, Last rpr Loss: 1.016819953918457, Last lagvar Loss: 0.8592585921287537\n",
      "Step 3185/10000- lr: [6.881830654545455e-06] - Loss total: 2.9470932483673096, Last rpr Loss: 1.033792495727539, Last lagvar Loss: 0.8383504152297974\n",
      "Step 3186/10000- lr: [6.880820557575758e-06] - Loss total: 2.9487972259521484, Last rpr Loss: 0.9628372192382812, Last lagvar Loss: 0.9129469394683838\n",
      "Step 3187/10000- lr: [6.879810460606061e-06] - Loss total: 2.945072650909424, Last rpr Loss: 0.9901573657989502, Last lagvar Loss: 0.8805257081985474\n",
      "Step 3188/10000- lr: [6.878800363636364e-06] - Loss total: 2.94765567779541, Last rpr Loss: 1.0463818311691284, Last lagvar Loss: 0.8283706903457642\n",
      "Step 3189/10000- lr: [6.877790266666667e-06] - Loss total: 2.945711374282837, Last rpr Loss: 0.9719836711883545, Last lagvar Loss: 0.9001023173332214\n",
      "Step 3190/10000- lr: [6.8767801696969695e-06] - Loss total: 2.945572853088379, Last rpr Loss: 1.0034130811691284, Last lagvar Loss: 0.8687995672225952\n",
      "Step 3191/10000- lr: [6.875770072727273e-06] - Loss total: 2.9443860054016113, Last rpr Loss: 0.9931356906890869, Last lagvar Loss: 0.8780881762504578\n",
      "Step 3192/10000- lr: [6.874759975757576e-06] - Loss total: 2.9437499046325684, Last rpr Loss: 1.005336046218872, Last lagvar Loss: 0.8654252886772156\n",
      "Step 3193/10000- lr: [6.873749878787879e-06] - Loss total: 2.944465398788452, Last rpr Loss: 1.0183517932891846, Last lagvar Loss: 0.8535946011543274\n",
      "Step 3194/10000- lr: [6.872739781818183e-06] - Loss total: 2.94358229637146, Last rpr Loss: 0.9659157991409302, Last lagvar Loss: 0.9052278995513916\n",
      "Step 3195/10000- lr: [6.871729684848485e-06] - Loss total: 2.943977117538452, Last rpr Loss: 1.033909797668457, Last lagvar Loss: 0.8386693596839905\n",
      "Step 3196/10000- lr: [6.8707195878787875e-06] - Loss total: 2.9425461292266846, Last rpr Loss: 0.9849855303764343, Last lagvar Loss: 0.8859099745750427\n",
      "Step 3197/10000- lr: [6.869709490909091e-06] - Loss total: 2.9421768188476562, Last rpr Loss: 1.0010651350021362, Last lagvar Loss: 0.8697353601455688\n",
      "Step 3198/10000- lr: [6.868699393939394e-06] - Loss total: 2.941573143005371, Last rpr Loss: 0.9983667731285095, Last lagvar Loss: 0.8723122477531433\n",
      "Step 3199/10000- lr: [6.867689296969697e-06] - Loss total: 2.941145658493042, Last rpr Loss: 0.9924072027206421, Last lagvar Loss: 0.8778547644615173\n",
      "Step 3200/10000- lr: [6.866679200000001e-06] - Loss total: 2.941364288330078, Last rpr Loss: 1.0180718898773193, Last lagvar Loss: 0.852921724319458\n",
      "Step 3201/10000- lr: [6.865669103030303e-06] - Loss total: 2.940544605255127, Last rpr Loss: 0.9773622155189514, Last lagvar Loss: 0.8929904699325562\n",
      "Step 3202/10000- lr: [6.864659006060606e-06] - Loss total: 2.940464973449707, Last rpr Loss: 1.0169143676757812, Last lagvar Loss: 0.8541388511657715\n",
      "Step 3203/10000- lr: [6.863648909090909e-06] - Loss total: 2.939450740814209, Last rpr Loss: 0.9931803345680237, Last lagvar Loss: 0.8767757415771484\n",
      "Step 3204/10000- lr: [6.862638812121212e-06] - Loss total: 2.9392459392547607, Last rpr Loss: 0.9996757507324219, Last lagvar Loss: 0.8705495595932007\n",
      "Step 3205/10000- lr: [6.861628715151515e-06] - Loss total: 2.938776969909668, Last rpr Loss: 1.0054051876068115, Last lagvar Loss: 0.8646559715270996\n",
      "Step 3206/10000- lr: [6.860618618181819e-06] - Loss total: 2.9384734630584717, Last rpr Loss: 0.9892109632492065, Last lagvar Loss: 0.8807839155197144\n",
      "Step 3207/10000- lr: [6.859608521212122e-06] - Loss total: 2.938227891921997, Last rpr Loss: 1.0115338563919067, Last lagvar Loss: 0.858554482460022\n",
      "Step 3208/10000- lr: [6.858598424242424e-06] - Loss total: 2.9375998973846436, Last rpr Loss: 0.9903681874275208, Last lagvar Loss: 0.879372239112854\n",
      "Step 3209/10000- lr: [6.8575883272727276e-06] - Loss total: 2.9373316764831543, Last rpr Loss: 1.0072605609893799, Last lagvar Loss: 0.8627527952194214\n",
      "Step 3210/10000- lr: [6.85657823030303e-06] - Loss total: 2.936689615249634, Last rpr Loss: 0.9979463815689087, Last lagvar Loss: 0.8714834451675415\n",
      "Step 3211/10000- lr: [6.855568133333333e-06] - Loss total: 2.9364700317382812, Last rpr Loss: 0.9970738887786865, Last lagvar Loss: 0.8725196123123169\n",
      "Step 3212/10000- lr: [6.8545580363636366e-06] - Loss total: 2.936002254486084, Last rpr Loss: 1.0067431926727295, Last lagvar Loss: 0.8626207113265991\n",
      "Step 3213/10000- lr: [6.85354793939394e-06] - Loss total: 2.9356796741485596, Last rpr Loss: 0.9906840324401855, Last lagvar Loss: 0.8786886930465698\n",
      "Step 3214/10000- lr: [6.852537842424243e-06] - Loss total: 2.9352643489837646, Last rpr Loss: 1.0039725303649902, Last lagvar Loss: 0.8651492595672607\n",
      "Step 3215/10000- lr: [6.851527745454546e-06] - Loss total: 2.9348011016845703, Last rpr Loss: 0.9975988864898682, Last lagvar Loss: 0.8713946342468262\n",
      "Step 3216/10000- lr: [6.85051764848485e-06] - Loss total: 2.934445381164551, Last rpr Loss: 1.0033352375030518, Last lagvar Loss: 0.865645170211792\n",
      "Step 3217/10000- lr: [6.849507551515152e-06] - Loss total: 2.9339802265167236, Last rpr Loss: 0.9990906715393066, Last lagvar Loss: 0.8696786165237427\n",
      "Step 3218/10000- lr: [6.848497454545455e-06] - Loss total: 2.933666944503784, Last rpr Loss: 0.9960523247718811, Last lagvar Loss: 0.8727332353591919\n",
      "Step 3219/10000- lr: [6.847487357575758e-06] - Loss total: 2.9332306385040283, Last rpr Loss: 1.0070827007293701, Last lagvar Loss: 0.8615847826004028\n",
      "Step 3220/10000- lr: [6.846477260606061e-06] - Loss total: 2.9328713417053223, Last rpr Loss: 0.9952976107597351, Last lagvar Loss: 0.873354434967041\n",
      "Step 3221/10000- lr: [6.845467163636364e-06] - Loss total: 2.932452440261841, Last rpr Loss: 1.000306248664856, Last lagvar Loss: 0.8682302236557007\n",
      "Step 3222/10000- lr: [6.844457066666668e-06] - Loss total: 2.932042360305786, Last rpr Loss: 0.9985566139221191, Last lagvar Loss: 0.8699088096618652\n",
      "Step 3223/10000- lr: [6.843446969696971e-06] - Loss total: 2.9316635131835938, Last rpr Loss: 1.0016391277313232, Last lagvar Loss: 0.8668025732040405\n",
      "Step 3224/10000- lr: [6.842436872727273e-06] - Loss total: 2.9312477111816406, Last rpr Loss: 0.9993453621864319, Last lagvar Loss: 0.8690063953399658\n",
      "Step 3225/10000- lr: [6.841426775757576e-06] - Loss total: 2.9308886528015137, Last rpr Loss: 0.9952439069747925, Last lagvar Loss: 0.8730859160423279\n",
      "Step 3226/10000- lr: [6.840416678787879e-06] - Loss total: 2.9304757118225098, Last rpr Loss: 1.005005121231079, Last lagvar Loss: 0.8632510900497437\n",
      "Step 3227/10000- lr: [6.839406581818182e-06] - Loss total: 2.930097818374634, Last rpr Loss: 0.9983110427856445, Last lagvar Loss: 0.8699125647544861\n",
      "Step 3228/10000- lr: [6.838396484848486e-06] - Loss total: 2.9296927452087402, Last rpr Loss: 0.9995838403701782, Last lagvar Loss: 0.8685651421546936\n",
      "Step 3229/10000- lr: [6.837386387878789e-06] - Loss total: 2.929295539855957, Last rpr Loss: 0.9984648823738098, Last lagvar Loss: 0.869617760181427\n",
      "Step 3230/10000- lr: [6.836376290909091e-06] - Loss total: 2.928910493850708, Last rpr Loss: 1.0020880699157715, Last lagvar Loss: 0.8659659624099731\n",
      "Step 3231/10000- lr: [6.835366193939395e-06] - Loss total: 2.9285082817077637, Last rpr Loss: 1.0010395050048828, Last lagvar Loss: 0.8669339418411255\n",
      "Step 3232/10000- lr: [6.834356096969697e-06] - Loss total: 2.9281349182128906, Last rpr Loss: 0.9960552453994751, Last lagvar Loss: 0.8718770742416382\n",
      "Step 3233/10000- lr: [6.833346e-06] - Loss total: 2.9277334213256836, Last rpr Loss: 1.0027048587799072, Last lagvar Loss: 0.8651432991027832\n",
      "Step 3234/10000- lr: [6.8323359030303036e-06] - Loss total: 2.9273552894592285, Last rpr Loss: 0.9995042085647583, Last lagvar Loss: 0.8682959079742432\n",
      "Step 3235/10000- lr: [6.831325806060607e-06] - Loss total: 2.92695951461792, Last rpr Loss: 0.9997179508209229, Last lagvar Loss: 0.8679836988449097\n",
      "Step 3236/10000- lr: [6.83031570909091e-06] - Loss total: 2.926574468612671, Last rpr Loss: 0.9975624084472656, Last lagvar Loss: 0.8700618743896484\n",
      "Step 3237/10000- lr: [6.8293056121212125e-06] - Loss total: 2.9261910915374756, Last rpr Loss: 1.0011935234069824, Last lagvar Loss: 0.8663618564605713\n",
      "Step 3238/10000- lr: [6.828295515151516e-06] - Loss total: 2.9258034229278564, Last rpr Loss: 1.0010932683944702, Last lagvar Loss: 0.8663716912269592\n",
      "Step 3239/10000- lr: [6.827285418181818e-06] - Loss total: 2.925429582595825, Last rpr Loss: 0.9971258640289307, Last lagvar Loss: 0.8702652454376221\n",
      "Step 3240/10000- lr: [6.8262753212121215e-06] - Loss total: 2.925042152404785, Last rpr Loss: 1.0012364387512207, Last lagvar Loss: 0.8660708069801331\n",
      "Step 3241/10000- lr: [6.825265224242425e-06] - Loss total: 2.924668788909912, Last rpr Loss: 1.0000412464141846, Last lagvar Loss: 0.8672038316726685\n",
      "Step 3242/10000- lr: [6.824255127272728e-06] - Loss total: 2.9242851734161377, Last rpr Loss: 1.0006837844848633, Last lagvar Loss: 0.866477370262146\n",
      "Step 3243/10000- lr: [6.823245030303031e-06] - Loss total: 2.9239089488983154, Last rpr Loss: 0.9979119300842285, Last lagvar Loss: 0.8691860437393188\n",
      "Step 3244/10000- lr: [6.822234933333334e-06] - Loss total: 2.9235312938690186, Last rpr Loss: 1.0010557174682617, Last lagvar Loss: 0.865980863571167\n",
      "Step 3245/10000- lr: [6.821224836363636e-06] - Loss total: 2.92315411567688, Last rpr Loss: 1.0009958744049072, Last lagvar Loss: 0.8659781217575073\n",
      "Step 3246/10000- lr: [6.8202147393939395e-06] - Loss total: 2.9227821826934814, Last rpr Loss: 0.998626172542572, Last lagvar Loss: 0.8682941198348999\n",
      "Step 3247/10000- lr: [6.819204642424243e-06] - Loss total: 2.922405242919922, Last rpr Loss: 1.0003232955932617, Last lagvar Loss: 0.8665423393249512\n",
      "Step 3248/10000- lr: [6.818194545454546e-06] - Loss total: 2.9220340251922607, Last rpr Loss: 0.9998487234115601, Last lagvar Loss: 0.8669716715812683\n",
      "Step 3249/10000- lr: [6.817184448484849e-06] - Loss total: 2.921657085418701, Last rpr Loss: 1.0008690357208252, Last lagvar Loss: 0.8658969402313232\n",
      "Step 3250/10000- lr: [6.816174351515152e-06] - Loss total: 2.92128324508667, Last rpr Loss: 0.9983134865760803, Last lagvar Loss: 0.8684098124504089\n",
      "Step 3251/10000- lr: [6.815164254545455e-06] - Loss total: 2.9209072589874268, Last rpr Loss: 1.0007516145706177, Last lagvar Loss: 0.8659266233444214\n",
      "Step 3252/10000- lr: [6.8141541575757575e-06] - Loss total: 2.9205310344696045, Last rpr Loss: 1.0002049207687378, Last lagvar Loss: 0.8664286136627197\n",
      "Step 3253/10000- lr: [6.813144060606061e-06] - Loss total: 2.9201557636260986, Last rpr Loss: 0.9995754957199097, Last lagvar Loss: 0.8670148849487305\n",
      "Step 3254/10000- lr: [6.812133963636364e-06] - Loss total: 2.9197795391082764, Last rpr Loss: 0.9996070861816406, Last lagvar Loss: 0.8669403195381165\n",
      "Step 3255/10000- lr: [6.811123866666667e-06] - Loss total: 2.9194064140319824, Last rpr Loss: 0.9997743964195251, Last lagvar Loss: 0.8667316436767578\n",
      "Step 3256/10000- lr: [6.810113769696971e-06] - Loss total: 2.919032335281372, Last rpr Loss: 1.0005500316619873, Last lagvar Loss: 0.8659065961837769\n",
      "Step 3257/10000- lr: [6.809103672727273e-06] - Loss total: 2.9186604022979736, Last rpr Loss: 0.998836874961853, Last lagvar Loss: 0.8675754070281982\n",
      "Step 3258/10000- lr: [6.808093575757576e-06] - Loss total: 2.9182891845703125, Last rpr Loss: 1.0003187656402588, Last lagvar Loss: 0.8660458326339722\n",
      "Step 3259/10000- lr: [6.807083478787879e-06] - Loss total: 2.9179182052612305, Last rpr Loss: 0.9995436668395996, Last lagvar Loss: 0.866771936416626\n",
      "Step 3260/10000- lr: [6.806073381818182e-06] - Loss total: 2.9175491333007812, Last rpr Loss: 1.0002018213272095, Last lagvar Loss: 0.8660642504692078\n",
      "Step 3261/10000- lr: [6.805063284848485e-06] - Loss total: 2.917180061340332, Last rpr Loss: 0.9994251728057861, Last lagvar Loss: 0.8667947053909302\n",
      "Step 3262/10000- lr: [6.8040531878787885e-06] - Loss total: 2.916813611984253, Last rpr Loss: 1.0001581907272339, Last lagvar Loss: 0.8660171031951904\n",
      "Step 3263/10000- lr: [6.803043090909092e-06] - Loss total: 2.9164469242095947, Last rpr Loss: 1.0001109838485718, Last lagvar Loss: 0.8660179376602173\n",
      "Step 3264/10000- lr: [6.802032993939394e-06] - Loss total: 2.9160823822021484, Last rpr Loss: 0.9996564984321594, Last lagvar Loss: 0.8664299249649048\n",
      "Step 3265/10000- lr: [6.801022896969697e-06] - Loss total: 2.9157192707061768, Last rpr Loss: 1.0000793933868408, Last lagvar Loss: 0.8659675717353821\n",
      "Step 3266/10000- lr: [6.8000128e-06] - Loss total: 2.915356397628784, Last rpr Loss: 0.9996386766433716, Last lagvar Loss: 0.8663684725761414\n",
      "Step 3267/10000- lr: [6.799002703030303e-06] - Loss total: 2.9149956703186035, Last rpr Loss: 1.0002992153167725, Last lagvar Loss: 0.865668773651123\n",
      "Step 3268/10000- lr: [6.7979926060606065e-06] - Loss total: 2.9146347045898438, Last rpr Loss: 0.999457836151123, Last lagvar Loss: 0.8664745092391968\n",
      "Step 3269/10000- lr: [6.79698250909091e-06] - Loss total: 2.914276123046875, Last rpr Loss: 1.0001955032348633, Last lagvar Loss: 0.8657029867172241\n",
      "Step 3270/10000- lr: [6.795972412121212e-06] - Loss total: 2.913917064666748, Last rpr Loss: 0.9995414018630981, Last lagvar Loss: 0.8663213849067688\n",
      "Step 3271/10000- lr: [6.7949623151515155e-06] - Loss total: 2.913560152053833, Last rpr Loss: 1.00007963180542, Last lagvar Loss: 0.8657493591308594\n",
      "Step 3272/10000- lr: [6.793952218181818e-06] - Loss total: 2.913203477859497, Last rpr Loss: 0.9996798038482666, Last lagvar Loss: 0.8661185503005981\n",
      "Step 3273/10000- lr: [6.792942121212121e-06] - Loss total: 2.912848472595215, Last rpr Loss: 0.999946653842926, Last lagvar Loss: 0.8658195734024048\n",
      "Step 3274/10000- lr: [6.7919320242424245e-06] - Loss total: 2.912493944168091, Last rpr Loss: 0.9998649954795837, Last lagvar Loss: 0.8658691644668579\n",
      "Step 3275/10000- lr: [6.790921927272728e-06] - Loss total: 2.9121406078338623, Last rpr Loss: 0.9998835921287537, Last lagvar Loss: 0.8658207058906555\n",
      "Step 3276/10000- lr: [6.789911830303031e-06] - Loss total: 2.91178822517395, Last rpr Loss: 0.9999876022338867, Last lagvar Loss: 0.8656878471374512\n",
      "Step 3277/10000- lr: [6.7889017333333335e-06] - Loss total: 2.911435604095459, Last rpr Loss: 0.9996238946914673, Last lagvar Loss: 0.866020679473877\n",
      "Step 3278/10000- lr: [6.787891636363637e-06] - Loss total: 2.9110844135284424, Last rpr Loss: 1.000038981437683, Last lagvar Loss: 0.8655756711959839\n",
      "Step 3279/10000- lr: [6.786881539393939e-06] - Loss total: 2.9107344150543213, Last rpr Loss: 0.9996737241744995, Last lagvar Loss: 0.8659125566482544\n",
      "Step 3280/10000- lr: [6.7858714424242425e-06] - Loss total: 2.9103846549987793, Last rpr Loss: 1.0000101327896118, Last lagvar Loss: 0.8655464053153992\n",
      "Step 3281/10000- lr: [6.784861345454546e-06] - Loss total: 2.910036087036133, Last rpr Loss: 0.9995448589324951, Last lagvar Loss: 0.8659815788269043\n",
      "Step 3282/10000- lr: [6.783851248484849e-06] - Loss total: 2.9096877574920654, Last rpr Loss: 1.000140905380249, Last lagvar Loss: 0.8653559684753418\n",
      "Step 3283/10000- lr: [6.782841151515152e-06] - Loss total: 2.9093403816223145, Last rpr Loss: 0.9996826648712158, Last lagvar Loss: 0.8657850027084351\n",
      "Step 3284/10000- lr: [6.781831054545455e-06] - Loss total: 2.908993721008301, Last rpr Loss: 0.9999493956565857, Last lagvar Loss: 0.8654874563217163\n",
      "Step 3285/10000- lr: [6.780820957575757e-06] - Loss total: 2.9086475372314453, Last rpr Loss: 0.9997088313102722, Last lagvar Loss: 0.8656976819038391\n",
      "Step 3286/10000- lr: [6.77981086060606e-06] - Loss total: 2.908301591873169, Last rpr Loss: 1.0001139640808105, Last lagvar Loss: 0.8652623891830444\n",
      "Step 3287/10000- lr: [6.778800763636364e-06] - Loss total: 2.907957077026367, Last rpr Loss: 0.9997375011444092, Last lagvar Loss: 0.8656080961227417\n",
      "Step 3288/10000- lr: [6.777790666666667e-06] - Loss total: 2.9076130390167236, Last rpr Loss: 0.9998637437820435, Last lagvar Loss: 0.8654504418373108\n",
      "Step 3289/10000- lr: [6.77678056969697e-06] - Loss total: 2.9072694778442383, Last rpr Loss: 0.9998816847801208, Last lagvar Loss: 0.8654018640518188\n",
      "Step 3290/10000- lr: [6.775770472727273e-06] - Loss total: 2.906926393508911, Last rpr Loss: 0.9999479055404663, Last lagvar Loss: 0.8653051257133484\n",
      "Step 3291/10000- lr: [6.774760375757576e-06] - Loss total: 2.9065840244293213, Last rpr Loss: 0.9997689723968506, Last lagvar Loss: 0.8654530644416809\n",
      "Step 3292/10000- lr: [6.773750278787878e-06] - Loss total: 2.9062418937683105, Last rpr Loss: 0.9998177289962769, Last lagvar Loss: 0.8653738498687744\n",
      "Step 3293/10000- lr: [6.772740181818182e-06] - Loss total: 2.905900716781616, Last rpr Loss: 0.9999806880950928, Last lagvar Loss: 0.8651810884475708\n",
      "Step 3294/10000- lr: [6.771730084848485e-06] - Loss total: 2.9055604934692383, Last rpr Loss: 0.9997938871383667, Last lagvar Loss: 0.8653383255004883\n",
      "Step 3295/10000- lr: [6.770719987878788e-06] - Loss total: 2.9052202701568604, Last rpr Loss: 0.9998443126678467, Last lagvar Loss: 0.865258514881134\n",
      "Step 3296/10000- lr: [6.7697098909090915e-06] - Loss total: 2.904881000518799, Last rpr Loss: 0.9998396635055542, Last lagvar Loss: 0.8652348518371582\n",
      "Step 3297/10000- lr: [6.768699793939394e-06] - Loss total: 2.9045422077178955, Last rpr Loss: 1.0000262260437012, Last lagvar Loss: 0.8650205135345459\n",
      "Step 3298/10000- lr: [6.767689696969697e-06] - Loss total: 2.9042043685913086, Last rpr Loss: 0.9997217655181885, Last lagvar Loss: 0.8652975559234619\n",
      "Step 3299/10000- lr: [6.7666796000000005e-06] - Loss total: 2.903866767883301, Last rpr Loss: 0.9999462962150574, Last lagvar Loss: 0.865046501159668\n",
      "Step 3300/10000- lr: [6.765669503030304e-06] - Loss total: 2.9035301208496094, Last rpr Loss: 0.9998192191123962, Last lagvar Loss: 0.8651480078697205\n",
      "Step 3301/10000- lr: [6.764659406060606e-06] - Loss total: 2.903193712234497, Last rpr Loss: 0.9999963045120239, Last lagvar Loss: 0.8649458289146423\n",
      "Step 3302/10000- lr: [6.7636493090909095e-06] - Loss total: 2.902858257293701, Last rpr Loss: 0.9996553659439087, Last lagvar Loss: 0.8652627468109131\n",
      "Step 3303/10000- lr: [6.762639212121213e-06] - Loss total: 2.9025237560272217, Last rpr Loss: 1.0000327825546265, Last lagvar Loss: 0.8648617267608643\n",
      "Step 3304/10000- lr: [6.761629115151516e-06] - Loss total: 2.902189016342163, Last rpr Loss: 0.9997413754463196, Last lagvar Loss: 0.8651307821273804\n",
      "Step 3305/10000- lr: [6.760619018181819e-06] - Loss total: 2.90185546875, Last rpr Loss: 1.0000224113464355, Last lagvar Loss: 0.864827573299408\n",
      "Step 3306/10000- lr: [6.759608921212122e-06] - Loss total: 2.9015228748321533, Last rpr Loss: 0.9996254444122314, Last lagvar Loss: 0.8652037382125854\n",
      "Step 3307/10000- lr: [6.758598824242425e-06] - Loss total: 2.9011905193328857, Last rpr Loss: 1.000159740447998, Last lagvar Loss: 0.8646489381790161\n",
      "Step 3308/10000- lr: [6.7575887272727274e-06] - Loss total: 2.9008586406707764, Last rpr Loss: 0.9996101260185242, Last lagvar Loss: 0.865179181098938\n",
      "Step 3309/10000- lr: [6.756578630303031e-06] - Loss total: 2.9005274772644043, Last rpr Loss: 1.0001389980316162, Last lagvar Loss: 0.864630937576294\n",
      "Step 3310/10000- lr: [6.755568533333334e-06] - Loss total: 2.9001967906951904, Last rpr Loss: 0.9994989633560181, Last lagvar Loss: 0.8652533292770386\n",
      "Step 3311/10000- lr: [6.754558436363637e-06] - Loss total: 2.899867057800293, Last rpr Loss: 1.0003231763839722, Last lagvar Loss: 0.8644109964370728\n",
      "Step 3312/10000- lr: [6.7535483393939405e-06] - Loss total: 2.8995375633239746, Last rpr Loss: 0.9993448257446289, Last lagvar Loss: 0.8653730154037476\n",
      "Step 3313/10000- lr: [6.752538242424243e-06] - Loss total: 2.8992092609405518, Last rpr Loss: 1.0004246234893799, Last lagvar Loss: 0.8642761707305908\n",
      "Step 3314/10000- lr: [6.751528145454545e-06] - Loss total: 2.898881196975708, Last rpr Loss: 0.9991872310638428, Last lagvar Loss: 0.8654989004135132\n",
      "Step 3315/10000- lr: [6.750518048484849e-06] - Loss total: 2.8985536098480225, Last rpr Loss: 1.0007123947143555, Last lagvar Loss: 0.8639575839042664\n",
      "Step 3316/10000- lr: [6.749507951515152e-06] - Loss total: 2.898226499557495, Last rpr Loss: 0.9988346099853516, Last lagvar Loss: 0.8658224940299988\n",
      "Step 3317/10000- lr: [6.748497854545455e-06] - Loss total: 2.8979005813598633, Last rpr Loss: 1.0010833740234375, Last lagvar Loss: 0.8635586500167847\n",
      "Step 3318/10000- lr: [6.7474877575757585e-06] - Loss total: 2.8975746631622314, Last rpr Loss: 0.9984093904495239, Last lagvar Loss: 0.866222083568573\n",
      "Step 3319/10000- lr: [6.746477660606061e-06] - Loss total: 2.8972504138946533, Last rpr Loss: 1.0016846656799316, Last lagvar Loss: 0.8629328012466431\n",
      "Step 3320/10000- lr: [6.745467563636364e-06] - Loss total: 2.89692759513855, Last rpr Loss: 0.9976118803024292, Last lagvar Loss: 0.8669986724853516\n",
      "Step 3321/10000- lr: [6.744457466666667e-06] - Loss total: 2.8966057300567627, Last rpr Loss: 1.002659559249878, Last lagvar Loss: 0.8619390726089478\n",
      "Step 3322/10000- lr: [6.74344736969697e-06] - Loss total: 2.896287202835083, Last rpr Loss: 0.9964195489883423, Last lagvar Loss: 0.868179202079773\n",
      "Step 3323/10000- lr: [6.742437272727273e-06] - Loss total: 2.895972490310669, Last rpr Loss: 1.0041956901550293, Last lagvar Loss: 0.8603959679603577\n",
      "Step 3324/10000- lr: [6.7414271757575765e-06] - Loss total: 2.895664930343628, Last rpr Loss: 0.9944051504135132, Last lagvar Loss: 0.870201587677002\n",
      "Step 3325/10000- lr: [6.74041707878788e-06] - Loss total: 2.8953654766082764, Last rpr Loss: 1.0067918300628662, Last lagvar Loss: 0.8578221797943115\n",
      "Step 3326/10000- lr: [6.739406981818182e-06] - Loss total: 2.895087480545044, Last rpr Loss: 0.9910951852798462, Last lagvar Loss: 0.8735707998275757\n",
      "Step 3327/10000- lr: [6.7383968848484855e-06] - Loss total: 2.8948280811309814, Last rpr Loss: 1.0110529661178589, Last lagvar Loss: 0.8536586165428162\n",
      "Step 3328/10000- lr: [6.737386787878788e-06] - Loss total: 2.8946328163146973, Last rpr Loss: 0.9855999946594238, Last lagvar Loss: 0.8792613744735718\n",
      "Step 3329/10000- lr: [6.736376690909091e-06] - Loss total: 2.894472599029541, Last rpr Loss: 1.0181677341461182, Last lagvar Loss: 0.8468412756919861\n",
      "Step 3330/10000- lr: [6.7353665939393944e-06] - Loss total: 2.8945114612579346, Last rpr Loss: 0.976560652256012, Last lagvar Loss: 0.8888645768165588\n",
      "Step 3331/10000- lr: [6.734356496969698e-06] - Loss total: 2.894559144973755, Last rpr Loss: 1.0294947624206543, Last lagvar Loss: 0.8362977504730225\n",
      "Step 3332/10000- lr: [6.733346400000001e-06] - Loss total: 2.8949925899505615, Last rpr Loss: 0.9644591808319092, Last lagvar Loss: 0.9021841287612915\n",
      "Step 3333/10000- lr: [6.7323363030303034e-06] - Loss total: 2.8931126594543457, Last rpr Loss: 1.016364336013794, Last lagvar Loss: 0.8485296964645386\n",
      "Step 3334/10000- lr: [6.731326206060606e-06] - Loss total: 2.892409563064575, Last rpr Loss: 1.0002694129943848, Last lagvar Loss: 0.8641964197158813\n",
      "Step 3335/10000- lr: [6.730316109090909e-06] - Loss total: 2.892426013946533, Last rpr Loss: 0.9853291511535645, Last lagvar Loss: 0.8795035481452942\n",
      "Step 3336/10000- lr: [6.729306012121212e-06] - Loss total: 2.8929553031921387, Last rpr Loss: 1.029470682144165, Last lagvar Loss: 0.8362500667572021\n",
      "Step 3337/10000- lr: [6.728295915151516e-06] - Loss total: 2.8942999839782715, Last rpr Loss: 0.957348644733429, Last lagvar Loss: 0.910248339176178\n",
      "Step 3338/10000- lr: [6.727285818181819e-06] - Loss total: 2.8911612033843994, Last rpr Loss: 1.000326156616211, Last lagvar Loss: 0.8641183376312256\n",
      "Step 3339/10000- lr: [6.726275721212121e-06] - Loss total: 2.893155336380005, Last rpr Loss: 1.0421961545944214, Last lagvar Loss: 0.8247542977333069\n",
      "Step 3340/10000- lr: [6.725265624242425e-06] - Loss total: 2.8926594257354736, Last rpr Loss: 0.9630687236785889, Last lagvar Loss: 0.9036810398101807\n",
      "Step 3341/10000- lr: [6.724255527272727e-06] - Loss total: 2.8902759552001953, Last rpr Loss: 1.002179503440857, Last lagvar Loss: 0.8622526526451111\n",
      "Step 3342/10000- lr: [6.72324543030303e-06] - Loss total: 2.8912675380706787, Last rpr Loss: 1.0315364599227905, Last lagvar Loss: 0.8343042135238647\n",
      "Step 3343/10000- lr: [6.722235333333334e-06] - Loss total: 2.8943114280700684, Last rpr Loss: 0.9472188353538513, Last lagvar Loss: 0.9222806096076965\n",
      "Step 3344/10000- lr: [6.721225236363637e-06] - Loss total: 2.8903520107269287, Last rpr Loss: 0.9747086763381958, Last lagvar Loss: 0.8907504081726074\n",
      "Step 3345/10000- lr: [6.72021513939394e-06] - Loss total: 2.904526710510254, Last rpr Loss: 1.1164705753326416, Last lagvar Loss: 0.7647976875305176\n",
      "Step 3346/10000- lr: [6.719205042424243e-06] - Loss total: 2.9041807651519775, Last rpr Loss: 1.1150271892547607, Last lagvar Loss: 0.7661091685295105\n",
      "Step 3347/10000- lr: [6.718194945454546e-06] - Loss total: 2.888896942138672, Last rpr Loss: 0.9837659597396851, Last lagvar Loss: 0.8809887170791626\n",
      "Step 3348/10000- lr: [6.717184848484848e-06] - Loss total: 2.893890380859375, Last rpr Loss: 0.9434455633163452, Last lagvar Loss: 0.9269051551818848\n",
      "Step 3349/10000- lr: [6.716174751515152e-06] - Loss total: 2.888157844543457, Last rpr Loss: 1.0046448707580566, Last lagvar Loss: 0.859846830368042\n",
      "Step 3350/10000- lr: [6.715164654545455e-06] - Loss total: 2.8927230834960938, Last rpr Loss: 1.0608183145523071, Last lagvar Loss: 0.8089077472686768\n",
      "Step 3351/10000- lr: [6.714154557575758e-06] - Loss total: 2.8877203464508057, Last rpr Loss: 0.9912232756614685, Last lagvar Loss: 0.8733687996864319\n",
      "Step 3352/10000- lr: [6.7131444606060615e-06] - Loss total: 2.8899781703948975, Last rpr Loss: 0.963942289352417, Last lagvar Loss: 0.9033350944519043\n",
      "Step 3353/10000- lr: [6.712134363636364e-06] - Loss total: 2.8887033462524414, Last rpr Loss: 1.038787603378296, Last lagvar Loss: 0.8273023366928101\n",
      "Step 3354/10000- lr: [6.711124266666666e-06] - Loss total: 2.887115478515625, Last rpr Loss: 0.9826133251190186, Last lagvar Loss: 0.8820538520812988\n",
      "Step 3355/10000- lr: [6.71011416969697e-06] - Loss total: 2.886831045150757, Last rpr Loss: 0.9865602254867554, Last lagvar Loss: 0.8780386447906494\n",
      "Step 3356/10000- lr: [6.709104072727273e-06] - Loss total: 2.887558937072754, Last rpr Loss: 1.0359318256378174, Last lagvar Loss: 0.8297160863876343\n",
      "Step 3357/10000- lr: [6.708093975757576e-06] - Loss total: 2.8889217376708984, Last rpr Loss: 0.9583368301391602, Last lagvar Loss: 0.909018874168396\n",
      "Step 3358/10000- lr: [6.7070838787878794e-06] - Loss total: 2.885936975479126, Last rpr Loss: 0.9944102764129639, Last lagvar Loss: 0.8700308799743652\n",
      "Step 3359/10000- lr: [6.706073781818182e-06] - Loss total: 2.8883466720581055, Last rpr Loss: 1.0486857891082764, Last lagvar Loss: 0.8185787200927734\n",
      "Step 3360/10000- lr: [6.705063684848485e-06] - Loss total: 2.8864686489105225, Last rpr Loss: 0.9775006771087646, Last lagvar Loss: 0.8880605697631836\n",
      "Step 3361/10000- lr: [6.7040535878787876e-06] - Loss total: 2.885261297225952, Last rpr Loss: 1.0013107061386108, Last lagvar Loss: 0.8632314205169678\n",
      "Step 3362/10000- lr: [6.703043490909091e-06] - Loss total: 2.8851163387298584, Last rpr Loss: 1.011414885520935, Last lagvar Loss: 0.8531659245491028\n",
      "Step 3363/10000- lr: [6.702033393939394e-06] - Loss total: 2.8858799934387207, Last rpr Loss: 0.9762404561042786, Last lagvar Loss: 0.8895475268363953\n",
      "Step 3364/10000- lr: [6.701023296969697e-06] - Loss total: 2.8862922191619873, Last rpr Loss: 1.038635015487671, Last lagvar Loss: 0.8278585076332092\n",
      "Step 3365/10000- lr: [6.700013200000001e-06] - Loss total: 2.884363889694214, Last rpr Loss: 0.9819967746734619, Last lagvar Loss: 0.8826890587806702\n",
      "Step 3366/10000- lr: [6.699003103030303e-06] - Loss total: 2.8839755058288574, Last rpr Loss: 0.9923232197761536, Last lagvar Loss: 0.8722150325775146\n",
      "Step 3367/10000- lr: [6.697993006060606e-06] - Loss total: 2.8846986293792725, Last rpr Loss: 1.0309799909591675, Last lagvar Loss: 0.8346121311187744\n",
      "Step 3368/10000- lr: [6.696982909090909e-06] - Loss total: 2.8861987590789795, Last rpr Loss: 0.9530212879180908, Last lagvar Loss: 0.914502739906311\n",
      "Step 3369/10000- lr: [6.695972812121212e-06] - Loss total: 2.883045196533203, Last rpr Loss: 0.9933800101280212, Last lagvar Loss: 0.8710280656814575\n",
      "Step 3370/10000- lr: [6.694962715151515e-06] - Loss total: 2.8865060806274414, Last rpr Loss: 1.0599608421325684, Last lagvar Loss: 0.8084720373153687\n",
      "Step 3371/10000- lr: [6.693952618181819e-06] - Loss total: 2.8826465606689453, Last rpr Loss: 0.9948096871376038, Last lagvar Loss: 0.8697574734687805\n",
      "Step 3372/10000- lr: [6.692942521212122e-06] - Loss total: 2.883436441421509, Last rpr Loss: 0.9661041498184204, Last lagvar Loss: 0.8996064066886902\n",
      "Step 3373/10000- lr: [6.691932424242424e-06] - Loss total: 2.886319875717163, Last rpr Loss: 1.058239221572876, Last lagvar Loss: 0.8106812834739685\n",
      "Step 3374/10000- lr: [6.690922327272727e-06] - Loss total: 2.8823864459991455, Last rpr Loss: 1.0251621007919312, Last lagvar Loss: 0.8398783206939697\n",
      "Step 3375/10000- lr: [6.68991223030303e-06] - Loss total: 2.8911869525909424, Last rpr Loss: 0.921781599521637, Last lagvar Loss: 0.9529105424880981\n",
      "Step 3376/10000- lr: [6.688902133333333e-06] - Loss total: 2.888840675354004, Last rpr Loss: 0.9273033142089844, Last lagvar Loss: 0.9451093673706055\n",
      "Step 3377/10000- lr: [6.687892036363637e-06] - Loss total: 2.8835573196411133, Last rpr Loss: 1.0418734550476074, Last lagvar Loss: 0.8254055380821228\n",
      "Step 3378/10000- lr: [6.68688193939394e-06] - Loss total: 2.882978677749634, Last rpr Loss: 1.044525146484375, Last lagvar Loss: 0.8221758604049683\n",
      "Step 3379/10000- lr: [6.685871842424242e-06] - Loss total: 2.886899948120117, Last rpr Loss: 0.9388499855995178, Last lagvar Loss: 0.9323461055755615\n",
      "Step 3380/10000- lr: [6.684861745454546e-06] - Loss total: 2.884742021560669, Last rpr Loss: 0.9439502358436584, Last lagvar Loss: 0.9250471591949463\n",
      "Step 3381/10000- lr: [6.683851648484848e-06] - Loss total: 2.885589599609375, Last rpr Loss: 1.0636379718780518, Last lagvar Loss: 0.806627631187439\n",
      "Step 3382/10000- lr: [6.682841551515151e-06] - Loss total: 2.8849751949310303, Last rpr Loss: 1.0631906986236572, Last lagvar Loss: 0.8064901232719421\n",
      "Step 3383/10000- lr: [6.681831454545455e-06] - Loss total: 2.8831799030303955, Last rpr Loss: 0.9539511203765869, Last lagvar Loss: 0.9141467809677124\n",
      "Step 3384/10000- lr: [6.680821357575758e-06] - Loss total: 2.8818111419677734, Last rpr Loss: 0.9619887471199036, Last lagvar Loss: 0.9047234058380127\n",
      "Step 3385/10000- lr: [6.679811260606061e-06] - Loss total: 2.8875911235809326, Last rpr Loss: 1.0838241577148438, Last lagvar Loss: 0.7894715070724487\n",
      "Step 3386/10000- lr: [6.678801163636364e-06] - Loss total: 2.8866310119628906, Last rpr Loss: 1.077336311340332, Last lagvar Loss: 0.7951177358627319\n",
      "Step 3387/10000- lr: [6.677791066666668e-06] - Loss total: 2.8810198307037354, Last rpr Loss: 0.959687352180481, Last lagvar Loss: 0.9067940711975098\n",
      "Step 3388/10000- lr: [6.67678096969697e-06] - Loss total: 2.8801238536834717, Last rpr Loss: 0.9732892513275146, Last lagvar Loss: 0.8924506902694702\n",
      "Step 3389/10000- lr: [6.675770872727273e-06] - Loss total: 2.8878185749053955, Last rpr Loss: 1.0925538539886475, Last lagvar Loss: 0.7818165421485901\n",
      "Step 3390/10000- lr: [6.674760775757576e-06] - Loss total: 2.885756492614746, Last rpr Loss: 1.0791430473327637, Last lagvar Loss: 0.7932990789413452\n",
      "Step 3391/10000- lr: [6.673750678787879e-06] - Loss total: 2.8808350563049316, Last rpr Loss: 0.9560215473175049, Last lagvar Loss: 0.9110028147697449\n",
      "Step 3392/10000- lr: [6.672740581818182e-06] - Loss total: 2.8803837299346924, Last rpr Loss: 0.9622305631637573, Last lagvar Loss: 0.9046300649642944\n",
      "Step 3393/10000- lr: [6.671730484848486e-06] - Loss total: 2.8844666481018066, Last rpr Loss: 1.0767375230789185, Last lagvar Loss: 0.7943882346153259\n",
      "Step 3394/10000- lr: [6.670720387878789e-06] - Loss total: 2.8828043937683105, Last rpr Loss: 1.0644290447235107, Last lagvar Loss: 0.8053013682365417\n",
      "Step 3395/10000- lr: [6.669710290909091e-06] - Loss total: 2.8812875747680664, Last rpr Loss: 0.946082592010498, Last lagvar Loss: 0.9221518039703369\n",
      "Step 3396/10000- lr: [6.668700193939395e-06] - Loss total: 2.880671977996826, Last rpr Loss: 0.9517334699630737, Last lagvar Loss: 0.9160199165344238\n",
      "Step 3397/10000- lr: [6.667690096969697e-06] - Loss total: 2.8819527626037598, Last rpr Loss: 1.0670137405395508, Last lagvar Loss: 0.8022944927215576\n",
      "Step 3398/10000- lr: [6.66668e-06] - Loss total: 2.8806307315826416, Last rpr Loss: 1.057878851890564, Last lagvar Loss: 0.8102582693099976\n",
      "Step 3399/10000- lr: [6.665669903030304e-06] - Loss total: 2.8815033435821533, Last rpr Loss: 0.9425945281982422, Last lagvar Loss: 0.9264782667160034\n",
      "Step 3400/10000- lr: [6.664659806060607e-06] - Loss total: 2.8806943893432617, Last rpr Loss: 0.9456285238265991, Last lagvar Loss: 0.9228188991546631\n",
      "Step 3401/10000- lr: [6.66364970909091e-06] - Loss total: 2.8803155422210693, Last rpr Loss: 1.0572092533111572, Last lagvar Loss: 0.8110032081604004\n",
      "Step 3402/10000- lr: [6.662639612121213e-06] - Loss total: 2.879127025604248, Last rpr Loss: 1.0490854978561401, Last lagvar Loss: 0.8180240392684937\n",
      "Step 3403/10000- lr: [6.661629515151515e-06] - Loss total: 2.8815975189208984, Last rpr Loss: 0.9382732510566711, Last lagvar Loss: 0.9316719770431519\n",
      "Step 3404/10000- lr: [6.660619418181818e-06] - Loss total: 2.8805956840515137, Last rpr Loss: 0.9423816204071045, Last lagvar Loss: 0.9266037344932556\n",
      "Step 3405/10000- lr: [6.659609321212122e-06] - Loss total: 2.879147529602051, Last rpr Loss: 1.053649663925171, Last lagvar Loss: 0.8141635656356812\n",
      "Step 3406/10000- lr: [6.658599224242425e-06] - Loss total: 2.8780980110168457, Last rpr Loss: 1.046875, Last lagvar Loss: 0.8199062347412109\n",
      "Step 3407/10000- lr: [6.657589127272728e-06] - Loss total: 2.881270170211792, Last rpr Loss: 0.9374555945396423, Last lagvar Loss: 0.9328531622886658\n",
      "Step 3408/10000- lr: [6.656579030303031e-06] - Loss total: 2.8802123069763184, Last rpr Loss: 0.9403495788574219, Last lagvar Loss: 0.928989589214325\n",
      "Step 3409/10000- lr: [6.655568933333334e-06] - Loss total: 2.8781864643096924, Last rpr Loss: 1.0491851568222046, Last lagvar Loss: 0.8182274103164673\n",
      "Step 3410/10000- lr: [6.654558836363636e-06] - Loss total: 2.877272844314575, Last rpr Loss: 1.0438957214355469, Last lagvar Loss: 0.822718620300293\n",
      "Step 3411/10000- lr: [6.6535487393939396e-06] - Loss total: 2.880627393722534, Last rpr Loss: 0.9381493330001831, Last lagvar Loss: 0.932090163230896\n",
      "Step 3412/10000- lr: [6.652538642424243e-06] - Loss total: 2.8795642852783203, Last rpr Loss: 0.9429739713668823, Last lagvar Loss: 0.9263167977333069\n",
      "Step 3413/10000- lr: [6.651528545454546e-06] - Loss total: 2.877398729324341, Last rpr Loss: 1.0501749515533447, Last lagvar Loss: 0.8171074986457825\n",
      "Step 3414/10000- lr: [6.650518448484849e-06] - Loss total: 2.876525640487671, Last rpr Loss: 1.0422649383544922, Last lagvar Loss: 0.8242762088775635\n",
      "Step 3415/10000- lr: [6.649508351515152e-06] - Loss total: 2.8799617290496826, Last rpr Loss: 0.936324417591095, Last lagvar Loss: 0.933924674987793\n",
      "Step 3416/10000- lr: [6.648498254545455e-06] - Loss total: 2.8789045810699463, Last rpr Loss: 0.9418826103210449, Last lagvar Loss: 0.9274647235870361\n",
      "Step 3417/10000- lr: [6.6474881575757575e-06] - Loss total: 2.876652717590332, Last rpr Loss: 1.0493595600128174, Last lagvar Loss: 0.8177609443664551\n",
      "Step 3418/10000- lr: [6.646478060606061e-06] - Loss total: 2.875835418701172, Last rpr Loss: 1.0420606136322021, Last lagvar Loss: 0.8244531750679016\n",
      "Step 3419/10000- lr: [6.645467963636364e-06] - Loss total: 2.8791685104370117, Last rpr Loss: 0.9368603229522705, Last lagvar Loss: 0.9331572651863098\n",
      "Step 3420/10000- lr: [6.644457866666667e-06] - Loss total: 2.8781189918518066, Last rpr Loss: 0.943048357963562, Last lagvar Loss: 0.926072895526886\n",
      "Step 3421/10000- lr: [6.643447769696971e-06] - Loss total: 2.8759689331054688, Last rpr Loss: 1.0506227016448975, Last lagvar Loss: 0.8164992332458496\n",
      "Step 3422/10000- lr: [6.642437672727273e-06] - Loss total: 2.875148296356201, Last rpr Loss: 1.0423851013183594, Last lagvar Loss: 0.8240615129470825\n",
      "Step 3423/10000- lr: [6.6414275757575755e-06] - Loss total: 2.878357172012329, Last rpr Loss: 0.936316967010498, Last lagvar Loss: 0.9335824847221375\n",
      "Step 3424/10000- lr: [6.640417478787879e-06] - Loss total: 2.87728214263916, Last rpr Loss: 0.9422084093093872, Last lagvar Loss: 0.9267469644546509\n",
      "Step 3425/10000- lr: [6.639407381818182e-06] - Loss total: 2.875354051589966, Last rpr Loss: 1.050789475440979, Last lagvar Loss: 0.8163772225379944\n",
      "Step 3426/10000- lr: [6.638397284848485e-06] - Loss total: 2.8745148181915283, Last rpr Loss: 1.043963074684143, Last lagvar Loss: 0.8225181102752686\n",
      "Step 3427/10000- lr: [6.637387187878789e-06] - Loss total: 2.8775253295898438, Last rpr Loss: 0.9377781748771667, Last lagvar Loss: 0.9319119453430176\n",
      "Step 3428/10000- lr: [6.636377090909091e-06] - Loss total: 2.876476764678955, Last rpr Loss: 0.9429200887680054, Last lagvar Loss: 0.9258633255958557\n",
      "Step 3429/10000- lr: [6.635366993939394e-06] - Loss total: 2.874701976776123, Last rpr Loss: 1.0508785247802734, Last lagvar Loss: 0.8163036108016968\n",
      "Step 3430/10000- lr: [6.634356896969697e-06] - Loss total: 2.873856782913208, Last rpr Loss: 1.0442638397216797, Last lagvar Loss: 0.822196364402771\n",
      "Step 3431/10000- lr: [6.6333468e-06] - Loss total: 2.876723051071167, Last rpr Loss: 0.9382326602935791, Last lagvar Loss: 0.9313395023345947\n",
      "Step 3432/10000- lr: [6.632336703030303e-06] - Loss total: 2.875682830810547, Last rpr Loss: 0.9429314136505127, Last lagvar Loss: 0.9257293939590454\n",
      "Step 3433/10000- lr: [6.6313266060606066e-06] - Loss total: 2.874058485031128, Last rpr Loss: 1.050636887550354, Last lagvar Loss: 0.816572368144989\n",
      "Step 3434/10000- lr: [6.63031650909091e-06] - Loss total: 2.8732166290283203, Last rpr Loss: 1.0448784828186035, Last lagvar Loss: 0.8216270804405212\n",
      "Step 3435/10000- lr: [6.629306412121212e-06] - Loss total: 2.875905990600586, Last rpr Loss: 0.9397584199905396, Last lagvar Loss: 0.9296342134475708\n",
      "Step 3436/10000- lr: [6.6282963151515156e-06] - Loss total: 2.874894857406616, Last rpr Loss: 0.9442945122718811, Last lagvar Loss: 0.9242269992828369\n",
      "Step 3437/10000- lr: [6.627286218181818e-06] - Loss total: 2.8733880519866943, Last rpr Loss: 1.0508389472961426, Last lagvar Loss: 0.8163647651672363\n",
      "Step 3438/10000- lr: [6.626276121212121e-06] - Loss total: 2.8725504875183105, Last rpr Loss: 1.0446405410766602, Last lagvar Loss: 0.8218634724617004\n",
      "Step 3439/10000- lr: [6.6252660242424245e-06] - Loss total: 2.8751018047332764, Last rpr Loss: 0.9401397705078125, Last lagvar Loss: 0.9291070103645325\n",
      "Step 3440/10000- lr: [6.624255927272728e-06] - Loss total: 2.8740952014923096, Last rpr Loss: 0.9450211524963379, Last lagvar Loss: 0.9233607649803162\n",
      "Step 3441/10000- lr: [6.623245830303031e-06] - Loss total: 2.8727428913116455, Last rpr Loss: 1.0511813163757324, Last lagvar Loss: 0.8160433769226074\n",
      "Step 3442/10000- lr: [6.6222357333333335e-06] - Loss total: 2.8718960285186768, Last rpr Loss: 1.0446619987487793, Last lagvar Loss: 0.8218598365783691\n",
      "Step 3443/10000- lr: [6.621225636363637e-06] - Loss total: 2.8743181228637695, Last rpr Loss: 0.9406599402427673, Last lagvar Loss: 0.9284657835960388\n",
      "Step 3444/10000- lr: [6.620215539393939e-06] - Loss total: 2.873337984085083, Last rpr Loss: 0.9458548426628113, Last lagvar Loss: 0.9224377870559692\n",
      "Step 3445/10000- lr: [6.6192054424242425e-06] - Loss total: 2.8720574378967285, Last rpr Loss: 1.0516220331192017, Last lagvar Loss: 0.8155744075775146\n",
      "Step 3446/10000- lr: [6.618195345454546e-06] - Loss total: 2.871225595474243, Last rpr Loss: 1.0448057651519775, Last lagvar Loss: 0.8217131495475769\n",
      "Step 3447/10000- lr: [6.617185248484849e-06] - Loss total: 2.8735275268554688, Last rpr Loss: 0.9408178925514221, Last lagvar Loss: 0.9281754493713379\n",
      "Step 3448/10000- lr: [6.616175151515152e-06] - Loss total: 2.872558116912842, Last rpr Loss: 0.9460411071777344, Last lagvar Loss: 0.9221357703208923\n",
      "Step 3449/10000- lr: [6.615165054545455e-06] - Loss total: 2.8713905811309814, Last rpr Loss: 1.0517133474349976, Last lagvar Loss: 0.8154795169830322\n",
      "Step 3450/10000- lr: [6.614154957575757e-06] - Loss total: 2.870556116104126, Last rpr Loss: 1.0450303554534912, Last lagvar Loss: 0.821487307548523\n",
      "Step 3451/10000- lr: [6.6131448606060605e-06] - Loss total: 2.872751235961914, Last rpr Loss: 0.9413918256759644, Last lagvar Loss: 0.9274832010269165\n",
      "Step 3452/10000- lr: [6.612134763636364e-06] - Loss total: 2.8717968463897705, Last rpr Loss: 0.9466774463653564, Last lagvar Loss: 0.9213977456092834\n",
      "Step 3453/10000- lr: [6.611124666666667e-06] - Loss total: 2.870709180831909, Last rpr Loss: 1.052079677581787, Last lagvar Loss: 0.8150997161865234\n",
      "Step 3454/10000- lr: [6.61011456969697e-06] - Loss total: 2.8698790073394775, Last rpr Loss: 1.0453468561172485, Last lagvar Loss: 0.821160078048706\n",
      "Step 3455/10000- lr: [6.609104472727273e-06] - Loss total: 2.8719751834869385, Last rpr Loss: 0.9416162967681885, Last lagvar Loss: 0.9271496534347534\n",
      "Step 3456/10000- lr: [6.608094375757576e-06] - Loss total: 2.871030569076538, Last rpr Loss: 0.9466384053230286, Last lagvar Loss: 0.9213413000106812\n",
      "Step 3457/10000- lr: [6.6070842787878785e-06] - Loss total: 2.8700335025787354, Last rpr Loss: 1.0518670082092285, Last lagvar Loss: 0.8153023719787598\n",
      "Step 3458/10000- lr: [6.606074181818182e-06] - Loss total: 2.8692030906677246, Last rpr Loss: 1.0455726385116577, Last lagvar Loss: 0.8209265470504761\n",
      "Step 3459/10000- lr: [6.605064084848485e-06] - Loss total: 2.871203660964966, Last rpr Loss: 0.9424159526824951, Last lagvar Loss: 0.9262399673461914\n",
      "Step 3460/10000- lr: [6.604053987878788e-06] - Loss total: 2.870272159576416, Last rpr Loss: 0.9473686218261719, Last lagvar Loss: 0.9205124378204346\n",
      "Step 3461/10000- lr: [6.6030438909090916e-06] - Loss total: 2.8693482875823975, Last rpr Loss: 1.0520706176757812, Last lagvar Loss: 0.815089225769043\n",
      "Step 3462/10000- lr: [6.602033793939394e-06] - Loss total: 2.868520498275757, Last rpr Loss: 1.0456715822219849, Last lagvar Loss: 0.8208143711090088\n",
      "Step 3463/10000- lr: [6.601023696969697e-06] - Loss total: 2.8704347610473633, Last rpr Loss: 0.9427033066749573, Last lagvar Loss: 0.9258584380149841\n",
      "Step 3464/10000- lr: [6.6000136e-06] - Loss total: 2.869509696960449, Last rpr Loss: 0.9475100040435791, Last lagvar Loss: 0.9202847480773926\n",
      "Step 3465/10000- lr: [6.599003503030303e-06] - Loss total: 2.868670701980591, Last rpr Loss: 1.051882266998291, Last lagvar Loss: 0.8152728080749512\n",
      "Step 3466/10000- lr: [6.597993406060606e-06] - Loss total: 2.867842435836792, Last rpr Loss: 1.0457499027252197, Last lagvar Loss: 0.8207337856292725\n",
      "Step 3467/10000- lr: [6.5969833090909095e-06] - Loss total: 2.869666814804077, Last rpr Loss: 0.9434204697608948, Last lagvar Loss: 0.925040602684021\n",
      "Step 3468/10000- lr: [6.595973212121213e-06] - Loss total: 2.8687539100646973, Last rpr Loss: 0.948291003704071, Last lagvar Loss: 0.919416069984436\n",
      "Step 3469/10000- lr: [6.594963115151515e-06] - Loss total: 2.8679847717285156, Last rpr Loss: 1.0521129369735718, Last lagvar Loss: 0.8150314092636108\n",
      "Step 3470/10000- lr: [6.593953018181819e-06] - Loss total: 2.867159605026245, Last rpr Loss: 1.0457684993743896, Last lagvar Loss: 0.8207061290740967\n",
      "Step 3471/10000- lr: [6.592942921212122e-06] - Loss total: 2.8689000606536865, Last rpr Loss: 0.9436628818511963, Last lagvar Loss: 0.9247114658355713\n",
      "Step 3472/10000- lr: [6.591932824242424e-06] - Loss total: 2.86799693107605, Last rpr Loss: 0.9485130310058594, Last lagvar Loss: 0.9191187024116516\n",
      "Step 3473/10000- lr: [6.5909227272727275e-06] - Loss total: 2.867300033569336, Last rpr Loss: 1.0520477294921875, Last lagvar Loss: 0.8150865435600281\n",
      "Step 3474/10000- lr: [6.589912630303031e-06] - Loss total: 2.86647891998291, Last rpr Loss: 1.0458858013153076, Last lagvar Loss: 0.8205907344818115\n",
      "Step 3475/10000- lr: [6.588902533333334e-06] - Loss total: 2.8681299686431885, Last rpr Loss: 0.9442934989929199, Last lagvar Loss: 0.9239794015884399\n",
      "Step 3476/10000- lr: [6.587892436363637e-06] - Loss total: 2.8672382831573486, Last rpr Loss: 0.9492027163505554, Last lagvar Loss: 0.918344259262085\n",
      "Step 3477/10000- lr: [6.58688233939394e-06] - Loss total: 2.866610288619995, Last rpr Loss: 1.0522480010986328, Last lagvar Loss: 0.8148730993270874\n",
      "Step 3478/10000- lr: [6.585872242424243e-06] - Loss total: 2.8657915592193604, Last rpr Loss: 1.0459070205688477, Last lagvar Loss: 0.8205599784851074\n",
      "Step 3479/10000- lr: [6.5848621454545455e-06] - Loss total: 2.8673622608184814, Last rpr Loss: 0.9445294141769409, Last lagvar Loss: 0.9236576557159424\n",
      "Step 3480/10000- lr: [6.583852048484849e-06] - Loss total: 2.86647891998291, Last rpr Loss: 0.9494493007659912, Last lagvar Loss: 0.9180216789245605\n",
      "Step 3481/10000- lr: [6.582841951515152e-06] - Loss total: 2.8659229278564453, Last rpr Loss: 1.0522558689117432, Last lagvar Loss: 0.8148571252822876\n",
      "Step 3482/10000- lr: [6.581831854545455e-06] - Loss total: 2.8651065826416016, Last rpr Loss: 1.0460656881332397, Last lagvar Loss: 0.8204002380371094\n",
      "Step 3483/10000- lr: [6.5808217575757586e-06] - Loss total: 2.8665904998779297, Last rpr Loss: 0.9450976848602295, Last lagvar Loss: 0.9229947328567505\n",
      "Step 3484/10000- lr: [6.579811660606061e-06] - Loss total: 2.865717887878418, Last rpr Loss: 0.9500224590301514, Last lagvar Loss: 0.9173666834831238\n",
      "Step 3485/10000- lr: [6.578801563636364e-06] - Loss total: 2.8652312755584717, Last rpr Loss: 1.052424430847168, Last lagvar Loss: 0.8146796226501465\n",
      "Step 3486/10000- lr: [6.577791466666667e-06] - Loss total: 2.8644165992736816, Last rpr Loss: 1.0461459159851074, Last lagvar Loss: 0.8203119039535522\n",
      "Step 3487/10000- lr: [6.57678136969697e-06] - Loss total: 2.86582088470459, Last rpr Loss: 0.9453980326652527, Last lagvar Loss: 0.9226115942001343\n",
      "Step 3488/10000- lr: [6.575771272727273e-06] - Loss total: 2.864955186843872, Last rpr Loss: 0.9502847194671631, Last lagvar Loss: 0.917030394077301\n",
      "Step 3489/10000- lr: [6.5747611757575765e-06] - Loss total: 2.864539861679077, Last rpr Loss: 1.052441120147705, Last lagvar Loss: 0.8146581649780273\n",
      "Step 3490/10000- lr: [6.57375107878788e-06] - Loss total: 2.86372709274292, Last rpr Loss: 1.0463372468948364, Last lagvar Loss: 0.820121169090271\n",
      "Step 3491/10000- lr: [6.572740981818182e-06] - Loss total: 2.8650453090667725, Last rpr Loss: 0.9459903240203857, Last lagvar Loss: 0.9219281673431396\n",
      "Step 3492/10000- lr: [6.571730884848485e-06] - Loss total: 2.8641889095306396, Last rpr Loss: 0.9508498311042786, Last lagvar Loss: 0.9163855314254761\n",
      "Step 3493/10000- lr: [6.570720787878788e-06] - Loss total: 2.8638463020324707, Last rpr Loss: 1.0525894165039062, Last lagvar Loss: 0.8145059943199158\n",
      "Step 3494/10000- lr: [6.569710690909091e-06] - Loss total: 2.8630332946777344, Last rpr Loss: 1.0464162826538086, Last lagvar Loss: 0.8200370073318481\n",
      "Step 3495/10000- lr: [6.5687005939393945e-06] - Loss total: 2.864271879196167, Last rpr Loss: 0.9463136196136475, Last lagvar Loss: 0.9215270280838013\n",
      "Step 3496/10000- lr: [6.567690496969698e-06] - Loss total: 2.8634231090545654, Last rpr Loss: 0.9511330723762512, Last lagvar Loss: 0.9160333275794983\n",
      "Step 3497/10000- lr: [6.566680400000001e-06] - Loss total: 2.863149881362915, Last rpr Loss: 1.052609920501709, Last lagvar Loss: 0.8144820928573608\n",
      "Step 3498/10000- lr: [6.5656703030303035e-06] - Loss total: 2.862339496612549, Last rpr Loss: 1.0466139316558838, Last lagvar Loss: 0.8198428153991699\n",
      "Step 3499/10000- lr: [6.564660206060606e-06] - Loss total: 2.8634915351867676, Last rpr Loss: 0.9469172954559326, Last lagvar Loss: 0.9208346605300903\n",
      "Step 3500/10000- lr: [6.563650109090909e-06] - Loss total: 2.862651824951172, Last rpr Loss: 0.9516971111297607, Last lagvar Loss: 0.9153927564620972\n",
      "Step 3501/10000- lr: [6.5626400121212125e-06] - Loss total: 2.862450122833252, Last rpr Loss: 1.052735447883606, Last lagvar Loss: 0.8143541812896729\n",
      "Step 3502/10000- lr: [6.561629915151516e-06] - Loss total: 2.8616397380828857, Last rpr Loss: 1.0466785430908203, Last lagvar Loss: 0.8197757005691528\n",
      "Step 3503/10000- lr: [6.560619818181819e-06] - Loss total: 2.862711191177368, Last rpr Loss: 0.9472809433937073, Last lagvar Loss: 0.9203941822052002\n",
      "Step 3504/10000- lr: [6.5596097212121215e-06] - Loss total: 2.8618786334991455, Last rpr Loss: 0.9520552158355713, Last lagvar Loss: 0.9149664044380188\n",
      "Step 3505/10000- lr: [6.558599624242425e-06] - Loss total: 2.861748456954956, Last rpr Loss: 1.0528024435043335, Last lagvar Loss: 0.8142869472503662\n",
      "Step 3506/10000- lr: [6.557589527272727e-06] - Loss total: 2.8609392642974854, Last rpr Loss: 1.0468586683273315, Last lagvar Loss: 0.8196010589599609\n",
      "Step 3507/10000- lr: [6.5565794303030304e-06] - Loss total: 2.861924409866333, Last rpr Loss: 0.9478428959846497, Last lagvar Loss: 0.9197475910186768\n",
      "Step 3508/10000- lr: [6.555569333333334e-06] - Loss total: 2.861100912094116, Last rpr Loss: 0.952597975730896, Last lagvar Loss: 0.9143509864807129\n",
      "Step 3509/10000- lr: [6.554559236363637e-06] - Loss total: 2.861042022705078, Last rpr Loss: 1.05292809009552, Last lagvar Loss: 0.8141604661941528\n",
      "Step 3510/10000- lr: [6.55354913939394e-06] - Loss total: 2.8602325916290283, Last rpr Loss: 1.046932578086853, Last lagvar Loss: 0.8195269107818604\n",
      "Step 3511/10000- lr: [6.552539042424243e-06] - Loss total: 2.861137628555298, Last rpr Loss: 0.9482305645942688, Last lagvar Loss: 0.9192847609519958\n",
      "Step 3512/10000- lr: [6.551528945454546e-06] - Loss total: 2.860320806503296, Last rpr Loss: 0.9530033469200134, Last lagvar Loss: 0.9138782620429993\n",
      "Step 3513/10000- lr: [6.550518848484848e-06] - Loss total: 2.8603336811065674, Last rpr Loss: 1.053045392036438, Last lagvar Loss: 0.8140456080436707\n",
      "Step 3514/10000- lr: [6.549508751515152e-06] - Loss total: 2.859525680541992, Last rpr Loss: 1.0471224784851074, Last lagvar Loss: 0.8193439245223999\n",
      "Step 3515/10000- lr: [6.548498654545455e-06] - Loss total: 2.860344886779785, Last rpr Loss: 0.9487569332122803, Last lagvar Loss: 0.918677806854248\n",
      "Step 3516/10000- lr: [6.547488557575758e-06] - Loss total: 2.85953688621521, Last rpr Loss: 0.9535045623779297, Last lagvar Loss: 0.913308322429657\n",
      "Step 3517/10000- lr: [6.5464784606060615e-06] - Loss total: 2.859621286392212, Last rpr Loss: 1.0531651973724365, Last lagvar Loss: 0.8139259219169617\n",
      "Step 3518/10000- lr: [6.545468363636364e-06] - Loss total: 2.8588130474090576, Last rpr Loss: 1.0472252368927002, Last lagvar Loss: 0.8192426562309265\n",
      "Step 3519/10000- lr: [6.544458266666666e-06] - Loss total: 2.8595516681671143, Last rpr Loss: 0.9491729736328125, Last lagvar Loss: 0.91818767786026\n",
      "Step 3520/10000- lr: [6.54344816969697e-06] - Loss total: 2.8587520122528076, Last rpr Loss: 0.9539259672164917, Last lagvar Loss: 0.9128210544586182\n",
      "Step 3521/10000- lr: [6.542438072727273e-06] - Loss total: 2.8589069843292236, Last rpr Loss: 1.053293228149414, Last lagvar Loss: 0.8138006925582886\n",
      "Step 3522/10000- lr: [6.541427975757576e-06] - Loss total: 2.8580994606018066, Last rpr Loss: 1.0474095344543457, Last lagvar Loss: 0.8190640807151794\n",
      "Step 3523/10000- lr: [6.5404178787878795e-06] - Loss total: 2.858757495880127, Last rpr Loss: 0.9496703147888184, Last lagvar Loss: 0.9176148176193237\n",
      "Step 3524/10000- lr: [6.539407781818182e-06] - Loss total: 2.857966423034668, Last rpr Loss: 0.9543914794921875, Last lagvar Loss: 0.9122908115386963\n",
      "Step 3525/10000- lr: [6.538397684848485e-06] - Loss total: 2.858189582824707, Last rpr Loss: 1.0534003973007202, Last lagvar Loss: 0.8136934041976929\n",
      "Step 3526/10000- lr: [6.537387587878788e-06] - Loss total: 2.8573832511901855, Last rpr Loss: 1.0475281476974487, Last lagvar Loss: 0.8189470767974854\n",
      "Step 3527/10000- lr: [6.536377490909091e-06] - Loss total: 2.8579647541046143, Last rpr Loss: 0.9501022696495056, Last lagvar Loss: 0.9171113967895508\n",
      "Step 3528/10000- lr: [6.535367393939394e-06] - Loss total: 2.857182025909424, Last rpr Loss: 0.9548080563545227, Last lagvar Loss: 0.9118114709854126\n",
      "Step 3529/10000- lr: [6.5343572969696975e-06] - Loss total: 2.8574717044830322, Last rpr Loss: 1.0535004138946533, Last lagvar Loss: 0.8135937452316284\n",
      "Step 3530/10000- lr: [6.533347200000001e-06] - Loss total: 2.856666326522827, Last rpr Loss: 1.0476727485656738, Last lagvar Loss: 0.8188048601150513\n",
      "Step 3531/10000- lr: [6.532337103030303e-06] - Loss total: 2.8571746349334717, Last rpr Loss: 0.950569212436676, Last lagvar Loss: 0.9165740013122559\n",
      "Step 3532/10000- lr: [6.5313270060606064e-06] - Loss total: 2.856400728225708, Last rpr Loss: 0.9552491903305054, Last lagvar Loss: 0.9113095998764038\n",
      "Step 3533/10000- lr: [6.530316909090909e-06] - Loss total: 2.856752395629883, Last rpr Loss: 1.0535876750946045, Last lagvar Loss: 0.8135037422180176\n",
      "Step 3534/10000- lr: [6.529306812121212e-06] - Loss total: 2.8559482097625732, Last rpr Loss: 1.0477683544158936, Last lagvar Loss: 0.818708062171936\n",
      "Step 3535/10000- lr: [6.5282967151515154e-06] - Loss total: 2.856388568878174, Last rpr Loss: 0.950973391532898, Last lagvar Loss: 0.9161036014556885\n",
      "Step 3536/10000- lr: [6.527286618181819e-06] - Loss total: 2.8556230068206787, Last rpr Loss: 0.9556413888931274, Last lagvar Loss: 0.9108593463897705\n",
      "Step 3537/10000- lr: [6.526276521212122e-06] - Loss total: 2.856032133102417, Last rpr Loss: 1.0536574125289917, Last lagvar Loss: 0.8134296536445618\n",
      "Step 3538/10000- lr: [6.525266424242424e-06] - Loss total: 2.855229616165161, Last rpr Loss: 1.0478700399398804, Last lagvar Loss: 0.8186042308807373\n",
      "Step 3539/10000- lr: [6.524256327272727e-06] - Loss total: 2.855607271194458, Last rpr Loss: 0.9513924717903137, Last lagvar Loss: 0.9156198501586914\n",
      "Step 3540/10000- lr: [6.52324623030303e-06] - Loss total: 2.8548507690429688, Last rpr Loss: 0.9560394287109375, Last lagvar Loss: 0.9104054570198059\n",
      "Step 3541/10000- lr: [6.522236133333333e-06] - Loss total: 2.8553106784820557, Last rpr Loss: 1.0537075996398926, Last lagvar Loss: 0.8133717179298401\n",
      "Step 3542/10000- lr: [6.521226036363637e-06] - Loss total: 2.8545100688934326, Last rpr Loss: 1.0479223728179932, Last lagvar Loss: 0.818545937538147\n",
      "Step 3543/10000- lr: [6.52021593939394e-06] - Loss total: 2.8548319339752197, Last rpr Loss: 0.9517478346824646, Last lagvar Loss: 0.9152043461799622\n",
      "Step 3544/10000- lr: [6.519205842424242e-06] - Loss total: 2.8540830612182617, Last rpr Loss: 0.9563845992088318, Last lagvar Loss: 0.9100080132484436\n",
      "Step 3545/10000- lr: [6.518195745454546e-06] - Loss total: 2.854588747024536, Last rpr Loss: 1.0537354946136475, Last lagvar Loss: 0.8133336305618286\n",
      "Step 3546/10000- lr: [6.517185648484848e-06] - Loss total: 2.853790044784546, Last rpr Loss: 1.0479800701141357, Last lagvar Loss: 0.8184810280799866\n",
      "Step 3547/10000- lr: [6.516175551515151e-06] - Loss total: 2.8540616035461426, Last rpr Loss: 0.9521155953407288, Last lagvar Loss: 0.9147781133651733\n",
      "Step 3548/10000- lr: [6.515165454545455e-06] - Loss total: 2.853320360183716, Last rpr Loss: 0.9567335844039917, Last lagvar Loss: 0.9096086025238037\n",
      "Step 3549/10000- lr: [6.514155357575758e-06] - Loss total: 2.853865623474121, Last rpr Loss: 1.05374276638031, Last lagvar Loss: 0.8133130073547363\n",
      "Step 3550/10000- lr: [6.513145260606061e-06] - Loss total: 2.8530688285827637, Last rpr Loss: 1.0479896068572998, Last lagvar Loss: 0.8184604048728943\n",
      "Step 3551/10000- lr: [6.512135163636364e-06] - Loss total: 2.8532955646514893, Last rpr Loss: 0.9524268507957458, Last lagvar Loss: 0.9144127368927002\n",
      "Step 3552/10000- lr: [6.511125066666667e-06] - Loss total: 2.8525614738464355, Last rpr Loss: 0.9570351839065552, Last lagvar Loss: 0.9092599749565125\n",
      "Step 3553/10000- lr: [6.510114969696969e-06] - Loss total: 2.8531417846679688, Last rpr Loss: 1.0537258386611938, Last lagvar Loss: 0.8133143186569214\n",
      "Step 3554/10000- lr: [6.509104872727273e-06] - Loss total: 2.8523476123809814, Last rpr Loss: 1.0479989051818848, Last lagvar Loss: 0.8184387683868408\n",
      "Step 3555/10000- lr: [6.508094775757576e-06] - Loss total: 2.852534532546997, Last rpr Loss: 0.9527413249015808, Last lagvar Loss: 0.9140459895133972\n",
      "Step 3556/10000- lr: [6.507084678787879e-06] - Loss total: 2.8518075942993164, Last rpr Loss: 0.9573352336883545, Last lagvar Loss: 0.9089148640632629\n",
      "Step 3557/10000- lr: [6.5060745818181824e-06] - Loss total: 2.852417469024658, Last rpr Loss: 1.0536972284317017, Last lagvar Loss: 0.8133252859115601\n",
      "Step 3558/10000- lr: [6.505064484848486e-06] - Loss total: 2.85162615776062, Last rpr Loss: 1.047975778579712, Last lagvar Loss: 0.8184469938278198\n",
      "Step 3559/10000- lr: [6.504054387878789e-06] - Loss total: 2.8517773151397705, Last rpr Loss: 0.953015923500061, Last lagvar Loss: 0.9137223958969116\n",
      "Step 3560/10000- lr: [6.5030442909090914e-06] - Loss total: 2.8510568141937256, Last rpr Loss: 0.9576009511947632, Last lagvar Loss: 0.9086064100265503\n",
      "Step 3561/10000- lr: [6.502034193939395e-06] - Loss total: 2.8516931533813477, Last rpr Loss: 1.0536527633666992, Last lagvar Loss: 0.8133507966995239\n",
      "Step 3562/10000- lr: [6.501024096969697e-06] - Loss total: 2.8509044647216797, Last rpr Loss: 1.047956109046936, Last lagvar Loss: 0.8184513449668884\n",
      "Step 3563/10000- lr: [6.500014e-06] - Loss total: 2.8510236740112305, Last rpr Loss: 0.9532972574234009, Last lagvar Loss: 0.913393497467041\n",
      "Step 3564/10000- lr: [6.499003903030304e-06] - Loss total: 2.850308656692505, Last rpr Loss: 0.9578661918640137, Last lagvar Loss: 0.9082999229431152\n",
      "Step 3565/10000- lr: [6.497993806060607e-06] - Loss total: 2.850968837738037, Last rpr Loss: 1.0535991191864014, Last lagvar Loss: 0.8133844137191772\n",
      "Step 3566/10000- lr: [6.49698370909091e-06] - Loss total: 2.8501834869384766, Last rpr Loss: 1.0479180812835693, Last lagvar Loss: 0.8184727430343628\n",
      "Step 3567/10000- lr: [6.495973612121213e-06] - Loss total: 2.8502728939056396, Last rpr Loss: 0.9535528421401978, Last lagvar Loss: 0.9130924940109253\n",
      "Step 3568/10000- lr: [6.494963515151515e-06] - Loss total: 2.8495638370513916, Last rpr Loss: 0.9581088423728943, Last lagvar Loss: 0.9080178737640381\n",
      "Step 3569/10000- lr: [6.493953418181818e-06] - Loss total: 2.850245475769043, Last rpr Loss: 1.053533673286438, Last lagvar Loss: 0.813429594039917\n",
      "Step 3570/10000- lr: [6.492943321212122e-06] - Loss total: 2.849463701248169, Last rpr Loss: 1.047882080078125, Last lagvar Loss: 0.8184922933578491\n",
      "Step 3571/10000- lr: [6.491933224242425e-06] - Loss total: 2.8495242595672607, Last rpr Loss: 0.9538160562515259, Last lagvar Loss: 0.9127848148345947\n",
      "Step 3572/10000- lr: [6.490923127272728e-06] - Loss total: 2.848820924758911, Last rpr Loss: 0.9583560228347778, Last lagvar Loss: 0.9077320098876953\n",
      "Step 3573/10000- lr: [6.489913030303031e-06] - Loss total: 2.849522829055786, Last rpr Loss: 1.0534695386886597, Last lagvar Loss: 0.8134733438491821\n",
      "Step 3574/10000- lr: [6.488902933333334e-06] - Loss total: 2.8487443923950195, Last rpr Loss: 1.0478367805480957, Last lagvar Loss: 0.8185205459594727\n",
      "Step 3575/10000- lr: [6.487892836363636e-06] - Loss total: 2.848778009414673, Last rpr Loss: 0.9540649652481079, Last lagvar Loss: 0.9124928712844849\n",
      "Step 3576/10000- lr: [6.48688273939394e-06] - Loss total: 2.8480796813964844, Last rpr Loss: 0.9585899114608765, Last lagvar Loss: 0.9074606895446777\n",
      "Step 3577/10000- lr: [6.485872642424243e-06] - Loss total: 2.8488011360168457, Last rpr Loss: 1.0533987283706665, Last lagvar Loss: 0.8135238885879517\n",
      "Step 3578/10000- lr: [6.484862545454546e-06] - Loss total: 2.8480262756347656, Last rpr Loss: 1.0477946996688843, Last lagvar Loss: 0.8185460567474365\n",
      "Step 3579/10000- lr: [6.4838524484848495e-06] - Loss total: 2.8480334281921387, Last rpr Loss: 0.9543206691741943, Last lagvar Loss: 0.9121947288513184\n",
      "Step 3580/10000- lr: [6.482842351515152e-06] - Loss total: 2.8473405838012695, Last rpr Loss: 0.9588257670402527, Last lagvar Loss: 0.9071880578994751\n",
      "Step 3581/10000- lr: [6.481832254545455e-06] - Loss total: 2.84808087348938, Last rpr Loss: 1.0533249378204346, Last lagvar Loss: 0.81357741355896\n",
      "Step 3582/10000- lr: [6.480822157575758e-06] - Loss total: 2.847308874130249, Last rpr Loss: 1.0477471351623535, Last lagvar Loss: 0.8185771703720093\n",
      "Step 3583/10000- lr: [6.479812060606061e-06] - Loss total: 2.8472907543182373, Last rpr Loss: 0.9545677304267883, Last lagvar Loss: 0.9119062423706055\n",
      "Step 3584/10000- lr: [6.478801963636364e-06] - Loss total: 2.8466038703918457, Last rpr Loss: 0.9590604901313782, Last lagvar Loss: 0.9069172739982605\n",
      "Step 3585/10000- lr: [6.4777918666666674e-06] - Loss total: 2.8473618030548096, Last rpr Loss: 1.0532546043395996, Last lagvar Loss: 0.8136279582977295\n",
      "Step 3586/10000- lr: [6.476781769696971e-06] - Loss total: 2.846592903137207, Last rpr Loss: 1.0477027893066406, Last lagvar Loss: 0.8186054825782776\n",
      "Step 3587/10000- lr: [6.475771672727273e-06] - Loss total: 2.8465497493743896, Last rpr Loss: 0.9548178911209106, Last lagvar Loss: 0.911615252494812\n",
      "Step 3588/10000- lr: [6.4747615757575756e-06] - Loss total: 2.845867156982422, Last rpr Loss: 0.959294855594635, Last lagvar Loss: 0.9066474437713623\n",
      "Step 3589/10000- lr: [6.473751478787879e-06] - Loss total: 2.8466436862945557, Last rpr Loss: 1.0531799793243408, Last lagvar Loss: 0.8136827349662781\n",
      "Step 3590/10000- lr: [6.472741381818182e-06] - Loss total: 2.8458781242370605, Last rpr Loss: 1.0476503372192383, Last lagvar Loss: 0.8186416625976562\n",
      "Step 3591/10000- lr: [6.471731284848485e-06] - Loss total: 2.8458104133605957, Last rpr Loss: 0.9550610184669495, Last lagvar Loss: 0.9113321304321289\n",
      "Step 3592/10000- lr: [6.470721187878789e-06] - Loss total: 2.845133066177368, Last rpr Loss: 0.9595242738723755, Last lagvar Loss: 0.9063831567764282\n",
      "Step 3593/10000- lr: [6.469711090909091e-06] - Loss total: 2.8459267616271973, Last rpr Loss: 1.0531085729599, Last lagvar Loss: 0.813734769821167\n",
      "Step 3594/10000- lr: [6.468700993939394e-06] - Loss total: 2.8451645374298096, Last rpr Loss: 1.0476012229919434, Last lagvar Loss: 0.8186748027801514\n",
      "Step 3595/10000- lr: [6.467690896969697e-06] - Loss total: 2.8450727462768555, Last rpr Loss: 0.9553050398826599, Last lagvar Loss: 0.9110488295555115\n",
      "Step 3596/10000- lr: [6.4666808e-06] - Loss total: 2.844400405883789, Last rpr Loss: 0.9597537517547607, Last lagvar Loss: 0.9061195850372314\n",
      "Step 3597/10000- lr: [6.465670703030303e-06] - Loss total: 2.845210313796997, Last rpr Loss: 1.0530335903167725, Last lagvar Loss: 0.8137904405593872\n",
      "Step 3598/10000- lr: [6.464660606060607e-06] - Loss total: 2.8444511890411377, Last rpr Loss: 1.0475488901138306, Last lagvar Loss: 0.8187112808227539\n",
      "Step 3599/10000- lr: [6.46365050909091e-06] - Loss total: 2.844336748123169, Last rpr Loss: 0.9555439352989197, Last lagvar Loss: 0.9107714295387268\n",
      "Step 3600/10000- lr: [6.462640412121212e-06] - Loss total: 2.8436689376831055, Last rpr Loss: 0.9599802494049072, Last lagvar Loss: 0.9058594703674316\n",
      "Step 3601/10000- lr: [6.461630315151516e-06] - Loss total: 2.844496011734009, Last rpr Loss: 1.0529611110687256, Last lagvar Loss: 0.8138439655303955\n",
      "Step 3602/10000- lr: [6.460620218181818e-06] - Loss total: 2.8437397480010986, Last rpr Loss: 1.0475008487701416, Last lagvar Loss: 0.8187437057495117\n",
      "Step 3603/10000- lr: [6.459610121212121e-06] - Loss total: 2.843602180480957, Last rpr Loss: 0.955784797668457, Last lagvar Loss: 0.9104925394058228\n",
      "Step 3604/10000- lr: [6.458600024242425e-06] - Loss total: 2.8429388999938965, Last rpr Loss: 0.9602043628692627, Last lagvar Loss: 0.9056024551391602\n",
      "Step 3605/10000- lr: [6.457589927272728e-06] - Loss total: 2.8437817096710205, Last rpr Loss: 1.0528841018676758, Last lagvar Loss: 0.8139020800590515\n",
      "Step 3606/10000- lr: [6.456579830303031e-06] - Loss total: 2.843029022216797, Last rpr Loss: 1.047446846961975, Last lagvar Loss: 0.8187822103500366\n",
      "Step 3607/10000- lr: [6.455569733333334e-06] - Loss total: 2.8428685665130615, Last rpr Loss: 0.9560200572013855, Last lagvar Loss: 0.9102200269699097\n",
      "Step 3608/10000- lr: [6.454559636363636e-06] - Loss total: 2.842210531234741, Last rpr Loss: 0.9604249596595764, Last lagvar Loss: 0.9053493738174438\n",
      "Step 3609/10000- lr: [6.453549539393939e-06] - Loss total: 2.843068838119507, Last rpr Loss: 1.0528076887130737, Last lagvar Loss: 0.8139596581459045\n",
      "Step 3610/10000- lr: [6.4525394424242426e-06] - Loss total: 2.8423190116882324, Last rpr Loss: 1.047393798828125, Last lagvar Loss: 0.8188198804855347\n",
      "Step 3611/10000- lr: [6.451529345454546e-06] - Loss total: 2.8421366214752197, Last rpr Loss: 0.9562549591064453, Last lagvar Loss: 0.909948468208313\n",
      "Step 3612/10000- lr: [6.450519248484849e-06] - Loss total: 2.8414835929870605, Last rpr Loss: 0.9606459736824036, Last lagvar Loss: 0.9050964117050171\n",
      "Step 3613/10000- lr: [6.4495091515151516e-06] - Loss total: 2.8423569202423096, Last rpr Loss: 1.0527315139770508, Last lagvar Loss: 0.8140172362327576\n",
      "Step 3614/10000- lr: [6.448499054545455e-06] - Loss total: 2.8416104316711426, Last rpr Loss: 1.0473406314849854, Last lagvar Loss: 0.8188576102256775\n",
      "Step 3615/10000- lr: [6.447488957575757e-06] - Loss total: 2.841407060623169, Last rpr Loss: 0.956488311290741, Last lagvar Loss: 0.9096789360046387\n",
      "Step 3616/10000- lr: [6.4464788606060605e-06] - Loss total: 2.8407576084136963, Last rpr Loss: 0.9608654379844666, Last lagvar Loss: 0.9048454761505127\n",
      "Step 3617/10000- lr: [6.445468763636364e-06] - Loss total: 2.841646432876587, Last rpr Loss: 1.0526548624038696, Last lagvar Loss: 0.8140754699707031\n",
      "Step 3618/10000- lr: [6.444458666666667e-06] - Loss total: 2.840902090072632, Last rpr Loss: 1.0472865104675293, Last lagvar Loss: 0.8188966512680054\n",
      "Step 3619/10000- lr: [6.44344856969697e-06] - Loss total: 2.8406779766082764, Last rpr Loss: 0.9567192792892456, Last lagvar Loss: 0.9094125032424927\n",
      "Step 3620/10000- lr: [6.442438472727273e-06] - Loss total: 2.8400332927703857, Last rpr Loss: 0.9610793590545654, Last lagvar Loss: 0.9046006202697754\n",
      "Step 3621/10000- lr: [6.441428375757576e-06] - Loss total: 2.8409361839294434, Last rpr Loss: 1.0525758266448975, Last lagvar Loss: 0.814136266708374\n",
      "Step 3622/10000- lr: [6.4404182787878785e-06] - Loss total: 2.8401951789855957, Last rpr Loss: 1.0472307205200195, Last lagvar Loss: 0.8189371824264526\n",
      "Step 3623/10000- lr: [6.439408181818182e-06] - Loss total: 2.8399500846862793, Last rpr Loss: 0.9569478034973145, Last lagvar Loss: 0.9091489911079407\n",
      "Step 3624/10000- lr: [6.438398084848485e-06] - Loss total: 2.83931040763855, Last rpr Loss: 0.9612946510314941, Last lagvar Loss: 0.9043546915054321\n",
      "Step 3625/10000- lr: [6.437387987878788e-06] - Loss total: 2.8402278423309326, Last rpr Loss: 1.0525013208389282, Last lagvar Loss: 0.8141929507255554\n",
      "Step 3626/10000- lr: [6.436377890909092e-06] - Loss total: 2.839489221572876, Last rpr Loss: 1.0471794605255127, Last lagvar Loss: 0.8189738392829895\n",
      "Step 3627/10000- lr: [6.435367793939394e-06] - Loss total: 2.839224338531494, Last rpr Loss: 0.9571772813796997, Last lagvar Loss: 0.9088849425315857\n",
      "Step 3628/10000- lr: [6.4343576969696965e-06] - Loss total: 2.8385884761810303, Last rpr Loss: 0.9615079164505005, Last lagvar Loss: 0.9041114449501038\n",
      "Step 3629/10000- lr: [6.4333476e-06] - Loss total: 2.839520215988159, Last rpr Loss: 1.0524249076843262, Last lagvar Loss: 0.8142516613006592\n",
      "Step 3630/10000- lr: [6.432337503030303e-06] - Loss total: 2.8387842178344727, Last rpr Loss: 1.047126054763794, Last lagvar Loss: 0.8190125226974487\n",
      "Step 3631/10000- lr: [6.431327406060606e-06] - Loss total: 2.838499069213867, Last rpr Loss: 0.9574037194252014, Last lagvar Loss: 0.9086243510246277\n",
      "Step 3632/10000- lr: [6.43031730909091e-06] - Loss total: 2.8378677368164062, Last rpr Loss: 0.9617184996604919, Last lagvar Loss: 0.9038711786270142\n",
      "Step 3633/10000- lr: [6.429307212121212e-06] - Loss total: 2.838813066482544, Last rpr Loss: 1.0523483753204346, Last lagvar Loss: 0.8143104910850525\n",
      "Step 3634/10000- lr: [6.428297115151515e-06] - Loss total: 2.838080644607544, Last rpr Loss: 1.0470726490020752, Last lagvar Loss: 0.8190514445304871\n",
      "Step 3635/10000- lr: [6.427287018181818e-06] - Loss total: 2.837775230407715, Last rpr Loss: 0.9576306343078613, Last lagvar Loss: 0.9083636999130249\n",
      "Step 3636/10000- lr: [6.426276921212121e-06] - Loss total: 2.8371481895446777, Last rpr Loss: 0.9619306325912476, Last lagvar Loss: 0.9036297798156738\n",
      "Step 3637/10000- lr: [6.425266824242424e-06] - Loss total: 2.8381073474884033, Last rpr Loss: 1.0522716045379639, Last lagvar Loss: 0.8143698573112488\n",
      "Step 3638/10000- lr: [6.4242567272727276e-06] - Loss total: 2.8373777866363525, Last rpr Loss: 1.0470188856124878, Last lagvar Loss: 0.8190908432006836\n",
      "Step 3639/10000- lr: [6.423246630303031e-06] - Loss total: 2.837052822113037, Last rpr Loss: 0.9578544497489929, Last lagvar Loss: 0.9081069231033325\n",
      "Step 3640/10000- lr: [6.422236533333334e-06] - Loss total: 2.8364298343658447, Last rpr Loss: 0.9621411561965942, Last lagvar Loss: 0.9033902883529663\n",
      "Step 3641/10000- lr: [6.421226436363637e-06] - Loss total: 2.837402582168579, Last rpr Loss: 1.0521953105926514, Last lagvar Loss: 0.8144289255142212\n",
      "Step 3642/10000- lr: [6.42021633939394e-06] - Loss total: 2.8366756439208984, Last rpr Loss: 1.0469632148742676, Last lagvar Loss: 0.8191321492195129\n",
      "Step 3643/10000- lr: [6.419206242424243e-06] - Loss total: 2.836331605911255, Last rpr Loss: 0.9580756425857544, Last lagvar Loss: 0.9078530669212341\n",
      "Step 3644/10000- lr: [6.4181961454545455e-06] - Loss total: 2.8357126712799072, Last rpr Loss: 0.9623457193374634, Last lagvar Loss: 0.9031572937965393\n",
      "Step 3645/10000- lr: [6.417186048484849e-06] - Loss total: 2.836698055267334, Last rpr Loss: 1.0521197319030762, Last lagvar Loss: 0.8144874572753906\n",
      "Step 3646/10000- lr: [6.416175951515152e-06] - Loss total: 2.8359742164611816, Last rpr Loss: 1.0469123125076294, Last lagvar Loss: 0.8191689848899841\n",
      "Step 3647/10000- lr: [6.415165854545455e-06] - Loss total: 2.83561110496521, Last rpr Loss: 0.9582986831665039, Last lagvar Loss: 0.9075977802276611\n",
      "Step 3648/10000- lr: [6.414155757575759e-06] - Loss total: 2.834996461868286, Last rpr Loss: 0.9625527262687683, Last lagvar Loss: 0.9029221534729004\n",
      "Step 3649/10000- lr: [6.413145660606061e-06] - Loss total: 2.8359951972961426, Last rpr Loss: 1.0520434379577637, Last lagvar Loss: 0.8145468235015869\n",
      "Step 3650/10000- lr: [6.412135563636364e-06] - Loss total: 2.835273265838623, Last rpr Loss: 1.046856164932251, Last lagvar Loss: 0.8192110061645508\n",
      "Step 3651/10000- lr: [6.411125466666667e-06] - Loss total: 2.834892749786377, Last rpr Loss: 0.9585152268409729, Last lagvar Loss: 0.9073496460914612\n",
      "Step 3652/10000- lr: [6.41011536969697e-06] - Loss total: 2.8342819213867188, Last rpr Loss: 0.9627541899681091, Last lagvar Loss: 0.9026930332183838\n",
      "Step 3653/10000- lr: [6.409105272727273e-06] - Loss total: 2.8352930545806885, Last rpr Loss: 1.0519661903381348, Last lagvar Loss: 0.8146073818206787\n",
      "Step 3654/10000- lr: [6.408095175757577e-06] - Loss total: 2.834573745727539, Last rpr Loss: 1.04680335521698, Last lagvar Loss: 0.8192498087882996\n",
      "Step 3655/10000- lr: [6.40708507878788e-06] - Loss total: 2.834174871444702, Last rpr Loss: 0.9587346911430359, Last lagvar Loss: 0.9070988297462463\n",
      "Step 3656/10000- lr: [6.406074981818182e-06] - Loss total: 2.8335678577423096, Last rpr Loss: 0.9629552364349365, Last lagvar Loss: 0.9024648666381836\n",
      "Step 3657/10000- lr: [6.405064884848485e-06] - Loss total: 2.8345911502838135, Last rpr Loss: 1.051885962486267, Last lagvar Loss: 0.8146706819534302\n",
      "Step 3658/10000- lr: [6.404054787878788e-06] - Loss total: 2.8338749408721924, Last rpr Loss: 1.0467441082000732, Last lagvar Loss: 0.8192950487136841\n",
      "Step 3659/10000- lr: [6.403044690909091e-06] - Loss total: 2.833458662033081, Last rpr Loss: 0.9589482545852661, Last lagvar Loss: 0.9068546295166016\n",
      "Step 3660/10000- lr: [6.4020345939393946e-06] - Loss total: 2.832854747772217, Last rpr Loss: 0.9631562829017639, Last lagvar Loss: 0.9022369384765625\n",
      "Step 3661/10000- lr: [6.401024496969698e-06] - Loss total: 2.833890199661255, Last rpr Loss: 1.0518081188201904, Last lagvar Loss: 0.8147321939468384\n",
      "Step 3662/10000- lr: [6.4000144e-06] - Loss total: 2.8331758975982666, Last rpr Loss: 1.0466874837875366, Last lagvar Loss: 0.8193379044532776\n",
      "Step 3663/10000- lr: [6.3990043030303036e-06] - Loss total: 2.832742691040039, Last rpr Loss: 0.9591599702835083, Last lagvar Loss: 0.9066128134727478\n",
      "Step 3664/10000- lr: [6.397994206060606e-06] - Loss total: 2.8321430683135986, Last rpr Loss: 0.9633500576019287, Last lagvar Loss: 0.9020171165466309\n",
      "Step 3665/10000- lr: [6.396984109090909e-06] - Loss total: 2.8331892490386963, Last rpr Loss: 1.0517256259918213, Last lagvar Loss: 0.81479811668396\n",
      "Step 3666/10000- lr: [6.3959740121212125e-06] - Loss total: 2.83247709274292, Last rpr Loss: 1.0466272830963135, Last lagvar Loss: 0.8193844556808472\n",
      "Step 3667/10000- lr: [6.394963915151516e-06] - Loss total: 2.8320281505584717, Last rpr Loss: 0.9593674540519714, Last lagvar Loss: 0.9063760042190552\n",
      "Step 3668/10000- lr: [6.393953818181819e-06] - Loss total: 2.8314318656921387, Last rpr Loss: 0.963538646697998, Last lagvar Loss: 0.9018030762672424\n",
      "Step 3669/10000- lr: [6.3929437212121215e-06] - Loss total: 2.8324873447418213, Last rpr Loss: 1.0516374111175537, Last lagvar Loss: 0.8148698806762695\n",
      "Step 3670/10000- lr: [6.391933624242425e-06] - Loss total: 2.831777811050415, Last rpr Loss: 1.0465633869171143, Last lagvar Loss: 0.819434642791748\n",
      "Step 3671/10000- lr: [6.390923527272727e-06] - Loss total: 2.8313136100769043, Last rpr Loss: 0.959570586681366, Last lagvar Loss: 0.9061446189880371\n",
      "Step 3672/10000- lr: [6.3899134303030305e-06] - Loss total: 2.830720901489258, Last rpr Loss: 0.963721513748169, Last lagvar Loss: 0.901595950126648\n",
      "Step 3673/10000- lr: [6.388903333333334e-06] - Loss total: 2.8317277431488037, Last rpr Loss: 1.0510270595550537, Last lagvar Loss: 0.8154110312461853\n",
      "Step 3674/10000- lr: [6.387893236363637e-06] - Loss total: 2.8309805393218994, Last rpr Loss: 1.0455191135406494, Last lagvar Loss: 0.8203755617141724\n",
      "Step 3675/10000- lr: [6.38688313939394e-06] - Loss total: 2.8307182788848877, Last rpr Loss: 0.9586309194564819, Last lagvar Loss: 0.9071710705757141\n",
      "Step 3676/10000- lr: [6.385873042424243e-06] - Loss total: 2.830146074295044, Last rpr Loss: 0.962460458278656, Last lagvar Loss: 0.9029635190963745\n",
      "Step 3677/10000- lr: [6.384862945454545e-06] - Loss total: 2.8308520317077637, Last rpr Loss: 1.0493656396865845, Last lagvar Loss: 0.8168990612030029\n",
      "Step 3678/10000- lr: [6.3838528484848485e-06] - Loss total: 2.830141305923462, Last rpr Loss: 1.0440523624420166, Last lagvar Loss: 0.8217047452926636\n",
      "Step 3679/10000- lr: [6.382842751515152e-06] - Loss total: 2.8301122188568115, Last rpr Loss: 0.9577797651290894, Last lagvar Loss: 0.9081019759178162\n",
      "Step 3680/10000- lr: [6.381832654545455e-06] - Loss total: 2.8295209407806396, Last rpr Loss: 0.961697518825531, Last lagvar Loss: 0.903791069984436\n",
      "Step 3681/10000- lr: [6.380822557575758e-06] - Loss total: 2.830036163330078, Last rpr Loss: 1.0482497215270996, Last lagvar Loss: 0.8179019689559937\n",
      "Step 3682/10000- lr: [6.379812460606061e-06] - Loss total: 2.829348564147949, Last rpr Loss: 1.0430681705474854, Last lagvar Loss: 0.8226005434989929\n",
      "Step 3683/10000- lr: [6.378802363636364e-06] - Loss total: 2.8294613361358643, Last rpr Loss: 0.9573041796684265, Last lagvar Loss: 0.9086202383041382\n",
      "Step 3684/10000- lr: [6.3777922666666664e-06] - Loss total: 2.8288586139678955, Last rpr Loss: 0.9613100290298462, Last lagvar Loss: 0.9042112827301025\n",
      "Step 3685/10000- lr: [6.37678216969697e-06] - Loss total: 2.82926082611084, Last rpr Loss: 1.0475609302520752, Last lagvar Loss: 0.8185189962387085\n",
      "Step 3686/10000- lr: [6.375772072727273e-06] - Loss total: 2.828590154647827, Last rpr Loss: 1.0424586534500122, Last lagvar Loss: 0.823153555393219\n",
      "Step 3687/10000- lr: [6.374761975757576e-06] - Loss total: 2.8287808895111084, Last rpr Loss: 0.9571153521537781, Last lagvar Loss: 0.9088208675384521\n",
      "Step 3688/10000- lr: [6.3737518787878796e-06] - Loss total: 2.828171491622925, Last rpr Loss: 0.9612137079238892, Last lagvar Loss: 0.90431147813797\n",
      "Step 3689/10000- lr: [6.372741781818182e-06] - Loss total: 2.8285205364227295, Last rpr Loss: 1.0472209453582764, Last lagvar Loss: 0.8188141584396362\n",
      "Step 3690/10000- lr: [6.371731684848485e-06] - Loss total: 2.8278613090515137, Last rpr Loss: 1.0421712398529053, Last lagvar Loss: 0.8234044313430786\n",
      "Step 3691/10000- lr: [6.370721587878788e-06] - Loss total: 2.828078508377075, Last rpr Loss: 0.9571346044540405, Last lagvar Loss: 0.9087872505187988\n",
      "Step 3692/10000- lr: [6.369711490909091e-06] - Loss total: 2.8274662494659424, Last rpr Loss: 0.9612489938735962, Last lagvar Loss: 0.904259443283081\n",
      "Step 3693/10000- lr: [6.368701393939394e-06] - Loss total: 2.8277981281280518, Last rpr Loss: 1.0470126867294312, Last lagvar Loss: 0.8189829587936401\n",
      "Step 3694/10000- lr: [6.3676912969696975e-06] - Loss total: 2.827143907546997, Last rpr Loss: 1.0420191287994385, Last lagvar Loss: 0.8235202431678772\n",
      "Step 3695/10000- lr: [6.366681200000001e-06] - Loss total: 2.827357292175293, Last rpr Loss: 0.9572426080703735, Last lagvar Loss: 0.9086436033248901\n",
      "Step 3696/10000- lr: [6.365671103030303e-06] - Loss total: 2.8267438411712646, Last rpr Loss: 0.9613221883773804, Last lagvar Loss: 0.9041479825973511\n",
      "Step 3697/10000- lr: [6.364661006060606e-06] - Loss total: 2.8270647525787354, Last rpr Loss: 1.0468047857284546, Last lagvar Loss: 0.8191120624542236\n",
      "Step 3698/10000- lr: [6.363650909090909e-06] - Loss total: 2.826404571533203, Last rpr Loss: 1.041855812072754, Last lagvar Loss: 0.8235806226730347\n",
      "Step 3699/10000- lr: [6.362640812121212e-06] - Loss total: 2.8266050815582275, Last rpr Loss: 0.9573608636856079, Last lagvar Loss: 0.9084241390228271\n",
      "Step 3700/10000- lr: [6.3616307151515155e-06] - Loss total: 2.8259785175323486, Last rpr Loss: 0.9613262414932251, Last lagvar Loss: 0.9039900898933411\n",
      "Step 3701/10000- lr: [6.360620618181819e-06] - Loss total: 2.8262526988983154, Last rpr Loss: 1.0463100671768188, Last lagvar Loss: 0.8192248344421387\n",
      "Step 3702/10000- lr: [6.359610521212121e-06] - Loss total: 2.825572967529297, Last rpr Loss: 1.0413572788238525, Last lagvar Loss: 0.8236024379730225\n",
      "Step 3703/10000- lr: [6.3586004242424245e-06] - Loss total: 2.8257741928100586, Last rpr Loss: 0.9572316408157349, Last lagvar Loss: 0.9080990552902222\n",
      "Step 3704/10000- lr: [6.357590327272727e-06] - Loss total: 2.8251447677612305, Last rpr Loss: 0.9613372087478638, Last lagvar Loss: 0.9034944176673889\n",
      "Step 3705/10000- lr: [6.35658023030303e-06] - Loss total: 2.8254520893096924, Last rpr Loss: 1.0464277267456055, Last lagvar Loss: 0.8187741041183472\n",
      "Step 3706/10000- lr: [6.3555701333333335e-06] - Loss total: 2.824803590774536, Last rpr Loss: 1.0417637825012207, Last lagvar Loss: 0.8229853510856628\n",
      "Step 3707/10000- lr: [6.354560036363637e-06] - Loss total: 2.8249733448028564, Last rpr Loss: 0.9580560922622681, Last lagvar Loss: 0.9070032835006714\n",
      "Step 3708/10000- lr: [6.35354993939394e-06] - Loss total: 2.8243465423583984, Last rpr Loss: 0.9622930884361267, Last lagvar Loss: 0.902319073677063\n",
      "Step 3709/10000- lr: [6.3525398424242424e-06] - Loss total: 2.8247499465942383, Last rpr Loss: 1.0471384525299072, Last lagvar Loss: 0.8180098533630371\n",
      "Step 3710/10000- lr: [6.351529745454546e-06] - Loss total: 2.824103593826294, Last rpr Loss: 1.0422604084014893, Last lagvar Loss: 0.8224189877510071\n",
      "Step 3711/10000- lr: [6.350519648484848e-06] - Loss total: 2.82415509223938, Last rpr Loss: 0.9585354924201965, Last lagvar Loss: 0.906352162361145\n",
      "Step 3712/10000- lr: [6.3495095515151514e-06] - Loss total: 2.8235344886779785, Last rpr Loss: 0.9627021551132202, Last lagvar Loss: 0.9017477035522461\n",
      "Step 3713/10000- lr: [6.348499454545455e-06] - Loss total: 2.824070930480957, Last rpr Loss: 1.0475949048995972, Last lagvar Loss: 0.8175069689750671\n",
      "Step 3714/10000- lr: [6.347489357575758e-06] - Loss total: 2.8234236240386963, Last rpr Loss: 1.0429697036743164, Last lagvar Loss: 0.8216713666915894\n",
      "Step 3715/10000- lr: [6.346479260606061e-06] - Loss total: 2.8233373165130615, Last rpr Loss: 0.959363579750061, Last lagvar Loss: 0.9053323268890381\n",
      "Step 3716/10000- lr: [6.345469163636364e-06] - Loss total: 2.8227312564849854, Last rpr Loss: 0.9634909629821777, Last lagvar Loss: 0.9007776379585266\n",
      "Step 3717/10000- lr: [6.344459066666666e-06] - Loss total: 2.8233437538146973, Last rpr Loss: 1.0478914976119995, Last lagvar Loss: 0.8171250820159912\n",
      "Step 3718/10000- lr: [6.343448969696969e-06] - Loss total: 2.8226585388183594, Last rpr Loss: 1.042931318283081, Last lagvar Loss: 0.8215805292129517\n",
      "Step 3719/10000- lr: [6.342438872727273e-06] - Loss total: 2.8226468563079834, Last rpr Loss: 0.9591476321220398, Last lagvar Loss: 0.905479907989502\n",
      "Step 3720/10000- lr: [6.341428775757576e-06] - Loss total: 2.822070360183716, Last rpr Loss: 0.9626390933990479, Last lagvar Loss: 0.9015991687774658\n",
      "Step 3721/10000- lr: [6.340418678787879e-06] - Loss total: 2.8225138187408447, Last rpr Loss: 1.0465621948242188, Last lagvar Loss: 0.818229079246521\n",
      "Step 3722/10000- lr: [6.339408581818182e-06] - Loss total: 2.8218612670898438, Last rpr Loss: 1.0418944358825684, Last lagvar Loss: 0.8224272727966309\n",
      "Step 3723/10000- lr: [6.338398484848485e-06] - Loss total: 2.821948766708374, Last rpr Loss: 0.9586601257324219, Last lagvar Loss: 0.9059110283851624\n",
      "Step 3724/10000- lr: [6.337388387878787e-06] - Loss total: 2.821364641189575, Last rpr Loss: 0.9620788097381592, Last lagvar Loss: 0.902093768119812\n",
      "Step 3725/10000- lr: [6.336378290909091e-06] - Loss total: 2.821744918823242, Last rpr Loss: 1.0457533597946167, Last lagvar Loss: 0.8188875913619995\n",
      "Step 3726/10000- lr: [6.335368193939394e-06] - Loss total: 2.821108341217041, Last rpr Loss: 1.041513442993164, Last lagvar Loss: 0.8226851224899292\n",
      "Step 3727/10000- lr: [6.334358096969697e-06] - Loss total: 2.8212215900421143, Last rpr Loss: 0.9589184522628784, Last lagvar Loss: 0.9055470824241638\n",
      "Step 3728/10000- lr: [6.3333480000000005e-06] - Loss total: 2.820633888244629, Last rpr Loss: 0.962372899055481, Last lagvar Loss: 0.9016873836517334\n",
      "Step 3729/10000- lr: [6.332337903030304e-06] - Loss total: 2.8210127353668213, Last rpr Loss: 1.0458009243011475, Last lagvar Loss: 0.8187592029571533\n",
      "Step 3730/10000- lr: [6.331327806060607e-06] - Loss total: 2.820384979248047, Last rpr Loss: 1.0417513847351074, Last lagvar Loss: 0.8223745226860046\n",
      "Step 3731/10000- lr: [6.3303177090909095e-06] - Loss total: 2.820474147796631, Last rpr Loss: 0.9595218300819397, Last lagvar Loss: 0.9048119783401489\n",
      "Step 3732/10000- lr: [6.329307612121213e-06] - Loss total: 2.8198864459991455, Last rpr Loss: 0.9628008604049683, Last lagvar Loss: 0.9011334776878357\n",
      "Step 3733/10000- lr: [6.328297515151515e-06] - Loss total: 2.8203060626983643, Last rpr Loss: 1.045724630355835, Last lagvar Loss: 0.81876540184021\n",
      "Step 3734/10000- lr: [6.3272874181818184e-06] - Loss total: 2.8196792602539062, Last rpr Loss: 1.0415871143341064, Last lagvar Loss: 0.8224595785140991\n",
      "Step 3735/10000- lr: [6.326277321212122e-06] - Loss total: 2.8197247982025146, Last rpr Loss: 0.9596772193908691, Last lagvar Loss: 0.9045504331588745\n",
      "Step 3736/10000- lr: [6.325267224242425e-06] - Loss total: 2.819140672683716, Last rpr Loss: 0.9629094004631042, Last lagvar Loss: 0.9009220600128174\n",
      "Step 3737/10000- lr: [6.324257127272728e-06] - Loss total: 2.819594621658325, Last rpr Loss: 1.045386552810669, Last lagvar Loss: 0.8190133571624756\n",
      "Step 3738/10000- lr: [6.323247030303031e-06] - Loss total: 2.8189568519592285, Last rpr Loss: 1.041257381439209, Last lagvar Loss: 0.8226926326751709\n",
      "Step 3739/10000- lr: [6.322236933333334e-06] - Loss total: 2.819011688232422, Last rpr Loss: 0.959829568862915, Last lagvar Loss: 0.9043166637420654\n",
      "Step 3740/10000- lr: [6.321226836363636e-06] - Loss total: 2.8184354305267334, Last rpr Loss: 0.963153064250946, Last lagvar Loss: 0.900597095489502\n",
      "Step 3741/10000- lr: [6.32021673939394e-06] - Loss total: 2.8188552856445312, Last rpr Loss: 1.045324683189392, Last lagvar Loss: 0.8189868927001953\n",
      "Step 3742/10000- lr: [6.319206642424243e-06] - Loss total: 2.818221092224121, Last rpr Loss: 1.0411081314086914, Last lagvar Loss: 0.8227516412734985\n",
      "Step 3743/10000- lr: [6.318196545454546e-06] - Loss total: 2.8183140754699707, Last rpr Loss: 0.959855318069458, Last lagvar Loss: 0.9042230844497681\n",
      "Step 3744/10000- lr: [6.3171864484848495e-06] - Loss total: 2.817739725112915, Last rpr Loss: 0.9630354046821594, Last lagvar Loss: 0.9006528258323669\n",
      "Step 3745/10000- lr: [6.316176351515152e-06] - Loss total: 2.8181216716766357, Last rpr Loss: 1.0448176860809326, Last lagvar Loss: 0.8193950653076172\n",
      "Step 3746/10000- lr: [6.315166254545454e-06] - Loss total: 2.817495107650757, Last rpr Loss: 1.0406115055084229, Last lagvar Loss: 0.8231550455093384\n",
      "Step 3747/10000- lr: [6.314156157575758e-06] - Loss total: 2.8176121711730957, Last rpr Loss: 0.9597501158714294, Last lagvar Loss: 0.9042673110961914\n",
      "Step 3748/10000- lr: [6.313146060606061e-06] - Loss total: 2.81703519821167, Last rpr Loss: 0.9630564451217651, Last lagvar Loss: 0.9005654454231262\n",
      "Step 3749/10000- lr: [6.312135963636364e-06] - Loss total: 2.8174057006835938, Last rpr Loss: 1.0446648597717285, Last lagvar Loss: 0.819475531578064\n",
      "Step 3750/10000- lr: [6.3111258666666675e-06] - Loss total: 2.8167831897735596, Last rpr Loss: 1.0405232906341553, Last lagvar Loss: 0.8231760263442993\n",
      "Step 3751/10000- lr: [6.31011576969697e-06] - Loss total: 2.816909074783325, Last rpr Loss: 0.9599032402038574, Last lagvar Loss: 0.9040445685386658\n",
      "Step 3752/10000- lr: [6.309105672727273e-06] - Loss total: 2.816335916519165, Last rpr Loss: 0.9631880521774292, Last lagvar Loss: 0.900367796421051\n",
      "Step 3753/10000- lr: [6.308095575757576e-06] - Loss total: 2.8166775703430176, Last rpr Loss: 1.0443711280822754, Last lagvar Loss: 0.8196878433227539\n",
      "Step 3754/10000- lr: [6.307085478787879e-06] - Loss total: 2.8160483837127686, Last rpr Loss: 1.0400679111480713, Last lagvar Loss: 0.8235412836074829\n",
      "Step 3755/10000- lr: [6.306075381818182e-06] - Loss total: 2.8162498474121094, Last rpr Loss: 0.9595587253570557, Last lagvar Loss: 0.9043673276901245\n",
      "Step 3756/10000- lr: [6.3050652848484855e-06] - Loss total: 2.815685749053955, Last rpr Loss: 0.9626902937889099, Last lagvar Loss: 0.9008539915084839\n",
      "Step 3757/10000- lr: [6.304055187878789e-06] - Loss total: 2.8159239292144775, Last rpr Loss: 1.0436413288116455, Last lagvar Loss: 0.8203067779541016\n",
      "Step 3758/10000- lr: [6.303045090909091e-06] - Loss total: 2.815312385559082, Last rpr Loss: 1.0395011901855469, Last lagvar Loss: 0.8240146636962891\n",
      "Step 3759/10000- lr: [6.3020349939393944e-06] - Loss total: 2.815581798553467, Last rpr Loss: 0.9593554139137268, Last lagvar Loss: 0.9045406579971313\n",
      "Step 3760/10000- lr: [6.301024896969697e-06] - Loss total: 2.815012216567993, Last rpr Loss: 0.9625329971313477, Last lagvar Loss: 0.900976300239563\n",
      "Step 3761/10000- lr: [6.3000148e-06] - Loss total: 2.81520414352417, Last rpr Loss: 1.0433235168457031, Last lagvar Loss: 0.8205496072769165\n",
      "Step 3762/10000- lr: [6.299004703030303e-06] - Loss total: 2.8146045207977295, Last rpr Loss: 1.039347529411316, Last lagvar Loss: 0.8241063952445984\n",
      "Step 3763/10000- lr: [6.297994606060607e-06] - Loss total: 2.8148932456970215, Last rpr Loss: 0.9594898223876953, Last lagvar Loss: 0.90435391664505\n",
      "Step 3764/10000- lr: [6.29698450909091e-06] - Loss total: 2.8143227100372314, Last rpr Loss: 0.96262526512146, Last lagvar Loss: 0.9008327722549438\n",
      "Step 3765/10000- lr: [6.295974412121212e-06] - Loss total: 2.8145101070404053, Last rpr Loss: 1.0431737899780273, Last lagvar Loss: 0.8206467032432556\n",
      "Step 3766/10000- lr: [6.294964315151515e-06] - Loss total: 2.813917875289917, Last rpr Loss: 1.0392718315124512, Last lagvar Loss: 0.8241358995437622\n",
      "Step 3767/10000- lr: [6.293954218181818e-06] - Loss total: 2.814192533493042, Last rpr Loss: 0.9596763849258423, Last lagvar Loss: 0.9041074514389038\n",
      "Step 3768/10000- lr: [6.292944121212121e-06] - Loss total: 2.813621997833252, Last rpr Loss: 0.9627926349639893, Last lagvar Loss: 0.9006068706512451\n",
      "Step 3769/10000- lr: [6.291934024242425e-06] - Loss total: 2.8138344287872314, Last rpr Loss: 1.043143630027771, Last lagvar Loss: 0.8206409215927124\n",
      "Step 3770/10000- lr: [6.290923927272728e-06] - Loss total: 2.8132455348968506, Last rpr Loss: 1.039323329925537, Last lagvar Loss: 0.8240528106689453\n",
      "Step 3771/10000- lr: [6.28991383030303e-06] - Loss total: 2.813483715057373, Last rpr Loss: 0.959989070892334, Last lagvar Loss: 0.9037280082702637\n",
      "Step 3772/10000- lr: [6.288903733333334e-06] - Loss total: 2.8129169940948486, Last rpr Loss: 0.963087797164917, Last lagvar Loss: 0.90024733543396\n",
      "Step 3773/10000- lr: [6.287893636363636e-06] - Loss total: 2.8131279945373535, Last rpr Loss: 1.0428030490875244, Last lagvar Loss: 0.8209199905395508\n",
      "Step 3774/10000- lr: [6.286883539393939e-06] - Loss total: 2.812512159347534, Last rpr Loss: 1.0386685132980347, Last lagvar Loss: 0.82462078332901\n",
      "Step 3775/10000- lr: [6.285873442424243e-06] - Loss total: 2.8128793239593506, Last rpr Loss: 0.9593910574913025, Last lagvar Loss: 0.904352605342865\n",
      "Step 3776/10000- lr: [6.284863345454546e-06] - Loss total: 2.8123319149017334, Last rpr Loss: 0.962214469909668, Last lagvar Loss: 0.9011654853820801\n",
      "Step 3777/10000- lr: [6.283853248484849e-06] - Loss total: 2.812345504760742, Last rpr Loss: 1.0416173934936523, Last lagvar Loss: 0.8219724297523499\n",
      "Step 3778/10000- lr: [6.282843151515152e-06] - Loss total: 2.8117570877075195, Last rpr Loss: 1.0376784801483154, Last lagvar Loss: 0.8255023956298828\n",
      "Step 3779/10000- lr: [6.281833054545455e-06] - Loss total: 2.8122622966766357, Last rpr Loss: 0.9588847160339355, Last lagvar Loss: 0.9048742055892944\n",
      "Step 3780/10000- lr: [6.280822957575757e-06] - Loss total: 2.8117005825042725, Last rpr Loss: 0.9618141651153564, Last lagvar Loss: 0.9015683531761169\n",
      "Step 3781/10000- lr: [6.279812860606061e-06] - Loss total: 2.811619520187378, Last rpr Loss: 1.0409917831420898, Last lagvar Loss: 0.8225135803222656\n",
      "Step 3782/10000- lr: [6.278802763636364e-06] - Loss total: 2.8110480308532715, Last rpr Loss: 1.037187099456787, Last lagvar Loss: 0.8259249925613403\n",
      "Step 3783/10000- lr: [6.277792666666667e-06] - Loss total: 2.8116049766540527, Last rpr Loss: 0.9587630033493042, Last lagvar Loss: 0.9049718976020813\n",
      "Step 3784/10000- lr: [6.2767825696969704e-06] - Loss total: 2.8110365867614746, Last rpr Loss: 0.961775541305542, Last lagvar Loss: 0.9015763998031616\n",
      "Step 3785/10000- lr: [6.275772472727273e-06] - Loss total: 2.8109302520751953, Last rpr Loss: 1.040773630142212, Last lagvar Loss: 0.8226790428161621\n",
      "Step 3786/10000- lr: [6.274762375757576e-06] - Loss total: 2.810368537902832, Last rpr Loss: 1.0370447635650635, Last lagvar Loss: 0.8260231614112854\n",
      "Step 3787/10000- lr: [6.2737522787878786e-06] - Loss total: 2.8109214305877686, Last rpr Loss: 0.9589006900787354, Last lagvar Loss: 0.904781699180603\n",
      "Step 3788/10000- lr: [6.272742181818182e-06] - Loss total: 2.8103504180908203, Last rpr Loss: 0.9619760513305664, Last lagvar Loss: 0.9013206958770752\n",
      "Step 3789/10000- lr: [6.271732084848485e-06] - Loss total: 2.8102664947509766, Last rpr Loss: 1.0408310890197754, Last lagvar Loss: 0.8225884437561035\n",
      "Step 3790/10000- lr: [6.270721987878788e-06] - Loss total: 2.8097097873687744, Last rpr Loss: 1.0371291637420654, Last lagvar Loss: 0.8259085416793823\n",
      "Step 3791/10000- lr: [6.269711890909092e-06] - Loss total: 2.8102214336395264, Last rpr Loss: 0.959186315536499, Last lagvar Loss: 0.9044256806373596\n",
      "Step 3792/10000- lr: [6.268701793939394e-06] - Loss total: 2.8096518516540527, Last rpr Loss: 0.9623025059700012, Last lagvar Loss: 0.9009241461753845\n",
      "Step 3793/10000- lr: [6.2676916969696965e-06] - Loss total: 2.809619426727295, Last rpr Loss: 1.0410468578338623, Last lagvar Loss: 0.8223497867584229\n",
      "Step 3794/10000- lr: [6.2666816e-06] - Loss total: 2.8090641498565674, Last rpr Loss: 1.0373666286468506, Last lagvar Loss: 0.8256489038467407\n",
      "Step 3795/10000- lr: [6.265671503030303e-06] - Loss total: 2.8095123767852783, Last rpr Loss: 0.9595908522605896, Last lagvar Loss: 0.9039380550384521\n",
      "Step 3796/10000- lr: [6.264661406060606e-06] - Loss total: 2.808946371078491, Last rpr Loss: 0.9627272486686707, Last lagvar Loss: 0.9004193544387817\n",
      "Step 3797/10000- lr: [6.26365130909091e-06] - Loss total: 2.808983087539673, Last rpr Loss: 1.0413661003112793, Last lagvar Loss: 0.8220131397247314\n",
      "Step 3798/10000- lr: [6.262641212121212e-06] - Loss total: 2.8084280490875244, Last rpr Loss: 1.0376917123794556, Last lagvar Loss: 0.8253053426742554\n",
      "Step 3799/10000- lr: [6.261631115151515e-06] - Loss total: 2.808799982070923, Last rpr Loss: 0.9600489139556885, Last lagvar Loss: 0.9033918380737305\n",
      "Step 3800/10000- lr: [6.260621018181818e-06] - Loss total: 2.808238983154297, Last rpr Loss: 0.9631925225257874, Last lagvar Loss: 0.8998703360557556\n",
      "Step 3801/10000- lr: [6.259610921212121e-06] - Loss total: 2.808281660079956, Last rpr Loss: 1.0409425497055054, Last lagvar Loss: 0.8223555684089661\n",
      "Step 3802/10000- lr: [6.258600824242424e-06] - Loss total: 2.8076748847961426, Last rpr Loss: 1.0365779399871826, Last lagvar Loss: 0.8262906074523926\n",
      "Step 3803/10000- lr: [6.257590727272728e-06] - Loss total: 2.8081767559051514, Last rpr Loss: 0.9596441388130188, Last lagvar Loss: 0.9037909507751465\n",
      "Step 3804/10000- lr: [6.256580630303031e-06] - Loss total: 2.807576894760132, Last rpr Loss: 0.9631777405738831, Last lagvar Loss: 0.8998440504074097\n",
      "Step 3805/10000- lr: [6.255570533333333e-06] - Loss total: 2.807634115219116, Last rpr Loss: 1.041111707687378, Last lagvar Loss: 0.8221547603607178\n",
      "Step 3806/10000- lr: [6.254560436363637e-06] - Loss total: 2.807050943374634, Last rpr Loss: 1.0370498895645142, Last lagvar Loss: 0.8258099555969238\n",
      "Step 3807/10000- lr: [6.253550339393939e-06] - Loss total: 2.8075201511383057, Last rpr Loss: 0.9596222639083862, Last lagvar Loss: 0.9037750363349915\n",
      "Step 3808/10000- lr: [6.252540242424242e-06] - Loss total: 2.8069710731506348, Last rpr Loss: 0.9626402854919434, Last lagvar Loss: 0.9003902673721313\n",
      "Step 3809/10000- lr: [6.251530145454546e-06] - Loss total: 2.8069303035736084, Last rpr Loss: 1.040621280670166, Last lagvar Loss: 0.822561502456665\n",
      "Step 3810/10000- lr: [6.250520048484849e-06] - Loss total: 2.8063786029815674, Last rpr Loss: 1.036875605583191, Last lagvar Loss: 0.8259308338165283\n",
      "Step 3811/10000- lr: [6.249509951515152e-06] - Loss total: 2.8067944049835205, Last rpr Loss: 0.9602332711219788, Last lagvar Loss: 0.9030656814575195\n",
      "Step 3812/10000- lr: [6.248499854545455e-06] - Loss total: 2.806199073791504, Last rpr Loss: 0.9637951254844666, Last lagvar Loss: 0.8990961313247681\n",
      "Step 3813/10000- lr: [6.247489757575759e-06] - Loss total: 2.8062217235565186, Last rpr Loss: 1.0400341749191284, Last lagvar Loss: 0.8230615854263306\n",
      "Step 3814/10000- lr: [6.246479660606061e-06] - Loss total: 2.8055503368377686, Last rpr Loss: 1.0347225666046143, Last lagvar Loss: 0.8278891444206238\n",
      "Step 3815/10000- lr: [6.2454695636363636e-06] - Loss total: 2.806013584136963, Last rpr Loss: 0.9613748788833618, Last lagvar Loss: 0.9017784595489502\n",
      "Step 3816/10000- lr: [6.244459466666667e-06] - Loss total: 2.805203676223755, Last rpr Loss: 0.9675129652023315, Last lagvar Loss: 0.8950401544570923\n",
      "Step 3817/10000- lr: [6.24344936969697e-06] - Loss total: 2.8054678440093994, Last rpr Loss: 1.0389161109924316, Last lagvar Loss: 0.8240535259246826\n",
      "Step 3818/10000- lr: [6.242439272727273e-06] - Loss total: 2.8044774532318115, Last rpr Loss: 1.0289028882980347, Last lagvar Loss: 0.833295464515686\n",
      "Step 3819/10000- lr: [6.241429175757577e-06] - Loss total: 2.805119514465332, Last rpr Loss: 0.9636421203613281, Last lagvar Loss: 0.8992674350738525\n",
      "Step 3820/10000- lr: [6.240419078787879e-06] - Loss total: 2.803942918777466, Last rpr Loss: 0.9756412506103516, Last lagvar Loss: 0.8863407969474792\n",
      "Step 3821/10000- lr: [6.239408981818182e-06] - Loss total: 2.804628372192383, Last rpr Loss: 1.036772608757019, Last lagvar Loss: 0.8259960412979126\n",
      "Step 3822/10000- lr: [6.238398884848485e-06] - Loss total: 2.8031952381134033, Last rpr Loss: 1.016845703125, Last lagvar Loss: 0.8447556495666504\n",
      "Step 3823/10000- lr: [6.237388787878788e-06] - Loss total: 2.8040895462036133, Last rpr Loss: 0.9674909114837646, Last lagvar Loss: 0.8950604796409607\n",
      "Step 3824/10000- lr: [6.236378690909091e-06] - Loss total: 2.8027892112731934, Last rpr Loss: 0.985680878162384, Last lagvar Loss: 0.8758351802825928\n",
      "Step 3825/10000- lr: [6.235368593939395e-06] - Loss total: 2.8036327362060547, Last rpr Loss: 1.0326030254364014, Last lagvar Loss: 0.8298295736312866\n",
      "Step 3826/10000- lr: [6.234358496969698e-06] - Loss total: 2.8022751808166504, Last rpr Loss: 1.0073716640472412, Last lagvar Loss: 0.8539714813232422\n",
      "Step 3827/10000- lr: [6.2333484e-06] - Loss total: 2.8030569553375244, Last rpr Loss: 0.9719224572181702, Last lagvar Loss: 0.8902722597122192\n",
      "Step 3828/10000- lr: [6.232338303030304e-06] - Loss total: 2.801922082901001, Last rpr Loss: 0.9940670132637024, Last lagvar Loss: 0.8672444820404053\n",
      "Step 3829/10000- lr: [6.231328206060606e-06] - Loss total: 2.802605152130127, Last rpr Loss: 1.0275022983551025, Last lagvar Loss: 0.8345739245414734\n",
      "Step 3830/10000- lr: [6.230318109090909e-06] - Loss total: 2.80155611038208, Last rpr Loss: 1.0007330179214478, Last lagvar Loss: 0.8605400323867798\n",
      "Step 3831/10000- lr: [6.229308012121213e-06] - Loss total: 2.802067279815674, Last rpr Loss: 0.9765491485595703, Last lagvar Loss: 0.8853310346603394\n",
      "Step 3832/10000- lr: [6.228297915151516e-06] - Loss total: 2.801222562789917, Last rpr Loss: 1.0001683235168457, Last lagvar Loss: 0.8610925674438477\n",
      "Step 3833/10000- lr: [6.227287818181819e-06] - Loss total: 2.8016197681427, Last rpr Loss: 1.0221298933029175, Last lagvar Loss: 0.8396332263946533\n",
      "Step 3834/10000- lr: [6.226277721212122e-06] - Loss total: 2.800913095474243, Last rpr Loss: 0.9963074922561646, Last lagvar Loss: 0.8649671077728271\n",
      "Step 3835/10000- lr: [6.225267624242424e-06] - Loss total: 2.801140069961548, Last rpr Loss: 0.9812113046646118, Last lagvar Loss: 0.8804117441177368\n",
      "Step 3836/10000- lr: [6.224257527272727e-06] - Loss total: 2.800586223602295, Last rpr Loss: 1.0043087005615234, Last lagvar Loss: 0.8569595217704773\n",
      "Step 3837/10000- lr: [6.2232474303030306e-06] - Loss total: 2.800708770751953, Last rpr Loss: 1.0169167518615723, Last lagvar Loss: 0.844603955745697\n",
      "Step 3838/10000- lr: [6.222237333333334e-06] - Loss total: 2.800283670425415, Last rpr Loss: 0.9936159253120422, Last lagvar Loss: 0.8676725625991821\n",
      "Step 3839/10000- lr: [6.221227236363637e-06] - Loss total: 2.8002824783325195, Last rpr Loss: 0.9857475161552429, Last lagvar Loss: 0.8756811618804932\n",
      "Step 3840/10000- lr: [6.22021713939394e-06] - Loss total: 2.799957513809204, Last rpr Loss: 1.0068110227584839, Last lagvar Loss: 0.8544703125953674\n",
      "Step 3841/10000- lr: [6.219207042424243e-06] - Loss total: 2.799877882003784, Last rpr Loss: 1.0121313333511353, Last lagvar Loss: 0.8492205142974854\n",
      "Step 3842/10000- lr: [6.218196945454545e-06] - Loss total: 2.7996418476104736, Last rpr Loss: 0.9922295212745667, Last lagvar Loss: 0.8690600991249084\n",
      "Step 3843/10000- lr: [6.2171868484848485e-06] - Loss total: 2.799492597579956, Last rpr Loss: 0.9899282455444336, Last lagvar Loss: 0.8713675737380981\n",
      "Step 3844/10000- lr: [6.216176751515152e-06] - Loss total: 2.7993109226226807, Last rpr Loss: 1.0079360008239746, Last lagvar Loss: 0.8533419370651245\n",
      "Step 3845/10000- lr: [6.215166654545455e-06] - Loss total: 2.799116849899292, Last rpr Loss: 1.007935643196106, Last lagvar Loss: 0.8533105850219727\n",
      "Step 3846/10000- lr: [6.214156557575758e-06] - Loss total: 2.798981189727783, Last rpr Loss: 0.99185711145401, Last lagvar Loss: 0.8694150447845459\n",
      "Step 3847/10000- lr: [6.213146460606061e-06] - Loss total: 2.798759937286377, Last rpr Loss: 0.9936196804046631, Last lagvar Loss: 0.8675944805145264\n",
      "Step 3848/10000- lr: [6.212136363636364e-06] - Loss total: 2.798645496368408, Last rpr Loss: 1.0080080032348633, Last lagvar Loss: 0.853246808052063\n",
      "Step 3849/10000- lr: [6.2111262666666665e-06] - Loss total: 2.7984087467193604, Last rpr Loss: 1.004455804824829, Last lagvar Loss: 0.8567310571670532\n",
      "Step 3850/10000- lr: [6.21011616969697e-06] - Loss total: 2.7983062267303467, Last rpr Loss: 0.9922679662704468, Last lagvar Loss: 0.8689720630645752\n",
      "Step 3851/10000- lr: [6.209106072727273e-06] - Loss total: 2.798069477081299, Last rpr Loss: 0.9967079162597656, Last lagvar Loss: 0.864461362361908\n",
      "Step 3852/10000- lr: [6.208095975757576e-06] - Loss total: 2.797966718673706, Last rpr Loss: 1.007312297821045, Last lagvar Loss: 0.853906512260437\n",
      "Step 3853/10000- lr: [6.20708587878788e-06] - Loss total: 2.797734498977661, Last rpr Loss: 1.001718282699585, Last lagvar Loss: 0.8594385385513306\n",
      "Step 3854/10000- lr: [6.206075781818182e-06] - Loss total: 2.7976248264312744, Last rpr Loss: 0.9932068586349487, Last lagvar Loss: 0.8679944276809692\n",
      "Step 3855/10000- lr: [6.205065684848485e-06] - Loss total: 2.7974045276641846, Last rpr Loss: 0.9991015791893005, Last lagvar Loss: 0.8620443344116211\n",
      "Step 3856/10000- lr: [6.204055587878788e-06] - Loss total: 2.797285318374634, Last rpr Loss: 1.0061239004135132, Last lagvar Loss: 0.8550550937652588\n",
      "Step 3857/10000- lr: [6.203045490909091e-06] - Loss total: 2.7970776557922363, Last rpr Loss: 0.9997308254241943, Last lagvar Loss: 0.8614096641540527\n",
      "Step 3858/10000- lr: [6.202035393939394e-06] - Loss total: 2.796945333480835, Last rpr Loss: 0.994481086730957, Last lagvar Loss: 0.8666818141937256\n",
      "Step 3859/10000- lr: [6.201025296969698e-06] - Loss total: 2.7967522144317627, Last rpr Loss: 1.0007853507995605, Last lagvar Loss: 0.8603463172912598\n",
      "Step 3860/10000- lr: [6.200015200000001e-06] - Loss total: 2.7966089248657227, Last rpr Loss: 1.0046968460083008, Last lagvar Loss: 0.8564462661743164\n",
      "Step 3861/10000- lr: [6.199005103030303e-06] - Loss total: 2.7964277267456055, Last rpr Loss: 0.9984469413757324, Last lagvar Loss: 0.8626811504364014\n",
      "Step 3862/10000- lr: [6.197995006060606e-06] - Loss total: 2.796273946762085, Last rpr Loss: 0.995905339717865, Last lagvar Loss: 0.8652244210243225\n",
      "Step 3863/10000- lr: [6.196984909090909e-06] - Loss total: 2.796103000640869, Last rpr Loss: 1.0017985105514526, Last lagvar Loss: 0.8593200445175171\n",
      "Step 3864/10000- lr: [6.195974812121212e-06] - Loss total: 2.7959413528442383, Last rpr Loss: 1.0032241344451904, Last lagvar Loss: 0.8578904271125793\n",
      "Step 3865/10000- lr: [6.1949647151515156e-06] - Loss total: 2.795778274536133, Last rpr Loss: 0.9977632761001587, Last lagvar Loss: 0.8633509278297424\n",
      "Step 3866/10000- lr: [6.193954618181819e-06] - Loss total: 2.795611619949341, Last rpr Loss: 0.997298002243042, Last lagvar Loss: 0.863805890083313\n",
      "Step 3867/10000- lr: [6.192944521212121e-06] - Loss total: 2.7954533100128174, Last rpr Loss: 1.0022351741790771, Last lagvar Loss: 0.8588680028915405\n",
      "Step 3868/10000- lr: [6.1919344242424245e-06] - Loss total: 2.795283555984497, Last rpr Loss: 1.001878261566162, Last lagvar Loss: 0.8592150211334229\n",
      "Step 3869/10000- lr: [6.190924327272727e-06] - Loss total: 2.795128107070923, Last rpr Loss: 0.9975813031196594, Last lagvar Loss: 0.8635162115097046\n",
      "Step 3870/10000- lr: [6.18991423030303e-06] - Loss total: 2.7949576377868652, Last rpr Loss: 0.998531699180603, Last lagvar Loss: 0.8625527620315552\n",
      "Step 3871/10000- lr: [6.1889041333333335e-06] - Loss total: 2.7948031425476074, Last rpr Loss: 1.0022187232971191, Last lagvar Loss: 0.8588671088218689\n",
      "Step 3872/10000- lr: [6.187894036363637e-06] - Loss total: 2.794633388519287, Last rpr Loss: 1.000770926475525, Last lagvar Loss: 0.8603060245513916\n",
      "Step 3873/10000- lr: [6.18688393939394e-06] - Loss total: 2.79447865486145, Last rpr Loss: 0.9977680444717407, Last lagvar Loss: 0.8633111715316772\n",
      "Step 3874/10000- lr: [6.1858738424242425e-06] - Loss total: 2.7943108081817627, Last rpr Loss: 0.9995039105415344, Last lagvar Loss: 0.8615648150444031\n",
      "Step 3875/10000- lr: [6.184863745454546e-06] - Loss total: 2.794153928756714, Last rpr Loss: 1.0018905401229858, Last lagvar Loss: 0.8591774702072144\n",
      "Step 3876/10000- lr: [6.183853648484848e-06] - Loss total: 2.7939884662628174, Last rpr Loss: 0.9999558925628662, Last lagvar Loss: 0.8611071109771729\n",
      "Step 3877/10000- lr: [6.1828435515151515e-06] - Loss total: 2.793830156326294, Last rpr Loss: 0.9981917142868042, Last lagvar Loss: 0.862869143486023\n",
      "Step 3878/10000- lr: [6.181833454545455e-06] - Loss total: 2.7936670780181885, Last rpr Loss: 1.0001780986785889, Last lagvar Loss: 0.8608764410018921\n",
      "Step 3879/10000- lr: [6.180823357575758e-06] - Loss total: 2.7935070991516113, Last rpr Loss: 1.0013939142227173, Last lagvar Loss: 0.8596570491790771\n",
      "Step 3880/10000- lr: [6.1798132606060605e-06] - Loss total: 2.7933459281921387, Last rpr Loss: 0.9994457364082336, Last lagvar Loss: 0.8616034984588623\n",
      "Step 3881/10000- lr: [6.178803163636364e-06] - Loss total: 2.7931854724884033, Last rpr Loss: 0.99871826171875, Last lagvar Loss: 0.8623255491256714\n",
      "Step 3882/10000- lr: [6.177793066666667e-06] - Loss total: 2.793025255203247, Last rpr Loss: 1.0005500316619873, Last lagvar Loss: 0.860490083694458\n",
      "Step 3883/10000- lr: [6.1767829696969695e-06] - Loss total: 2.7928643226623535, Last rpr Loss: 1.0008530616760254, Last lagvar Loss: 0.8601821660995483\n",
      "Step 3884/10000- lr: [6.175772872727273e-06] - Loss total: 2.7927052974700928, Last rpr Loss: 0.9992120265960693, Last lagvar Loss: 0.8618226051330566\n",
      "Step 3885/10000- lr: [6.174762775757576e-06] - Loss total: 2.792543888092041, Last rpr Loss: 0.9992417097091675, Last lagvar Loss: 0.8617863655090332\n",
      "Step 3886/10000- lr: [6.1737526787878784e-06] - Loss total: 2.792386054992676, Last rpr Loss: 1.0006656646728516, Last lagvar Loss: 0.8603597283363342\n",
      "Step 3887/10000- lr: [6.172742581818182e-06] - Loss total: 2.792224645614624, Last rpr Loss: 1.0003654956817627, Last lagvar Loss: 0.8606554269790649\n",
      "Step 3888/10000- lr: [6.171732484848485e-06] - Loss total: 2.7920660972595215, Last rpr Loss: 0.9991998672485352, Last lagvar Loss: 0.861819326877594\n",
      "Step 3889/10000- lr: [6.170722387878788e-06] - Loss total: 2.791905641555786, Last rpr Loss: 0.9996812343597412, Last lagvar Loss: 0.8613318800926208\n",
      "Step 3890/10000- lr: [6.169712290909091e-06] - Loss total: 2.7917473316192627, Last rpr Loss: 1.0005929470062256, Last lagvar Loss: 0.8604170083999634\n",
      "Step 3891/10000- lr: [6.168702193939394e-06] - Loss total: 2.7915875911712646, Last rpr Loss: 0.999992847442627, Last lagvar Loss: 0.8610135912895203\n",
      "Step 3892/10000- lr: [6.167692096969697e-06] - Loss total: 2.791429281234741, Last rpr Loss: 0.9993356466293335, Last lagvar Loss: 0.8616675138473511\n",
      "Step 3893/10000- lr: [6.166682e-06] - Loss total: 2.7912697792053223, Last rpr Loss: 0.9999851584434509, Last lagvar Loss: 0.8610130548477173\n",
      "Step 3894/10000- lr: [6.165671903030303e-06] - Loss total: 2.791111469268799, Last rpr Loss: 1.0004103183746338, Last lagvar Loss: 0.860584020614624\n",
      "Step 3895/10000- lr: [6.164661806060606e-06] - Loss total: 2.7909531593322754, Last rpr Loss: 0.9997642040252686, Last lagvar Loss: 0.8612273931503296\n",
      "Step 3896/10000- lr: [6.1636517090909095e-06] - Loss total: 2.7907941341400146, Last rpr Loss: 0.9995441436767578, Last lagvar Loss: 0.8614426851272583\n",
      "Step 3897/10000- lr: [6.162641612121213e-06] - Loss total: 2.7906363010406494, Last rpr Loss: 1.0001444816589355, Last lagvar Loss: 0.8608379364013672\n",
      "Step 3898/10000- lr: [6.161631515151516e-06] - Loss total: 2.7904775142669678, Last rpr Loss: 1.000186800956726, Last lagvar Loss: 0.8607913255691528\n",
      "Step 3899/10000- lr: [6.1606214181818185e-06] - Loss total: 2.7903199195861816, Last rpr Loss: 0.9996693730354309, Last lagvar Loss: 0.8613058924674988\n",
      "Step 3900/10000- lr: [6.159611321212122e-06] - Loss total: 2.790161371231079, Last rpr Loss: 0.9997591972351074, Last lagvar Loss: 0.8612106442451477\n",
      "Step 3901/10000- lr: [6.158601224242425e-06] - Loss total: 2.790003776550293, Last rpr Loss: 1.000178337097168, Last lagvar Loss: 0.8607871532440186\n",
      "Step 3902/10000- lr: [6.1575911272727275e-06] - Loss total: 2.7898452281951904, Last rpr Loss: 0.9999909996986389, Last lagvar Loss: 0.8609699010848999\n",
      "Step 3903/10000- lr: [6.156581030303031e-06] - Loss total: 2.789687395095825, Last rpr Loss: 0.9996833801269531, Last lagvar Loss: 0.8612737059593201\n",
      "Step 3904/10000- lr: [6.155570933333334e-06] - Loss total: 2.7895288467407227, Last rpr Loss: 0.9999265670776367, Last lagvar Loss: 0.8610248565673828\n",
      "Step 3905/10000- lr: [6.1545608363636365e-06] - Loss total: 2.7893712520599365, Last rpr Loss: 1.0001225471496582, Last lagvar Loss: 0.8608240485191345\n",
      "Step 3906/10000- lr: [6.15355073939394e-06] - Loss total: 2.789212465286255, Last rpr Loss: 0.999855637550354, Last lagvar Loss: 0.8610861897468567\n",
      "Step 3907/10000- lr: [6.152540642424243e-06] - Loss total: 2.7890548706054688, Last rpr Loss: 0.9997637271881104, Last lagvar Loss: 0.8611730337142944\n",
      "Step 3908/10000- lr: [6.151530545454546e-06] - Loss total: 2.788896322250366, Last rpr Loss: 1.0000234842300415, Last lagvar Loss: 0.8609074950218201\n",
      "Step 3909/10000- lr: [6.150520448484849e-06] - Loss total: 2.788738489151001, Last rpr Loss: 1.00002121925354, Last lagvar Loss: 0.8609042167663574\n",
      "Step 3910/10000- lr: [6.149510351515152e-06] - Loss total: 2.7885806560516357, Last rpr Loss: 0.9997903108596802, Last lagvar Loss: 0.8611299991607666\n",
      "Step 3911/10000- lr: [6.148500254545455e-06] - Loss total: 2.7884228229522705, Last rpr Loss: 0.9998683929443359, Last lagvar Loss: 0.8610458374023438\n",
      "Step 3912/10000- lr: [6.147490157575758e-06] - Loss total: 2.7882657051086426, Last rpr Loss: 1.0000536441802979, Last lagvar Loss: 0.8608545064926147\n",
      "Step 3913/10000- lr: [6.146480060606061e-06] - Loss total: 2.7881081104278564, Last rpr Loss: 0.9999204874038696, Last lagvar Loss: 0.8609815835952759\n",
      "Step 3914/10000- lr: [6.145469963636364e-06] - Loss total: 2.787951707839966, Last rpr Loss: 0.999796450138092, Last lagvar Loss: 0.8611000776290894\n",
      "Step 3915/10000- lr: [6.144459866666667e-06] - Loss total: 2.787794589996338, Last rpr Loss: 0.9999635815620422, Last lagvar Loss: 0.8609263300895691\n",
      "Step 3916/10000- lr: [6.14344976969697e-06] - Loss total: 2.7876384258270264, Last rpr Loss: 1.0000264644622803, Last lagvar Loss: 0.8608571290969849\n",
      "Step 3917/10000- lr: [6.142439672727273e-06] - Loss total: 2.787482500076294, Last rpr Loss: 0.9998525977134705, Last lagvar Loss: 0.8610251545906067\n",
      "Step 3918/10000- lr: [6.1414295757575765e-06] - Loss total: 2.7873260974884033, Last rpr Loss: 0.9998569488525391, Last lagvar Loss: 0.8610147833824158\n",
      "Step 3919/10000- lr: [6.140419478787879e-06] - Loss total: 2.7871711254119873, Last rpr Loss: 1.0000295639038086, Last lagvar Loss: 0.8608356714248657\n",
      "Step 3920/10000- lr: [6.139409381818182e-06] - Loss total: 2.787015438079834, Last rpr Loss: 0.9999805688858032, Last lagvar Loss: 0.8608784675598145\n",
      "Step 3921/10000- lr: [6.1383992848484855e-06] - Loss total: 2.786860704421997, Last rpr Loss: 0.9998377561569214, Last lagvar Loss: 0.8610153198242188\n",
      "Step 3922/10000- lr: [6.137389187878788e-06] - Loss total: 2.78670597076416, Last rpr Loss: 0.9999368190765381, Last lagvar Loss: 0.8609102964401245\n",
      "Step 3923/10000- lr: [6.136379090909091e-06] - Loss total: 2.7865517139434814, Last rpr Loss: 1.0000545978546143, Last lagvar Loss: 0.8607863187789917\n",
      "Step 3924/10000- lr: [6.1353689939393945e-06] - Loss total: 2.7863972187042236, Last rpr Loss: 0.9999294281005859, Last lagvar Loss: 0.8609055280685425\n",
      "Step 3925/10000- lr: [6.134358896969697e-06] - Loss total: 2.786242961883545, Last rpr Loss: 0.9998560547828674, Last lagvar Loss: 0.8609732389450073\n",
      "Step 3926/10000- lr: [6.1333488e-06] - Loss total: 2.7860889434814453, Last rpr Loss: 1.0000008344650269, Last lagvar Loss: 0.8608223795890808\n",
      "Step 3927/10000- lr: [6.1323387030303035e-06] - Loss total: 2.785935640335083, Last rpr Loss: 1.000030517578125, Last lagvar Loss: 0.8607871532440186\n",
      "Step 3928/10000- lr: [6.131328606060607e-06] - Loss total: 2.7857820987701416, Last rpr Loss: 0.9998818039894104, Last lagvar Loss: 0.8609302043914795\n",
      "Step 3929/10000- lr: [6.130318509090909e-06] - Loss total: 2.7856287956237793, Last rpr Loss: 0.9998935461044312, Last lagvar Loss: 0.8609130382537842\n",
      "Step 3930/10000- lr: [6.1293084121212125e-06] - Loss total: 2.785475969314575, Last rpr Loss: 1.0000293254852295, Last lagvar Loss: 0.860771894454956\n",
      "Step 3931/10000- lr: [6.128298315151516e-06] - Loss total: 2.785322904586792, Last rpr Loss: 0.9999780654907227, Last lagvar Loss: 0.8608177900314331\n",
      "Step 3932/10000- lr: [6.127288218181818e-06] - Loss total: 2.785170793533325, Last rpr Loss: 0.999858021736145, Last lagvar Loss: 0.8609327077865601\n",
      "Step 3933/10000- lr: [6.1262781212121215e-06] - Loss total: 2.7850182056427, Last rpr Loss: 0.9999339580535889, Last lagvar Loss: 0.8608516454696655\n",
      "Step 3934/10000- lr: [6.125268024242425e-06] - Loss total: 2.784865617752075, Last rpr Loss: 1.0000231266021729, Last lagvar Loss: 0.8607574105262756\n",
      "Step 3935/10000- lr: [6.124257927272727e-06] - Loss total: 2.7847139835357666, Last rpr Loss: 0.9999240636825562, Last lagvar Loss: 0.860851526260376\n",
      "Step 3936/10000- lr: [6.1232478303030304e-06] - Loss total: 2.784562349319458, Last rpr Loss: 0.9998651146888733, Last lagvar Loss: 0.8609057664871216\n",
      "Step 3937/10000- lr: [6.122237733333334e-06] - Loss total: 2.784410238265991, Last rpr Loss: 0.9999743700027466, Last lagvar Loss: 0.8607915639877319\n",
      "Step 3938/10000- lr: [6.121227636363637e-06] - Loss total: 2.7842588424682617, Last rpr Loss: 1.0000030994415283, Last lagvar Loss: 0.8607580661773682\n",
      "Step 3939/10000- lr: [6.120217539393939e-06] - Loss total: 2.7841076850891113, Last rpr Loss: 0.9998903870582581, Last lagvar Loss: 0.8608662486076355\n",
      "Step 3940/10000- lr: [6.119207442424243e-06] - Loss total: 2.7839572429656982, Last rpr Loss: 0.999893069267273, Last lagvar Loss: 0.8608590364456177\n",
      "Step 3941/10000- lr: [6.118197345454546e-06] - Loss total: 2.783806085586548, Last rpr Loss: 0.9999962449073792, Last lagvar Loss: 0.8607513308525085\n",
      "Step 3942/10000- lr: [6.117187248484848e-06] - Loss total: 2.7836554050445557, Last rpr Loss: 0.9999678730964661, Last lagvar Loss: 0.860775351524353\n",
      "Step 3943/10000- lr: [6.116177151515152e-06] - Loss total: 2.7835047245025635, Last rpr Loss: 0.999874472618103, Last lagvar Loss: 0.8608644008636475\n",
      "Step 3944/10000- lr: [6.115167054545455e-06] - Loss total: 2.7833542823791504, Last rpr Loss: 0.9999258518218994, Last lagvar Loss: 0.8608088493347168\n",
      "Step 3945/10000- lr: [6.114156957575757e-06] - Loss total: 2.7832043170928955, Last rpr Loss: 0.9999988675117493, Last lagvar Loss: 0.8607316017150879\n",
      "Step 3946/10000- lr: [6.113146860606061e-06] - Loss total: 2.7830543518066406, Last rpr Loss: 0.9999336004257202, Last lagvar Loss: 0.8607927560806274\n",
      "Step 3947/10000- lr: [6.112136763636364e-06] - Loss total: 2.7829043865203857, Last rpr Loss: 0.9998805522918701, Last lagvar Loss: 0.8608418107032776\n",
      "Step 3948/10000- lr: [6.111126666666667e-06] - Loss total: 2.782754898071289, Last rpr Loss: 0.9999530911445618, Last lagvar Loss: 0.8607653379440308\n",
      "Step 3949/10000- lr: [6.11011656969697e-06] - Loss total: 2.7826054096221924, Last rpr Loss: 0.9999846816062927, Last lagvar Loss: 0.8607297539710999\n",
      "Step 3950/10000- lr: [6.109106472727273e-06] - Loss total: 2.7824559211730957, Last rpr Loss: 0.9999099373817444, Last lagvar Loss: 0.8608006238937378\n",
      "Step 3951/10000- lr: [6.108096375757576e-06] - Loss total: 2.7823069095611572, Last rpr Loss: 0.999902606010437, Last lagvar Loss: 0.8608042001724243\n",
      "Step 3952/10000- lr: [6.107086278787879e-06] - Loss total: 2.7821578979492188, Last rpr Loss: 0.9999716281890869, Last lagvar Loss: 0.8607313632965088\n",
      "Step 3953/10000- lr: [6.106076181818182e-06] - Loss total: 2.7820093631744385, Last rpr Loss: 0.9999618530273438, Last lagvar Loss: 0.8607374429702759\n",
      "Step 3954/10000- lr: [6.105066084848485e-06] - Loss total: 2.7818610668182373, Last rpr Loss: 0.9999046325683594, Last lagvar Loss: 0.860791027545929\n",
      "Step 3955/10000- lr: [6.104055987878788e-06] - Loss total: 2.781712293624878, Last rpr Loss: 0.999932050704956, Last lagvar Loss: 0.8607600331306458\n",
      "Step 3956/10000- lr: [6.103045890909091e-06] - Loss total: 2.7815639972686768, Last rpr Loss: 0.9999802112579346, Last lagvar Loss: 0.8607082366943359\n",
      "Step 3957/10000- lr: [6.102035793939394e-06] - Loss total: 2.781416177749634, Last rpr Loss: 0.9999477863311768, Last lagvar Loss: 0.8607372045516968\n",
      "Step 3958/10000- lr: [6.1010256969696974e-06] - Loss total: 2.781268358230591, Last rpr Loss: 0.9999126195907593, Last lagvar Loss: 0.8607687950134277\n",
      "Step 3959/10000- lr: [6.1000156e-06] - Loss total: 2.7811203002929688, Last rpr Loss: 0.9999523162841797, Last lagvar Loss: 0.8607257008552551\n",
      "Step 3960/10000- lr: [6.099005503030303e-06] - Loss total: 2.780972957611084, Last rpr Loss: 0.9999701380729675, Last lagvar Loss: 0.8607043027877808\n",
      "Step 3961/10000- lr: [6.0979954060606064e-06] - Loss total: 2.7808258533477783, Last rpr Loss: 0.999930739402771, Last lagvar Loss: 0.8607403039932251\n",
      "Step 3962/10000- lr: [6.096985309090909e-06] - Loss total: 2.7806787490844727, Last rpr Loss: 0.9999287724494934, Last lagvar Loss: 0.86073899269104\n",
      "Step 3963/10000- lr: [6.095975212121212e-06] - Loss total: 2.780531644821167, Last rpr Loss: 0.9999649524688721, Last lagvar Loss: 0.8606994152069092\n",
      "Step 3964/10000- lr: [6.094965115151515e-06] - Loss total: 2.7803850173950195, Last rpr Loss: 0.9999562501907349, Last lagvar Loss: 0.8607048988342285\n",
      "Step 3965/10000- lr: [6.093955018181819e-06] - Loss total: 2.780238151550293, Last rpr Loss: 0.9999257326126099, Last lagvar Loss: 0.8607320785522461\n",
      "Step 3966/10000- lr: [6.092944921212121e-06] - Loss total: 2.7800917625427246, Last rpr Loss: 0.9999417662620544, Last lagvar Loss: 0.8607127666473389\n",
      "Step 3967/10000- lr: [6.091934824242424e-06] - Loss total: 2.779945135116577, Last rpr Loss: 0.9999625086784363, Last lagvar Loss: 0.8606887459754944\n",
      "Step 3968/10000- lr: [6.090924727272728e-06] - Loss total: 2.779799222946167, Last rpr Loss: 0.9999437928199768, Last lagvar Loss: 0.8607043027877808\n",
      "Step 3969/10000- lr: [6.08991463030303e-06] - Loss total: 2.7796528339385986, Last rpr Loss: 0.9999330043792725, Last lagvar Loss: 0.8607118725776672\n",
      "Step 3970/10000- lr: [6.088904533333333e-06] - Loss total: 2.7795071601867676, Last rpr Loss: 0.999954104423523, Last lagvar Loss: 0.8606874942779541\n",
      "Step 3971/10000- lr: [6.087894436363637e-06] - Loss total: 2.779362201690674, Last rpr Loss: 0.9999575614929199, Last lagvar Loss: 0.8606808185577393\n",
      "Step 3972/10000- lr: [6.086884339393939e-06] - Loss total: 2.7792162895202637, Last rpr Loss: 0.9999370574951172, Last lagvar Loss: 0.8606982827186584\n",
      "Step 3973/10000- lr: [6.085874242424242e-06] - Loss total: 2.779071092605591, Last rpr Loss: 0.9999417662620544, Last lagvar Loss: 0.8606904149055481\n",
      "Step 3974/10000- lr: [6.084864145454546e-06] - Loss total: 2.778925895690918, Last rpr Loss: 0.9999581575393677, Last lagvar Loss: 0.8606709241867065\n",
      "Step 3975/10000- lr: [6.083854048484849e-06] - Loss total: 2.778780698776245, Last rpr Loss: 0.9999483823776245, Last lagvar Loss: 0.8606775999069214\n",
      "Step 3976/10000- lr: [6.082843951515151e-06] - Loss total: 2.7786357402801514, Last rpr Loss: 0.9999382495880127, Last lagvar Loss: 0.8606846332550049\n",
      "Step 3977/10000- lr: [6.081833854545455e-06] - Loss total: 2.7784910202026367, Last rpr Loss: 0.9999516606330872, Last lagvar Loss: 0.8606681823730469\n",
      "Step 3978/10000- lr: [6.080823757575758e-06] - Loss total: 2.778346538543701, Last rpr Loss: 0.9999544620513916, Last lagvar Loss: 0.8606622219085693\n",
      "Step 3979/10000- lr: [6.07981366060606e-06] - Loss total: 2.7782022953033447, Last rpr Loss: 0.9999390840530396, Last lagvar Loss: 0.8606746792793274\n",
      "Step 3980/10000- lr: [6.078803563636364e-06] - Loss total: 2.778057813644409, Last rpr Loss: 0.9999434947967529, Last lagvar Loss: 0.8606672286987305\n",
      "Step 3981/10000- lr: [6.077793466666667e-06] - Loss total: 2.777913808822632, Last rpr Loss: 0.9999542236328125, Last lagvar Loss: 0.8606534600257874\n",
      "Step 3982/10000- lr: [6.07678336969697e-06] - Loss total: 2.7777698040008545, Last rpr Loss: 0.999947190284729, Last lagvar Loss: 0.8606574535369873\n",
      "Step 3983/10000- lr: [6.0757732727272734e-06] - Loss total: 2.777625799179077, Last rpr Loss: 0.999941349029541, Last lagvar Loss: 0.8606603145599365\n",
      "Step 3984/10000- lr: [6.074763175757576e-06] - Loss total: 2.777482271194458, Last rpr Loss: 0.9999501705169678, Last lagvar Loss: 0.860648512840271\n",
      "Step 3985/10000- lr: [6.073753078787879e-06] - Loss total: 2.777338743209839, Last rpr Loss: 0.9999520182609558, Last lagvar Loss: 0.8606438040733337\n",
      "Step 3986/10000- lr: [6.0727429818181824e-06] - Loss total: 2.777195453643799, Last rpr Loss: 0.9999432563781738, Last lagvar Loss: 0.8606495261192322\n",
      "Step 3987/10000- lr: [6.071732884848486e-06] - Loss total: 2.777052402496338, Last rpr Loss: 0.9999457597732544, Last lagvar Loss: 0.8606441617012024\n",
      "Step 3988/10000- lr: [6.070722787878788e-06] - Loss total: 2.7769086360931396, Last rpr Loss: 0.9999510049819946, Last lagvar Loss: 0.8606359958648682\n",
      "Step 3989/10000- lr: [6.069712690909091e-06] - Loss total: 2.7767655849456787, Last rpr Loss: 0.9999458193778992, Last lagvar Loss: 0.8606380820274353\n",
      "Step 3990/10000- lr: [6.068702593939395e-06] - Loss total: 2.776622772216797, Last rpr Loss: 0.9999408721923828, Last lagvar Loss: 0.8606400489807129\n",
      "Step 3991/10000- lr: [6.067692496969697e-06] - Loss total: 2.776480197906494, Last rpr Loss: 0.9999484419822693, Last lagvar Loss: 0.8606296181678772\n",
      "Step 3992/10000- lr: [6.0666824e-06] - Loss total: 2.7763373851776123, Last rpr Loss: 0.9999520182609558, Last lagvar Loss: 0.8606231212615967\n",
      "Step 3993/10000- lr: [6.065672303030304e-06] - Loss total: 2.7761945724487305, Last rpr Loss: 0.9999450445175171, Last lagvar Loss: 0.860627293586731\n",
      "Step 3994/10000- lr: [6.064662206060606e-06] - Loss total: 2.7760519981384277, Last rpr Loss: 0.9999455213546753, Last lagvar Loss: 0.8606238961219788\n",
      "Step 3995/10000- lr: [6.063652109090909e-06] - Loss total: 2.775909662246704, Last rpr Loss: 0.9999507665634155, Last lagvar Loss: 0.8606157302856445\n",
      "Step 3996/10000- lr: [6.062642012121213e-06] - Loss total: 2.7757675647735596, Last rpr Loss: 0.999946117401123, Last lagvar Loss: 0.860617458820343\n",
      "Step 3997/10000- lr: [6.061631915151516e-06] - Loss total: 2.775625228881836, Last rpr Loss: 0.9999427795410156, Last lagvar Loss: 0.860617995262146\n",
      "Step 3998/10000- lr: [6.060621818181818e-06] - Loss total: 2.7754828929901123, Last rpr Loss: 0.9999483227729797, Last lagvar Loss: 0.8606095314025879\n",
      "Step 3999/10000- lr: [6.059611721212122e-06] - Loss total: 2.7753407955169678, Last rpr Loss: 0.999951183795929, Last lagvar Loss: 0.8606038093566895\n",
      "Step 4000/10000- lr: [6.058601624242425e-06] - Loss total: 2.775198459625244, Last rpr Loss: 0.9999470710754395, Last lagvar Loss: 0.860605001449585\n",
      "Step 4001/10000- lr: [6.057591527272727e-06] - Loss total: 2.775056838989258, Last rpr Loss: 0.9999478459358215, Last lagvar Loss: 0.860601544380188\n",
      "Step 4002/10000- lr: [6.056581430303031e-06] - Loss total: 2.7749149799346924, Last rpr Loss: 0.9999516606330872, Last lagvar Loss: 0.8605948686599731\n",
      "Step 4003/10000- lr: [6.055571333333334e-06] - Loss total: 2.774773120880127, Last rpr Loss: 0.9999499320983887, Last lagvar Loss: 0.8605937361717224\n",
      "Step 4004/10000- lr: [6.054561236363636e-06] - Loss total: 2.7746315002441406, Last rpr Loss: 0.999947190284729, Last lagvar Loss: 0.8605936765670776\n",
      "Step 4005/10000- lr: [6.05355113939394e-06] - Loss total: 2.774489641189575, Last rpr Loss: 0.9999529719352722, Last lagvar Loss: 0.8605850338935852\n",
      "Step 4006/10000- lr: [6.052541042424243e-06] - Loss total: 2.774348020553589, Last rpr Loss: 0.999954104423523, Last lagvar Loss: 0.8605811595916748\n",
      "Step 4007/10000- lr: [6.051530945454546e-06] - Loss total: 2.7742063999176025, Last rpr Loss: 0.9999475479125977, Last lagvar Loss: 0.8605848550796509\n",
      "Step 4008/10000- lr: [6.050520848484849e-06] - Loss total: 2.7740652561187744, Last rpr Loss: 0.9999493956565857, Last lagvar Loss: 0.8605802059173584\n",
      "Step 4009/10000- lr: [6.049510751515152e-06] - Loss total: 2.773923397064209, Last rpr Loss: 0.9999566078186035, Last lagvar Loss: 0.8605703115463257\n",
      "Step 4010/10000- lr: [6.048500654545455e-06] - Loss total: 2.77378249168396, Last rpr Loss: 0.9999572038650513, Last lagvar Loss: 0.8605668544769287\n",
      "Step 4011/10000- lr: [6.047490557575758e-06] - Loss total: 2.7736411094665527, Last rpr Loss: 0.9999527931213379, Last lagvar Loss: 0.8605684041976929\n",
      "Step 4012/10000- lr: [6.046480460606061e-06] - Loss total: 2.773500442504883, Last rpr Loss: 0.9999549388885498, Last lagvar Loss: 0.8605635762214661\n",
      "Step 4013/10000- lr: [6.045470363636364e-06] - Loss total: 2.773359537124634, Last rpr Loss: 0.999958336353302, Last lagvar Loss: 0.8605573177337646\n",
      "Step 4014/10000- lr: [6.044460266666667e-06] - Loss total: 2.773218870162964, Last rpr Loss: 0.9999568462371826, Last lagvar Loss: 0.8605560064315796\n",
      "Step 4015/10000- lr: [6.04345016969697e-06] - Loss total: 2.773078203201294, Last rpr Loss: 0.9999560713768005, Last lagvar Loss: 0.8605539202690125\n",
      "Step 4016/10000- lr: [6.042440072727273e-06] - Loss total: 2.7729380130767822, Last rpr Loss: 0.9999581575393677, Last lagvar Loss: 0.8605489730834961\n",
      "Step 4017/10000- lr: [6.041429975757576e-06] - Loss total: 2.7727980613708496, Last rpr Loss: 0.9999599456787109, Last lagvar Loss: 0.8605443239212036\n",
      "Step 4018/10000- lr: [6.040419878787879e-06] - Loss total: 2.772658109664917, Last rpr Loss: 0.9999560117721558, Last lagvar Loss: 0.86054527759552\n",
      "Step 4019/10000- lr: [6.039409781818182e-06] - Loss total: 2.7725181579589844, Last rpr Loss: 0.9999573230743408, Last lagvar Loss: 0.8605411052703857\n",
      "Step 4020/10000- lr: [6.038399684848485e-06] - Loss total: 2.77237868309021, Last rpr Loss: 0.9999595880508423, Last lagvar Loss: 0.8605358600616455\n",
      "Step 4021/10000- lr: [6.037389587878788e-06] - Loss total: 2.7722392082214355, Last rpr Loss: 0.9999601244926453, Last lagvar Loss: 0.8605324029922485\n",
      "Step 4022/10000- lr: [6.036379490909091e-06] - Loss total: 2.7721002101898193, Last rpr Loss: 0.9999570846557617, Last lagvar Loss: 0.8605324029922485\n",
      "Step 4023/10000- lr: [6.035369393939394e-06] - Loss total: 2.771960973739624, Last rpr Loss: 0.9999539256095886, Last lagvar Loss: 0.8605324029922485\n",
      "Step 4024/10000- lr: [6.034359296969698e-06] - Loss total: 2.7718217372894287, Last rpr Loss: 0.9999564290046692, Last lagvar Loss: 0.8605269193649292\n",
      "Step 4025/10000- lr: [6.0333492e-06] - Loss total: 2.77168345451355, Last rpr Loss: 0.9999565482139587, Last lagvar Loss: 0.8605235815048218\n",
      "Step 4026/10000- lr: [6.032339103030303e-06] - Loss total: 2.7715446949005127, Last rpr Loss: 0.9999560117721558, Last lagvar Loss: 0.8605210185050964\n",
      "Step 4027/10000- lr: [6.031329006060607e-06] - Loss total: 2.7714059352874756, Last rpr Loss: 0.999955415725708, Last lagvar Loss: 0.8605184555053711\n",
      "Step 4028/10000- lr: [6.030318909090909e-06] - Loss total: 2.771267890930176, Last rpr Loss: 0.9999542832374573, Last lagvar Loss: 0.8605163097381592\n",
      "Step 4029/10000- lr: [6.029308812121212e-06] - Loss total: 2.7711293697357178, Last rpr Loss: 0.9999548196792603, Last lagvar Loss: 0.8605125546455383\n",
      "Step 4030/10000- lr: [6.028298715151516e-06] - Loss total: 2.770991563796997, Last rpr Loss: 0.9999527931213379, Last lagvar Loss: 0.8605112433433533\n",
      "Step 4031/10000- lr: [6.027288618181818e-06] - Loss total: 2.770853042602539, Last rpr Loss: 0.9999536275863647, Last lagvar Loss: 0.8605071306228638\n",
      "Step 4032/10000- lr: [6.026278521212121e-06] - Loss total: 2.7707154750823975, Last rpr Loss: 0.9999523162841797, Last lagvar Loss: 0.8605049848556519\n",
      "Step 4033/10000- lr: [6.025268424242425e-06] - Loss total: 2.7705776691436768, Last rpr Loss: 0.999951183795929, Last lagvar Loss: 0.8605026602745056\n",
      "Step 4034/10000- lr: [6.024258327272728e-06] - Loss total: 2.770440101623535, Last rpr Loss: 0.999950647354126, Last lagvar Loss: 0.8604996204376221\n",
      "Step 4035/10000- lr: [6.02324823030303e-06] - Loss total: 2.7703025341033936, Last rpr Loss: 0.9999507069587708, Last lagvar Loss: 0.860495924949646\n",
      "Step 4036/10000- lr: [6.022238133333334e-06] - Loss total: 2.770165205001831, Last rpr Loss: 0.9999487400054932, Last lagvar Loss: 0.8604942560195923\n",
      "Step 4037/10000- lr: [6.021228036363637e-06] - Loss total: 2.7700276374816895, Last rpr Loss: 0.9999496340751648, Last lagvar Loss: 0.8604894876480103\n",
      "Step 4038/10000- lr: [6.020217939393939e-06] - Loss total: 2.769890546798706, Last rpr Loss: 0.9999481439590454, Last lagvar Loss: 0.8604868650436401\n",
      "Step 4039/10000- lr: [6.0192078424242426e-06] - Loss total: 2.7697532176971436, Last rpr Loss: 0.9999481439590454, Last lagvar Loss: 0.8604828715324402\n",
      "Step 4040/10000- lr: [6.018197745454546e-06] - Loss total: 2.7696163654327393, Last rpr Loss: 0.9999462962150574, Last lagvar Loss: 0.860480546951294\n",
      "Step 4041/10000- lr: [6.017187648484848e-06] - Loss total: 2.769479274749756, Last rpr Loss: 0.9999454021453857, Last lagvar Loss: 0.8604768514633179\n",
      "Step 4042/10000- lr: [6.0161775515151515e-06] - Loss total: 2.7693426609039307, Last rpr Loss: 0.9999454021453857, Last lagvar Loss: 0.8604722619056702\n",
      "Step 4043/10000- lr: [6.015167454545455e-06] - Loss total: 2.7692058086395264, Last rpr Loss: 0.9999475479125977, Last lagvar Loss: 0.8604652881622314\n",
      "Step 4044/10000- lr: [6.014157357575758e-06] - Loss total: 2.769069194793701, Last rpr Loss: 0.9999444484710693, Last lagvar Loss: 0.8604632019996643\n",
      "Step 4045/10000- lr: [6.0131472606060605e-06] - Loss total: 2.768932580947876, Last rpr Loss: 0.9999426007270813, Last lagvar Loss: 0.8604596257209778\n",
      "Step 4046/10000- lr: [6.012137163636364e-06] - Loss total: 2.7687957286834717, Last rpr Loss: 0.9999445676803589, Last lagvar Loss: 0.8604518175125122\n",
      "Step 4047/10000- lr: [6.011127066666667e-06] - Loss total: 2.7686593532562256, Last rpr Loss: 0.9999433159828186, Last lagvar Loss: 0.8604468703269958\n",
      "Step 4048/10000- lr: [6.0101169696969695e-06] - Loss total: 2.7685229778289795, Last rpr Loss: 0.9999409914016724, Last lagvar Loss: 0.8604425191879272\n",
      "Step 4049/10000- lr: [6.009106872727273e-06] - Loss total: 2.768386125564575, Last rpr Loss: 0.999940037727356, Last lagvar Loss: 0.8604363203048706\n",
      "Step 4050/10000- lr: [6.008096775757576e-06] - Loss total: 2.768249988555908, Last rpr Loss: 0.9999402761459351, Last lagvar Loss: 0.8604283332824707\n",
      "Step 4051/10000- lr: [6.0070866787878785e-06] - Loss total: 2.768113374710083, Last rpr Loss: 0.9999402165412903, Last lagvar Loss: 0.8604200482368469\n",
      "Step 4052/10000- lr: [6.006076581818182e-06] - Loss total: 2.767977237701416, Last rpr Loss: 0.9999388456344604, Last lagvar Loss: 0.8604123592376709\n",
      "Step 4053/10000- lr: [6.005066484848485e-06] - Loss total: 2.767840623855591, Last rpr Loss: 0.9999386072158813, Last lagvar Loss: 0.8604027628898621\n",
      "Step 4054/10000- lr: [6.004056387878788e-06] - Loss total: 2.767704725265503, Last rpr Loss: 0.9999378323554993, Last lagvar Loss: 0.8603929281234741\n",
      "Step 4055/10000- lr: [6.003046290909091e-06] - Loss total: 2.7675678730010986, Last rpr Loss: 0.9999370574951172, Last lagvar Loss: 0.860382080078125\n",
      "Step 4056/10000- lr: [6.002036193939394e-06] - Loss total: 2.7674317359924316, Last rpr Loss: 0.9999361038208008, Last lagvar Loss: 0.8603707551956177\n",
      "Step 4057/10000- lr: [6.001026096969697e-06] - Loss total: 2.7672951221466064, Last rpr Loss: 0.9999336004257202, Last lagvar Loss: 0.8603600263595581\n",
      "Step 4058/10000- lr: [6.000016e-06] - Loss total: 2.7671589851379395, Last rpr Loss: 0.9999350905418396, Last lagvar Loss: 0.860344648361206\n",
      "Step 4059/10000- lr: [5.999005903030303e-06] - Loss total: 2.7670223712921143, Last rpr Loss: 0.9999396800994873, Last lagvar Loss: 0.8603254556655884\n",
      "Step 4060/10000- lr: [5.997995806060606e-06] - Loss total: 2.766885995864868, Last rpr Loss: 0.9999380707740784, Last lagvar Loss: 0.8603121042251587\n",
      "Step 4061/10000- lr: [5.996985709090909e-06] - Loss total: 2.766749620437622, Last rpr Loss: 0.9999368786811829, Last lagvar Loss: 0.8602977991104126\n",
      "Step 4062/10000- lr: [5.995975612121212e-06] - Loss total: 2.766613006591797, Last rpr Loss: 0.9999408721923828, Last lagvar Loss: 0.8602783679962158\n",
      "Step 4063/10000- lr: [5.994965515151515e-06] - Loss total: 2.76647686958313, Last rpr Loss: 0.9999461770057678, Last lagvar Loss: 0.860257625579834\n",
      "Step 4064/10000- lr: [5.9939554181818186e-06] - Loss total: 2.766340732574463, Last rpr Loss: 0.999945878982544, Last lagvar Loss: 0.8602429628372192\n",
      "Step 4065/10000- lr: [5.992945321212121e-06] - Loss total: 2.766204595565796, Last rpr Loss: 0.9999486804008484, Last lagvar Loss: 0.8602254390716553\n",
      "Step 4066/10000- lr: [5.991935224242424e-06] - Loss total: 2.766068696975708, Last rpr Loss: 0.9999535083770752, Last lagvar Loss: 0.8602066040039062\n",
      "Step 4067/10000- lr: [5.9909251272727275e-06] - Loss total: 2.765932559967041, Last rpr Loss: 0.9999568462371826, Last lagvar Loss: 0.8601899147033691\n",
      "Step 4068/10000- lr: [5.989915030303031e-06] - Loss total: 2.7657968997955322, Last rpr Loss: 0.9999591112136841, Last lagvar Loss: 0.8601751327514648\n",
      "Step 4069/10000- lr: [5.988904933333334e-06] - Loss total: 2.7656610012054443, Last rpr Loss: 0.99996018409729, Last lagvar Loss: 0.860162079334259\n",
      "Step 4070/10000- lr: [5.9878948363636365e-06] - Loss total: 2.7655251026153564, Last rpr Loss: 0.9999622106552124, Last lagvar Loss: 0.8601487874984741\n",
      "Step 4071/10000- lr: [5.98688473939394e-06] - Loss total: 2.7653896808624268, Last rpr Loss: 0.9999645352363586, Last lagvar Loss: 0.8601359128952026\n",
      "Step 4072/10000- lr: [5.985874642424243e-06] - Loss total: 2.765254020690918, Last rpr Loss: 0.9999682903289795, Last lagvar Loss: 0.8601220846176147\n",
      "Step 4073/10000- lr: [5.984864545454546e-06] - Loss total: 2.765118360519409, Last rpr Loss: 0.9999663829803467, Last lagvar Loss: 0.8601146340370178\n",
      "Step 4074/10000- lr: [5.983854448484849e-06] - Loss total: 2.7649827003479004, Last rpr Loss: 0.9999641180038452, Last lagvar Loss: 0.8601078987121582\n",
      "Step 4075/10000- lr: [5.982844351515152e-06] - Loss total: 2.7648472785949707, Last rpr Loss: 0.9999656677246094, Last lagvar Loss: 0.8600978851318359\n",
      "Step 4076/10000- lr: [5.981834254545455e-06] - Loss total: 2.764711380004883, Last rpr Loss: 0.999968409538269, Last lagvar Loss: 0.8600870370864868\n",
      "Step 4077/10000- lr: [5.980824157575758e-06] - Loss total: 2.764575719833374, Last rpr Loss: 0.9999675154685974, Last lagvar Loss: 0.8600801825523376\n",
      "Step 4078/10000- lr: [5.979814060606061e-06] - Loss total: 2.7644405364990234, Last rpr Loss: 0.9999665021896362, Last lagvar Loss: 0.8600738644599915\n",
      "Step 4079/10000- lr: [5.978803963636364e-06] - Loss total: 2.7643046379089355, Last rpr Loss: 0.999967098236084, Last lagvar Loss: 0.8600660562515259\n",
      "Step 4080/10000- lr: [5.977793866666667e-06] - Loss total: 2.7641689777374268, Last rpr Loss: 0.9999704360961914, Last lagvar Loss: 0.8600558042526245\n",
      "Step 4081/10000- lr: [5.97678376969697e-06] - Loss total: 2.764033079147339, Last rpr Loss: 0.9999698996543884, Last lagvar Loss: 0.8600496053695679\n",
      "Step 4082/10000- lr: [5.975773672727273e-06] - Loss total: 2.763897180557251, Last rpr Loss: 0.9999711513519287, Last lagvar Loss: 0.8600418567657471\n",
      "Step 4083/10000- lr: [5.974763575757577e-06] - Loss total: 2.763761281967163, Last rpr Loss: 0.9999703168869019, Last lagvar Loss: 0.8600363731384277\n",
      "Step 4084/10000- lr: [5.973753478787879e-06] - Loss total: 2.763625383377075, Last rpr Loss: 0.999970555305481, Last lagvar Loss: 0.860029935836792\n",
      "Step 4085/10000- lr: [5.972743381818182e-06] - Loss total: 2.763489246368408, Last rpr Loss: 0.9999723434448242, Last lagvar Loss: 0.8600219488143921\n",
      "Step 4086/10000- lr: [5.9717332848484856e-06] - Loss total: 2.763353109359741, Last rpr Loss: 0.999970555305481, Last lagvar Loss: 0.8600176572799683\n",
      "Step 4087/10000- lr: [5.970723187878788e-06] - Loss total: 2.763216733932495, Last rpr Loss: 0.9999706745147705, Last lagvar Loss: 0.8600116968154907\n",
      "Step 4088/10000- lr: [5.969713090909091e-06] - Loss total: 2.763080358505249, Last rpr Loss: 0.9999725222587585, Last lagvar Loss: 0.8600038290023804\n",
      "Step 4089/10000- lr: [5.9687029939393946e-06] - Loss total: 2.762943744659424, Last rpr Loss: 0.9999740719795227, Last lagvar Loss: 0.8599963188171387\n",
      "Step 4090/10000- lr: [5.967692896969697e-06] - Loss total: 2.7628073692321777, Last rpr Loss: 0.999973714351654, Last lagvar Loss: 0.8599909543991089\n",
      "Step 4091/10000- lr: [5.9666828e-06] - Loss total: 2.7626707553863525, Last rpr Loss: 0.9999724626541138, Last lagvar Loss: 0.8599863052368164\n",
      "Step 4092/10000- lr: [5.9656727030303035e-06] - Loss total: 2.762533664703369, Last rpr Loss: 0.9999728798866272, Last lagvar Loss: 0.8599799275398254\n",
      "Step 4093/10000- lr: [5.964662606060607e-06] - Loss total: 2.7623965740203857, Last rpr Loss: 0.9999718070030212, Last lagvar Loss: 0.8599750995635986\n",
      "Step 4094/10000- lr: [5.963652509090909e-06] - Loss total: 2.7622592449188232, Last rpr Loss: 0.9999728202819824, Last lagvar Loss: 0.8599681258201599\n",
      "Step 4095/10000- lr: [5.9626424121212125e-06] - Loss total: 2.7621207237243652, Last rpr Loss: 0.9999703764915466, Last lagvar Loss: 0.8599645495414734\n",
      "Step 4096/10000- lr: [5.961632315151516e-06] - Loss total: 2.7619829177856445, Last rpr Loss: 0.9999727010726929, Last lagvar Loss: 0.8599560260772705\n",
      "Step 4097/10000- lr: [5.960622218181818e-06] - Loss total: 2.7618439197540283, Last rpr Loss: 0.9999740123748779, Last lagvar Loss: 0.8599485754966736\n",
      "Step 4098/10000- lr: [5.9596121212121215e-06] - Loss total: 2.761704683303833, Last rpr Loss: 0.9999738931655884, Last lagvar Loss: 0.8599424362182617\n",
      "Step 4099/10000- lr: [5.958602024242425e-06] - Loss total: 2.7615644931793213, Last rpr Loss: 0.9999724626541138, Last lagvar Loss: 0.8599374294281006\n",
      "Step 4100/10000- lr: [5.957591927272727e-06] - Loss total: 2.7614243030548096, Last rpr Loss: 0.999970555305481, Last lagvar Loss: 0.8599326014518738\n",
      "Step 4101/10000- lr: [5.9565818303030305e-06] - Loss total: 2.7612831592559814, Last rpr Loss: 0.9999695420265198, Last lagvar Loss: 0.8599265813827515\n",
      "Step 4102/10000- lr: [5.955571733333334e-06] - Loss total: 2.7611420154571533, Last rpr Loss: 0.999967098236084, Last lagvar Loss: 0.8599218130111694\n",
      "Step 4103/10000- lr: [5.954561636363637e-06] - Loss total: 2.761000394821167, Last rpr Loss: 0.9999622106552124, Last lagvar Loss: 0.8599187135696411\n",
      "Step 4104/10000- lr: [5.9535515393939395e-06] - Loss total: 2.7608590126037598, Last rpr Loss: 0.999955952167511, Last lagvar Loss: 0.8599165678024292\n",
      "Step 4105/10000- lr: [5.952541442424243e-06] - Loss total: 2.76071834564209, Last rpr Loss: 0.9999520182609558, Last lagvar Loss: 0.8599112033843994\n",
      "Step 4106/10000- lr: [5.951531345454546e-06] - Loss total: 2.760577440261841, Last rpr Loss: 0.9999502897262573, Last lagvar Loss: 0.85990309715271\n",
      "Step 4107/10000- lr: [5.9505212484848485e-06] - Loss total: 2.76043701171875, Last rpr Loss: 0.9999492168426514, Last lagvar Loss: 0.8598934412002563\n",
      "Step 4108/10000- lr: [5.949511151515152e-06] - Loss total: 2.7602970600128174, Last rpr Loss: 0.9999462962150574, Last lagvar Loss: 0.8598853349685669\n",
      "Step 4109/10000- lr: [5.948501054545455e-06] - Loss total: 2.760157823562622, Last rpr Loss: 0.999944806098938, Last lagvar Loss: 0.8598752021789551\n",
      "Step 4110/10000- lr: [5.9474909575757574e-06] - Loss total: 2.7600185871124268, Last rpr Loss: 0.9999441504478455, Last lagvar Loss: 0.8598639965057373\n",
      "Step 4111/10000- lr: [5.946480860606061e-06] - Loss total: 2.7598793506622314, Last rpr Loss: 0.9999401569366455, Last lagvar Loss: 0.8598560094833374\n",
      "Step 4112/10000- lr: [5.945470763636364e-06] - Loss total: 2.7597405910491943, Last rpr Loss: 0.9999371767044067, Last lagvar Loss: 0.8598470687866211\n",
      "Step 4113/10000- lr: [5.944460666666667e-06] - Loss total: 2.7596023082733154, Last rpr Loss: 0.9999409914016724, Last lagvar Loss: 0.8598315715789795\n",
      "Step 4114/10000- lr: [5.94345056969697e-06] - Loss total: 2.7594637870788574, Last rpr Loss: 0.9999464750289917, Last lagvar Loss: 0.8598147630691528\n",
      "Step 4115/10000- lr: [5.942440472727273e-06] - Loss total: 2.7593259811401367, Last rpr Loss: 0.9999504685401917, Last lagvar Loss: 0.8597997426986694\n",
      "Step 4116/10000- lr: [5.941430375757576e-06] - Loss total: 2.7591874599456787, Last rpr Loss: 0.9999537467956543, Last lagvar Loss: 0.8597860336303711\n",
      "Step 4117/10000- lr: [5.940420278787879e-06] - Loss total: 2.759049415588379, Last rpr Loss: 0.9999578595161438, Last lagvar Loss: 0.8597718477249146\n",
      "Step 4118/10000- lr: [5.939410181818182e-06] - Loss total: 2.758911609649658, Last rpr Loss: 0.9999598860740662, Last lagvar Loss: 0.8597604036331177\n",
      "Step 4119/10000- lr: [5.938400084848485e-06] - Loss total: 2.7587735652923584, Last rpr Loss: 0.9999582171440125, Last lagvar Loss: 0.8597532510757446\n",
      "Step 4120/10000- lr: [5.937389987878788e-06] - Loss total: 2.7586357593536377, Last rpr Loss: 0.9999563694000244, Last lagvar Loss: 0.8597469329833984\n",
      "Step 4121/10000- lr: [5.936379890909091e-06] - Loss total: 2.758497714996338, Last rpr Loss: 0.9999531507492065, Last lagvar Loss: 0.8597426414489746\n",
      "Step 4122/10000- lr: [5.935369793939394e-06] - Loss total: 2.758359670639038, Last rpr Loss: 0.999949038028717, Last lagvar Loss: 0.8597397804260254\n",
      "Step 4123/10000- lr: [5.9343596969696975e-06] - Loss total: 2.7582218647003174, Last rpr Loss: 0.9999462366104126, Last lagvar Loss: 0.8597360849380493\n",
      "Step 4124/10000- lr: [5.9333496e-06] - Loss total: 2.758084535598755, Last rpr Loss: 0.9999496936798096, Last lagvar Loss: 0.8597268462181091\n",
      "Step 4125/10000- lr: [5.932339503030303e-06] - Loss total: 2.7579469680786133, Last rpr Loss: 0.9999558925628662, Last lagvar Loss: 0.8597154021263123\n",
      "Step 4126/10000- lr: [5.9313294060606065e-06] - Loss total: 2.7578094005584717, Last rpr Loss: 0.9999631643295288, Last lagvar Loss: 0.8597033023834229\n",
      "Step 4127/10000- lr: [5.930319309090909e-06] - Loss total: 2.7576725482940674, Last rpr Loss: 0.9999696016311646, Last lagvar Loss: 0.8596923351287842\n",
      "Step 4128/10000- lr: [5.929309212121212e-06] - Loss total: 2.757535696029663, Last rpr Loss: 0.9999773502349854, Last lagvar Loss: 0.8596805930137634\n",
      "Step 4129/10000- lr: [5.9282991151515155e-06] - Loss total: 2.757399559020996, Last rpr Loss: 0.9999824166297913, Last lagvar Loss: 0.8596718311309814\n",
      "Step 4130/10000- lr: [5.927289018181818e-06] - Loss total: 2.757263422012329, Last rpr Loss: 0.9999828934669495, Last lagvar Loss: 0.8596681356430054\n",
      "Step 4131/10000- lr: [5.926278921212121e-06] - Loss total: 2.7571280002593994, Last rpr Loss: 0.9999831318855286, Last lagvar Loss: 0.859664797782898\n",
      "Step 4132/10000- lr: [5.9252688242424245e-06] - Loss total: 2.756992816925049, Last rpr Loss: 0.9999824166297913, Last lagvar Loss: 0.8596627116203308\n",
      "Step 4133/10000- lr: [5.924258727272728e-06] - Loss total: 2.7568581104278564, Last rpr Loss: 0.9999805688858032, Last lagvar Loss: 0.8596619963645935\n",
      "Step 4134/10000- lr: [5.92324863030303e-06] - Loss total: 2.756723642349243, Last rpr Loss: 0.9999799728393555, Last lagvar Loss: 0.859660267829895\n",
      "Step 4135/10000- lr: [5.9222385333333334e-06] - Loss total: 2.7565901279449463, Last rpr Loss: 0.9999750852584839, Last lagvar Loss: 0.8596628308296204\n",
      "Step 4136/10000- lr: [5.921228436363637e-06] - Loss total: 2.7564568519592285, Last rpr Loss: 0.9999697208404541, Last lagvar Loss: 0.859666109085083\n",
      "Step 4137/10000- lr: [5.920218339393939e-06] - Loss total: 2.7563235759735107, Last rpr Loss: 0.9999710917472839, Last lagvar Loss: 0.8596625328063965\n",
      "Step 4138/10000- lr: [5.9192082424242424e-06] - Loss total: 2.756190776824951, Last rpr Loss: 0.9999704957008362, Last lagvar Loss: 0.8596612215042114\n",
      "Step 4139/10000- lr: [5.918198145454546e-06] - Loss total: 2.756058931350708, Last rpr Loss: 0.9999653100967407, Last lagvar Loss: 0.8596644401550293\n",
      "Step 4140/10000- lr: [5.917188048484848e-06] - Loss total: 2.7559268474578857, Last rpr Loss: 0.999967634677887, Last lagvar Loss: 0.8596600890159607\n",
      "Step 4141/10000- lr: [5.916177951515151e-06] - Loss total: 2.7557952404022217, Last rpr Loss: 0.9999706745147705, Last lagvar Loss: 0.85965496301651\n",
      "Step 4142/10000- lr: [5.915167854545455e-06] - Loss total: 2.755664110183716, Last rpr Loss: 0.9999708533287048, Last lagvar Loss: 0.8596527576446533\n",
      "Step 4143/10000- lr: [5.914157757575758e-06] - Loss total: 2.755533218383789, Last rpr Loss: 0.9999727010726929, Last lagvar Loss: 0.8596488237380981\n",
      "Step 4144/10000- lr: [5.91314766060606e-06] - Loss total: 2.7554028034210205, Last rpr Loss: 0.9999749660491943, Last lagvar Loss: 0.8596444129943848\n",
      "Step 4145/10000- lr: [5.912137563636364e-06] - Loss total: 2.755272388458252, Last rpr Loss: 0.999972939491272, Last lagvar Loss: 0.8596442341804504\n",
      "Step 4146/10000- lr: [5.911127466666667e-06] - Loss total: 2.7551419734954834, Last rpr Loss: 0.9999735951423645, Last lagvar Loss: 0.8596413731575012\n",
      "Step 4147/10000- lr: [5.910117369696969e-06] - Loss total: 2.7550125122070312, Last rpr Loss: 0.9999704360961914, Last lagvar Loss: 0.8596420288085938\n",
      "Step 4148/10000- lr: [5.909107272727273e-06] - Loss total: 2.7548835277557373, Last rpr Loss: 0.9999710321426392, Last lagvar Loss: 0.8596392273902893\n",
      "Step 4149/10000- lr: [5.908097175757576e-06] - Loss total: 2.7547543048858643, Last rpr Loss: 0.9999727010726929, Last lagvar Loss: 0.8596351146697998\n",
      "Step 4150/10000- lr: [5.907087078787878e-06] - Loss total: 2.7546253204345703, Last rpr Loss: 0.9999730587005615, Last lagvar Loss: 0.8596323132514954\n",
      "Step 4151/10000- lr: [5.906076981818182e-06] - Loss total: 2.7544968128204346, Last rpr Loss: 0.999972939491272, Last lagvar Loss: 0.8596299886703491\n",
      "Step 4152/10000- lr: [5.905066884848486e-06] - Loss total: 2.754368305206299, Last rpr Loss: 0.9999743700027466, Last lagvar Loss: 0.8596261739730835\n",
      "Step 4153/10000- lr: [5.904056787878788e-06] - Loss total: 2.754240036010742, Last rpr Loss: 0.9999740719795227, Last lagvar Loss: 0.8596240282058716\n",
      "Step 4154/10000- lr: [5.9030466909090915e-06] - Loss total: 2.7541122436523438, Last rpr Loss: 0.9999706149101257, Last lagvar Loss: 0.8596252202987671\n",
      "Step 4155/10000- lr: [5.902036593939395e-06] - Loss total: 2.753984212875366, Last rpr Loss: 0.9999706745147705, Last lagvar Loss: 0.8596227169036865\n",
      "Step 4156/10000- lr: [5.901026496969697e-06] - Loss total: 2.753856897354126, Last rpr Loss: 0.9999688267707825, Last lagvar Loss: 0.8596222400665283\n",
      "Step 4157/10000- lr: [5.9000164000000005e-06] - Loss total: 2.753730058670044, Last rpr Loss: 0.9999708533287048, Last lagvar Loss: 0.8596179485321045\n",
      "Step 4158/10000- lr: [5.899006303030304e-06] - Loss total: 2.753602981567383, Last rpr Loss: 0.9999699592590332, Last lagvar Loss: 0.8596165776252747\n",
      "Step 4159/10000- lr: [5.897996206060606e-06] - Loss total: 2.7534759044647217, Last rpr Loss: 0.9999706149101257, Last lagvar Loss: 0.8596136569976807\n",
      "Step 4160/10000- lr: [5.8969861090909094e-06] - Loss total: 2.7533493041992188, Last rpr Loss: 0.9999735355377197, Last lagvar Loss: 0.8596086502075195\n",
      "Step 4161/10000- lr: [5.895976012121213e-06] - Loss total: 2.753222942352295, Last rpr Loss: 0.9999737739562988, Last lagvar Loss: 0.8596062660217285\n",
      "Step 4162/10000- lr: [5.894965915151516e-06] - Loss total: 2.7530970573425293, Last rpr Loss: 0.9999750256538391, Last lagvar Loss: 0.8596029877662659\n",
      "Step 4163/10000- lr: [5.8939558181818184e-06] - Loss total: 2.7529711723327637, Last rpr Loss: 0.9999773502349854, Last lagvar Loss: 0.859598696231842\n",
      "Step 4164/10000- lr: [5.892945721212122e-06] - Loss total: 2.752845287322998, Last rpr Loss: 0.9999798536300659, Last lagvar Loss: 0.8595942854881287\n",
      "Step 4165/10000- lr: [5.891935624242425e-06] - Loss total: 2.7527198791503906, Last rpr Loss: 0.9999773502349854, Last lagvar Loss: 0.8595948219299316\n",
      "Step 4166/10000- lr: [5.890925527272727e-06] - Loss total: 2.752594232559204, Last rpr Loss: 0.9999781250953674, Last lagvar Loss: 0.8595923185348511\n",
      "Step 4167/10000- lr: [5.889915430303031e-06] - Loss total: 2.752469301223755, Last rpr Loss: 0.9999804496765137, Last lagvar Loss: 0.859588086605072\n",
      "Step 4168/10000- lr: [5.888905333333334e-06] - Loss total: 2.7523441314697266, Last rpr Loss: 0.9999812841415405, Last lagvar Loss: 0.8595855236053467\n",
      "Step 4169/10000- lr: [5.887895236363636e-06] - Loss total: 2.7522194385528564, Last rpr Loss: 0.9999807476997375, Last lagvar Loss: 0.8595843315124512\n",
      "Step 4170/10000- lr: [5.88688513939394e-06] - Loss total: 2.7520945072174072, Last rpr Loss: 0.9999821782112122, Last lagvar Loss: 0.8595812916755676\n",
      "Step 4171/10000- lr: [5.885875042424243e-06] - Loss total: 2.751970052719116, Last rpr Loss: 0.9999853372573853, Last lagvar Loss: 0.8595764636993408\n",
      "Step 4172/10000- lr: [5.884864945454546e-06] - Loss total: 2.7518460750579834, Last rpr Loss: 0.9999840259552002, Last lagvar Loss: 0.8595761656761169\n",
      "Step 4173/10000- lr: [5.883854848484849e-06] - Loss total: 2.7517218589782715, Last rpr Loss: 0.9999805688858032, Last lagvar Loss: 0.8595780730247498\n",
      "Step 4174/10000- lr: [5.882844751515152e-06] - Loss total: 2.7515976428985596, Last rpr Loss: 0.9999837875366211, Last lagvar Loss: 0.859573245048523\n",
      "Step 4175/10000- lr: [5.881834654545455e-06] - Loss total: 2.751473903656006, Last rpr Loss: 0.9999827146530151, Last lagvar Loss: 0.8595727682113647\n",
      "Step 4176/10000- lr: [5.880824557575758e-06] - Loss total: 2.751350164413452, Last rpr Loss: 0.9999778270721436, Last lagvar Loss: 0.8595761656761169\n",
      "Step 4177/10000- lr: [5.879814460606061e-06] - Loss total: 2.7512266635894775, Last rpr Loss: 0.9999794363975525, Last lagvar Loss: 0.8595731258392334\n",
      "Step 4178/10000- lr: [5.878804363636364e-06] - Loss total: 2.751103401184082, Last rpr Loss: 0.9999804496765137, Last lagvar Loss: 0.8595707416534424\n",
      "Step 4179/10000- lr: [5.877794266666667e-06] - Loss total: 2.7509801387786865, Last rpr Loss: 0.9999780654907227, Last lagvar Loss: 0.8595716953277588\n",
      "Step 4180/10000- lr: [5.87678416969697e-06] - Loss total: 2.75085711479187, Last rpr Loss: 0.9999780654907227, Last lagvar Loss: 0.859570324420929\n",
      "Step 4181/10000- lr: [5.875774072727273e-06] - Loss total: 2.7507340908050537, Last rpr Loss: 0.9999799728393555, Last lagvar Loss: 0.8595670461654663\n",
      "Step 4182/10000- lr: [5.8747639757575765e-06] - Loss total: 2.7506115436553955, Last rpr Loss: 0.9999787211418152, Last lagvar Loss: 0.8595669269561768\n",
      "Step 4183/10000- lr: [5.873753878787879e-06] - Loss total: 2.7504889965057373, Last rpr Loss: 0.9999799132347107, Last lagvar Loss: 0.859564483165741\n",
      "Step 4184/10000- lr: [5.872743781818182e-06] - Loss total: 2.750366449356079, Last rpr Loss: 0.9999828934669495, Last lagvar Loss: 0.8595601916313171\n",
      "Step 4185/10000- lr: [5.8717336848484854e-06] - Loss total: 2.750244140625, Last rpr Loss: 0.9999816417694092, Last lagvar Loss: 0.8595602512359619\n",
      "Step 4186/10000- lr: [5.870723587878788e-06] - Loss total: 2.750121831893921, Last rpr Loss: 0.9999823570251465, Last lagvar Loss: 0.8595582246780396\n",
      "Step 4187/10000- lr: [5.869713490909091e-06] - Loss total: 2.75, Last rpr Loss: 0.9999866485595703, Last lagvar Loss: 0.8595526218414307\n",
      "Step 4188/10000- lr: [5.8687033939393944e-06] - Loss total: 2.749878168106079, Last rpr Loss: 0.9999840259552002, Last lagvar Loss: 0.8595540523529053\n",
      "Step 4189/10000- lr: [5.867693296969697e-06] - Loss total: 2.749755859375, Last rpr Loss: 0.999981164932251, Last lagvar Loss: 0.8595556616783142\n",
      "Step 4190/10000- lr: [5.8666832e-06] - Loss total: 2.7496345043182373, Last rpr Loss: 0.9999853372573853, Last lagvar Loss: 0.8595503568649292\n",
      "Step 4191/10000- lr: [5.865673103030303e-06] - Loss total: 2.7495129108428955, Last rpr Loss: 0.9999861121177673, Last lagvar Loss: 0.8595484495162964\n",
      "Step 4192/10000- lr: [5.864663006060607e-06] - Loss total: 2.749391794204712, Last rpr Loss: 0.9999828934669495, Last lagvar Loss: 0.8595504760742188\n",
      "Step 4193/10000- lr: [5.863652909090909e-06] - Loss total: 2.749270439147949, Last rpr Loss: 0.9999822378158569, Last lagvar Loss: 0.859549880027771\n",
      "Step 4194/10000- lr: [5.862642812121212e-06] - Loss total: 2.7491493225097656, Last rpr Loss: 0.9999829530715942, Last lagvar Loss: 0.859548032283783\n",
      "Step 4195/10000- lr: [5.861632715151516e-06] - Loss total: 2.749028205871582, Last rpr Loss: 0.9999858140945435, Last lagvar Loss: 0.8595439791679382\n",
      "Step 4196/10000- lr: [5.860622618181818e-06] - Loss total: 2.7489075660705566, Last rpr Loss: 0.9999847412109375, Last lagvar Loss: 0.8595438599586487\n",
      "Step 4197/10000- lr: [5.859612521212121e-06] - Loss total: 2.7487869262695312, Last rpr Loss: 0.9999806880950928, Last lagvar Loss: 0.8595468997955322\n",
      "Step 4198/10000- lr: [5.858602424242425e-06] - Loss total: 2.748666286468506, Last rpr Loss: 0.9999825954437256, Last lagvar Loss: 0.8595438003540039\n",
      "Step 4199/10000- lr: [5.857592327272727e-06] - Loss total: 2.7485458850860596, Last rpr Loss: 0.9999827742576599, Last lagvar Loss: 0.8595426082611084\n",
      "Step 4200/10000- lr: [5.85658223030303e-06] - Loss total: 2.7484254837036133, Last rpr Loss: 0.9999832510948181, Last lagvar Loss: 0.8595410585403442\n",
      "Step 4201/10000- lr: [5.855572133333334e-06] - Loss total: 2.748305559158325, Last rpr Loss: 0.9999796152114868, Last lagvar Loss: 0.8595435619354248\n",
      "Step 4202/10000- lr: [5.854562036363637e-06] - Loss total: 2.748185157775879, Last rpr Loss: 0.999982476234436, Last lagvar Loss: 0.8595396280288696\n",
      "Step 4203/10000- lr: [5.853551939393939e-06] - Loss total: 2.748065233230591, Last rpr Loss: 0.9999843239784241, Last lagvar Loss: 0.8595366477966309\n",
      "Step 4204/10000- lr: [5.852541842424243e-06] - Loss total: 2.747945547103882, Last rpr Loss: 0.9999821186065674, Last lagvar Loss: 0.8595378398895264\n",
      "Step 4205/10000- lr: [5.851531745454546e-06] - Loss total: 2.747825860977173, Last rpr Loss: 0.9999817609786987, Last lagvar Loss: 0.8595371246337891\n",
      "Step 4206/10000- lr: [5.850521648484848e-06] - Loss total: 2.747706413269043, Last rpr Loss: 0.9999861717224121, Last lagvar Loss: 0.8595316410064697\n",
      "Step 4207/10000- lr: [5.849511551515152e-06] - Loss total: 2.747586488723755, Last rpr Loss: 0.9999841451644897, Last lagvar Loss: 0.8595326542854309\n",
      "Step 4208/10000- lr: [5.848501454545455e-06] - Loss total: 2.747467517852783, Last rpr Loss: 0.9999827146530151, Last lagvar Loss: 0.8595330119132996\n",
      "Step 4209/10000- lr: [5.847491357575757e-06] - Loss total: 2.7473483085632324, Last rpr Loss: 0.9999843835830688, Last lagvar Loss: 0.8595303297042847\n",
      "Step 4210/10000- lr: [5.846481260606061e-06] - Loss total: 2.7472290992736816, Last rpr Loss: 0.9999858736991882, Last lagvar Loss: 0.8595278859138489\n",
      "Step 4211/10000- lr: [5.845471163636364e-06] - Loss total: 2.747109889984131, Last rpr Loss: 0.9999821186065674, Last lagvar Loss: 0.8595305681228638\n",
      "Step 4212/10000- lr: [5.844461066666667e-06] - Loss total: 2.7469911575317383, Last rpr Loss: 0.999981164932251, Last lagvar Loss: 0.8595304489135742\n",
      "Step 4213/10000- lr: [5.84345096969697e-06] - Loss total: 2.7468721866607666, Last rpr Loss: 0.999988317489624, Last lagvar Loss: 0.8595222234725952\n",
      "Step 4214/10000- lr: [5.842440872727273e-06] - Loss total: 2.7467539310455322, Last rpr Loss: 0.9999861121177673, Last lagvar Loss: 0.8595235347747803\n",
      "Step 4215/10000- lr: [5.841430775757576e-06] - Loss total: 2.7466351985931396, Last rpr Loss: 0.9999845027923584, Last lagvar Loss: 0.859524130821228\n",
      "Step 4216/10000- lr: [5.8404206787878786e-06] - Loss total: 2.7465171813964844, Last rpr Loss: 0.9999860525131226, Last lagvar Loss: 0.8595215082168579\n",
      "Step 4217/10000- lr: [5.839410581818182e-06] - Loss total: 2.74639892578125, Last rpr Loss: 0.9999854564666748, Last lagvar Loss: 0.8595211505889893\n",
      "Step 4218/10000- lr: [5.838400484848485e-06] - Loss total: 2.7462806701660156, Last rpr Loss: 0.9999847412109375, Last lagvar Loss: 0.8595209121704102\n",
      "Step 4219/10000- lr: [5.8373903878787875e-06] - Loss total: 2.7461624145507812, Last rpr Loss: 0.9999876022338867, Last lagvar Loss: 0.8595170974731445\n",
      "Step 4220/10000- lr: [5.836380290909091e-06] - Loss total: 2.746044874191284, Last rpr Loss: 0.9999867081642151, Last lagvar Loss: 0.859516978263855\n",
      "Step 4221/10000- lr: [5.835370193939394e-06] - Loss total: 2.745926856994629, Last rpr Loss: 0.9999842047691345, Last lagvar Loss: 0.8595184683799744\n",
      "Step 4222/10000- lr: [5.834360096969697e-06] - Loss total: 2.7458090782165527, Last rpr Loss: 0.9999853372573853, Last lagvar Loss: 0.8595163822174072\n",
      "Step 4223/10000- lr: [5.83335e-06] - Loss total: 2.7456915378570557, Last rpr Loss: 0.9999855756759644, Last lagvar Loss: 0.8595150709152222\n",
      "Step 4224/10000- lr: [5.832339903030303e-06] - Loss total: 2.7455742359161377, Last rpr Loss: 0.9999851584434509, Last lagvar Loss: 0.859514594078064\n",
      "Step 4225/10000- lr: [5.831329806060606e-06] - Loss total: 2.7454569339752197, Last rpr Loss: 0.9999859929084778, Last lagvar Loss: 0.8595128059387207\n",
      "Step 4226/10000- lr: [5.830319709090909e-06] - Loss total: 2.7453396320343018, Last rpr Loss: 0.999988317489624, Last lagvar Loss: 0.8595095872879028\n",
      "Step 4227/10000- lr: [5.829309612121212e-06] - Loss total: 2.745222330093384, Last rpr Loss: 0.999987006187439, Last lagvar Loss: 0.8595098257064819\n",
      "Step 4228/10000- lr: [5.828299515151515e-06] - Loss total: 2.745105266571045, Last rpr Loss: 0.9999868273735046, Last lagvar Loss: 0.8595091104507446\n",
      "Step 4229/10000- lr: [5.827289418181818e-06] - Loss total: 2.7449886798858643, Last rpr Loss: 0.99998539686203, Last lagvar Loss: 0.8595097064971924\n",
      "Step 4230/10000- lr: [5.826279321212121e-06] - Loss total: 2.7448716163635254, Last rpr Loss: 0.9999876618385315, Last lagvar Loss: 0.8595064282417297\n",
      "Step 4231/10000- lr: [5.825269224242424e-06] - Loss total: 2.7447550296783447, Last rpr Loss: 0.9999850988388062, Last lagvar Loss: 0.8595080375671387\n",
      "Step 4232/10000- lr: [5.824259127272728e-06] - Loss total: 2.744638204574585, Last rpr Loss: 0.9999839067459106, Last lagvar Loss: 0.8595083355903625\n",
      "Step 4233/10000- lr: [5.82324903030303e-06] - Loss total: 2.7445220947265625, Last rpr Loss: 0.9999864101409912, Last lagvar Loss: 0.8595050573348999\n",
      "Step 4234/10000- lr: [5.822238933333333e-06] - Loss total: 2.744405508041382, Last rpr Loss: 0.9999903440475464, Last lagvar Loss: 0.8595001697540283\n",
      "Step 4235/10000- lr: [5.821228836363637e-06] - Loss total: 2.7442893981933594, Last rpr Loss: 0.9999889135360718, Last lagvar Loss: 0.859500527381897\n",
      "Step 4236/10000- lr: [5.820218739393939e-06] - Loss total: 2.744173049926758, Last rpr Loss: 0.9999841451644897, Last lagvar Loss: 0.8595044612884521\n",
      "Step 4237/10000- lr: [5.819208642424242e-06] - Loss total: 2.7440574169158936, Last rpr Loss: 0.9999867677688599, Last lagvar Loss: 0.8595008850097656\n",
      "Step 4238/10000- lr: [5.8181985454545456e-06] - Loss total: 2.74394154548645, Last rpr Loss: 0.9999895095825195, Last lagvar Loss: 0.8594971895217896\n",
      "Step 4239/10000- lr: [5.817188448484849e-06] - Loss total: 2.7438254356384277, Last rpr Loss: 0.9999856948852539, Last lagvar Loss: 0.8595001697540283\n",
      "Step 4240/10000- lr: [5.816178351515152e-06] - Loss total: 2.7437095642089844, Last rpr Loss: 0.9999845027923584, Last lagvar Loss: 0.8595004081726074\n",
      "Step 4241/10000- lr: [5.815168254545455e-06] - Loss total: 2.743594169616699, Last rpr Loss: 0.9999904036521912, Last lagvar Loss: 0.8594937324523926\n",
      "Step 4242/10000- lr: [5.814158157575758e-06] - Loss total: 2.743478536605835, Last rpr Loss: 0.9999889135360718, Last lagvar Loss: 0.8594942688941956\n",
      "Step 4243/10000- lr: [5.813148060606061e-06] - Loss total: 2.74336314201355, Last rpr Loss: 0.9999866485595703, Last lagvar Loss: 0.8594956398010254\n",
      "Step 4244/10000- lr: [5.812137963636364e-06] - Loss total: 2.743248224258423, Last rpr Loss: 0.9999873638153076, Last lagvar Loss: 0.8594940900802612\n",
      "Step 4245/10000- lr: [5.811127866666667e-06] - Loss total: 2.743133068084717, Last rpr Loss: 0.9999902248382568, Last lagvar Loss: 0.8594903349876404\n",
      "Step 4246/10000- lr: [5.81011776969697e-06] - Loss total: 2.7430174350738525, Last rpr Loss: 0.9999867677688599, Last lagvar Loss: 0.8594928979873657\n",
      "Step 4247/10000- lr: [5.809107672727273e-06] - Loss total: 2.7429025173187256, Last rpr Loss: 0.9999871850013733, Last lagvar Loss: 0.8594915866851807\n",
      "Step 4248/10000- lr: [5.808097575757576e-06] - Loss total: 2.7427878379821777, Last rpr Loss: 0.9999873638153076, Last lagvar Loss: 0.8594905138015747\n",
      "Step 4249/10000- lr: [5.807087478787879e-06] - Loss total: 2.742673397064209, Last rpr Loss: 0.9999879002571106, Last lagvar Loss: 0.8594890832901001\n",
      "Step 4250/10000- lr: [5.806077381818182e-06] - Loss total: 2.742558717727661, Last rpr Loss: 0.999987781047821, Last lagvar Loss: 0.8594882488250732\n",
      "Step 4251/10000- lr: [5.805067284848486e-06] - Loss total: 2.742443799972534, Last rpr Loss: 0.9999884366989136, Last lagvar Loss: 0.8594868183135986\n",
      "Step 4252/10000- lr: [5.804057187878788e-06] - Loss total: 2.7423295974731445, Last rpr Loss: 0.9999881386756897, Last lagvar Loss: 0.8594862222671509\n",
      "Step 4253/10000- lr: [5.803047090909091e-06] - Loss total: 2.742215156555176, Last rpr Loss: 0.9999868869781494, Last lagvar Loss: 0.8594866991043091\n",
      "Step 4254/10000- lr: [5.802036993939395e-06] - Loss total: 2.742100954055786, Last rpr Loss: 0.9999881982803345, Last lagvar Loss: 0.8594843745231628\n",
      "Step 4255/10000- lr: [5.801026896969697e-06] - Loss total: 2.7419867515563965, Last rpr Loss: 0.9999915957450867, Last lagvar Loss: 0.8594802021980286\n",
      "Step 4256/10000- lr: [5.8000168e-06] - Loss total: 2.741872787475586, Last rpr Loss: 0.9999874830245972, Last lagvar Loss: 0.8594833612442017\n",
      "Step 4257/10000- lr: [5.799006703030304e-06] - Loss total: 2.7417590618133545, Last rpr Loss: 0.9999874830245972, Last lagvar Loss: 0.8594826459884644\n",
      "Step 4258/10000- lr: [5.797996606060606e-06] - Loss total: 2.741645097732544, Last rpr Loss: 0.9999891519546509, Last lagvar Loss: 0.8594800233840942\n",
      "Step 4259/10000- lr: [5.796986509090909e-06] - Loss total: 2.7415316104888916, Last rpr Loss: 0.9999889731407166, Last lagvar Loss: 0.8594794273376465\n",
      "Step 4260/10000- lr: [5.795976412121213e-06] - Loss total: 2.74141788482666, Last rpr Loss: 0.999987006187439, Last lagvar Loss: 0.8594805002212524\n",
      "Step 4261/10000- lr: [5.794966315151516e-06] - Loss total: 2.7413041591644287, Last rpr Loss: 0.9999878406524658, Last lagvar Loss: 0.8594787120819092\n",
      "Step 4262/10000- lr: [5.793956218181818e-06] - Loss total: 2.7411904335021973, Last rpr Loss: 0.9999899864196777, Last lagvar Loss: 0.8594757914543152\n",
      "Step 4263/10000- lr: [5.7929461212121216e-06] - Loss total: 2.741077423095703, Last rpr Loss: 0.9999892115592957, Last lagvar Loss: 0.8594757318496704\n",
      "Step 4264/10000- lr: [5.791936024242425e-06] - Loss total: 2.74096417427063, Last rpr Loss: 0.9999876022338867, Last lagvar Loss: 0.8594765067100525\n",
      "Step 4265/10000- lr: [5.790925927272727e-06] - Loss total: 2.7408511638641357, Last rpr Loss: 0.9999895691871643, Last lagvar Loss: 0.859473705291748\n",
      "Step 4266/10000- lr: [5.7899158303030306e-06] - Loss total: 2.7407379150390625, Last rpr Loss: 0.999990701675415, Last lagvar Loss: 0.8594716787338257\n",
      "Step 4267/10000- lr: [5.788905733333334e-06] - Loss total: 2.7406251430511475, Last rpr Loss: 0.9999883770942688, Last lagvar Loss: 0.8594732284545898\n",
      "Step 4268/10000- lr: [5.787895636363636e-06] - Loss total: 2.7405121326446533, Last rpr Loss: 0.9999873638153076, Last lagvar Loss: 0.8594733476638794\n",
      "Step 4269/10000- lr: [5.7868855393939395e-06] - Loss total: 2.7403995990753174, Last rpr Loss: 0.9999903440475464, Last lagvar Loss: 0.859469473361969\n",
      "Step 4270/10000- lr: [5.785875442424243e-06] - Loss total: 2.7402868270874023, Last rpr Loss: 0.9999891519546509, Last lagvar Loss: 0.8594698309898376\n",
      "Step 4271/10000- lr: [5.784865345454546e-06] - Loss total: 2.7401742935180664, Last rpr Loss: 0.9999869465827942, Last lagvar Loss: 0.8594712018966675\n",
      "Step 4272/10000- lr: [5.7838552484848485e-06] - Loss total: 2.7400619983673096, Last rpr Loss: 0.9999903440475464, Last lagvar Loss: 0.8594669699668884\n",
      "Step 4273/10000- lr: [5.782845151515152e-06] - Loss total: 2.7399494647979736, Last rpr Loss: 0.9999920725822449, Last lagvar Loss: 0.8594644069671631\n",
      "Step 4274/10000- lr: [5.781835054545455e-06] - Loss total: 2.739837169647217, Last rpr Loss: 0.9999891519546509, Last lagvar Loss: 0.8594664335250854\n",
      "Step 4275/10000- lr: [5.7808249575757575e-06] - Loss total: 2.739725351333618, Last rpr Loss: 0.9999884366989136, Last lagvar Loss: 0.8594664931297302\n",
      "Step 4276/10000- lr: [5.779814860606061e-06] - Loss total: 2.7396135330200195, Last rpr Loss: 0.9999908804893494, Last lagvar Loss: 0.8594631552696228\n",
      "Step 4277/10000- lr: [5.778804763636364e-06] - Loss total: 2.739501476287842, Last rpr Loss: 0.9999887943267822, Last lagvar Loss: 0.8594644069671631\n",
      "Step 4278/10000- lr: [5.7777946666666665e-06] - Loss total: 2.739389657974243, Last rpr Loss: 0.9999878406524658, Last lagvar Loss: 0.8594645261764526\n",
      "Step 4279/10000- lr: [5.77678456969697e-06] - Loss total: 2.7392773628234863, Last rpr Loss: 0.9999898672103882, Last lagvar Loss: 0.8594616055488586\n",
      "Step 4280/10000- lr: [5.775774472727273e-06] - Loss total: 2.739166021347046, Last rpr Loss: 0.9999921917915344, Last lagvar Loss: 0.8594584465026855\n",
      "Step 4281/10000- lr: [5.774764375757576e-06] - Loss total: 2.7390544414520264, Last rpr Loss: 0.9999897480010986, Last lagvar Loss: 0.859460175037384\n",
      "Step 4282/10000- lr: [5.773754278787879e-06] - Loss total: 2.738943099975586, Last rpr Loss: 0.9999879598617554, Last lagvar Loss: 0.8594610691070557\n",
      "Step 4283/10000- lr: [5.772744181818182e-06] - Loss total: 2.7388317584991455, Last rpr Loss: 0.9999923706054688, Last lagvar Loss: 0.8594558238983154\n",
      "Step 4284/10000- lr: [5.771734084848485e-06] - Loss total: 2.738720417022705, Last rpr Loss: 0.9999909996986389, Last lagvar Loss: 0.8594564199447632\n",
      "Step 4285/10000- lr: [5.770723987878788e-06] - Loss total: 2.7386093139648438, Last rpr Loss: 0.9999880790710449, Last lagvar Loss: 0.8594585061073303\n",
      "Step 4286/10000- lr: [5.769713890909091e-06] - Loss total: 2.7384979724884033, Last rpr Loss: 0.9999891519546509, Last lagvar Loss: 0.8594565987586975\n",
      "Step 4287/10000- lr: [5.768703793939394e-06] - Loss total: 2.738386631011963, Last rpr Loss: 0.9999918937683105, Last lagvar Loss: 0.8594531416893005\n",
      "Step 4288/10000- lr: [5.767693696969697e-06] - Loss total: 2.738276243209839, Last rpr Loss: 0.9999892115592957, Last lagvar Loss: 0.8594549894332886\n",
      "Step 4289/10000- lr: [5.7666836e-06] - Loss total: 2.7381653785705566, Last rpr Loss: 0.9999887943267822, Last lagvar Loss: 0.8594545125961304\n",
      "Step 4290/10000- lr: [5.765673503030303e-06] - Loss total: 2.7380545139312744, Last rpr Loss: 0.9999932050704956, Last lagvar Loss: 0.8594493865966797\n",
      "Step 4291/10000- lr: [5.7646634060606066e-06] - Loss total: 2.7379438877105713, Last rpr Loss: 0.9999929666519165, Last lagvar Loss: 0.8594487905502319\n",
      "Step 4292/10000- lr: [5.763653309090909e-06] - Loss total: 2.7378334999084473, Last rpr Loss: 0.9999884366989136, Last lagvar Loss: 0.859452486038208\n",
      "Step 4293/10000- lr: [5.762643212121212e-06] - Loss total: 2.737722873687744, Last rpr Loss: 0.9999880790710449, Last lagvar Loss: 0.8594520092010498\n",
      "Step 4294/10000- lr: [5.7616331151515155e-06] - Loss total: 2.737612724304199, Last rpr Loss: 0.9999920725822449, Last lagvar Loss: 0.8594472408294678\n",
      "Step 4295/10000- lr: [5.760623018181818e-06] - Loss total: 2.7375025749206543, Last rpr Loss: 0.9999942779541016, Last lagvar Loss: 0.859444260597229\n",
      "Step 4296/10000- lr: [5.759612921212121e-06] - Loss total: 2.737391948699951, Last rpr Loss: 0.9999877214431763, Last lagvar Loss: 0.8594500422477722\n",
      "Step 4297/10000- lr: [5.7586028242424245e-06] - Loss total: 2.7372817993164062, Last rpr Loss: 0.9999899864196777, Last lagvar Loss: 0.8594469428062439\n",
      "Step 4298/10000- lr: [5.757592727272727e-06] - Loss total: 2.7371723651885986, Last rpr Loss: 0.9999929666519165, Last lagvar Loss: 0.859443187713623\n",
      "Step 4299/10000- lr: [5.75658263030303e-06] - Loss total: 2.7370622158050537, Last rpr Loss: 0.999990701675415, Last lagvar Loss: 0.8594445586204529\n",
      "Step 4300/10000- lr: [5.7555725333333335e-06] - Loss total: 2.736952304840088, Last rpr Loss: 0.9999915957450867, Last lagvar Loss: 0.859442949295044\n",
      "Step 4301/10000- lr: [5.754562436363637e-06] - Loss total: 2.736842632293701, Last rpr Loss: 0.9999933838844299, Last lagvar Loss: 0.8594403862953186\n",
      "Step 4302/10000- lr: [5.753552339393939e-06] - Loss total: 2.7367329597473145, Last rpr Loss: 0.9999891519546509, Last lagvar Loss: 0.8594437837600708\n",
      "Step 4303/10000- lr: [5.7525422424242425e-06] - Loss total: 2.7366232872009277, Last rpr Loss: 0.9999911189079285, Last lagvar Loss: 0.8594410419464111\n",
      "Step 4304/10000- lr: [5.751532145454546e-06] - Loss total: 2.7365143299102783, Last rpr Loss: 0.9999942779541016, Last lagvar Loss: 0.8594370484352112\n",
      "Step 4305/10000- lr: [5.750522048484848e-06] - Loss total: 2.7364046573638916, Last rpr Loss: 0.9999904632568359, Last lagvar Loss: 0.8594402074813843\n",
      "Step 4306/10000- lr: [5.7495119515151515e-06] - Loss total: 2.736295223236084, Last rpr Loss: 0.9999919533729553, Last lagvar Loss: 0.8594379425048828\n",
      "Step 4307/10000- lr: [5.748501854545455e-06] - Loss total: 2.7361862659454346, Last rpr Loss: 0.999994695186615, Last lagvar Loss: 0.8594343662261963\n",
      "Step 4308/10000- lr: [5.747491757575758e-06] - Loss total: 2.736077308654785, Last rpr Loss: 0.999990701675415, Last lagvar Loss: 0.8594374656677246\n",
      "Step 4309/10000- lr: [5.7464816606060605e-06] - Loss total: 2.7359681129455566, Last rpr Loss: 0.999990701675415, Last lagvar Loss: 0.8594366908073425\n",
      "Step 4310/10000- lr: [5.745471563636364e-06] - Loss total: 2.7358591556549072, Last rpr Loss: 0.9999914169311523, Last lagvar Loss: 0.8594352006912231\n",
      "Step 4311/10000- lr: [5.744461466666667e-06] - Loss total: 2.735750198364258, Last rpr Loss: 0.9999921321868896, Last lagvar Loss: 0.8594337701797485\n",
      "Step 4312/10000- lr: [5.7434513696969694e-06] - Loss total: 2.7356414794921875, Last rpr Loss: 0.9999939203262329, Last lagvar Loss: 0.859431266784668\n",
      "Step 4313/10000- lr: [5.742441272727273e-06] - Loss total: 2.7355329990386963, Last rpr Loss: 0.9999939203262329, Last lagvar Loss: 0.8594304919242859\n",
      "Step 4314/10000- lr: [5.741431175757576e-06] - Loss total: 2.735424280166626, Last rpr Loss: 0.9999911785125732, Last lagvar Loss: 0.8594324588775635\n",
      "Step 4315/10000- lr: [5.7404210787878784e-06] - Loss total: 2.7353155612945557, Last rpr Loss: 0.9999940395355225, Last lagvar Loss: 0.8594288229942322\n",
      "Step 4316/10000- lr: [5.739410981818182e-06] - Loss total: 2.7352075576782227, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8594271540641785\n",
      "Step 4317/10000- lr: [5.738400884848485e-06] - Loss total: 2.7350990772247314, Last rpr Loss: 0.9999913573265076, Last lagvar Loss: 0.8594299554824829\n",
      "Step 4318/10000- lr: [5.737390787878788e-06] - Loss total: 2.7349905967712402, Last rpr Loss: 0.999993085861206, Last lagvar Loss: 0.8594273924827576\n",
      "Step 4319/10000- lr: [5.736380690909091e-06] - Loss total: 2.7348828315734863, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.8594232797622681\n",
      "Step 4320/10000- lr: [5.735370593939394e-06] - Loss total: 2.734774589538574, Last rpr Loss: 0.9999910593032837, Last lagvar Loss: 0.859427809715271\n",
      "Step 4321/10000- lr: [5.734360496969697e-06] - Loss total: 2.734666585922241, Last rpr Loss: 0.9999906420707703, Last lagvar Loss: 0.8594274520874023\n",
      "Step 4322/10000- lr: [5.7333504e-06] - Loss total: 2.7345588207244873, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.859422504901886\n",
      "Step 4323/10000- lr: [5.732340303030304e-06] - Loss total: 2.7344508171081543, Last rpr Loss: 0.9999943375587463, Last lagvar Loss: 0.8594222068786621\n",
      "Step 4324/10000- lr: [5.731330206060606e-06] - Loss total: 2.7343432903289795, Last rpr Loss: 0.9999942779541016, Last lagvar Loss: 0.8594215512275696\n",
      "Step 4325/10000- lr: [5.7303201090909095e-06] - Loss total: 2.7342355251312256, Last rpr Loss: 0.9999953508377075, Last lagvar Loss: 0.8594197034835815\n",
      "Step 4326/10000- lr: [5.729310012121213e-06] - Loss total: 2.73412823677063, Last rpr Loss: 0.9999943971633911, Last lagvar Loss: 0.8594199419021606\n",
      "Step 4327/10000- lr: [5.728299915151515e-06] - Loss total: 2.734020471572876, Last rpr Loss: 0.9999926090240479, Last lagvar Loss: 0.8594209551811218\n",
      "Step 4328/10000- lr: [5.7272898181818185e-06] - Loss total: 2.733912944793701, Last rpr Loss: 0.9999950528144836, Last lagvar Loss: 0.8594177961349487\n",
      "Step 4329/10000- lr: [5.726279721212122e-06] - Loss total: 2.7338058948516846, Last rpr Loss: 0.9999949336051941, Last lagvar Loss: 0.859417200088501\n",
      "Step 4330/10000- lr: [5.725269624242425e-06] - Loss total: 2.7336983680725098, Last rpr Loss: 0.9999951124191284, Last lagvar Loss: 0.859416127204895\n",
      "Step 4331/10000- lr: [5.7242595272727275e-06] - Loss total: 2.7335915565490723, Last rpr Loss: 0.9999961256980896, Last lagvar Loss: 0.8594143390655518\n",
      "Step 4332/10000- lr: [5.723249430303031e-06] - Loss total: 2.7334842681884766, Last rpr Loss: 0.9999922513961792, Last lagvar Loss: 0.8594174981117249\n",
      "Step 4333/10000- lr: [5.722239333333334e-06] - Loss total: 2.733377456665039, Last rpr Loss: 0.999992311000824, Last lagvar Loss: 0.859416663646698\n",
      "Step 4334/10000- lr: [5.7212292363636365e-06] - Loss total: 2.7332706451416016, Last rpr Loss: 0.9999968409538269, Last lagvar Loss: 0.8594114184379578\n",
      "Step 4335/10000- lr: [5.72021913939394e-06] - Loss total: 2.733163356781006, Last rpr Loss: 0.9999955892562866, Last lagvar Loss: 0.8594119548797607\n",
      "Step 4336/10000- lr: [5.719209042424243e-06] - Loss total: 2.7330567836761475, Last rpr Loss: 0.9999933838844299, Last lagvar Loss: 0.8594133853912354\n",
      "Step 4337/10000- lr: [5.7181989454545454e-06] - Loss total: 2.732950210571289, Last rpr Loss: 0.9999978542327881, Last lagvar Loss: 0.8594081401824951\n",
      "Step 4338/10000- lr: [5.717188848484849e-06] - Loss total: 2.7328436374664307, Last rpr Loss: 0.9999961853027344, Last lagvar Loss: 0.8594091534614563\n",
      "Step 4339/10000- lr: [5.716178751515152e-06] - Loss total: 2.7327373027801514, Last rpr Loss: 0.9999936819076538, Last lagvar Loss: 0.85941082239151\n",
      "Step 4340/10000- lr: [5.715168654545455e-06] - Loss total: 2.732630968093872, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.8594073057174683\n",
      "Step 4341/10000- lr: [5.714158557575758e-06] - Loss total: 2.7325243949890137, Last rpr Loss: 0.9999967813491821, Last lagvar Loss: 0.8594062328338623\n",
      "Step 4342/10000- lr: [5.713148460606061e-06] - Loss total: 2.7324185371398926, Last rpr Loss: 0.9999955892562866, Last lagvar Loss: 0.8594067692756653\n",
      "Step 4343/10000- lr: [5.712138363636364e-06] - Loss total: 2.7323124408721924, Last rpr Loss: 0.9999939203262329, Last lagvar Loss: 0.8594076633453369\n",
      "Step 4344/10000- lr: [5.711128266666667e-06] - Loss total: 2.732206106185913, Last rpr Loss: 0.9999973773956299, Last lagvar Loss: 0.8594034910202026\n",
      "Step 4345/10000- lr: [5.71011816969697e-06] - Loss total: 2.732100248336792, Last rpr Loss: 0.9999951124191284, Last lagvar Loss: 0.8594049215316772\n",
      "Step 4346/10000- lr: [5.709108072727273e-06] - Loss total: 2.731994152069092, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.8594030141830444\n",
      "Step 4347/10000- lr: [5.708097975757576e-06] - Loss total: 2.7318882942199707, Last rpr Loss: 0.999996542930603, Last lagvar Loss: 0.8594020009040833\n",
      "Step 4348/10000- lr: [5.707087878787879e-06] - Loss total: 2.7317826747894287, Last rpr Loss: 0.9999954700469971, Last lagvar Loss: 0.8594022989273071\n",
      "Step 4349/10000- lr: [5.706077781818182e-06] - Loss total: 2.7316768169403076, Last rpr Loss: 0.9999953508377075, Last lagvar Loss: 0.8594017028808594\n",
      "Step 4350/10000- lr: [5.7050676848484855e-06] - Loss total: 2.7315714359283447, Last rpr Loss: 0.9999970197677612, Last lagvar Loss: 0.8593993186950684\n",
      "Step 4351/10000- lr: [5.704057587878788e-06] - Loss total: 2.7314655780792236, Last rpr Loss: 0.9999979734420776, Last lagvar Loss: 0.8593976497650146\n",
      "Step 4352/10000- lr: [5.703047490909091e-06] - Loss total: 2.7313601970672607, Last rpr Loss: 0.9999973773956299, Last lagvar Loss: 0.8593975901603699\n",
      "Step 4353/10000- lr: [5.7020373939393945e-06] - Loss total: 2.731254816055298, Last rpr Loss: 0.9999954700469971, Last lagvar Loss: 0.8593987226486206\n",
      "Step 4354/10000- lr: [5.701027296969697e-06] - Loss total: 2.731149435043335, Last rpr Loss: 0.9999969005584717, Last lagvar Loss: 0.8593966364860535\n",
      "Step 4355/10000- lr: [5.7000172e-06] - Loss total: 2.731044292449951, Last rpr Loss: 0.9999967813491821, Last lagvar Loss: 0.8593960404396057\n",
      "Step 4356/10000- lr: [5.6990071030303035e-06] - Loss total: 2.7309391498565674, Last rpr Loss: 0.999995231628418, Last lagvar Loss: 0.8593966960906982\n",
      "Step 4357/10000- lr: [5.697997006060607e-06] - Loss total: 2.7308342456817627, Last rpr Loss: 0.9999970197677612, Last lagvar Loss: 0.8593941926956177\n",
      "Step 4358/10000- lr: [5.696986909090909e-06] - Loss total: 2.730729341506958, Last rpr Loss: 0.9999968409538269, Last lagvar Loss: 0.8593937158584595\n",
      "Step 4359/10000- lr: [5.6959768121212125e-06] - Loss total: 2.7306244373321533, Last rpr Loss: 0.9999973773956299, Last lagvar Loss: 0.8593924045562744\n",
      "Step 4360/10000- lr: [5.694966715151516e-06] - Loss total: 2.7305195331573486, Last rpr Loss: 0.9999990463256836, Last lagvar Loss: 0.8593900203704834\n",
      "Step 4361/10000- lr: [5.693956618181818e-06] - Loss total: 2.730414867401123, Last rpr Loss: 0.9999957084655762, Last lagvar Loss: 0.859392523765564\n",
      "Step 4362/10000- lr: [5.6929465212121214e-06] - Loss total: 2.7303099632263184, Last rpr Loss: 0.9999996423721313, Last lagvar Loss: 0.859387993812561\n",
      "Step 4363/10000- lr: [5.691936424242425e-06] - Loss total: 2.730205535888672, Last rpr Loss: 0.9999963641166687, Last lagvar Loss: 0.8593904972076416\n",
      "Step 4364/10000- lr: [5.690926327272727e-06] - Loss total: 2.7301011085510254, Last rpr Loss: 0.999995231628418, Last lagvar Loss: 0.8593908548355103\n",
      "Step 4365/10000- lr: [5.6899162303030304e-06] - Loss total: 2.729996681213379, Last rpr Loss: 0.9999982714653015, Last lagvar Loss: 0.8593871593475342\n",
      "Step 4366/10000- lr: [5.688906133333334e-06] - Loss total: 2.7298922538757324, Last rpr Loss: 0.9999978542327881, Last lagvar Loss: 0.8593869209289551\n",
      "Step 4367/10000- lr: [5.687896036363637e-06] - Loss total: 2.729787826538086, Last rpr Loss: 0.9999966621398926, Last lagvar Loss: 0.8593872785568237\n",
      "Step 4368/10000- lr: [5.686885939393939e-06] - Loss total: 2.7296838760375977, Last rpr Loss: 0.9999984502792358, Last lagvar Loss: 0.8593848347663879\n",
      "Step 4369/10000- lr: [5.685875842424243e-06] - Loss total: 2.7295799255371094, Last rpr Loss: 0.9999974966049194, Last lagvar Loss: 0.8593850135803223\n",
      "Step 4370/10000- lr: [5.684865745454546e-06] - Loss total: 2.729475736618042, Last rpr Loss: 0.9999987483024597, Last lagvar Loss: 0.8593830466270447\n",
      "Step 4371/10000- lr: [5.683855648484848e-06] - Loss total: 2.7293717861175537, Last rpr Loss: 0.999995231628418, Last lagvar Loss: 0.8593857884407043\n",
      "Step 4372/10000- lr: [5.682845551515152e-06] - Loss total: 2.7292678356170654, Last rpr Loss: 0.9999969005584717, Last lagvar Loss: 0.8593834638595581\n",
      "Step 4373/10000- lr: [5.681835454545455e-06] - Loss total: 2.7291641235351562, Last rpr Loss: 1.0000014305114746, Last lagvar Loss: 0.8593782186508179\n",
      "Step 4374/10000- lr: [5.680825357575757e-06] - Loss total: 2.729060411453247, Last rpr Loss: 0.9999977350234985, Last lagvar Loss: 0.8593811988830566\n",
      "Step 4375/10000- lr: [5.679815260606061e-06] - Loss total: 2.728956937789917, Last rpr Loss: 0.9999955892562866, Last lagvar Loss: 0.8593826293945312\n",
      "Step 4376/10000- lr: [5.678805163636364e-06] - Loss total: 2.728853464126587, Last rpr Loss: 1.000001072883606, Last lagvar Loss: 0.8593764305114746\n",
      "Step 4377/10000- lr: [5.677795066666667e-06] - Loss total: 2.728749990463257, Last rpr Loss: 0.9999993443489075, Last lagvar Loss: 0.859377384185791\n",
      "Step 4378/10000- lr: [5.67678496969697e-06] - Loss total: 2.7286465167999268, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.8593796491622925\n",
      "Step 4379/10000- lr: [5.675774872727273e-06] - Loss total: 2.728543519973755, Last rpr Loss: 0.9999967217445374, Last lagvar Loss: 0.8593786954879761\n",
      "Step 4380/10000- lr: [5.674764775757576e-06] - Loss total: 2.728440523147583, Last rpr Loss: 0.9999977350234985, Last lagvar Loss: 0.859376847743988\n",
      "Step 4381/10000- lr: [5.673754678787879e-06] - Loss total: 2.728337049484253, Last rpr Loss: 0.9999994039535522, Last lagvar Loss: 0.8593745231628418\n",
      "Step 4382/10000- lr: [5.672744581818182e-06] - Loss total: 2.728233575820923, Last rpr Loss: 0.9999977350234985, Last lagvar Loss: 0.8593754768371582\n",
      "Step 4383/10000- lr: [5.671734484848485e-06] - Loss total: 2.728131055831909, Last rpr Loss: 0.999998152256012, Last lagvar Loss: 0.8593744039535522\n",
      "Step 4384/10000- lr: [5.670724387878788e-06] - Loss total: 2.7280282974243164, Last rpr Loss: 1.0000028610229492, Last lagvar Loss: 0.8593689203262329\n",
      "Step 4385/10000- lr: [5.669714290909091e-06] - Loss total: 2.7279255390167236, Last rpr Loss: 1.000000238418579, Last lagvar Loss: 0.859370768070221\n",
      "Step 4386/10000- lr: [5.668704193939394e-06] - Loss total: 2.72782301902771, Last rpr Loss: 0.9999951124191284, Last lagvar Loss: 0.8593752980232239\n",
      "Step 4387/10000- lr: [5.6676940969696974e-06] - Loss total: 2.727720022201538, Last rpr Loss: 0.9999971389770508, Last lagvar Loss: 0.8593724370002747\n",
      "Step 4388/10000- lr: [5.666684e-06] - Loss total: 2.7276179790496826, Last rpr Loss: 1.0000009536743164, Last lagvar Loss: 0.8593679070472717\n",
      "Step 4389/10000- lr: [5.665673903030303e-06] - Loss total: 2.7275149822235107, Last rpr Loss: 0.9999989867210388, Last lagvar Loss: 0.859369158744812\n",
      "Step 4390/10000- lr: [5.664663806060606e-06] - Loss total: 2.727412700653076, Last rpr Loss: 0.9999974370002747, Last lagvar Loss: 0.8593700528144836\n",
      "Step 4391/10000- lr: [5.663653709090909e-06] - Loss total: 2.7273106575012207, Last rpr Loss: 1.0000020265579224, Last lagvar Loss: 0.8593646883964539\n",
      "Step 4392/10000- lr: [5.662643612121212e-06] - Loss total: 2.727208375930786, Last rpr Loss: 0.9999969601631165, Last lagvar Loss: 0.859369158744812\n",
      "Step 4393/10000- lr: [5.661633515151515e-06] - Loss total: 2.7271063327789307, Last rpr Loss: 0.9999974966049194, Last lagvar Loss: 0.8593677878379822\n",
      "Step 4394/10000- lr: [5.660623418181818e-06] - Loss total: 2.727004289627075, Last rpr Loss: 1.000001072883606, Last lagvar Loss: 0.8593636155128479\n",
      "Step 4395/10000- lr: [5.659613321212121e-06] - Loss total: 2.726902484893799, Last rpr Loss: 0.9999977350234985, Last lagvar Loss: 0.8593661785125732\n",
      "Step 4396/10000- lr: [5.658603224242424e-06] - Loss total: 2.7268006801605225, Last rpr Loss: 0.9999995231628418, Last lagvar Loss: 0.8593636751174927\n",
      "Step 4397/10000- lr: [5.657593127272728e-06] - Loss total: 2.726699113845825, Last rpr Loss: 1.0000016689300537, Last lagvar Loss: 0.8593608140945435\n",
      "Step 4398/10000- lr: [5.65658303030303e-06] - Loss total: 2.726597547531128, Last rpr Loss: 1.0, Last lagvar Loss: 0.8593617677688599\n",
      "Step 4399/10000- lr: [5.655572933333333e-06] - Loss total: 2.7264957427978516, Last rpr Loss: 0.999998927116394, Last lagvar Loss: 0.8593621253967285\n",
      "Step 4400/10000- lr: [5.654562836363637e-06] - Loss total: 2.7263946533203125, Last rpr Loss: 1.0000009536743164, Last lagvar Loss: 0.8593593835830688\n",
      "Step 4401/10000- lr: [5.653552739393939e-06] - Loss total: 2.726292848587036, Last rpr Loss: 0.9999977350234985, Last lagvar Loss: 0.8593618869781494\n",
      "Step 4402/10000- lr: [5.652542642424242e-06] - Loss total: 2.726191759109497, Last rpr Loss: 0.9999961853027344, Last lagvar Loss: 0.8593628406524658\n",
      "Step 4403/10000- lr: [5.651532545454546e-06] - Loss total: 2.726090669631958, Last rpr Loss: 1.000001072883606, Last lagvar Loss: 0.8593572378158569\n",
      "Step 4404/10000- lr: [5.650522448484848e-06] - Loss total: 2.725989580154419, Last rpr Loss: 1.000002145767212, Last lagvar Loss: 0.8593552112579346\n",
      "Step 4405/10000- lr: [5.649512351515151e-06] - Loss total: 2.725888252258301, Last rpr Loss: 0.9999993443489075, Last lagvar Loss: 0.8593575358390808\n",
      "Step 4406/10000- lr: [5.648502254545455e-06] - Loss total: 2.725787401199341, Last rpr Loss: 0.9999997615814209, Last lagvar Loss: 0.8593562841415405\n",
      "Step 4407/10000- lr: [5.647492157575758e-06] - Loss total: 2.725686550140381, Last rpr Loss: 0.9999992847442627, Last lagvar Loss: 0.8593562245368958\n",
      "Step 4408/10000- lr: [5.646482060606061e-06] - Loss total: 2.725585460662842, Last rpr Loss: 0.9999997615814209, Last lagvar Loss: 0.8593548536300659\n",
      "Step 4409/10000- lr: [5.6454719636363645e-06] - Loss total: 2.72548508644104, Last rpr Loss: 0.9999999403953552, Last lagvar Loss: 0.8593540191650391\n",
      "Step 4410/10000- lr: [5.644461866666667e-06] - Loss total: 2.725384473800659, Last rpr Loss: 0.9999982118606567, Last lagvar Loss: 0.859355092048645\n",
      "Step 4411/10000- lr: [5.64345176969697e-06] - Loss total: 2.7252840995788574, Last rpr Loss: 1.0000007152557373, Last lagvar Loss: 0.8593518733978271\n",
      "Step 4412/10000- lr: [5.6424416727272734e-06] - Loss total: 2.7251837253570557, Last rpr Loss: 1.0000038146972656, Last lagvar Loss: 0.8593480587005615\n",
      "Step 4413/10000- lr: [5.641431575757576e-06] - Loss total: 2.725083351135254, Last rpr Loss: 0.9999982118606567, Last lagvar Loss: 0.8593529462814331\n",
      "Step 4414/10000- lr: [5.640421478787879e-06] - Loss total: 2.7249832153320312, Last rpr Loss: 0.9999995827674866, Last lagvar Loss: 0.8593508005142212\n",
      "Step 4415/10000- lr: [5.639411381818182e-06] - Loss total: 2.7248833179473877, Last rpr Loss: 1.0000028610229492, Last lagvar Loss: 0.859346866607666\n",
      "Step 4416/10000- lr: [5.638401284848486e-06] - Loss total: 2.724782943725586, Last rpr Loss: 0.9999995231628418, Last lagvar Loss: 0.8593494296073914\n",
      "Step 4417/10000- lr: [5.637391187878788e-06] - Loss total: 2.7246830463409424, Last rpr Loss: 0.9999966621398926, Last lagvar Loss: 0.859351634979248\n",
      "Step 4418/10000- lr: [5.636381090909091e-06] - Loss total: 2.7245826721191406, Last rpr Loss: 1.0000007152557373, Last lagvar Loss: 0.8593469262123108\n",
      "Step 4419/10000- lr: [5.635370993939395e-06] - Loss total: 2.7244834899902344, Last rpr Loss: 1.0000004768371582, Last lagvar Loss: 0.8593465089797974\n",
      "Step 4420/10000- lr: [5.634360896969697e-06] - Loss total: 2.724383592605591, Last rpr Loss: 0.9999998807907104, Last lagvar Loss: 0.859346330165863\n",
      "Step 4421/10000- lr: [5.6333508e-06] - Loss total: 2.7242839336395264, Last rpr Loss: 1.0000028610229492, Last lagvar Loss: 0.859342634677887\n",
      "Step 4422/10000- lr: [5.632340703030304e-06] - Loss total: 2.724184274673462, Last rpr Loss: 1.0000004768371582, Last lagvar Loss: 0.8593443036079407\n",
      "Step 4423/10000- lr: [5.631330606060606e-06] - Loss total: 2.7240850925445557, Last rpr Loss: 1.0000014305114746, Last lagvar Loss: 0.8593426942825317\n",
      "Step 4424/10000- lr: [5.630320509090909e-06] - Loss total: 2.7239856719970703, Last rpr Loss: 0.9999994039535522, Last lagvar Loss: 0.8593440055847168\n",
      "Step 4425/10000- lr: [5.629310412121213e-06] - Loss total: 2.723886489868164, Last rpr Loss: 0.9999998807907104, Last lagvar Loss: 0.8593428134918213\n",
      "Step 4426/10000- lr: [5.628300315151516e-06] - Loss total: 2.7237870693206787, Last rpr Loss: 1.0000004768371582, Last lagvar Loss: 0.859341561794281\n",
      "Step 4427/10000- lr: [5.627290218181818e-06] - Loss total: 2.7236878871917725, Last rpr Loss: 0.9999986886978149, Last lagvar Loss: 0.8593426942825317\n",
      "Step 4428/10000- lr: [5.626280121212122e-06] - Loss total: 2.7235889434814453, Last rpr Loss: 0.9999997615814209, Last lagvar Loss: 0.8593407869338989\n",
      "Step 4429/10000- lr: [5.625270024242425e-06] - Loss total: 2.723489999771118, Last rpr Loss: 1.0000017881393433, Last lagvar Loss: 0.8593380451202393\n",
      "Step 4430/10000- lr: [5.624259927272727e-06] - Loss total: 2.723391056060791, Last rpr Loss: 1.0000019073486328, Last lagvar Loss: 0.8593372106552124\n",
      "Step 4431/10000- lr: [5.623249830303031e-06] - Loss total: 2.723292350769043, Last rpr Loss: 1.0000008344650269, Last lagvar Loss: 0.859337568283081\n",
      "Step 4432/10000- lr: [5.622239733333334e-06] - Loss total: 2.723193883895874, Last rpr Loss: 1.0000033378601074, Last lagvar Loss: 0.8593345284461975\n",
      "Step 4433/10000- lr: [5.621229636363636e-06] - Loss total: 2.723095178604126, Last rpr Loss: 1.0000007152557373, Last lagvar Loss: 0.8593363165855408\n",
      "Step 4434/10000- lr: [5.62021953939394e-06] - Loss total: 2.722996473312378, Last rpr Loss: 0.9999985694885254, Last lagvar Loss: 0.8593379259109497\n",
      "Step 4435/10000- lr: [5.619209442424243e-06] - Loss total: 2.722898006439209, Last rpr Loss: 0.9999994039535522, Last lagvar Loss: 0.859336256980896\n",
      "Step 4436/10000- lr: [5.618199345454546e-06] - Loss total: 2.722799777984619, Last rpr Loss: 0.9999992847442627, Last lagvar Loss: 0.8593356609344482\n",
      "Step 4437/10000- lr: [5.617189248484849e-06] - Loss total: 2.72270131111145, Last rpr Loss: 1.0000032186508179, Last lagvar Loss: 0.8593310713768005\n",
      "Step 4438/10000- lr: [5.616179151515152e-06] - Loss total: 2.7226030826568604, Last rpr Loss: 1.0000007152557373, Last lagvar Loss: 0.8593330383300781\n",
      "Step 4439/10000- lr: [5.615169054545455e-06] - Loss total: 2.7225050926208496, Last rpr Loss: 0.9999995827674866, Last lagvar Loss: 0.859333336353302\n",
      "Step 4440/10000- lr: [5.6141589575757576e-06] - Loss total: 2.722407341003418, Last rpr Loss: 1.0000064373016357, Last lagvar Loss: 0.8593258857727051\n",
      "Step 4441/10000- lr: [5.613148860606061e-06] - Loss total: 2.7223095893859863, Last rpr Loss: 0.9999978542327881, Last lagvar Loss: 0.8593336939811707\n",
      "Step 4442/10000- lr: [5.612138763636364e-06] - Loss total: 2.7222111225128174, Last rpr Loss: 0.9999967813491821, Last lagvar Loss: 0.8593341112136841\n",
      "Step 4443/10000- lr: [5.6111286666666666e-06] - Loss total: 2.722113609313965, Last rpr Loss: 1.0000030994415283, Last lagvar Loss: 0.8593271374702454\n",
      "Step 4444/10000- lr: [5.61011856969697e-06] - Loss total: 2.722015857696533, Last rpr Loss: 1.000002145767212, Last lagvar Loss: 0.8593273162841797\n",
      "Step 4445/10000- lr: [5.609108472727273e-06] - Loss total: 2.7219181060791016, Last rpr Loss: 0.9999980330467224, Last lagvar Loss: 0.8593307733535767\n",
      "Step 4446/10000- lr: [5.608098375757576e-06] - Loss total: 2.721820831298828, Last rpr Loss: 1.0000028610229492, Last lagvar Loss: 0.8593252301216125\n",
      "Step 4447/10000- lr: [5.607088278787879e-06] - Loss total: 2.7217230796813965, Last rpr Loss: 1.0000019073486328, Last lagvar Loss: 0.8593254685401917\n",
      "Step 4448/10000- lr: [5.606078181818182e-06] - Loss total: 2.721625804901123, Last rpr Loss: 0.9999999403953552, Last lagvar Loss: 0.8593268394470215\n",
      "Step 4449/10000- lr: [5.605068084848485e-06] - Loss total: 2.7215282917022705, Last rpr Loss: 1.0000020265579224, Last lagvar Loss: 0.8593239188194275\n",
      "Step 4450/10000- lr: [5.604057987878788e-06] - Loss total: 2.721431016921997, Last rpr Loss: 1.000001072883606, Last lagvar Loss: 0.8593242168426514\n",
      "Step 4451/10000- lr: [5.603047890909091e-06] - Loss total: 2.7213337421417236, Last rpr Loss: 0.9999991655349731, Last lagvar Loss: 0.8593255281448364\n",
      "Step 4452/10000- lr: [5.602037793939394e-06] - Loss total: 2.7212371826171875, Last rpr Loss: 1.000001072883606, Last lagvar Loss: 0.8593229055404663\n",
      "Step 4453/10000- lr: [5.601027696969697e-06] - Loss total: 2.721140146255493, Last rpr Loss: 0.9999996423721313, Last lagvar Loss: 0.8593236207962036\n",
      "Step 4454/10000- lr: [5.6000176e-06] - Loss total: 2.721043348312378, Last rpr Loss: 1.0000026226043701, Last lagvar Loss: 0.8593199253082275\n",
      "Step 4455/10000- lr: [5.599007503030303e-06] - Loss total: 2.7209465503692627, Last rpr Loss: 1.0000026226043701, Last lagvar Loss: 0.8593192100524902\n",
      "Step 4456/10000- lr: [5.597997406060607e-06] - Loss total: 2.7208495140075684, Last rpr Loss: 0.9999985694885254, Last lagvar Loss: 0.8593226671218872\n",
      "Step 4457/10000- lr: [5.596987309090909e-06] - Loss total: 2.720752716064453, Last rpr Loss: 1.0000026226043701, Last lagvar Loss: 0.8593178987503052\n",
      "Step 4458/10000- lr: [5.595977212121212e-06] - Loss total: 2.720656394958496, Last rpr Loss: 1.000000238418579, Last lagvar Loss: 0.8593195676803589\n",
      "Step 4459/10000- lr: [5.594967115151516e-06] - Loss total: 2.72055983543396, Last rpr Loss: 0.9999985694885254, Last lagvar Loss: 0.8593205213546753\n",
      "Step 4460/10000- lr: [5.593957018181818e-06] - Loss total: 2.7204630374908447, Last rpr Loss: 1.0000028610229492, Last lagvar Loss: 0.8593155741691589\n",
      "Step 4461/10000- lr: [5.592946921212121e-06] - Loss total: 2.7203667163848877, Last rpr Loss: 1.0000016689300537, Last lagvar Loss: 0.8593161702156067\n",
      "Step 4462/10000- lr: [5.591936824242425e-06] - Loss total: 2.7202706336975098, Last rpr Loss: 1.0000001192092896, Last lagvar Loss: 0.8593170642852783\n",
      "Step 4463/10000- lr: [5.590926727272727e-06] - Loss total: 2.720174551010132, Last rpr Loss: 1.0000017881393433, Last lagvar Loss: 0.8593146800994873\n",
      "Step 4464/10000- lr: [5.58991663030303e-06] - Loss total: 2.720078229904175, Last rpr Loss: 0.9999984502792358, Last lagvar Loss: 0.8593173027038574\n",
      "Step 4465/10000- lr: [5.5889065333333336e-06] - Loss total: 2.7199819087982178, Last rpr Loss: 1.0000003576278687, Last lagvar Loss: 0.8593147993087769\n",
      "Step 4466/10000- lr: [5.587896436363637e-06] - Loss total: 2.719886064529419, Last rpr Loss: 1.0000035762786865, Last lagvar Loss: 0.8593108654022217\n",
      "Step 4467/10000- lr: [5.586886339393939e-06] - Loss total: 2.719790458679199, Last rpr Loss: 1.0000004768371582, Last lagvar Loss: 0.8593133687973022\n",
      "Step 4468/10000- lr: [5.5858762424242426e-06] - Loss total: 2.7196946144104004, Last rpr Loss: 1.000000238418579, Last lagvar Loss: 0.8593130111694336\n",
      "Step 4469/10000- lr: [5.584866145454546e-06] - Loss total: 2.7195985317230225, Last rpr Loss: 1.0000033378601074, Last lagvar Loss: 0.8593090176582336\n",
      "Step 4470/10000- lr: [5.583856048484848e-06] - Loss total: 2.719503164291382, Last rpr Loss: 1.0000011920928955, Last lagvar Loss: 0.8593106865882874\n",
      "Step 4471/10000- lr: [5.5828459515151515e-06] - Loss total: 2.719407320022583, Last rpr Loss: 1.0000007152557373, Last lagvar Loss: 0.8593104481697083\n",
      "Step 4472/10000- lr: [5.581835854545455e-06] - Loss total: 2.7193119525909424, Last rpr Loss: 1.0000001192092896, Last lagvar Loss: 0.8593102693557739\n",
      "Step 4473/10000- lr: [5.580825757575757e-06] - Loss total: 2.7192165851593018, Last rpr Loss: 1.0, Last lagvar Loss: 0.8593097925186157\n",
      "Step 4474/10000- lr: [5.5798156606060605e-06] - Loss total: 2.719121217727661, Last rpr Loss: 1.000001311302185, Last lagvar Loss: 0.8593077659606934\n",
      "Step 4475/10000- lr: [5.578805563636364e-06] - Loss total: 2.7190256118774414, Last rpr Loss: 1.0000001192092896, Last lagvar Loss: 0.8593082427978516\n",
      "Step 4476/10000- lr: [5.577795466666667e-06] - Loss total: 2.718930244445801, Last rpr Loss: 1.0000020265579224, Last lagvar Loss: 0.859305739402771\n",
      "Step 4477/10000- lr: [5.5767853696969695e-06] - Loss total: 2.7188351154327393, Last rpr Loss: 1.0000007152557373, Last lagvar Loss: 0.8593064546585083\n",
      "Step 4478/10000- lr: [5.575775272727273e-06] - Loss total: 2.7187397480010986, Last rpr Loss: 1.000000238418579, Last lagvar Loss: 0.8593060970306396\n",
      "Step 4479/10000- lr: [5.574765175757576e-06] - Loss total: 2.718644857406616, Last rpr Loss: 1.0000007152557373, Last lagvar Loss: 0.8593050837516785\n",
      "Step 4480/10000- lr: [5.5737550787878785e-06] - Loss total: 2.718549966812134, Last rpr Loss: 1.0000015497207642, Last lagvar Loss: 0.8593034744262695\n",
      "Step 4481/10000- lr: [5.572744981818182e-06] - Loss total: 2.7184550762176514, Last rpr Loss: 1.0000019073486328, Last lagvar Loss: 0.8593025207519531\n",
      "Step 4482/10000- lr: [5.571734884848485e-06] - Loss total: 2.718360185623169, Last rpr Loss: 1.000001072883606, Last lagvar Loss: 0.8593026995658875\n",
      "Step 4483/10000- lr: [5.5707247878787875e-06] - Loss total: 2.7182652950286865, Last rpr Loss: 0.9999991655349731, Last lagvar Loss: 0.8593038320541382\n",
      "Step 4484/10000- lr: [5.569714690909091e-06] - Loss total: 2.7181708812713623, Last rpr Loss: 1.0000016689300537, Last lagvar Loss: 0.8593007326126099\n",
      "Step 4485/10000- lr: [5.568704593939394e-06] - Loss total: 2.718075752258301, Last rpr Loss: 1.000001072883606, Last lagvar Loss: 0.8593007326126099\n",
      "Step 4486/10000- lr: [5.567694496969697e-06] - Loss total: 2.7179815769195557, Last rpr Loss: 0.9999999403953552, Last lagvar Loss: 0.8593011498451233\n",
      "Step 4487/10000- lr: [5.5666844e-06] - Loss total: 2.7178871631622314, Last rpr Loss: 1.0000009536743164, Last lagvar Loss: 0.8592995405197144\n",
      "Step 4488/10000- lr: [5.565674303030303e-06] - Loss total: 2.7177927494049072, Last rpr Loss: 1.0000004768371582, Last lagvar Loss: 0.8592993021011353\n",
      "Step 4489/10000- lr: [5.564664206060606e-06] - Loss total: 2.717698335647583, Last rpr Loss: 1.0000028610229492, Last lagvar Loss: 0.8592963218688965\n",
      "Step 4490/10000- lr: [5.563654109090909e-06] - Loss total: 2.717604160308838, Last rpr Loss: 1.0000008344650269, Last lagvar Loss: 0.8592977523803711\n",
      "Step 4491/10000- lr: [5.562644012121212e-06] - Loss total: 2.7175097465515137, Last rpr Loss: 0.999998152256012, Last lagvar Loss: 0.8592997193336487\n",
      "Step 4492/10000- lr: [5.561633915151515e-06] - Loss total: 2.7174155712127686, Last rpr Loss: 1.000001072883606, Last lagvar Loss: 0.8592963218688965\n",
      "Step 4493/10000- lr: [5.560623818181818e-06] - Loss total: 2.7173218727111816, Last rpr Loss: 1.0000029802322388, Last lagvar Loss: 0.8592936992645264\n",
      "Step 4494/10000- lr: [5.559613721212122e-06] - Loss total: 2.7172276973724365, Last rpr Loss: 0.9999992847442627, Last lagvar Loss: 0.8592966198921204\n",
      "Step 4495/10000- lr: [5.558603624242425e-06] - Loss total: 2.7171337604522705, Last rpr Loss: 1.0000009536743164, Last lagvar Loss: 0.8592944145202637\n",
      "Step 4496/10000- lr: [5.5575935272727275e-06] - Loss total: 2.7170398235321045, Last rpr Loss: 1.0000014305114746, Last lagvar Loss: 0.8592931628227234\n",
      "Step 4497/10000- lr: [5.556583430303031e-06] - Loss total: 2.7169461250305176, Last rpr Loss: 1.0000020265579224, Last lagvar Loss: 0.8592919111251831\n",
      "Step 4498/10000- lr: [5.555573333333334e-06] - Loss total: 2.7168524265289307, Last rpr Loss: 0.9999985694885254, Last lagvar Loss: 0.8592948913574219\n",
      "Step 4499/10000- lr: [5.5545632363636365e-06] - Loss total: 2.716758966445923, Last rpr Loss: 1.000000238418579, Last lagvar Loss: 0.8592925071716309\n",
      "Step 4500/10000- lr: [5.55355313939394e-06] - Loss total: 2.716665267944336, Last rpr Loss: 1.0000005960464478, Last lagvar Loss: 0.8592914342880249\n",
      "Step 4501/10000- lr: [5.552543042424243e-06] - Loss total: 2.71657133102417, Last rpr Loss: 1.0000017881393433, Last lagvar Loss: 0.8592897057533264\n",
      "Step 4502/10000- lr: [5.5515329454545455e-06] - Loss total: 2.7164783477783203, Last rpr Loss: 1.0000007152557373, Last lagvar Loss: 0.8592901229858398\n",
      "Step 4503/10000- lr: [5.550522848484849e-06] - Loss total: 2.7163846492767334, Last rpr Loss: 1.000002145767212, Last lagvar Loss: 0.8592880368232727\n",
      "Step 4504/10000- lr: [5.549512751515152e-06] - Loss total: 2.7162914276123047, Last rpr Loss: 1.000001311302185, Last lagvar Loss: 0.859288215637207\n",
      "Step 4505/10000- lr: [5.548502654545455e-06] - Loss total: 2.716198682785034, Last rpr Loss: 0.9999985694885254, Last lagvar Loss: 0.859290361404419\n",
      "Step 4506/10000- lr: [5.547492557575758e-06] - Loss total: 2.7161052227020264, Last rpr Loss: 1.0000014305114746, Last lagvar Loss: 0.8592867851257324\n",
      "Step 4507/10000- lr: [5.546482460606061e-06] - Loss total: 2.7160120010375977, Last rpr Loss: 1.0, Last lagvar Loss: 0.8592875003814697\n",
      "Step 4508/10000- lr: [5.545472363636364e-06] - Loss total: 2.715918779373169, Last rpr Loss: 1.0, Last lagvar Loss: 0.8592870831489563\n",
      "Step 4509/10000- lr: [5.544462266666667e-06] - Loss total: 2.7158257961273193, Last rpr Loss: 1.0000017881393433, Last lagvar Loss: 0.8592846393585205\n",
      "Step 4510/10000- lr: [5.54345216969697e-06] - Loss total: 2.715733051300049, Last rpr Loss: 1.0000004768371582, Last lagvar Loss: 0.8592853546142578\n",
      "Step 4511/10000- lr: [5.542442072727273e-06] - Loss total: 2.7156405448913574, Last rpr Loss: 0.9999992251396179, Last lagvar Loss: 0.8592859506607056\n",
      "Step 4512/10000- lr: [5.541431975757576e-06] - Loss total: 2.715547561645508, Last rpr Loss: 1.0000048875808716, Last lagvar Loss: 0.8592796325683594\n",
      "Step 4513/10000- lr: [5.540421878787879e-06] - Loss total: 2.7154550552368164, Last rpr Loss: 0.9999998807907104, Last lagvar Loss: 0.8592840433120728\n",
      "Step 4514/10000- lr: [5.539411781818182e-06] - Loss total: 2.7153618335723877, Last rpr Loss: 0.9999997615814209, Last lagvar Loss: 0.8592835664749146\n",
      "Step 4515/10000- lr: [5.5384016848484856e-06] - Loss total: 2.7152695655822754, Last rpr Loss: 1.0000025033950806, Last lagvar Loss: 0.8592801690101624\n",
      "Step 4516/10000- lr: [5.537391587878788e-06] - Loss total: 2.715176820755005, Last rpr Loss: 0.9999945759773254, Last lagvar Loss: 0.8592875003814697\n",
      "Step 4517/10000- lr: [5.536381490909091e-06] - Loss total: 2.7150847911834717, Last rpr Loss: 0.9999992251396179, Last lagvar Loss: 0.8592821359634399\n",
      "Step 4518/10000- lr: [5.5353713939393945e-06] - Loss total: 2.714991807937622, Last rpr Loss: 1.000004768371582, Last lagvar Loss: 0.8592761754989624\n",
      "Step 4519/10000- lr: [5.534361296969697e-06] - Loss total: 2.714900016784668, Last rpr Loss: 1.0000017881393433, Last lagvar Loss: 0.8592783212661743\n",
      "Step 4520/10000- lr: [5.5333512e-06] - Loss total: 2.7148075103759766, Last rpr Loss: 1.0000019073486328, Last lagvar Loss: 0.8592776656150818\n",
      "Step 4521/10000- lr: [5.5323411030303035e-06] - Loss total: 2.7147152423858643, Last rpr Loss: 1.0000014305114746, Last lagvar Loss: 0.8592774868011475\n",
      "Step 4522/10000- lr: [5.531331006060606e-06] - Loss total: 2.71462345123291, Last rpr Loss: 0.9999976754188538, Last lagvar Loss: 0.8592805862426758\n",
      "Step 4523/10000- lr: [5.530320909090909e-06] - Loss total: 2.7145309448242188, Last rpr Loss: 1.0000030994415283, Last lagvar Loss: 0.8592747449874878\n",
      "Step 4524/10000- lr: [5.5293108121212125e-06] - Loss total: 2.7144391536712646, Last rpr Loss: 0.9999964833259583, Last lagvar Loss: 0.8592806458473206\n",
      "Step 4525/10000- lr: [5.528300715151516e-06] - Loss total: 2.7143471240997314, Last rpr Loss: 0.9999992251396179, Last lagvar Loss: 0.8592773675918579\n",
      "Step 4526/10000- lr: [5.527290618181818e-06] - Loss total: 2.7142553329467773, Last rpr Loss: 1.0000053644180298, Last lagvar Loss: 0.8592705726623535\n",
      "Step 4527/10000- lr: [5.5262805212121215e-06] - Loss total: 2.7141635417938232, Last rpr Loss: 1.0000004768371582, Last lagvar Loss: 0.8592748641967773\n",
      "Step 4528/10000- lr: [5.525270424242425e-06] - Loss total: 2.7140719890594482, Last rpr Loss: 0.9999974370002747, Last lagvar Loss: 0.8592771887779236\n",
      "Step 4529/10000- lr: [5.524260327272727e-06] - Loss total: 2.713980197906494, Last rpr Loss: 1.0000028610229492, Last lagvar Loss: 0.859271228313446\n",
      "Step 4530/10000- lr: [5.5232502303030305e-06] - Loss total: 2.713888645172119, Last rpr Loss: 1.0000007152557373, Last lagvar Loss: 0.859272837638855\n",
      "Step 4531/10000- lr: [5.522240133333334e-06] - Loss total: 2.713796854019165, Last rpr Loss: 0.9999995231628418, Last lagvar Loss: 0.8592734336853027\n",
      "Step 4532/10000- lr: [5.521230036363636e-06] - Loss total: 2.713705062866211, Last rpr Loss: 1.0000009536743164, Last lagvar Loss: 0.8592714071273804\n",
      "Step 4533/10000- lr: [5.5202199393939395e-06] - Loss total: 2.7136142253875732, Last rpr Loss: 0.9999989867210388, Last lagvar Loss: 0.8592727184295654\n",
      "Step 4534/10000- lr: [5.519209842424243e-06] - Loss total: 2.713522434234619, Last rpr Loss: 1.0000038146972656, Last lagvar Loss: 0.8592671751976013\n",
      "Step 4535/10000- lr: [5.518199745454546e-06] - Loss total: 2.713430881500244, Last rpr Loss: 0.999997615814209, Last lagvar Loss: 0.859272837638855\n",
      "Step 4536/10000- lr: [5.5171896484848485e-06] - Loss total: 2.7133400440216064, Last rpr Loss: 0.999997615814209, Last lagvar Loss: 0.859272301197052\n",
      "Step 4537/10000- lr: [5.516179551515152e-06] - Loss total: 2.7132487297058105, Last rpr Loss: 1.0000057220458984, Last lagvar Loss: 0.85926353931427\n",
      "Step 4538/10000- lr: [5.515169454545455e-06] - Loss total: 2.7131576538085938, Last rpr Loss: 0.9999992847442627, Last lagvar Loss: 0.8592694997787476\n",
      "Step 4539/10000- lr: [5.5141593575757574e-06] - Loss total: 2.713066577911377, Last rpr Loss: 0.9999983906745911, Last lagvar Loss: 0.8592697381973267\n",
      "Step 4540/10000- lr: [5.513149260606061e-06] - Loss total: 2.71297550201416, Last rpr Loss: 1.0000054836273193, Last lagvar Loss: 0.8592620491981506\n",
      "Step 4541/10000- lr: [5.512139163636364e-06] - Loss total: 2.7128844261169434, Last rpr Loss: 0.9999977350234985, Last lagvar Loss: 0.8592692613601685\n",
      "Step 4542/10000- lr: [5.5111290666666664e-06] - Loss total: 2.7127933502197266, Last rpr Loss: 1.0000009536743164, Last lagvar Loss: 0.8592654466629028\n",
      "Step 4543/10000- lr: [5.51011896969697e-06] - Loss total: 2.712702512741089, Last rpr Loss: 1.0000007152557373, Last lagvar Loss: 0.8592650890350342\n",
      "Step 4544/10000- lr: [5.509108872727273e-06] - Loss total: 2.712611675262451, Last rpr Loss: 0.9999967813491821, Last lagvar Loss: 0.8592684864997864\n",
      "Step 4545/10000- lr: [5.508098775757576e-06] - Loss total: 2.7125210762023926, Last rpr Loss: 1.0000030994415283, Last lagvar Loss: 0.8592614531517029\n",
      "Step 4546/10000- lr: [5.507088678787879e-06] - Loss total: 2.712430238723755, Last rpr Loss: 0.9999986886978149, Last lagvar Loss: 0.8592653870582581\n",
      "Step 4547/10000- lr: [5.506078581818182e-06] - Loss total: 2.7123398780822754, Last rpr Loss: 0.9999996423721313, Last lagvar Loss: 0.8592637777328491\n",
      "Step 4548/10000- lr: [5.505068484848485e-06] - Loss total: 2.712249279022217, Last rpr Loss: 1.0000059604644775, Last lagvar Loss: 0.8592568635940552\n",
      "Step 4549/10000- lr: [5.504058387878788e-06] - Loss total: 2.7121589183807373, Last rpr Loss: 0.9999972581863403, Last lagvar Loss: 0.8592650294303894\n",
      "Step 4550/10000- lr: [5.503048290909091e-06] - Loss total: 2.7120683193206787, Last rpr Loss: 0.9999990463256836, Last lagvar Loss: 0.8592626452445984\n",
      "Step 4551/10000- lr: [5.502038193939394e-06] - Loss total: 2.7119781970977783, Last rpr Loss: 1.0000014305114746, Last lagvar Loss: 0.8592596054077148\n",
      "Step 4552/10000- lr: [5.501028096969697e-06] - Loss total: 2.7118875980377197, Last rpr Loss: 0.9999982118606567, Last lagvar Loss: 0.8592623472213745\n",
      "Step 4553/10000- lr: [5.500018e-06] - Loss total: 2.7117974758148193, Last rpr Loss: 1.0, Last lagvar Loss: 0.8592599630355835\n",
      "Step 4554/10000- lr: [5.499007903030303e-06] - Loss total: 2.711707353591919, Last rpr Loss: 1.0000030994415283, Last lagvar Loss: 0.859256386756897\n",
      "Step 4555/10000- lr: [5.4979978060606065e-06] - Loss total: 2.7116167545318604, Last rpr Loss: 1.0000008344650269, Last lagvar Loss: 0.8592580556869507\n",
      "Step 4556/10000- lr: [5.496987709090909e-06] - Loss total: 2.711526870727539, Last rpr Loss: 1.0000016689300537, Last lagvar Loss: 0.8592565655708313\n",
      "Step 4557/10000- lr: [5.495977612121212e-06] - Loss total: 2.7114365100860596, Last rpr Loss: 1.0000014305114746, Last lagvar Loss: 0.8592561483383179\n",
      "Step 4558/10000- lr: [5.4949675151515155e-06] - Loss total: 2.7113466262817383, Last rpr Loss: 0.9999966025352478, Last lagvar Loss: 0.8592605590820312\n",
      "Step 4559/10000- lr: [5.493957418181818e-06] - Loss total: 2.711256742477417, Last rpr Loss: 0.999998927116394, Last lagvar Loss: 0.8592576384544373\n",
      "Step 4560/10000- lr: [5.492947321212121e-06] - Loss total: 2.7111666202545166, Last rpr Loss: 1.0000004768371582, Last lagvar Loss: 0.8592554330825806\n",
      "Step 4561/10000- lr: [5.4919372242424245e-06] - Loss total: 2.7110769748687744, Last rpr Loss: 0.9999988079071045, Last lagvar Loss: 0.8592566251754761\n",
      "Step 4562/10000- lr: [5.490927127272727e-06] - Loss total: 2.7109873294830322, Last rpr Loss: 1.0000039339065552, Last lagvar Loss: 0.8592509627342224\n",
      "Step 4563/10000- lr: [5.48991703030303e-06] - Loss total: 2.710897207260132, Last rpr Loss: 1.0000009536743164, Last lagvar Loss: 0.8592534065246582\n",
      "Step 4564/10000- lr: [5.4889069333333334e-06] - Loss total: 2.7108078002929688, Last rpr Loss: 0.999998927116394, Last lagvar Loss: 0.8592548370361328\n",
      "Step 4565/10000- lr: [5.487896836363637e-06] - Loss total: 2.7107181549072266, Last rpr Loss: 1.0000005960464478, Last lagvar Loss: 0.8592525720596313\n",
      "Step 4566/10000- lr: [5.486886739393939e-06] - Loss total: 2.7106287479400635, Last rpr Loss: 1.000000238418579, Last lagvar Loss: 0.8592524528503418\n",
      "Step 4567/10000- lr: [5.485876642424242e-06] - Loss total: 2.7105391025543213, Last rpr Loss: 0.9999997019767761, Last lagvar Loss: 0.8592524528503418\n",
      "Step 4568/10000- lr: [5.484866545454546e-06] - Loss total: 2.710449695587158, Last rpr Loss: 0.9999984502792358, Last lagvar Loss: 0.8592531681060791\n",
      "Step 4569/10000- lr: [5.483856448484848e-06] - Loss total: 2.710360288619995, Last rpr Loss: 1.0000001192092896, Last lagvar Loss: 0.8592508435249329\n",
      "Step 4570/10000- lr: [5.482846351515151e-06] - Loss total: 2.710271120071411, Last rpr Loss: 1.0000003576278687, Last lagvar Loss: 0.8592501282691956\n",
      "Step 4571/10000- lr: [5.481836254545455e-06] - Loss total: 2.710181474685669, Last rpr Loss: 1.0000011920928955, Last lagvar Loss: 0.8592487573623657\n",
      "Step 4572/10000- lr: [5.480826157575757e-06] - Loss total: 2.710092306137085, Last rpr Loss: 1.0000004768371582, Last lagvar Loss: 0.8592488765716553\n",
      "Step 4573/10000- lr: [5.47981606060606e-06] - Loss total: 2.710003137588501, Last rpr Loss: 1.0000009536743164, Last lagvar Loss: 0.8592478036880493\n",
      "Step 4574/10000- lr: [5.478805963636364e-06] - Loss total: 2.709913969039917, Last rpr Loss: 1.0000008344650269, Last lagvar Loss: 0.8592474460601807\n",
      "Step 4575/10000- lr: [5.477795866666667e-06] - Loss total: 2.709825277328491, Last rpr Loss: 1.0000009536743164, Last lagvar Loss: 0.8592467308044434\n",
      "Step 4576/10000- lr: [5.476785769696969e-06] - Loss total: 2.7097361087799072, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.8592506647109985\n",
      "Step 4577/10000- lr: [5.475775672727273e-06] - Loss total: 2.709646701812744, Last rpr Loss: 1.000002384185791, Last lagvar Loss: 0.8592441082000732\n",
      "Step 4578/10000- lr: [5.474765575757576e-06] - Loss total: 2.7095577716827393, Last rpr Loss: 1.000000238418579, Last lagvar Loss: 0.8592458367347717\n",
      "Step 4579/10000- lr: [5.473755478787879e-06] - Loss total: 2.7094686031341553, Last rpr Loss: 0.9999999403953552, Last lagvar Loss: 0.8592455983161926\n",
      "Step 4580/10000- lr: [5.4727453818181825e-06] - Loss total: 2.7093803882598877, Last rpr Loss: 1.0, Last lagvar Loss: 0.8592450618743896\n",
      "Step 4581/10000- lr: [5.471735284848485e-06] - Loss total: 2.709291458129883, Last rpr Loss: 0.9999988675117493, Last lagvar Loss: 0.8592456579208374\n",
      "Step 4582/10000- lr: [5.470725187878788e-06] - Loss total: 2.709202766418457, Last rpr Loss: 1.0000020265579224, Last lagvar Loss: 0.8592419624328613\n",
      "Step 4583/10000- lr: [5.4697150909090915e-06] - Loss total: 2.709113597869873, Last rpr Loss: 1.0000016689300537, Last lagvar Loss: 0.859241783618927\n",
      "Step 4584/10000- lr: [5.468704993939395e-06] - Loss total: 2.7090249061584473, Last rpr Loss: 0.9999979734420776, Last lagvar Loss: 0.8592448234558105\n",
      "Step 4585/10000- lr: [5.467694896969697e-06] - Loss total: 2.7089366912841797, Last rpr Loss: 0.9999985694885254, Last lagvar Loss: 0.8592436909675598\n",
      "Step 4586/10000- lr: [5.4666848000000005e-06] - Loss total: 2.708847761154175, Last rpr Loss: 1.0000019073486328, Last lagvar Loss: 0.8592398762702942\n",
      "Step 4587/10000- lr: [5.465674703030304e-06] - Loss total: 2.7087595462799072, Last rpr Loss: 0.9999990463256836, Last lagvar Loss: 0.85924232006073\n",
      "Step 4588/10000- lr: [5.464664606060606e-06] - Loss total: 2.7086708545684814, Last rpr Loss: 1.0000011920928955, Last lagvar Loss: 0.8592395782470703\n",
      "Step 4589/10000- lr: [5.4636545090909094e-06] - Loss total: 2.7085824012756348, Last rpr Loss: 1.0000007152557373, Last lagvar Loss: 0.8592395186424255\n",
      "Step 4590/10000- lr: [5.462644412121213e-06] - Loss total: 2.708493947982788, Last rpr Loss: 0.9999973773956299, Last lagvar Loss: 0.85924232006073\n",
      "Step 4591/10000- lr: [5.461634315151515e-06] - Loss total: 2.7084054946899414, Last rpr Loss: 1.0000015497207642, Last lagvar Loss: 0.8592376708984375\n",
      "Step 4592/10000- lr: [5.460624218181818e-06] - Loss total: 2.708317518234253, Last rpr Loss: 1.0000016689300537, Last lagvar Loss: 0.8592370748519897\n",
      "Step 4593/10000- lr: [5.459614121212122e-06] - Loss total: 2.708228826522827, Last rpr Loss: 0.9999988079071045, Last lagvar Loss: 0.8592392802238464\n",
      "Step 4594/10000- lr: [5.458604024242425e-06] - Loss total: 2.7081408500671387, Last rpr Loss: 0.9999995231628418, Last lagvar Loss: 0.8592381477355957\n",
      "Step 4595/10000- lr: [5.457593927272727e-06] - Loss total: 2.70805287361145, Last rpr Loss: 1.0000007152557373, Last lagvar Loss: 0.859236478805542\n",
      "Step 4596/10000- lr: [5.456583830303031e-06] - Loss total: 2.7079646587371826, Last rpr Loss: 0.9999992847442627, Last lagvar Loss: 0.8592373132705688\n",
      "Step 4597/10000- lr: [5.455573733333334e-06] - Loss total: 2.707876205444336, Last rpr Loss: 1.000000238418579, Last lagvar Loss: 0.8592358827590942\n",
      "Step 4598/10000- lr: [5.454563636363636e-06] - Loss total: 2.7077887058258057, Last rpr Loss: 0.999998152256012, Last lagvar Loss: 0.8592374324798584\n",
      "Step 4599/10000- lr: [5.45355353939394e-06] - Loss total: 2.707700252532959, Last rpr Loss: 1.0000011920928955, Last lagvar Loss: 0.8592339754104614\n",
      "Step 4600/10000- lr: [5.452543442424243e-06] - Loss total: 2.7076122760772705, Last rpr Loss: 1.0000033378601074, Last lagvar Loss: 0.859231173992157\n",
      "Step 4601/10000- lr: [5.451533345454545e-06] - Loss total: 2.707524538040161, Last rpr Loss: 0.9999973177909851, Last lagvar Loss: 0.8592367172241211\n",
      "Step 4602/10000- lr: [5.450523248484849e-06] - Loss total: 2.7074363231658936, Last rpr Loss: 1.0000009536743164, Last lagvar Loss: 0.859232485294342\n",
      "Step 4603/10000- lr: [5.449513151515152e-06] - Loss total: 2.7073488235473633, Last rpr Loss: 1.0000004768371582, Last lagvar Loss: 0.8592326641082764\n",
      "Step 4604/10000- lr: [5.448503054545455e-06] - Loss total: 2.707261085510254, Last rpr Loss: 0.9999994039535522, Last lagvar Loss: 0.859233021736145\n",
      "Step 4605/10000- lr: [5.447492957575758e-06] - Loss total: 2.7071731090545654, Last rpr Loss: 1.0000001192092896, Last lagvar Loss: 0.8592318296432495\n",
      "Step 4606/10000- lr: [5.446482860606061e-06] - Loss total: 2.707085371017456, Last rpr Loss: 1.0000009536743164, Last lagvar Loss: 0.8592305183410645\n",
      "Step 4607/10000- lr: [5.445472763636364e-06] - Loss total: 2.7069976329803467, Last rpr Loss: 0.9999991655349731, Last lagvar Loss: 0.8592318296432495\n",
      "Step 4608/10000- lr: [5.444462666666667e-06] - Loss total: 2.7069101333618164, Last rpr Loss: 1.0000007152557373, Last lagvar Loss: 0.8592297434806824\n",
      "Step 4609/10000- lr: [5.44345256969697e-06] - Loss total: 2.706822395324707, Last rpr Loss: 0.9999993443489075, Last lagvar Loss: 0.8592305779457092\n",
      "Step 4610/10000- lr: [5.442442472727273e-06] - Loss total: 2.7067348957061768, Last rpr Loss: 0.999998152256012, Last lagvar Loss: 0.8592312335968018\n",
      "Step 4611/10000- lr: [5.441432375757576e-06] - Loss total: 2.7066471576690674, Last rpr Loss: 1.000001311302185, Last lagvar Loss: 0.8592276573181152\n",
      "Step 4612/10000- lr: [5.440422278787879e-06] - Loss total: 2.706559658050537, Last rpr Loss: 1.0000007152557373, Last lagvar Loss: 0.8592277765274048\n",
      "Step 4613/10000- lr: [5.439412181818182e-06] - Loss total: 2.706472396850586, Last rpr Loss: 0.9999979734420776, Last lagvar Loss: 0.8592299222946167\n",
      "Step 4614/10000- lr: [5.4384020848484854e-06] - Loss total: 2.7063848972320557, Last rpr Loss: 1.0000003576278687, Last lagvar Loss: 0.8592269420623779\n",
      "Step 4615/10000- lr: [5.437391987878788e-06] - Loss total: 2.7062973976135254, Last rpr Loss: 1.0000041723251343, Last lagvar Loss: 0.8592226505279541\n",
      "Step 4616/10000- lr: [5.436381890909091e-06] - Loss total: 2.706210136413574, Last rpr Loss: 0.9999988079071045, Last lagvar Loss: 0.8592275381088257\n",
      "Step 4617/10000- lr: [5.435371793939394e-06] - Loss total: 2.706122636795044, Last rpr Loss: 0.9999974966049194, Last lagvar Loss: 0.859228253364563\n",
      "Step 4618/10000- lr: [5.434361696969697e-06] - Loss total: 2.7060353755950928, Last rpr Loss: 1.0000009536743164, Last lagvar Loss: 0.8592243790626526\n",
      "Step 4619/10000- lr: [5.4333516e-06] - Loss total: 2.7059478759765625, Last rpr Loss: 1.0000016689300537, Last lagvar Loss: 0.8592231273651123\n",
      "Step 4620/10000- lr: [5.432341503030303e-06] - Loss total: 2.7058608531951904, Last rpr Loss: 0.9999973773956299, Last lagvar Loss: 0.8592268824577332\n",
      "Step 4621/10000- lr: [5.431331406060606e-06] - Loss total: 2.70577335357666, Last rpr Loss: 1.0000011920928955, Last lagvar Loss: 0.859222412109375\n",
      "Step 4622/10000- lr: [5.430321309090909e-06] - Loss total: 2.705686330795288, Last rpr Loss: 1.0000004768371582, Last lagvar Loss: 0.8592227101325989\n",
      "Step 4623/10000- lr: [5.429311212121212e-06] - Loss total: 2.705599069595337, Last rpr Loss: 0.9999972581863403, Last lagvar Loss: 0.8592253923416138\n",
      "Step 4624/10000- lr: [5.428301115151516e-06] - Loss total: 2.705512285232544, Last rpr Loss: 1.0000009536743164, Last lagvar Loss: 0.8592211008071899\n",
      "Step 4625/10000- lr: [5.427291018181818e-06] - Loss total: 2.7054247856140137, Last rpr Loss: 1.0000020265579224, Last lagvar Loss: 0.8592194318771362\n",
      "Step 4626/10000- lr: [5.426280921212121e-06] - Loss total: 2.7053380012512207, Last rpr Loss: 1.0000011920928955, Last lagvar Loss: 0.8592197895050049\n",
      "Step 4627/10000- lr: [5.425270824242425e-06] - Loss total: 2.7052509784698486, Last rpr Loss: 0.9999982118606567, Last lagvar Loss: 0.8592222929000854\n",
      "Step 4628/10000- lr: [5.424260727272727e-06] - Loss total: 2.7051639556884766, Last rpr Loss: 1.000001072883606, Last lagvar Loss: 0.8592187166213989\n",
      "Step 4629/10000- lr: [5.42325063030303e-06] - Loss total: 2.7050774097442627, Last rpr Loss: 1.000000238418579, Last lagvar Loss: 0.859218955039978\n",
      "Step 4630/10000- lr: [5.422240533333334e-06] - Loss total: 2.7049899101257324, Last rpr Loss: 0.9999988079071045, Last lagvar Loss: 0.8592197895050049\n",
      "Step 4631/10000- lr: [5.421230436363636e-06] - Loss total: 2.7049031257629395, Last rpr Loss: 0.9999998807907104, Last lagvar Loss: 0.859218180179596\n",
      "Step 4632/10000- lr: [5.420220339393939e-06] - Loss total: 2.7048168182373047, Last rpr Loss: 0.9999998807907104, Last lagvar Loss: 0.8592174053192139\n",
      "Step 4633/10000- lr: [5.419210242424243e-06] - Loss total: 2.7047300338745117, Last rpr Loss: 0.9999997615814209, Last lagvar Loss: 0.8592170476913452\n",
      "Step 4634/10000- lr: [5.418200145454546e-06] - Loss total: 2.7046427726745605, Last rpr Loss: 1.0000001192092896, Last lagvar Loss: 0.8592159748077393\n",
      "Step 4635/10000- lr: [5.417190048484848e-06] - Loss total: 2.704556465148926, Last rpr Loss: 0.9999991655349731, Last lagvar Loss: 0.8592162132263184\n",
      "Step 4636/10000- lr: [5.416179951515152e-06] - Loss total: 2.704469680786133, Last rpr Loss: 1.0000033378601074, Last lagvar Loss: 0.8592115044593811\n",
      "Step 4637/10000- lr: [5.415169854545455e-06] - Loss total: 2.70438289642334, Last rpr Loss: 1.0000004768371582, Last lagvar Loss: 0.8592134714126587\n",
      "Step 4638/10000- lr: [5.414159757575757e-06] - Loss total: 2.704296350479126, Last rpr Loss: 1.0000001192092896, Last lagvar Loss: 0.8592131733894348\n",
      "Step 4639/10000- lr: [5.413149660606061e-06] - Loss total: 2.704209804534912, Last rpr Loss: 1.0000003576278687, Last lagvar Loss: 0.8592122197151184\n",
      "Step 4640/10000- lr: [5.412139563636364e-06] - Loss total: 2.704123020172119, Last rpr Loss: 0.9999998807907104, Last lagvar Loss: 0.8592118620872498\n",
      "Step 4641/10000- lr: [5.411129466666666e-06] - Loss total: 2.7040369510650635, Last rpr Loss: 0.9999978542327881, Last lagvar Loss: 0.85921311378479\n",
      "Step 4642/10000- lr: [5.4101193696969696e-06] - Loss total: 2.7039501667022705, Last rpr Loss: 1.0000032186508179, Last lagvar Loss: 0.8592067956924438\n",
      "Step 4643/10000- lr: [5.409109272727273e-06] - Loss total: 2.7038638591766357, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.859214186668396\n",
      "Step 4644/10000- lr: [5.408099175757576e-06] - Loss total: 2.703777551651001, Last rpr Loss: 1.000004768371582, Last lagvar Loss: 0.8592033386230469\n",
      "Step 4645/10000- lr: [5.4070890787878786e-06] - Loss total: 2.703691244125366, Last rpr Loss: 0.9999992847442627, Last lagvar Loss: 0.8592077493667603\n",
      "Step 4646/10000- lr: [5.406078981818182e-06] - Loss total: 2.7036049365997314, Last rpr Loss: 0.9999980926513672, Last lagvar Loss: 0.859207808971405\n",
      "Step 4647/10000- lr: [5.405068884848485e-06] - Loss total: 2.703518867492676, Last rpr Loss: 1.0000035762786865, Last lagvar Loss: 0.8592012524604797\n",
      "Step 4648/10000- lr: [5.4040587878787875e-06] - Loss total: 2.703432321548462, Last rpr Loss: 0.9999969005584717, Last lagvar Loss: 0.8592067956924438\n",
      "Step 4649/10000- lr: [5.403048690909091e-06] - Loss total: 2.703346014022827, Last rpr Loss: 1.0000026226043701, Last lagvar Loss: 0.8591995239257812\n",
      "Step 4650/10000- lr: [5.402038593939394e-06] - Loss total: 2.7032601833343506, Last rpr Loss: 1.0, Last lagvar Loss: 0.8592007160186768\n",
      "Step 4651/10000- lr: [5.401028496969697e-06] - Loss total: 2.703174114227295, Last rpr Loss: 0.9999990463256836, Last lagvar Loss: 0.8592001795768738\n",
      "Step 4652/10000- lr: [5.4000184e-06] - Loss total: 2.70308780670166, Last rpr Loss: 1.000001072883606, Last lagvar Loss: 0.8591963648796082\n",
      "Step 4653/10000- lr: [5.399008303030303e-06] - Loss total: 2.7030019760131836, Last rpr Loss: 0.9999988079071045, Last lagvar Loss: 0.8591967225074768\n",
      "Step 4654/10000- lr: [5.397998206060606e-06] - Loss total: 2.702915906906128, Last rpr Loss: 0.999998152256012, Last lagvar Loss: 0.8591951727867126\n",
      "Step 4655/10000- lr: [5.396988109090909e-06] - Loss total: 2.7028298377990723, Last rpr Loss: 0.9999985694885254, Last lagvar Loss: 0.8591923713684082\n",
      "Step 4656/10000- lr: [5.395978012121212e-06] - Loss total: 2.7027440071105957, Last rpr Loss: 0.9999980330467224, Last lagvar Loss: 0.8591902852058411\n",
      "Step 4657/10000- lr: [5.394967915151515e-06] - Loss total: 2.702657699584961, Last rpr Loss: 1.0000039339065552, Last lagvar Loss: 0.8591814041137695\n",
      "Step 4658/10000- lr: [5.393957818181818e-06] - Loss total: 2.7025718688964844, Last rpr Loss: 0.9999968409538269, Last lagvar Loss: 0.8591850996017456\n",
      "Step 4659/10000- lr: [5.392947721212121e-06] - Loss total: 2.702486276626587, Last rpr Loss: 0.9999959468841553, Last lagvar Loss: 0.8591822385787964\n",
      "Step 4660/10000- lr: [5.391937624242424e-06] - Loss total: 2.7024002075195312, Last rpr Loss: 1.0000044107437134, Last lagvar Loss: 0.8591693639755249\n",
      "Step 4661/10000- lr: [5.390927527272728e-06] - Loss total: 2.7023138999938965, Last rpr Loss: 0.999993622303009, Last lagvar Loss: 0.8591753244400024\n",
      "Step 4662/10000- lr: [5.38991743030303e-06] - Loss total: 2.70222806930542, Last rpr Loss: 0.9999977946281433, Last lagvar Loss: 0.8591656684875488\n",
      "Step 4663/10000- lr: [5.388907333333333e-06] - Loss total: 2.7021420001983643, Last rpr Loss: 0.9999992847442627, Last lagvar Loss: 0.8591578006744385\n",
      "Step 4664/10000- lr: [5.387897236363637e-06] - Loss total: 2.7020561695098877, Last rpr Loss: 0.9999924898147583, Last lagvar Loss: 0.8591574430465698\n",
      "Step 4665/10000- lr: [5.38688713939394e-06] - Loss total: 2.701970100402832, Last rpr Loss: 0.9999971985816956, Last lagvar Loss: 0.8591448068618774\n",
      "Step 4666/10000- lr: [5.385877042424243e-06] - Loss total: 2.7018837928771973, Last rpr Loss: 0.9999955892562866, Last lagvar Loss: 0.8591374158859253\n",
      "Step 4667/10000- lr: [5.3848669454545456e-06] - Loss total: 2.7017974853515625, Last rpr Loss: 0.9999982118606567, Last lagvar Loss: 0.8591247200965881\n",
      "Step 4668/10000- lr: [5.383856848484849e-06] - Loss total: 2.7017109394073486, Last rpr Loss: 1.0, Last lagvar Loss: 0.8591120839118958\n",
      "Step 4669/10000- lr: [5.382846751515152e-06] - Loss total: 2.701624631881714, Last rpr Loss: 0.999997615814209, Last lagvar Loss: 0.859102725982666\n",
      "Step 4670/10000- lr: [5.3818366545454546e-06] - Loss total: 2.7015380859375, Last rpr Loss: 0.9999991059303284, Last lagvar Loss: 0.8590884804725647\n",
      "Step 4671/10000- lr: [5.380826557575758e-06] - Loss total: 2.701451539993286, Last rpr Loss: 0.9999977350234985, Last lagvar Loss: 0.8590765595436096\n",
      "Step 4672/10000- lr: [5.379816460606061e-06] - Loss total: 2.701364755630493, Last rpr Loss: 1.000002145767212, Last lagvar Loss: 0.8590583801269531\n",
      "Step 4673/10000- lr: [5.378806363636364e-06] - Loss total: 2.7012779712677, Last rpr Loss: 1.0000019073486328, Last lagvar Loss: 0.8590445518493652\n",
      "Step 4674/10000- lr: [5.377796266666667e-06] - Loss total: 2.701190710067749, Last rpr Loss: 1.0000046491622925, Last lagvar Loss: 0.8590278029441833\n",
      "Step 4675/10000- lr: [5.37678616969697e-06] - Loss total: 2.701103687286377, Last rpr Loss: 1.0000048875808716, Last lagvar Loss: 0.8590134382247925\n",
      "Step 4676/10000- lr: [5.375776072727273e-06] - Loss total: 2.701016426086426, Last rpr Loss: 1.0000075101852417, Last lagvar Loss: 0.8589969873428345\n",
      "Step 4677/10000- lr: [5.374765975757576e-06] - Loss total: 2.7009289264678955, Last rpr Loss: 1.0000057220458984, Last lagvar Loss: 0.8589850664138794\n",
      "Step 4678/10000- lr: [5.373755878787879e-06] - Loss total: 2.700841188430786, Last rpr Loss: 1.0000050067901611, Last lagvar Loss: 0.8589727878570557\n",
      "Step 4679/10000- lr: [5.372745781818182e-06] - Loss total: 2.7007534503936768, Last rpr Loss: 1.0000054836273193, Last lagvar Loss: 0.8589591979980469\n",
      "Step 4680/10000- lr: [5.371735684848485e-06] - Loss total: 2.70066499710083, Last rpr Loss: 1.000002384185791, Last lagvar Loss: 0.8589498996734619\n",
      "Step 4681/10000- lr: [5.370725587878788e-06] - Loss total: 2.7005763053894043, Last rpr Loss: 1.0000016689300537, Last lagvar Loss: 0.8589383363723755\n",
      "Step 4682/10000- lr: [5.369715490909091e-06] - Loss total: 2.7004878520965576, Last rpr Loss: 0.9999995827674866, Last lagvar Loss: 0.8589285612106323\n",
      "Step 4683/10000- lr: [5.368705393939395e-06] - Loss total: 2.7003989219665527, Last rpr Loss: 0.9999955892562866, Last lagvar Loss: 0.8589208126068115\n",
      "Step 4684/10000- lr: [5.367695296969697e-06] - Loss total: 2.7003092765808105, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8589088916778564\n",
      "Step 4685/10000- lr: [5.3666852e-06] - Loss total: 2.7002198696136475, Last rpr Loss: 0.9999954700469971, Last lagvar Loss: 0.8588975667953491\n",
      "Step 4686/10000- lr: [5.365675103030304e-06] - Loss total: 2.7001307010650635, Last rpr Loss: 0.999991238117218, Last lagvar Loss: 0.8588899374008179\n",
      "Step 4687/10000- lr: [5.364665006060606e-06] - Loss total: 2.7000410556793213, Last rpr Loss: 0.9999889135360718, Last lagvar Loss: 0.8588801026344299\n",
      "Step 4688/10000- lr: [5.363654909090909e-06] - Loss total: 2.6999518871307373, Last rpr Loss: 0.9999912977218628, Last lagvar Loss: 0.8588653802871704\n",
      "Step 4689/10000- lr: [5.362644812121213e-06] - Loss total: 2.699862480163574, Last rpr Loss: 0.9999874234199524, Last lagvar Loss: 0.8588563799858093\n",
      "Step 4690/10000- lr: [5.361634715151515e-06] - Loss total: 2.6997733116149902, Last rpr Loss: 0.9999875426292419, Last lagvar Loss: 0.858843207359314\n",
      "Step 4691/10000- lr: [5.360624618181818e-06] - Loss total: 2.699683904647827, Last rpr Loss: 0.9999865293502808, Last lagvar Loss: 0.8588308095932007\n",
      "Step 4692/10000- lr: [5.3596145212121216e-06] - Loss total: 2.699594497680664, Last rpr Loss: 0.9999955296516418, Last lagvar Loss: 0.8588080406188965\n",
      "Step 4693/10000- lr: [5.358604424242425e-06] - Loss total: 2.699505090713501, Last rpr Loss: 0.9999921321868896, Last lagvar Loss: 0.8587974905967712\n",
      "Step 4694/10000- lr: [5.357594327272727e-06] - Loss total: 2.6994152069091797, Last rpr Loss: 0.9999898672103882, Last lagvar Loss: 0.8587855100631714\n",
      "Step 4695/10000- lr: [5.3565842303030305e-06] - Loss total: 2.6993260383605957, Last rpr Loss: 0.9999943971633911, Last lagvar Loss: 0.8587665557861328\n",
      "Step 4696/10000- lr: [5.355574133333334e-06] - Loss total: 2.699235439300537, Last rpr Loss: 0.9999932646751404, Last lagvar Loss: 0.8587526679039001\n",
      "Step 4697/10000- lr: [5.354564036363636e-06] - Loss total: 2.6991450786590576, Last rpr Loss: 0.9999912977218628, Last lagvar Loss: 0.8587391972541809\n",
      "Step 4698/10000- lr: [5.3535539393939395e-06] - Loss total: 2.69905424118042, Last rpr Loss: 0.9999930262565613, Last lagvar Loss: 0.8587212562561035\n",
      "Step 4699/10000- lr: [5.352543842424243e-06] - Loss total: 2.698962926864624, Last rpr Loss: 0.999991774559021, Last lagvar Loss: 0.8587053418159485\n",
      "Step 4700/10000- lr: [5.351533745454545e-06] - Loss total: 2.6988706588745117, Last rpr Loss: 0.9999883770942688, Last lagvar Loss: 0.8586900234222412\n",
      "Step 4701/10000- lr: [5.3505236484848485e-06] - Loss total: 2.698777437210083, Last rpr Loss: 0.9999880194664001, Last lagvar Loss: 0.8586698770523071\n",
      "Step 4702/10000- lr: [5.349513551515152e-06] - Loss total: 2.6986825466156006, Last rpr Loss: 0.9999869465827942, Last lagvar Loss: 0.8586481809616089\n",
      "Step 4703/10000- lr: [5.348503454545455e-06] - Loss total: 2.69858717918396, Last rpr Loss: 0.9999775886535645, Last lagvar Loss: 0.8586320877075195\n",
      "Step 4704/10000- lr: [5.3474933575757575e-06] - Loss total: 2.6984896659851074, Last rpr Loss: 0.9999754428863525, Last lagvar Loss: 0.8586055040359497\n",
      "Step 4705/10000- lr: [5.346483260606061e-06] - Loss total: 2.6983909606933594, Last rpr Loss: 0.9999748468399048, Last lagvar Loss: 0.8585741519927979\n",
      "Step 4706/10000- lr: [5.345473163636364e-06] - Loss total: 2.6982905864715576, Last rpr Loss: 0.9999718070030212, Last lagvar Loss: 0.8585417866706848\n",
      "Step 4707/10000- lr: [5.3444630666666665e-06] - Loss total: 2.698188066482544, Last rpr Loss: 0.9999819993972778, Last lagvar Loss: 0.8584933280944824\n",
      "Step 4708/10000- lr: [5.34345296969697e-06] - Loss total: 2.6980843544006348, Last rpr Loss: 0.9999947547912598, Last lagvar Loss: 0.8584399223327637\n",
      "Step 4709/10000- lr: [5.342442872727273e-06] - Loss total: 2.6979799270629883, Last rpr Loss: 1.0000007152557373, Last lagvar Loss: 0.8583914041519165\n",
      "Step 4710/10000- lr: [5.341432775757576e-06] - Loss total: 2.697874069213867, Last rpr Loss: 1.000004768371582, Last lagvar Loss: 0.8583441972732544\n",
      "Step 4711/10000- lr: [5.340422678787879e-06] - Loss total: 2.697768449783325, Last rpr Loss: 1.0000039339065552, Last lagvar Loss: 0.8583016395568848\n",
      "Step 4712/10000- lr: [5.339412581818182e-06] - Loss total: 2.6976616382598877, Last rpr Loss: 0.9999892711639404, Last lagvar Loss: 0.8582733273506165\n",
      "Step 4713/10000- lr: [5.338402484848485e-06] - Loss total: 2.6975550651550293, Last rpr Loss: 0.9999793767929077, Last lagvar Loss: 0.8582409024238586\n",
      "Step 4714/10000- lr: [5.337392387878788e-06] - Loss total: 2.697448492050171, Last rpr Loss: 0.9999656677246094, Last lagvar Loss: 0.8582131862640381\n",
      "Step 4715/10000- lr: [5.336382290909091e-06] - Loss total: 2.6973421573638916, Last rpr Loss: 0.9999574422836304, Last lagvar Loss: 0.8581812381744385\n",
      "Step 4716/10000- lr: [5.335372193939394e-06] - Loss total: 2.6972360610961914, Last rpr Loss: 0.9999509453773499, Last lagvar Loss: 0.8581483364105225\n",
      "Step 4717/10000- lr: [5.334362096969697e-06] - Loss total: 2.6971311569213867, Last rpr Loss: 0.9999545812606812, Last lagvar Loss: 0.8581063151359558\n",
      "Step 4718/10000- lr: [5.333352e-06] - Loss total: 2.6970267295837402, Last rpr Loss: 0.9999701976776123, Last lagvar Loss: 0.8580531477928162\n",
      "Step 4719/10000- lr: [5.332341903030303e-06] - Loss total: 2.69692325592041, Last rpr Loss: 0.9999682307243347, Last lagvar Loss: 0.8580185174942017\n",
      "Step 4720/10000- lr: [5.3313318060606065e-06] - Loss total: 2.69681978225708, Last rpr Loss: 0.9999889731407166, Last lagvar Loss: 0.8579621315002441\n",
      "Step 4721/10000- lr: [5.330321709090909e-06] - Loss total: 2.69671630859375, Last rpr Loss: 0.9999906420707703, Last lagvar Loss: 0.8579257130622864\n",
      "Step 4722/10000- lr: [5.329311612121212e-06] - Loss total: 2.69661283493042, Last rpr Loss: 0.9999853372573853, Last lagvar Loss: 0.8578970432281494\n",
      "Step 4723/10000- lr: [5.3283015151515155e-06] - Loss total: 2.69650936126709, Last rpr Loss: 0.9999842643737793, Last lagvar Loss: 0.8578652143478394\n",
      "Step 4724/10000- lr: [5.327291418181818e-06] - Loss total: 2.6964054107666016, Last rpr Loss: 0.9999734163284302, Last lagvar Loss: 0.8578440546989441\n",
      "Step 4725/10000- lr: [5.326281321212121e-06] - Loss total: 2.696301221847534, Last rpr Loss: 0.9999805688858032, Last lagvar Loss: 0.8578054308891296\n",
      "Step 4726/10000- lr: [5.3252712242424245e-06] - Loss total: 2.6961965560913086, Last rpr Loss: 0.9999783039093018, Last lagvar Loss: 0.8577765822410583\n",
      "Step 4727/10000- lr: [5.324261127272727e-06] - Loss total: 2.69608998298645, Last rpr Loss: 0.9999992847442627, Last lagvar Loss: 0.8577243089675903\n",
      "Step 4728/10000- lr: [5.32325103030303e-06] - Loss total: 2.69598126411438, Last rpr Loss: 1.0000152587890625, Last lagvar Loss: 0.8576749563217163\n",
      "Step 4729/10000- lr: [5.3222409333333335e-06] - Loss total: 2.6958673000335693, Last rpr Loss: 1.0000102519989014, Last lagvar Loss: 0.8576419353485107\n",
      "Step 4730/10000- lr: [5.321230836363637e-06] - Loss total: 2.695746660232544, Last rpr Loss: 1.0000158548355103, Last lagvar Loss: 0.8575854301452637\n",
      "Step 4731/10000- lr: [5.320220739393939e-06] - Loss total: 2.69561505317688, Last rpr Loss: 0.9999673962593079, Last lagvar Loss: 0.8575526475906372\n",
      "Step 4732/10000- lr: [5.3192106424242425e-06] - Loss total: 2.69547438621521, Last rpr Loss: 0.9998935461044312, Last lagvar Loss: 0.8574904799461365\n",
      "Step 4733/10000- lr: [5.318200545454546e-06] - Loss total: 2.69533634185791, Last rpr Loss: 0.9997958540916443, Last lagvar Loss: 0.857422411441803\n",
      "Step 4734/10000- lr: [5.317190448484848e-06] - Loss total: 2.6952126026153564, Last rpr Loss: 0.9997356534004211, Last lagvar Loss: 0.8573700785636902\n",
      "Step 4735/10000- lr: [5.3161803515151515e-06] - Loss total: 2.695101261138916, Last rpr Loss: 0.999749481678009, Last lagvar Loss: 0.8572999238967896\n",
      "Step 4736/10000- lr: [5.315170254545455e-06] - Loss total: 2.694993495941162, Last rpr Loss: 0.9997817277908325, Last lagvar Loss: 0.8572322130203247\n",
      "Step 4737/10000- lr: [5.314160157575757e-06] - Loss total: 2.69488787651062, Last rpr Loss: 0.9999698996543884, Last lagvar Loss: 0.8570131659507751\n",
      "Step 4738/10000- lr: [5.3131500606060605e-06] - Loss total: 2.694782018661499, Last rpr Loss: 1.0002315044403076, Last lagvar Loss: 0.8567206859588623\n",
      "Step 4739/10000- lr: [5.312139963636364e-06] - Loss total: 2.694676160812378, Last rpr Loss: 1.0003286600112915, Last lagvar Loss: 0.8565918207168579\n",
      "Step 4740/10000- lr: [5.311129866666667e-06] - Loss total: 2.694570779800415, Last rpr Loss: 1.0002998113632202, Last lagvar Loss: 0.8565882444381714\n",
      "Step 4741/10000- lr: [5.3101197696969694e-06] - Loss total: 2.6944656372070312, Last rpr Loss: 1.0001084804534912, Last lagvar Loss: 0.8567466735839844\n",
      "Step 4742/10000- lr: [5.309109672727273e-06] - Loss total: 2.694361448287964, Last rpr Loss: 0.9998390078544617, Last lagvar Loss: 0.8569828271865845\n",
      "Step 4743/10000- lr: [5.308099575757576e-06] - Loss total: 2.694257974624634, Last rpr Loss: 0.9996901750564575, Last lagvar Loss: 0.8570982217788696\n",
      "Step 4744/10000- lr: [5.307089478787878e-06] - Loss total: 2.69415545463562, Last rpr Loss: 0.9997245669364929, Last lagvar Loss: 0.8570300936698914\n",
      "Step 4745/10000- lr: [5.306079381818182e-06] - Loss total: 2.6940529346466064, Last rpr Loss: 0.99989914894104, Last lagvar Loss: 0.8568217754364014\n",
      "Step 4746/10000- lr: [5.305069284848485e-06] - Loss total: 2.6939518451690674, Last rpr Loss: 1.0000743865966797, Last lagvar Loss: 0.8566129803657532\n",
      "Step 4747/10000- lr: [5.304059187878787e-06] - Loss total: 2.6938514709472656, Last rpr Loss: 1.0001674890518188, Last lagvar Loss: 0.856486439704895\n",
      "Step 4748/10000- lr: [5.303049090909091e-06] - Loss total: 2.6937525272369385, Last rpr Loss: 1.0001397132873535, Last lagvar Loss: 0.8564813137054443\n",
      "Step 4749/10000- lr: [5.302038993939394e-06] - Loss total: 2.6936535835266113, Last rpr Loss: 1.0000355243682861, Last lagvar Loss: 0.8565528392791748\n",
      "Step 4750/10000- lr: [5.301028896969697e-06] - Loss total: 2.6935558319091797, Last rpr Loss: 0.9999680519104004, Last lagvar Loss: 0.8565883636474609\n",
      "Step 4751/10000- lr: [5.3000188000000005e-06] - Loss total: 2.693458318710327, Last rpr Loss: 0.999906063079834, Last lagvar Loss: 0.8566186428070068\n",
      "Step 4752/10000- lr: [5.299008703030304e-06] - Loss total: 2.69336199760437, Last rpr Loss: 0.9998633861541748, Last lagvar Loss: 0.8566304445266724\n",
      "Step 4753/10000- lr: [5.297998606060606e-06] - Loss total: 2.693265676498413, Last rpr Loss: 0.9998833537101746, Last lagvar Loss: 0.8565804362297058\n",
      "Step 4754/10000- lr: [5.2969885090909095e-06] - Loss total: 2.6931703090667725, Last rpr Loss: 0.9999436140060425, Last lagvar Loss: 0.8564907312393188\n",
      "Step 4755/10000- lr: [5.295978412121213e-06] - Loss total: 2.693075180053711, Last rpr Loss: 1.0000110864639282, Last lagvar Loss: 0.8563939929008484\n",
      "Step 4756/10000- lr: [5.294968315151515e-06] - Loss total: 2.6929807662963867, Last rpr Loss: 1.0000768899917603, Last lagvar Loss: 0.8562993407249451\n",
      "Step 4757/10000- lr: [5.2939582181818185e-06] - Loss total: 2.6928865909576416, Last rpr Loss: 1.0001015663146973, Last lagvar Loss: 0.8562464714050293\n",
      "Step 4758/10000- lr: [5.292948121212122e-06] - Loss total: 2.692793130874634, Last rpr Loss: 1.0000648498535156, Last lagvar Loss: 0.8562557697296143\n",
      "Step 4759/10000- lr: [5.291938024242425e-06] - Loss total: 2.692699432373047, Last rpr Loss: 1.0000231266021729, Last lagvar Loss: 0.8562707901000977\n",
      "Step 4760/10000- lr: [5.2909279272727275e-06] - Loss total: 2.6926066875457764, Last rpr Loss: 1.0000169277191162, Last lagvar Loss: 0.8562509417533875\n",
      "Step 4761/10000- lr: [5.289917830303031e-06] - Loss total: 2.692513942718506, Last rpr Loss: 1.0000081062316895, Last lagvar Loss: 0.8562345504760742\n",
      "Step 4762/10000- lr: [5.288907733333334e-06] - Loss total: 2.6924214363098145, Last rpr Loss: 0.9999950528144836, Last lagvar Loss: 0.8562226295471191\n",
      "Step 4763/10000- lr: [5.2878976363636364e-06] - Loss total: 2.6923296451568604, Last rpr Loss: 0.9999826550483704, Last lagvar Loss: 0.8562105894088745\n",
      "Step 4764/10000- lr: [5.28688753939394e-06] - Loss total: 2.692237377166748, Last rpr Loss: 0.9999517798423767, Last lagvar Loss: 0.8562173843383789\n",
      "Step 4765/10000- lr: [5.285877442424243e-06] - Loss total: 2.692145824432373, Last rpr Loss: 0.9999339580535889, Last lagvar Loss: 0.8562113642692566\n",
      "Step 4766/10000- lr: [5.2848673454545454e-06] - Loss total: 2.6920547485351562, Last rpr Loss: 0.999957799911499, Last lagvar Loss: 0.8561640977859497\n",
      "Step 4767/10000- lr: [5.283857248484849e-06] - Loss total: 2.6919636726379395, Last rpr Loss: 0.9999984502792358, Last lagvar Loss: 0.8561002612113953\n",
      "Step 4768/10000- lr: [5.282847151515152e-06] - Loss total: 2.6918723583221436, Last rpr Loss: 1.0000370740890503, Last lagvar Loss: 0.8560385704040527\n",
      "Step 4769/10000- lr: [5.281837054545455e-06] - Loss total: 2.691781520843506, Last rpr Loss: 1.000060796737671, Last lagvar Loss: 0.855992317199707\n",
      "Step 4770/10000- lr: [5.280826957575758e-06] - Loss total: 2.69169020652771, Last rpr Loss: 1.0000522136688232, Last lagvar Loss: 0.8559784889221191\n",
      "Step 4771/10000- lr: [5.279816860606061e-06] - Loss total: 2.6916000843048096, Last rpr Loss: 1.0000091791152954, Last lagvar Loss: 0.8559993505477905\n",
      "Step 4772/10000- lr: [5.278806763636364e-06] - Loss total: 2.691509246826172, Last rpr Loss: 0.9999633431434631, Last lagvar Loss: 0.856023371219635\n",
      "Step 4773/10000- lr: [5.277796666666667e-06] - Loss total: 2.6914188861846924, Last rpr Loss: 0.9999510049819946, Last lagvar Loss: 0.8560139536857605\n",
      "Step 4774/10000- lr: [5.27678656969697e-06] - Loss total: 2.691328287124634, Last rpr Loss: 0.9999527931213379, Last lagvar Loss: 0.8559905290603638\n",
      "Step 4775/10000- lr: [5.275776472727273e-06] - Loss total: 2.6912381649017334, Last rpr Loss: 0.9999935030937195, Last lagvar Loss: 0.8559280633926392\n",
      "Step 4776/10000- lr: [5.274766375757576e-06] - Loss total: 2.691147804260254, Last rpr Loss: 1.0000345706939697, Last lagvar Loss: 0.8558650016784668\n",
      "Step 4777/10000- lr: [5.273756278787879e-06] - Loss total: 2.6910572052001953, Last rpr Loss: 1.0000590085983276, Last lagvar Loss: 0.8558182716369629\n",
      "Step 4778/10000- lr: [5.272746181818182e-06] - Loss total: 2.690967082977295, Last rpr Loss: 1.0000593662261963, Last lagvar Loss: 0.8557952642440796\n",
      "Step 4779/10000- lr: [5.2717360848484855e-06] - Loss total: 2.6908767223358154, Last rpr Loss: 1.0000382661819458, Last lagvar Loss: 0.8557931184768677\n",
      "Step 4780/10000- lr: [5.270725987878788e-06] - Loss total: 2.690786361694336, Last rpr Loss: 1.0000172853469849, Last lagvar Loss: 0.8557897806167603\n",
      "Step 4781/10000- lr: [5.269715890909091e-06] - Loss total: 2.6906955242156982, Last rpr Loss: 0.9999978542327881, Last lagvar Loss: 0.8557837009429932\n",
      "Step 4782/10000- lr: [5.2687057939393945e-06] - Loss total: 2.6906046867370605, Last rpr Loss: 1.000008225440979, Last lagvar Loss: 0.8557461500167847\n",
      "Step 4783/10000- lr: [5.267695696969697e-06] - Loss total: 2.6905136108398438, Last rpr Loss: 1.0000028610229492, Last lagvar Loss: 0.8557217121124268\n",
      "Step 4784/10000- lr: [5.2666856e-06] - Loss total: 2.690422296524048, Last rpr Loss: 1.00001060962677, Last lagvar Loss: 0.8556808829307556\n",
      "Step 4785/10000- lr: [5.2656755030303035e-06] - Loss total: 2.6903300285339355, Last rpr Loss: 1.0000174045562744, Last lagvar Loss: 0.8556356430053711\n",
      "Step 4786/10000- lr: [5.264665406060606e-06] - Loss total: 2.690237522125244, Last rpr Loss: 1.0000014305114746, Last lagvar Loss: 0.8556059002876282\n",
      "Step 4787/10000- lr: [5.263655309090909e-06] - Loss total: 2.690143346786499, Last rpr Loss: 0.9999974966049194, Last lagvar Loss: 0.8555539846420288\n",
      "Step 4788/10000- lr: [5.2626452121212124e-06] - Loss total: 2.6900482177734375, Last rpr Loss: 0.9999735355377197, Last lagvar Loss: 0.8555095195770264\n",
      "Step 4789/10000- lr: [5.261635115151516e-06] - Loss total: 2.6899516582489014, Last rpr Loss: 0.9999648928642273, Last lagvar Loss: 0.8554360866546631\n",
      "Step 4790/10000- lr: [5.260625018181818e-06] - Loss total: 2.6898529529571533, Last rpr Loss: 0.9999744296073914, Last lagvar Loss: 0.8553333878517151\n",
      "Step 4791/10000- lr: [5.2596149212121214e-06] - Loss total: 2.689753770828247, Last rpr Loss: 1.0000202655792236, Last lagvar Loss: 0.8551896810531616\n",
      "Step 4792/10000- lr: [5.258604824242425e-06] - Loss total: 2.6896533966064453, Last rpr Loss: 1.0001012086868286, Last lagvar Loss: 0.8550127744674683\n",
      "Step 4793/10000- lr: [5.257594727272727e-06] - Loss total: 2.6895527839660645, Last rpr Loss: 1.0001741647720337, Last lagvar Loss: 0.8548500537872314\n",
      "Step 4794/10000- lr: [5.25658463030303e-06] - Loss total: 2.689451217651367, Last rpr Loss: 1.0002422332763672, Last lagvar Loss: 0.8546993732452393\n",
      "Step 4795/10000- lr: [5.255574533333334e-06] - Loss total: 2.689347982406616, Last rpr Loss: 1.0002567768096924, Last lagvar Loss: 0.8546094298362732\n",
      "Step 4796/10000- lr: [5.254564436363636e-06] - Loss total: 2.6892428398132324, Last rpr Loss: 1.0002386569976807, Last lagvar Loss: 0.854559063911438\n",
      "Step 4797/10000- lr: [5.253554339393939e-06] - Loss total: 2.6891353130340576, Last rpr Loss: 1.0001907348632812, Last lagvar Loss: 0.8545453548431396\n",
      "Step 4798/10000- lr: [5.252544242424243e-06] - Loss total: 2.68902587890625, Last rpr Loss: 1.000127911567688, Last lagvar Loss: 0.8545539975166321\n",
      "Step 4799/10000- lr: [5.251534145454546e-06] - Loss total: 2.6889164447784424, Last rpr Loss: 1.0000579357147217, Last lagvar Loss: 0.8545772433280945\n",
      "Step 4800/10000- lr: [5.250524048484848e-06] - Loss total: 2.688807725906372, Last rpr Loss: 1.0000094175338745, Last lagvar Loss: 0.8545858263969421\n",
      "Step 4801/10000- lr: [5.249513951515152e-06] - Loss total: 2.6887006759643555, Last rpr Loss: 0.9999790191650391, Last lagvar Loss: 0.8545815348625183\n",
      "Step 4802/10000- lr: [5.248503854545455e-06] - Loss total: 2.6885950565338135, Last rpr Loss: 0.9999763369560242, Last lagvar Loss: 0.8545513153076172\n",
      "Step 4803/10000- lr: [5.247493757575757e-06] - Loss total: 2.688490390777588, Last rpr Loss: 0.9999870657920837, Last lagvar Loss: 0.8545055985450745\n",
      "Step 4804/10000- lr: [5.246483660606061e-06] - Loss total: 2.6883857250213623, Last rpr Loss: 1.0000147819519043, Last lagvar Loss: 0.854437530040741\n",
      "Step 4805/10000- lr: [5.245473563636364e-06] - Loss total: 2.688281297683716, Last rpr Loss: 1.0000178813934326, Last lagvar Loss: 0.8543883562088013\n",
      "Step 4806/10000- lr: [5.244463466666666e-06] - Loss total: 2.688175678253174, Last rpr Loss: 1.0000035762786865, Last lagvar Loss: 0.8543517589569092\n",
      "Step 4807/10000- lr: [5.24345336969697e-06] - Loss total: 2.688070058822632, Last rpr Loss: 0.9999656677246094, Last lagvar Loss: 0.8543362617492676\n",
      "Step 4808/10000- lr: [5.242443272727273e-06] - Loss total: 2.687964916229248, Last rpr Loss: 0.9999240636825562, Last lagvar Loss: 0.8543241024017334\n",
      "Step 4809/10000- lr: [5.241433175757576e-06] - Loss total: 2.687859296798706, Last rpr Loss: 0.9999099969863892, Last lagvar Loss: 0.854285478591919\n",
      "Step 4810/10000- lr: [5.240423078787879e-06] - Loss total: 2.6877541542053223, Last rpr Loss: 0.9999266266822815, Last lagvar Loss: 0.8542181253433228\n",
      "Step 4811/10000- lr: [5.239412981818182e-06] - Loss total: 2.6876494884490967, Last rpr Loss: 0.9999645948410034, Last lagvar Loss: 0.8541316986083984\n",
      "Step 4812/10000- lr: [5.238402884848485e-06] - Loss total: 2.68754506111145, Last rpr Loss: 1.0000133514404297, Last lagvar Loss: 0.8540366888046265\n",
      "Step 4813/10000- lr: [5.237392787878788e-06] - Loss total: 2.687441349029541, Last rpr Loss: 1.000040054321289, Last lagvar Loss: 0.8539658784866333\n",
      "Step 4814/10000- lr: [5.236382690909091e-06] - Loss total: 2.68733811378479, Last rpr Loss: 1.0000580549240112, Last lagvar Loss: 0.853905439376831\n",
      "Step 4815/10000- lr: [5.235372593939394e-06] - Loss total: 2.6872358322143555, Last rpr Loss: 1.0000436305999756, Last lagvar Loss: 0.8538790345191956\n",
      "Step 4816/10000- lr: [5.234362496969697e-06] - Loss total: 2.687133312225342, Last rpr Loss: 1.0000299215316772, Last lagvar Loss: 0.8538534641265869\n",
      "Step 4817/10000- lr: [5.2333524e-06] - Loss total: 2.6870312690734863, Last rpr Loss: 1.0000088214874268, Last lagvar Loss: 0.8538362979888916\n",
      "Step 4818/10000- lr: [5.232342303030303e-06] - Loss total: 2.686929225921631, Last rpr Loss: 0.9999899864196777, Last lagvar Loss: 0.8538180589675903\n",
      "Step 4819/10000- lr: [5.231332206060606e-06] - Loss total: 2.686828374862671, Last rpr Loss: 0.999993085861206, Last lagvar Loss: 0.8537784814834595\n",
      "Step 4820/10000- lr: [5.230322109090909e-06] - Loss total: 2.6867268085479736, Last rpr Loss: 0.9999862313270569, Last lagvar Loss: 0.8537495732307434\n",
      "Step 4821/10000- lr: [5.229312012121212e-06] - Loss total: 2.6866257190704346, Last rpr Loss: 0.9999985694885254, Last lagvar Loss: 0.8537020087242126\n",
      "Step 4822/10000- lr: [5.228301915151515e-06] - Loss total: 2.6865246295928955, Last rpr Loss: 0.9999784231185913, Last lagvar Loss: 0.8536873459815979\n",
      "Step 4823/10000- lr: [5.227291818181818e-06] - Loss total: 2.6864235401153564, Last rpr Loss: 0.9999852180480957, Last lagvar Loss: 0.8536461591720581\n",
      "Step 4824/10000- lr: [5.226281721212121e-06] - Loss total: 2.6863224506378174, Last rpr Loss: 0.9999772906303406, Last lagvar Loss: 0.8536198139190674\n",
      "Step 4825/10000- lr: [5.225271624242424e-06] - Loss total: 2.6862213611602783, Last rpr Loss: 0.9999898076057434, Last lagvar Loss: 0.8535729646682739\n",
      "Step 4826/10000- lr: [5.224261527272727e-06] - Loss total: 2.6861202716827393, Last rpr Loss: 1.0000046491622925, Last lagvar Loss: 0.8535237312316895\n",
      "Step 4827/10000- lr: [5.22325143030303e-06] - Loss total: 2.6860198974609375, Last rpr Loss: 1.0000063180923462, Last lagvar Loss: 0.853486955165863\n",
      "Step 4828/10000- lr: [5.222241333333333e-06] - Loss total: 2.6859190464019775, Last rpr Loss: 1.0000152587890625, Last lagvar Loss: 0.8534417152404785\n",
      "Step 4829/10000- lr: [5.221231236363637e-06] - Loss total: 2.6858179569244385, Last rpr Loss: 0.9999877214431763, Last lagvar Loss: 0.8534308671951294\n",
      "Step 4830/10000- lr: [5.220221139393939e-06] - Loss total: 2.6857171058654785, Last rpr Loss: 0.9999822974205017, Last lagvar Loss: 0.8533948659896851\n",
      "Step 4831/10000- lr: [5.219211042424242e-06] - Loss total: 2.685615062713623, Last rpr Loss: 0.9999598860740662, Last lagvar Loss: 0.8533707857131958\n",
      "Step 4832/10000- lr: [5.218200945454546e-06] - Loss total: 2.685511827468872, Last rpr Loss: 0.9999454021453857, Last lagvar Loss: 0.8533318638801575\n",
      "Step 4833/10000- lr: [5.217190848484848e-06] - Loss total: 2.6854071617126465, Last rpr Loss: 0.9999562501907349, Last lagvar Loss: 0.853258490562439\n",
      "Step 4834/10000- lr: [5.216180751515151e-06] - Loss total: 2.68530011177063, Last rpr Loss: 0.9999504089355469, Last lagvar Loss: 0.8531917333602905\n",
      "Step 4835/10000- lr: [5.215170654545455e-06] - Loss total: 2.6851911544799805, Last rpr Loss: 0.9999839067459106, Last lagvar Loss: 0.8530781865119934\n",
      "Step 4836/10000- lr: [5.214160557575758e-06] - Loss total: 2.6850812435150146, Last rpr Loss: 0.9999996423721313, Last lagvar Loss: 0.8529815077781677\n",
      "Step 4837/10000- lr: [5.213150460606061e-06] - Loss total: 2.684971332550049, Last rpr Loss: 1.0000317096710205, Last lagvar Loss: 0.8528729677200317\n",
      "Step 4838/10000- lr: [5.2121403636363644e-06] - Loss total: 2.684861421585083, Last rpr Loss: 1.000003457069397, Last lagvar Loss: 0.8528310060501099\n",
      "Step 4839/10000- lr: [5.211130266666667e-06] - Loss total: 2.6847527027130127, Last rpr Loss: 0.9999873042106628, Last lagvar Loss: 0.8527816534042358\n",
      "Step 4840/10000- lr: [5.21012016969697e-06] - Loss total: 2.6846439838409424, Last rpr Loss: 0.9999412298202515, Last lagvar Loss: 0.8527652025222778\n",
      "Step 4841/10000- lr: [5.2091100727272734e-06] - Loss total: 2.6845359802246094, Last rpr Loss: 0.9999274015426636, Last lagvar Loss: 0.8527188897132874\n",
      "Step 4842/10000- lr: [5.208099975757576e-06] - Loss total: 2.6844279766082764, Last rpr Loss: 0.9999405145645142, Last lagvar Loss: 0.8526483774185181\n",
      "Step 4843/10000- lr: [5.207089878787879e-06] - Loss total: 2.6843206882476807, Last rpr Loss: 0.9999734163284302, Last lagvar Loss: 0.8525608777999878\n",
      "Step 4844/10000- lr: [5.206079781818182e-06] - Loss total: 2.684213638305664, Last rpr Loss: 1.0000096559524536, Last lagvar Loss: 0.852473258972168\n",
      "Step 4845/10000- lr: [5.205069684848485e-06] - Loss total: 2.6841070652008057, Last rpr Loss: 1.0000128746032715, Last lagvar Loss: 0.8524217009544373\n",
      "Step 4846/10000- lr: [5.204059587878788e-06] - Loss total: 2.6840012073516846, Last rpr Loss: 1.0000073909759521, Last lagvar Loss: 0.852381706237793\n",
      "Step 4847/10000- lr: [5.203049490909091e-06] - Loss total: 2.6838958263397217, Last rpr Loss: 0.9999834299087524, Last lagvar Loss: 0.8523629307746887\n",
      "Step 4848/10000- lr: [5.202039393939395e-06] - Loss total: 2.683790445327759, Last rpr Loss: 0.9999809265136719, Last lagvar Loss: 0.8523252010345459\n",
      "Step 4849/10000- lr: [5.201029296969697e-06] - Loss total: 2.683685541152954, Last rpr Loss: 0.9999890327453613, Last lagvar Loss: 0.852278470993042\n",
      "Step 4850/10000- lr: [5.2000192e-06] - Loss total: 2.6835808753967285, Last rpr Loss: 1.0000044107437134, Last lagvar Loss: 0.8522257208824158\n",
      "Step 4851/10000- lr: [5.199009103030304e-06] - Loss total: 2.683476209640503, Last rpr Loss: 1.0000213384628296, Last lagvar Loss: 0.8521718978881836\n",
      "Step 4852/10000- lr: [5.197999006060606e-06] - Loss total: 2.6833720207214355, Last rpr Loss: 1.0000019073486328, Last lagvar Loss: 0.8521538972854614\n",
      "Step 4853/10000- lr: [5.196988909090909e-06] - Loss total: 2.683267831802368, Last rpr Loss: 0.9999815225601196, Last lagvar Loss: 0.852135181427002\n",
      "Step 4854/10000- lr: [5.195978812121213e-06] - Loss total: 2.6831626892089844, Last rpr Loss: 0.9999370574951172, Last lagvar Loss: 0.8521378040313721\n",
      "Step 4855/10000- lr: [5.194968715151515e-06] - Loss total: 2.6830570697784424, Last rpr Loss: 0.9998979568481445, Last lagvar Loss: 0.8521308302879333\n",
      "Step 4856/10000- lr: [5.193958618181818e-06] - Loss total: 2.6829514503479004, Last rpr Loss: 0.9998641014099121, Last lagvar Loss: 0.8521132469177246\n",
      "Step 4857/10000- lr: [5.192948521212122e-06] - Loss total: 2.682845115661621, Last rpr Loss: 0.9998456239700317, Last lagvar Loss: 0.8520745635032654\n",
      "Step 4858/10000- lr: [5.191938424242425e-06] - Loss total: 2.682737350463867, Last rpr Loss: 0.9998451471328735, Last lagvar Loss: 0.8520119190216064\n",
      "Step 4859/10000- lr: [5.190928327272727e-06] - Loss total: 2.682629108428955, Last rpr Loss: 0.9998635649681091, Last lagvar Loss: 0.8519262671470642\n",
      "Step 4860/10000- lr: [5.189918230303031e-06] - Loss total: 2.6825191974639893, Last rpr Loss: 0.9999030828475952, Last lagvar Loss: 0.8518171310424805\n",
      "Step 4861/10000- lr: [5.188908133333334e-06] - Loss total: 2.6824090480804443, Last rpr Loss: 0.9999412894248962, Last lagvar Loss: 0.8517090082168579\n",
      "Step 4862/10000- lr: [5.187898036363636e-06] - Loss total: 2.682297945022583, Last rpr Loss: 0.9999789595603943, Last lagvar Loss: 0.85160231590271\n",
      "Step 4863/10000- lr: [5.18688793939394e-06] - Loss total: 2.682185649871826, Last rpr Loss: 1.0000088214874268, Last lagvar Loss: 0.8515045642852783\n",
      "Step 4864/10000- lr: [5.185877842424243e-06] - Loss total: 2.682072877883911, Last rpr Loss: 1.000028133392334, Last lagvar Loss: 0.851418673992157\n",
      "Step 4865/10000- lr: [5.184867745454545e-06] - Loss total: 2.6819589138031006, Last rpr Loss: 1.0000265836715698, Last lagvar Loss: 0.8513545989990234\n",
      "Step 4866/10000- lr: [5.183857648484849e-06] - Loss total: 2.681844472885132, Last rpr Loss: 1.0000048875808716, Last lagvar Loss: 0.851311445236206\n",
      "Step 4867/10000- lr: [5.182847551515152e-06] - Loss total: 2.6817290782928467, Last rpr Loss: 0.9999773502349854, Last lagvar Loss: 0.8512743711471558\n",
      "Step 4868/10000- lr: [5.181837454545455e-06] - Loss total: 2.6816132068634033, Last rpr Loss: 0.9999403357505798, Last lagvar Loss: 0.8512473106384277\n",
      "Step 4869/10000- lr: [5.1808273575757576e-06] - Loss total: 2.6814959049224854, Last rpr Loss: 0.9999416470527649, Last lagvar Loss: 0.8511823415756226\n",
      "Step 4870/10000- lr: [5.179817260606061e-06] - Loss total: 2.68137788772583, Last rpr Loss: 0.9999527931213379, Last lagvar Loss: 0.8511083126068115\n",
      "Step 4871/10000- lr: [5.178807163636364e-06] - Loss total: 2.6812589168548584, Last rpr Loss: 1.0000054836273193, Last lagvar Loss: 0.8509935140609741\n",
      "Step 4872/10000- lr: [5.1777970666666665e-06] - Loss total: 2.6811394691467285, Last rpr Loss: 1.0000331401824951, Last lagvar Loss: 0.8509045839309692\n",
      "Step 4873/10000- lr: [5.17678696969697e-06] - Loss total: 2.6810193061828613, Last rpr Loss: 1.000074863433838, Last lagvar Loss: 0.8508024215698242\n",
      "Step 4874/10000- lr: [5.175776872727273e-06] - Loss total: 2.6808996200561523, Last rpr Loss: 1.0000561475753784, Last lagvar Loss: 0.8507615327835083\n",
      "Step 4875/10000- lr: [5.1747667757575755e-06] - Loss total: 2.6807801723480225, Last rpr Loss: 1.0000494718551636, Last lagvar Loss: 0.8507091999053955\n",
      "Step 4876/10000- lr: [5.173756678787879e-06] - Loss total: 2.680661916732788, Last rpr Loss: 1.0000061988830566, Last lagvar Loss: 0.8506941795349121\n",
      "Step 4877/10000- lr: [5.172746581818182e-06] - Loss total: 2.6805450916290283, Last rpr Loss: 0.9999847412109375, Last lagvar Loss: 0.8506581783294678\n",
      "Step 4878/10000- lr: [5.171736484848485e-06] - Loss total: 2.680428981781006, Last rpr Loss: 0.9999732375144958, Last lagvar Loss: 0.8506134152412415\n",
      "Step 4879/10000- lr: [5.170726387878788e-06] - Loss total: 2.680314779281616, Last rpr Loss: 0.9999830722808838, Last lagvar Loss: 0.8505487442016602\n",
      "Step 4880/10000- lr: [5.169716290909091e-06] - Loss total: 2.680202007293701, Last rpr Loss: 1.0000046491622925, Last lagvar Loss: 0.8504740595817566\n",
      "Step 4881/10000- lr: [5.168706193939394e-06] - Loss total: 2.680091142654419, Last rpr Loss: 1.0000245571136475, Last lagvar Loss: 0.8504029512405396\n",
      "Step 4882/10000- lr: [5.167696096969697e-06] - Loss total: 2.679980993270874, Last rpr Loss: 1.0000340938568115, Last lagvar Loss: 0.8503443002700806\n",
      "Step 4883/10000- lr: [5.166686e-06] - Loss total: 2.6798717975616455, Last rpr Loss: 1.0000133514404297, Last lagvar Loss: 0.8503177762031555\n",
      "Step 4884/10000- lr: [5.165675903030303e-06] - Loss total: 2.6797642707824707, Last rpr Loss: 1.000000238418579, Last lagvar Loss: 0.8502855896949768\n",
      "Step 4885/10000- lr: [5.164665806060606e-06] - Loss total: 2.6796579360961914, Last rpr Loss: 0.9999817609786987, Last lagvar Loss: 0.8502607345581055\n",
      "Step 4886/10000- lr: [5.163655709090909e-06] - Loss total: 2.679551839828491, Last rpr Loss: 0.9999771118164062, Last lagvar Loss: 0.8502237796783447\n",
      "Step 4887/10000- lr: [5.162645612121212e-06] - Loss total: 2.6794469356536865, Last rpr Loss: 0.9999792575836182, Last lagvar Loss: 0.8501816987991333\n",
      "Step 4888/10000- lr: [5.161635515151516e-06] - Loss total: 2.6793432235717773, Last rpr Loss: 0.9999951124191284, Last lagvar Loss: 0.8501273989677429\n",
      "Step 4889/10000- lr: [5.160625418181818e-06] - Loss total: 2.6792397499084473, Last rpr Loss: 0.9999998807907104, Last lagvar Loss: 0.8500854969024658\n",
      "Step 4890/10000- lr: [5.159615321212121e-06] - Loss total: 2.6791374683380127, Last rpr Loss: 1.0000046491622925, Last lagvar Loss: 0.8500449061393738\n",
      "Step 4891/10000- lr: [5.1586052242424246e-06] - Loss total: 2.679035186767578, Last rpr Loss: 1.000001072883606, Last lagvar Loss: 0.8500136137008667\n",
      "Step 4892/10000- lr: [5.157595127272727e-06] - Loss total: 2.67893385887146, Last rpr Loss: 0.9999920129776001, Last lagvar Loss: 0.8499889373779297\n",
      "Step 4893/10000- lr: [5.15658503030303e-06] - Loss total: 2.678832769393921, Last rpr Loss: 0.9999823570251465, Last lagvar Loss: 0.8499656915664673\n",
      "Step 4894/10000- lr: [5.1555749333333336e-06] - Loss total: 2.6787326335906982, Last rpr Loss: 0.9999760985374451, Last lagvar Loss: 0.8499400019645691\n",
      "Step 4895/10000- lr: [5.154564836363636e-06] - Loss total: 2.6786324977874756, Last rpr Loss: 0.9999696612358093, Last lagvar Loss: 0.8499152660369873\n",
      "Step 4896/10000- lr: [5.153554739393939e-06] - Loss total: 2.6785330772399902, Last rpr Loss: 0.9999683499336243, Last lagvar Loss: 0.8498860597610474\n",
      "Step 4897/10000- lr: [5.1525446424242425e-06] - Loss total: 2.678433895111084, Last rpr Loss: 0.9999720454216003, Last lagvar Loss: 0.8498529195785522\n",
      "Step 4898/10000- lr: [5.151534545454546e-06] - Loss total: 2.678334951400757, Last rpr Loss: 0.9999856948852539, Last lagvar Loss: 0.8498104214668274\n",
      "Step 4899/10000- lr: [5.150524448484848e-06] - Loss total: 2.678236246109009, Last rpr Loss: 0.9999951720237732, Last lagvar Loss: 0.8497728109359741\n",
      "Step 4900/10000- lr: [5.1495143515151515e-06] - Loss total: 2.678138256072998, Last rpr Loss: 1.000010371208191, Last lagvar Loss: 0.8497300148010254\n",
      "Step 4901/10000- lr: [5.148504254545455e-06] - Loss total: 2.6780405044555664, Last rpr Loss: 1.000016689300537, Last lagvar Loss: 0.849696934223175\n",
      "Step 4902/10000- lr: [5.147494157575757e-06] - Loss total: 2.677942991256714, Last rpr Loss: 1.000025749206543, Last lagvar Loss: 0.8496615290641785\n",
      "Step 4903/10000- lr: [5.1464840606060605e-06] - Loss total: 2.6778459548950195, Last rpr Loss: 1.000014305114746, Last lagvar Loss: 0.8496469259262085\n",
      "Step 4904/10000- lr: [5.145473963636364e-06] - Loss total: 2.677748918533325, Last rpr Loss: 1.0000122785568237, Last lagvar Loss: 0.8496236205101013\n",
      "Step 4905/10000- lr: [5.144463866666666e-06] - Loss total: 2.67765212059021, Last rpr Loss: 1.0000038146972656, Last lagvar Loss: 0.8496071696281433\n",
      "Step 4906/10000- lr: [5.1434537696969695e-06] - Loss total: 2.6775553226470947, Last rpr Loss: 0.9999994039535522, Last lagvar Loss: 0.8495869040489197\n",
      "Step 4907/10000- lr: [5.142443672727273e-06] - Loss total: 2.677459239959717, Last rpr Loss: 0.9999912977218628, Last lagvar Loss: 0.8495706915855408\n",
      "Step 4908/10000- lr: [5.141433575757576e-06] - Loss total: 2.677363634109497, Last rpr Loss: 1.0000004768371582, Last lagvar Loss: 0.8495374321937561\n",
      "Step 4909/10000- lr: [5.1404234787878785e-06] - Loss total: 2.67726731300354, Last rpr Loss: 1.0000154972076416, Last lagvar Loss: 0.8494988679885864\n",
      "Step 4910/10000- lr: [5.139413381818182e-06] - Loss total: 2.6771717071533203, Last rpr Loss: 1.0000211000442505, Last lagvar Loss: 0.8494699001312256\n",
      "Step 4911/10000- lr: [5.138403284848485e-06] - Loss total: 2.6770758628845215, Last rpr Loss: 1.000028371810913, Last lagvar Loss: 0.849439263343811\n",
      "Step 4912/10000- lr: [5.1373931878787875e-06] - Loss total: 2.6769802570343018, Last rpr Loss: 1.0000324249267578, Last lagvar Loss: 0.849412202835083\n",
      "Step 4913/10000- lr: [5.136383090909091e-06] - Loss total: 2.676884651184082, Last rpr Loss: 1.0000231266021729, Last lagvar Loss: 0.8493989109992981\n",
      "Step 4914/10000- lr: [5.135372993939394e-06] - Loss total: 2.6767892837524414, Last rpr Loss: 1.0000239610671997, Last lagvar Loss: 0.8493756055831909\n",
      "Step 4915/10000- lr: [5.1343628969696964e-06] - Loss total: 2.6766936779022217, Last rpr Loss: 1.0000076293945312, Last lagvar Loss: 0.8493698835372925\n",
      "Step 4916/10000- lr: [5.1333528e-06] - Loss total: 2.676597833633423, Last rpr Loss: 1.0000271797180176, Last lagvar Loss: 0.8493281602859497\n",
      "Step 4917/10000- lr: [5.132342703030303e-06] - Loss total: 2.6765024662017822, Last rpr Loss: 0.9999960660934448, Last lagvar Loss: 0.8493375778198242\n",
      "Step 4918/10000- lr: [5.131332606060606e-06] - Loss total: 2.6764068603515625, Last rpr Loss: 1.0000349283218384, Last lagvar Loss: 0.8492772579193115\n",
      "Step 4919/10000- lr: [5.130322509090909e-06] - Loss total: 2.6763112545013428, Last rpr Loss: 0.9999934434890747, Last lagvar Loss: 0.8492974042892456\n",
      "Step 4920/10000- lr: [5.129312412121213e-06] - Loss total: 2.676215410232544, Last rpr Loss: 1.000049352645874, Last lagvar Loss: 0.8492203950881958\n",
      "Step 4921/10000- lr: [5.128302315151515e-06] - Loss total: 2.676119804382324, Last rpr Loss: 0.9999860525131226, Last lagvar Loss: 0.8492627143859863\n",
      "Step 4922/10000- lr: [5.1272922181818185e-06] - Loss total: 2.6760241985321045, Last rpr Loss: 1.0000627040863037, Last lagvar Loss: 0.8491650819778442\n",
      "Step 4923/10000- lr: [5.126282121212122e-06] - Loss total: 2.6759281158447266, Last rpr Loss: 0.999982476234436, Last lagvar Loss: 0.8492246866226196\n",
      "Step 4924/10000- lr: [5.125272024242424e-06] - Loss total: 2.675832509994507, Last rpr Loss: 1.0000782012939453, Last lagvar Loss: 0.8491082191467285\n",
      "Step 4925/10000- lr: [5.1242619272727275e-06] - Loss total: 2.675736904144287, Last rpr Loss: 0.9999746084213257, Last lagvar Loss: 0.8491913676261902\n",
      "Step 4926/10000- lr: [5.123251830303031e-06] - Loss total: 2.6756412982940674, Last rpr Loss: 1.000108003616333, Last lagvar Loss: 0.8490374088287354\n",
      "Step 4927/10000- lr: [5.122241733333334e-06] - Loss total: 2.6755454540252686, Last rpr Loss: 0.9999580979347229, Last lagvar Loss: 0.849166989326477\n",
      "Step 4928/10000- lr: [5.1212316363636365e-06] - Loss total: 2.675450086593628, Last rpr Loss: 1.0001293420791626, Last lagvar Loss: 0.8489753007888794\n",
      "Step 4929/10000- lr: [5.12022153939394e-06] - Loss total: 2.675354480743408, Last rpr Loss: 0.9999212622642517, Last lagvar Loss: 0.849163293838501\n",
      "Step 4930/10000- lr: [5.119211442424243e-06] - Loss total: 2.6752588748931885, Last rpr Loss: 1.000164270401001, Last lagvar Loss: 0.8488998413085938\n",
      "Step 4931/10000- lr: [5.1182013454545455e-06] - Loss total: 2.6751632690429688, Last rpr Loss: 0.9998655319213867, Last lagvar Loss: 0.8491787910461426\n",
      "Step 4932/10000- lr: [5.117191248484849e-06] - Loss total: 2.675067186355591, Last rpr Loss: 1.000216007232666, Last lagvar Loss: 0.8488079309463501\n",
      "Step 4933/10000- lr: [5.116181151515152e-06] - Loss total: 2.6749725341796875, Last rpr Loss: 0.9997872114181519, Last lagvar Loss: 0.8492175340652466\n",
      "Step 4934/10000- lr: [5.1151710545454545e-06] - Loss total: 2.6748764514923096, Last rpr Loss: 1.000306487083435, Last lagvar Loss: 0.8486779928207397\n",
      "Step 4935/10000- lr: [5.114160957575758e-06] - Loss total: 2.67478084564209, Last rpr Loss: 0.9996745586395264, Last lagvar Loss: 0.849291205406189\n",
      "Step 4936/10000- lr: [5.113150860606061e-06] - Loss total: 2.6746857166290283, Last rpr Loss: 1.0004597902297974, Last lagvar Loss: 0.8484857678413391\n",
      "Step 4937/10000- lr: [5.112140763636364e-06] - Loss total: 2.6745903491973877, Last rpr Loss: 0.9994962811470032, Last lagvar Loss: 0.8494315147399902\n",
      "Step 4938/10000- lr: [5.111130666666667e-06] - Loss total: 2.674495220184326, Last rpr Loss: 1.0006859302520752, Last lagvar Loss: 0.8482217788696289\n",
      "Step 4939/10000- lr: [5.11012056969697e-06] - Loss total: 2.6744000911712646, Last rpr Loss: 0.9992040395736694, Last lagvar Loss: 0.8496870994567871\n",
      "Step 4940/10000- lr: [5.109110472727273e-06] - Loss total: 2.674304962158203, Last rpr Loss: 1.0010627508163452, Last lagvar Loss: 0.8478085398674011\n",
      "Step 4941/10000- lr: [5.108100375757576e-06] - Loss total: 2.6742103099823, Last rpr Loss: 0.998732328414917, Last lagvar Loss: 0.850124716758728\n",
      "Step 4942/10000- lr: [5.107090278787879e-06] - Loss total: 2.6741161346435547, Last rpr Loss: 1.001658320426941, Last lagvar Loss: 0.847179114818573\n",
      "Step 4943/10000- lr: [5.106080181818182e-06] - Loss total: 2.674023389816284, Last rpr Loss: 0.9979627132415771, Last lagvar Loss: 0.8508644104003906\n",
      "Step 4944/10000- lr: [5.105070084848485e-06] - Loss total: 2.673931121826172, Last rpr Loss: 1.002640724182129, Last lagvar Loss: 0.846167802810669\n",
      "Step 4945/10000- lr: [5.104059987878788e-06] - Loss total: 2.6738414764404297, Last rpr Loss: 0.9966915845870972, Last lagvar Loss: 0.852114737033844\n",
      "Step 4946/10000- lr: [5.103049890909091e-06] - Loss total: 2.6737558841705322, Last rpr Loss: 1.0042804479599, Last lagvar Loss: 0.8445116281509399\n",
      "Step 4947/10000- lr: [5.1020397939393945e-06] - Loss total: 2.673678398132324, Last rpr Loss: 0.9945741891860962, Last lagvar Loss: 0.8542332649230957\n",
      "Step 4948/10000- lr: [5.101029696969697e-06] - Loss total: 2.673609972000122, Last rpr Loss: 1.007013201713562, Last lagvar Loss: 0.8417925834655762\n",
      "Step 4949/10000- lr: [5.1000196e-06] - Loss total: 2.6735668182373047, Last rpr Loss: 0.9910253286361694, Last lagvar Loss: 0.8578407764434814\n",
      "Step 4950/10000- lr: [5.0990095030303035e-06] - Loss total: 2.673543691635132, Last rpr Loss: 1.011584758758545, Last lagvar Loss: 0.8373154401779175\n",
      "Step 4951/10000- lr: [5.097999406060606e-06] - Loss total: 2.6736011505126953, Last rpr Loss: 0.9851787090301514, Last lagvar Loss: 0.8638996481895447\n",
      "Step 4952/10000- lr: [5.096989309090909e-06] - Loss total: 2.673682928085327, Last rpr Loss: 1.0189509391784668, Last lagvar Loss: 0.830244243144989\n",
      "Step 4953/10000- lr: [5.0959792121212125e-06] - Loss total: 2.6739983558654785, Last rpr Loss: 0.9760987162590027, Last lagvar Loss: 0.8735666275024414\n",
      "Step 4954/10000- lr: [5.094969115151515e-06] - Loss total: 2.674217700958252, Last rpr Loss: 1.0295473337173462, Last lagvar Loss: 0.820325493812561\n",
      "Step 4955/10000- lr: [5.093959018181818e-06] - Loss total: 2.6743791103363037, Last rpr Loss: 0.9695159196853638, Last lagvar Loss: 0.880678653717041\n",
      "Step 4956/10000- lr: [5.0929489212121215e-06] - Loss total: 2.673447847366333, Last rpr Loss: 1.0223888158798218, Last lagvar Loss: 0.8267444372177124\n",
      "Step 4957/10000- lr: [5.091938824242425e-06] - Loss total: 2.672945976257324, Last rpr Loss: 0.98478102684021, Last lagvar Loss: 0.863925576210022\n",
      "Step 4958/10000- lr: [5.090928727272727e-06] - Loss total: 2.6725809574127197, Last rpr Loss: 1.0077173709869385, Last lagvar Loss: 0.8406106233596802\n",
      "Step 4959/10000- lr: [5.0899186303030305e-06] - Loss total: 2.6723930835723877, Last rpr Loss: 0.9998927116394043, Last lagvar Loss: 0.8482941389083862\n",
      "Step 4960/10000- lr: [5.088908533333334e-06] - Loss total: 2.6723344326019287, Last rpr Loss: 0.9946388006210327, Last lagvar Loss: 0.8535370826721191\n",
      "Step 4961/10000- lr: [5.087898436363636e-06] - Loss total: 2.6723623275756836, Last rpr Loss: 1.011545181274414, Last lagvar Loss: 0.8367035388946533\n",
      "Step 4962/10000- lr: [5.0868883393939395e-06] - Loss total: 2.6724703311920166, Last rpr Loss: 0.9843190908432007, Last lagvar Loss: 0.864132285118103\n",
      "Step 4963/10000- lr: [5.085878242424243e-06] - Loss total: 2.672539234161377, Last rpr Loss: 1.0186033248901367, Last lagvar Loss: 0.8299432992935181\n",
      "Step 4964/10000- lr: [5.084868145454545e-06] - Loss total: 2.672710657119751, Last rpr Loss: 0.9771007299423218, Last lagvar Loss: 0.8717484474182129\n",
      "Step 4965/10000- lr: [5.0838580484848484e-06] - Loss total: 2.6726388931274414, Last rpr Loss: 1.0244877338409424, Last lagvar Loss: 0.8242802023887634\n",
      "Step 4966/10000- lr: [5.082847951515152e-06] - Loss total: 2.672682762145996, Last rpr Loss: 0.9748367071151733, Last lagvar Loss: 0.8740969896316528\n",
      "Step 4967/10000- lr: [5.081837854545455e-06] - Loss total: 2.672363042831421, Last rpr Loss: 1.0243194103240967, Last lagvar Loss: 0.8242975473403931\n",
      "Step 4968/10000- lr: [5.0808277575757574e-06] - Loss total: 2.6721298694610596, Last rpr Loss: 0.9800626039505005, Last lagvar Loss: 0.8684260845184326\n",
      "Step 4969/10000- lr: [5.079817660606061e-06] - Loss total: 2.671725273132324, Last rpr Loss: 1.0154458284378052, Last lagvar Loss: 0.8326466083526611\n",
      "Step 4970/10000- lr: [5.078807563636364e-06] - Loss total: 2.671422243118286, Last rpr Loss: 0.9904442429542542, Last lagvar Loss: 0.8574352264404297\n",
      "Step 4971/10000- lr: [5.077797466666666e-06] - Loss total: 2.6712021827697754, Last rpr Loss: 1.0033979415893555, Last lagvar Loss: 0.8443084955215454\n",
      "Step 4972/10000- lr: [5.07678736969697e-06] - Loss total: 2.671097755432129, Last rpr Loss: 1.0024287700653076, Last lagvar Loss: 0.845248281955719\n",
      "Step 4973/10000- lr: [5.075777272727273e-06] - Loss total: 2.671079158782959, Last rpr Loss: 0.9921852946281433, Last lagvar Loss: 0.8555653095245361\n",
      "Step 4974/10000- lr: [5.074767175757575e-06] - Loss total: 2.6710848808288574, Last rpr Loss: 1.0118577480316162, Last lagvar Loss: 0.835966169834137\n",
      "Step 4975/10000- lr: [5.073757078787879e-06] - Loss total: 2.671096086502075, Last rpr Loss: 0.9858645796775818, Last lagvar Loss: 0.8620736598968506\n",
      "Step 4976/10000- lr: [5.072746981818182e-06] - Loss total: 2.6710104942321777, Last rpr Loss: 1.0151768922805786, Last lagvar Loss: 0.8327322006225586\n",
      "Step 4977/10000- lr: [5.071736884848485e-06] - Loss total: 2.6709091663360596, Last rpr Loss: 0.9855576753616333, Last lagvar Loss: 0.8623542785644531\n",
      "Step 4978/10000- lr: [5.070726787878788e-06] - Loss total: 2.6707119941711426, Last rpr Loss: 1.0125014781951904, Last lagvar Loss: 0.835250735282898\n",
      "Step 4979/10000- lr: [5.069716690909091e-06] - Loss total: 2.6705257892608643, Last rpr Loss: 0.9904528856277466, Last lagvar Loss: 0.857191801071167\n",
      "Step 4980/10000- lr: [5.068706593939394e-06] - Loss total: 2.670341730117798, Last rpr Loss: 1.0060479640960693, Last lagvar Loss: 0.8414521217346191\n",
      "Step 4981/10000- lr: [5.067696496969697e-06] - Loss total: 2.6702017784118652, Last rpr Loss: 0.998021125793457, Last lagvar Loss: 0.8493897914886475\n",
      "Step 4982/10000- lr: [5.0666864e-06] - Loss total: 2.670104742050171, Last rpr Loss: 0.9983247518539429, Last lagvar Loss: 0.8490346074104309\n",
      "Step 4983/10000- lr: [5.065676303030303e-06] - Loss total: 2.67004132270813, Last rpr Loss: 1.0047197341918945, Last lagvar Loss: 0.8426203727722168\n",
      "Step 4984/10000- lr: [5.064666206060606e-06] - Loss total: 2.6699936389923096, Last rpr Loss: 0.9923866987228394, Last lagvar Loss: 0.8549617528915405\n",
      "Step 4985/10000- lr: [5.063656109090909e-06] - Loss total: 2.669934034347534, Last rpr Loss: 1.0085194110870361, Last lagvar Loss: 0.8388186693191528\n",
      "Step 4986/10000- lr: [5.062646012121212e-06] - Loss total: 2.669865369796753, Last rpr Loss: 0.9905200600624084, Last lagvar Loss: 0.8568178415298462\n",
      "Step 4987/10000- lr: [5.0616359151515155e-06] - Loss total: 2.6697611808776855, Last rpr Loss: 1.0091590881347656, Last lagvar Loss: 0.8381296992301941\n",
      "Step 4988/10000- lr: [5.060625818181818e-06] - Loss total: 2.669649839401245, Last rpr Loss: 0.9921941757202148, Last lagvar Loss: 0.8550498485565186\n",
      "Step 4989/10000- lr: [5.059615721212121e-06] - Loss total: 2.6695218086242676, Last rpr Loss: 1.006950855255127, Last lagvar Loss: 0.840228259563446\n",
      "Step 4990/10000- lr: [5.0586056242424244e-06] - Loss total: 2.669400691986084, Last rpr Loss: 0.9957749247550964, Last lagvar Loss: 0.8513519167900085\n",
      "Step 4991/10000- lr: [5.057595527272727e-06] - Loss total: 2.6692898273468018, Last rpr Loss: 1.0023140907287598, Last lagvar Loss: 0.844767689704895\n",
      "Step 4992/10000- lr: [5.05658543030303e-06] - Loss total: 2.669193744659424, Last rpr Loss: 0.9998770952224731, Last lagvar Loss: 0.8471789360046387\n",
      "Step 4993/10000- lr: [5.0555753333333334e-06] - Loss total: 2.66910982131958, Last rpr Loss: 0.9978474378585815, Last lagvar Loss: 0.8491964936256409\n",
      "Step 4994/10000- lr: [5.054565236363637e-06] - Loss total: 2.669034242630005, Last rpr Loss: 1.0032541751861572, Last lagvar Loss: 0.8437818288803101\n",
      "Step 4995/10000- lr: [5.053555139393939e-06] - Loss total: 2.6689605712890625, Last rpr Loss: 0.9952009916305542, Last lagvar Loss: 0.8518374562263489\n",
      "Step 4996/10000- lr: [5.052545042424242e-06] - Loss total: 2.668882131576538, Last rpr Loss: 1.0052921772003174, Last lagvar Loss: 0.8417351245880127\n",
      "Step 4997/10000- lr: [5.051534945454546e-06] - Loss total: 2.668799638748169, Last rpr Loss: 0.994337797164917, Last lagvar Loss: 0.8526812195777893\n",
      "Step 4998/10000- lr: [5.050524848484848e-06] - Loss total: 2.668708086013794, Last rpr Loss: 1.0057013034820557, Last lagvar Loss: 0.8412941098213196\n",
      "Step 4999/10000- lr: [5.049514751515151e-06] - Loss total: 2.6686129570007324, Last rpr Loss: 0.9952492117881775, Last lagvar Loss: 0.851723849773407\n",
      "Step 5000/10000- lr: [5.048504654545455e-06] - Loss total: 2.668513298034668, Last rpr Loss: 1.004276156425476, Last lagvar Loss: 0.8426666855812073\n",
      "Step 5001/10000- lr: [5.047494557575757e-06] - Loss total: 2.6684157848358154, Last rpr Loss: 0.9970705509185791, Last lagvar Loss: 0.8498479127883911\n",
      "Step 5002/10000- lr: [5.04648446060606e-06] - Loss total: 2.6683201789855957, Last rpr Loss: 1.0019373893737793, Last lagvar Loss: 0.8449546098709106\n",
      "Step 5003/10000- lr: [5.045474363636364e-06] - Loss total: 2.6682286262512207, Last rpr Loss: 0.9991835951805115, Last lagvar Loss: 0.8476901054382324\n",
      "Step 5004/10000- lr: [5.044464266666667e-06] - Loss total: 2.6681413650512695, Last rpr Loss: 0.9996548295021057, Last lagvar Loss: 0.8472033739089966\n",
      "Step 5005/10000- lr: [5.043454169696969e-06] - Loss total: 2.6680572032928467, Last rpr Loss: 1.0012006759643555, Last lagvar Loss: 0.845644474029541\n",
      "Step 5006/10000- lr: [5.0424440727272735e-06] - Loss total: 2.6679747104644775, Last rpr Loss: 0.9978804588317871, Last lagvar Loss: 0.8489563465118408\n",
      "Step 5007/10000- lr: [5.041433975757576e-06] - Loss total: 2.6678924560546875, Last rpr Loss: 1.0026276111602783, Last lagvar Loss: 0.8441972732543945\n",
      "Step 5008/10000- lr: [5.040423878787879e-06] - Loss total: 2.6678097248077393, Last rpr Loss: 0.9969408512115479, Last lagvar Loss: 0.8498765230178833\n",
      "Step 5009/10000- lr: [5.0394137818181825e-06] - Loss total: 2.6677258014678955, Last rpr Loss: 1.0033020973205566, Last lagvar Loss: 0.8435014486312866\n",
      "Step 5010/10000- lr: [5.038403684848485e-06] - Loss total: 2.667639970779419, Last rpr Loss: 0.9969212412834167, Last lagvar Loss: 0.8498715162277222\n",
      "Step 5011/10000- lr: [5.037393587878788e-06] - Loss total: 2.667552947998047, Last rpr Loss: 1.0032204389572144, Last lagvar Loss: 0.8435556888580322\n",
      "Step 5012/10000- lr: [5.0363834909090915e-06] - Loss total: 2.6674649715423584, Last rpr Loss: 0.9973323941230774, Last lagvar Loss: 0.8494305610656738\n",
      "Step 5013/10000- lr: [5.035373393939394e-06] - Loss total: 2.667376756668091, Last rpr Loss: 1.002508282661438, Last lagvar Loss: 0.844237208366394\n",
      "Step 5014/10000- lr: [5.034363296969697e-06] - Loss total: 2.6672885417938232, Last rpr Loss: 0.9980348348617554, Last lagvar Loss: 0.8486976027488708\n",
      "Step 5015/10000- lr: [5.0333532000000004e-06] - Loss total: 2.667201042175293, Last rpr Loss: 1.0014212131500244, Last lagvar Loss: 0.8452949523925781\n",
      "Step 5016/10000- lr: [5.032343103030304e-06] - Loss total: 2.6671142578125, Last rpr Loss: 0.9989862442016602, Last lagvar Loss: 0.8477175235748291\n",
      "Step 5017/10000- lr: [5.031333006060606e-06] - Loss total: 2.6670284271240234, Last rpr Loss: 1.0004254579544067, Last lagvar Loss: 0.8462650179862976\n",
      "Step 5018/10000- lr: [5.0303229090909094e-06] - Loss total: 2.6669437885284424, Last rpr Loss: 0.9999363422393799, Last lagvar Loss: 0.8467423915863037\n",
      "Step 5019/10000- lr: [5.029312812121213e-06] - Loss total: 2.6668593883514404, Last rpr Loss: 0.9996954798698425, Last lagvar Loss: 0.8469722270965576\n",
      "Step 5020/10000- lr: [5.028302715151515e-06] - Loss total: 2.6667754650115967, Last rpr Loss: 1.0008147954940796, Last lagvar Loss: 0.8458420038223267\n",
      "Step 5021/10000- lr: [5.027292618181818e-06] - Loss total: 2.666692018508911, Last rpr Loss: 0.9990748167037964, Last lagvar Loss: 0.8475723266601562\n",
      "Step 5022/10000- lr: [5.026282521212122e-06] - Loss total: 2.6666088104248047, Last rpr Loss: 1.0013906955718994, Last lagvar Loss: 0.845245897769928\n",
      "Step 5023/10000- lr: [5.025272424242424e-06] - Loss total: 2.666525363922119, Last rpr Loss: 0.9986052513122559, Last lagvar Loss: 0.8480222821235657\n",
      "Step 5024/10000- lr: [5.024262327272727e-06] - Loss total: 2.6664421558380127, Last rpr Loss: 1.00162935256958, Last lagvar Loss: 0.844987154006958\n",
      "Step 5025/10000- lr: [5.023252230303031e-06] - Loss total: 2.6663591861724854, Last rpr Loss: 0.9983240365982056, Last lagvar Loss: 0.848284125328064\n",
      "Step 5026/10000- lr: [5.022242133333334e-06] - Loss total: 2.666276216506958, Last rpr Loss: 1.001732587814331, Last lagvar Loss: 0.8448641896247864\n",
      "Step 5027/10000- lr: [5.021232036363636e-06] - Loss total: 2.6661927700042725, Last rpr Loss: 0.9982073307037354, Last lagvar Loss: 0.8483811616897583\n",
      "Step 5028/10000- lr: [5.02022193939394e-06] - Loss total: 2.666109323501587, Last rpr Loss: 1.0017520189285278, Last lagvar Loss: 0.8448249101638794\n",
      "Step 5029/10000- lr: [5.019211842424243e-06] - Loss total: 2.6660263538360596, Last rpr Loss: 0.9982643723487854, Last lagvar Loss: 0.8483041524887085\n",
      "Step 5030/10000- lr: [5.018201745454545e-06] - Loss total: 2.6659433841705322, Last rpr Loss: 1.0017191171646118, Last lagvar Loss: 0.8448383212089539\n",
      "Step 5031/10000- lr: [5.017191648484849e-06] - Loss total: 2.665860176086426, Last rpr Loss: 0.9984093904495239, Last lagvar Loss: 0.8481394648551941\n",
      "Step 5032/10000- lr: [5.016181551515152e-06] - Loss total: 2.6657769680023193, Last rpr Loss: 1.0016498565673828, Last lagvar Loss: 0.8448882102966309\n",
      "Step 5033/10000- lr: [5.015171454545454e-06] - Loss total: 2.66569447517395, Last rpr Loss: 0.9985232353210449, Last lagvar Loss: 0.8480064868927002\n",
      "Step 5034/10000- lr: [5.014161357575758e-06] - Loss total: 2.665611982345581, Last rpr Loss: 1.001542568206787, Last lagvar Loss: 0.8449768424034119\n",
      "Step 5035/10000- lr: [5.013151260606061e-06] - Loss total: 2.665529251098633, Last rpr Loss: 0.9985854625701904, Last lagvar Loss: 0.8479260206222534\n",
      "Step 5036/10000- lr: [5.012141163636364e-06] - Loss total: 2.6654467582702637, Last rpr Loss: 1.0014225244522095, Last lagvar Loss: 0.845078706741333\n",
      "Step 5037/10000- lr: [5.011131066666667e-06] - Loss total: 2.665364980697632, Last rpr Loss: 0.9986347556114197, Last lagvar Loss: 0.8478591442108154\n",
      "Step 5038/10000- lr: [5.01012096969697e-06] - Loss total: 2.665283203125, Last rpr Loss: 1.0013716220855713, Last lagvar Loss: 0.8451124429702759\n",
      "Step 5039/10000- lr: [5.009110872727273e-06] - Loss total: 2.665201425552368, Last rpr Loss: 0.9986388683319092, Last lagvar Loss: 0.8478380441665649\n",
      "Step 5040/10000- lr: [5.008100775757576e-06] - Loss total: 2.6651198863983154, Last rpr Loss: 1.0014172792434692, Last lagvar Loss: 0.8450502157211304\n",
      "Step 5041/10000- lr: [5.007090678787879e-06] - Loss total: 2.665038824081421, Last rpr Loss: 0.9986084699630737, Last lagvar Loss: 0.8478521108627319\n",
      "Step 5042/10000- lr: [5.006080581818182e-06] - Loss total: 2.6649580001831055, Last rpr Loss: 1.0015156269073486, Last lagvar Loss: 0.844935953617096\n",
      "Step 5043/10000- lr: [5.0050704848484846e-06] - Loss total: 2.664876937866211, Last rpr Loss: 0.9985076189041138, Last lagvar Loss: 0.8479376435279846\n",
      "Step 5044/10000- lr: [5.004060387878788e-06] - Loss total: 2.6647965908050537, Last rpr Loss: 1.0016847848892212, Last lagvar Loss: 0.8447519540786743\n",
      "Step 5045/10000- lr: [5.003050290909091e-06] - Loss total: 2.6647164821624756, Last rpr Loss: 0.9982578754425049, Last lagvar Loss: 0.8481732606887817\n",
      "Step 5046/10000- lr: [5.002040193939394e-06] - Loss total: 2.6646366119384766, Last rpr Loss: 1.0019490718841553, Last lagvar Loss: 0.8444737195968628\n",
      "Step 5047/10000- lr: [5.001030096969697e-06] - Loss total: 2.6645567417144775, Last rpr Loss: 0.9979060292243958, Last lagvar Loss: 0.8485122919082642\n",
      "Step 5048/10000- lr: [5.00002e-06] - Loss total: 2.664478302001953, Last rpr Loss: 1.0023486614227295, Last lagvar Loss: 0.8440617322921753\n",
      "Step 5049/10000- lr: [4.999009903030303e-06] - Loss total: 2.664400100708008, Last rpr Loss: 0.9974125623703003, Last lagvar Loss: 0.8489952683448792\n",
      "Step 5050/10000- lr: [4.997999806060606e-06] - Loss total: 2.6643226146698, Last rpr Loss: 1.0029563903808594, Last lagvar Loss: 0.8434444665908813\n",
      "Step 5051/10000- lr: [4.99698970909091e-06] - Loss total: 2.6642465591430664, Last rpr Loss: 0.9966882467269897, Last lagvar Loss: 0.8497124910354614\n",
      "Step 5052/10000- lr: [4.995979612121212e-06] - Loss total: 2.664170980453491, Last rpr Loss: 1.003844976425171, Last lagvar Loss: 0.8425507545471191\n",
      "Step 5053/10000- lr: [4.994969515151516e-06] - Loss total: 2.6640985012054443, Last rpr Loss: 0.9956570267677307, Last lagvar Loss: 0.850743293762207\n",
      "Step 5054/10000- lr: [4.993959418181818e-06] - Loss total: 2.664027452468872, Last rpr Loss: 1.0050922632217407, Last lagvar Loss: 0.8413064479827881\n",
      "Step 5055/10000- lr: [4.992949321212122e-06] - Loss total: 2.6639626026153564, Last rpr Loss: 0.9941593408584595, Last lagvar Loss: 0.8522530198097229\n",
      "Step 5056/10000- lr: [4.991939224242425e-06] - Loss total: 2.6638996601104736, Last rpr Loss: 1.0068800449371338, Last lagvar Loss: 0.8395376205444336\n",
      "Step 5057/10000- lr: [4.990929127272728e-06] - Loss total: 2.663849115371704, Last rpr Loss: 0.991996705532074, Last lagvar Loss: 0.8544518947601318\n",
      "Step 5058/10000- lr: [4.98991903030303e-06] - Loss total: 2.663801431655884, Last rpr Loss: 1.0094417333602905, Last lagvar Loss: 0.8370254039764404\n",
      "Step 5059/10000- lr: [4.988908933333334e-06] - Loss total: 2.6637794971466064, Last rpr Loss: 0.9889511466026306, Last lagvar Loss: 0.857580304145813\n",
      "Step 5060/10000- lr: [4.987898836363636e-06] - Loss total: 2.6637566089630127, Last rpr Loss: 1.0130258798599243, Last lagvar Loss: 0.8335475921630859\n",
      "Step 5061/10000- lr: [4.98688873939394e-06] - Loss total: 2.663789987564087, Last rpr Loss: 0.9847759008407593, Last lagvar Loss: 0.8619241714477539\n",
      "Step 5062/10000- lr: [4.985878642424243e-06] - Loss total: 2.6638023853302, Last rpr Loss: 1.0177891254425049, Last lagvar Loss: 0.8289841413497925\n",
      "Step 5063/10000- lr: [4.984868545454546e-06] - Loss total: 2.6639246940612793, Last rpr Loss: 0.9794861078262329, Last lagvar Loss: 0.8675134778022766\n",
      "Step 5064/10000- lr: [4.983858448484848e-06] - Loss total: 2.663952112197876, Last rpr Loss: 1.023385763168335, Last lagvar Loss: 0.8236947655677795\n",
      "Step 5065/10000- lr: [4.9828483515151524e-06] - Loss total: 2.664163112640381, Last rpr Loss: 0.9739350080490112, Last lagvar Loss: 0.8734725713729858\n",
      "Step 5066/10000- lr: [4.981838254545455e-06] - Loss total: 2.6641054153442383, Last rpr Loss: 1.0281270742416382, Last lagvar Loss: 0.8192592859268188\n",
      "Step 5067/10000- lr: [4.980828157575758e-06] - Loss total: 2.6642637252807617, Last rpr Loss: 0.9707080125808716, Last lagvar Loss: 0.8769572973251343\n",
      "Step 5068/10000- lr: [4.9798180606060606e-06] - Loss total: 2.6639671325683594, Last rpr Loss: 1.0286446809768677, Last lagvar Loss: 0.8187404870986938\n",
      "Step 5069/10000- lr: [4.978807963636364e-06] - Loss total: 2.6638317108154297, Last rpr Loss: 0.9736893177032471, Last lagvar Loss: 0.8736686110496521\n",
      "Step 5070/10000- lr: [4.977797866666666e-06] - Loss total: 2.6633615493774414, Last rpr Loss: 1.0218713283538818, Last lagvar Loss: 0.825034499168396\n",
      "Step 5071/10000- lr: [4.97678776969697e-06] - Loss total: 2.6630160808563232, Last rpr Loss: 0.9843470454216003, Last lagvar Loss: 0.8622995615005493\n",
      "Step 5072/10000- lr: [4.975777672727273e-06] - Loss total: 2.6626930236816406, Last rpr Loss: 1.0089354515075684, Last lagvar Loss: 0.8374335765838623\n",
      "Step 5073/10000- lr: [4.974767575757576e-06] - Loss total: 2.66251540184021, Last rpr Loss: 0.9985636472702026, Last lagvar Loss: 0.8477005958557129\n",
      "Step 5074/10000- lr: [4.9737574787878785e-06] - Loss total: 2.6624674797058105, Last rpr Loss: 0.9952596426010132, Last lagvar Loss: 0.851029634475708\n",
      "Step 5075/10000- lr: [4.972747381818183e-06] - Loss total: 2.662501811981201, Last rpr Loss: 1.0103089809417725, Last lagvar Loss: 0.8360855579376221\n",
      "Step 5076/10000- lr: [4.971737284848485e-06] - Loss total: 2.66257381439209, Last rpr Loss: 0.9857481718063354, Last lagvar Loss: 0.8608067035675049\n",
      "Step 5077/10000- lr: [4.970727187878788e-06] - Loss total: 2.66257381439209, Last rpr Loss: 1.0164176225662231, Last lagvar Loss: 0.8301990628242493\n",
      "Step 5078/10000- lr: [4.969717090909091e-06] - Loss total: 2.6625595092773438, Last rpr Loss: 0.9826751351356506, Last lagvar Loss: 0.8640155792236328\n",
      "Step 5079/10000- lr: [4.968706993939394e-06] - Loss total: 2.6624016761779785, Last rpr Loss: 1.0161420106887817, Last lagvar Loss: 0.830441415309906\n",
      "Step 5080/10000- lr: [4.9676968969696965e-06] - Loss total: 2.6622419357299805, Last rpr Loss: 0.9864180088043213, Last lagvar Loss: 0.8600869178771973\n",
      "Step 5081/10000- lr: [4.966686800000001e-06] - Loss total: 2.662036180496216, Last rpr Loss: 1.0100551843643188, Last lagvar Loss: 0.8362990617752075\n",
      "Step 5082/10000- lr: [4.965676703030303e-06] - Loss total: 2.661872148513794, Last rpr Loss: 0.9946110248565674, Last lagvar Loss: 0.8516528606414795\n",
      "Step 5083/10000- lr: [4.964666606060606e-06] - Loss total: 2.6617560386657715, Last rpr Loss: 1.001114845275879, Last lagvar Loss: 0.8450990915298462\n",
      "Step 5084/10000- lr: [4.963656509090909e-06] - Loss total: 2.661691665649414, Last rpr Loss: 1.0030403137207031, Last lagvar Loss: 0.8431800603866577\n",
      "Step 5085/10000- lr: [4.962646412121213e-06] - Loss total: 2.6616623401641846, Last rpr Loss: 0.9934612512588501, Last lagvar Loss: 0.8528057336807251\n",
      "Step 5086/10000- lr: [4.961636315151515e-06] - Loss total: 2.6616368293762207, Last rpr Loss: 1.0087413787841797, Last lagvar Loss: 0.8375684022903442\n",
      "Step 5087/10000- lr: [4.960626218181819e-06] - Loss total: 2.661604881286621, Last rpr Loss: 0.9896137714385986, Last lagvar Loss: 0.8567426800727844\n",
      "Step 5088/10000- lr: [4.959616121212121e-06] - Loss total: 2.6615312099456787, Last rpr Loss: 1.0105865001678467, Last lagvar Loss: 0.8357604742050171\n",
      "Step 5089/10000- lr: [4.958606024242424e-06] - Loss total: 2.6614434719085693, Last rpr Loss: 0.9901108741760254, Last lagvar Loss: 0.856224536895752\n",
      "Step 5090/10000- lr: [4.957595927272727e-06] - Loss total: 2.6613247394561768, Last rpr Loss: 1.0084360837936401, Last lagvar Loss: 0.8378430604934692\n",
      "Step 5091/10000- lr: [4.956585830303031e-06] - Loss total: 2.6612093448638916, Last rpr Loss: 0.9939674735069275, Last lagvar Loss: 0.8522714376449585\n",
      "Step 5092/10000- lr: [4.955575733333333e-06] - Loss total: 2.661100387573242, Last rpr Loss: 1.0036182403564453, Last lagvar Loss: 0.8425769805908203\n",
      "Step 5093/10000- lr: [4.9545656363636366e-06] - Loss total: 2.6610100269317627, Last rpr Loss: 0.999054491519928, Last lagvar Loss: 0.8471226692199707\n",
      "Step 5094/10000- lr: [4.953555539393939e-06] - Loss total: 2.660937786102295, Last rpr Loss: 0.9985117316246033, Last lagvar Loss: 0.8476641178131104\n",
      "Step 5095/10000- lr: [4.952545442424243e-06] - Loss total: 2.6608779430389404, Last rpr Loss: 1.0034377574920654, Last lagvar Loss: 0.8427469730377197\n",
      "Step 5096/10000- lr: [4.9515353454545456e-06] - Loss total: 2.660823345184326, Last rpr Loss: 0.9948654770851135, Last lagvar Loss: 0.8513405323028564\n",
      "Step 5097/10000- lr: [4.950525248484849e-06] - Loss total: 2.66076397895813, Last rpr Loss: 1.0060242414474487, Last lagvar Loss: 0.8401879072189331\n",
      "Step 5098/10000- lr: [4.949515151515151e-06] - Loss total: 2.660698890686035, Last rpr Loss: 0.9934704899787903, Last lagvar Loss: 0.8527532815933228\n",
      "Step 5099/10000- lr: [4.9485050545454545e-06] - Loss total: 2.660620927810669, Last rpr Loss: 1.0063786506652832, Last lagvar Loss: 0.8398319482803345\n",
      "Step 5100/10000- lr: [4.947494957575757e-06] - Loss total: 2.660538911819458, Last rpr Loss: 0.9943435192108154, Last lagvar Loss: 0.8518595099449158\n",
      "Step 5101/10000- lr: [4.946484860606061e-06] - Loss total: 2.660449981689453, Last rpr Loss: 1.004808783531189, Last lagvar Loss: 0.8413712978363037\n",
      "Step 5102/10000- lr: [4.9454747636363635e-06] - Loss total: 2.660362958908081, Last rpr Loss: 0.9966421723365784, Last lagvar Loss: 0.849523663520813\n",
      "Step 5103/10000- lr: [4.944464666666667e-06] - Loss total: 2.6602792739868164, Last rpr Loss: 1.0021600723266602, Last lagvar Loss: 0.8439893126487732\n",
      "Step 5104/10000- lr: [4.943454569696969e-06] - Loss total: 2.660200834274292, Last rpr Loss: 0.9993168711662292, Last lagvar Loss: 0.846825361251831\n",
      "Step 5105/10000- lr: [4.942444472727273e-06] - Loss total: 2.660127639770508, Last rpr Loss: 0.9993693828582764, Last lagvar Loss: 0.8467698693275452\n",
      "Step 5106/10000- lr: [4.941434375757576e-06] - Loss total: 2.6600582599639893, Last rpr Loss: 1.001650333404541, Last lagvar Loss: 0.8444883227348328\n",
      "Step 5107/10000- lr: [4.940424278787879e-06] - Loss total: 2.6599910259246826, Last rpr Loss: 0.9972505569458008, Last lagvar Loss: 0.8488937020301819\n",
      "Step 5108/10000- lr: [4.9394141818181815e-06] - Loss total: 2.6599228382110596, Last rpr Loss: 1.0032161474227905, Last lagvar Loss: 0.8429272174835205\n",
      "Step 5109/10000- lr: [4.938404084848485e-06] - Loss total: 2.6598544120788574, Last rpr Loss: 0.9962780475616455, Last lagvar Loss: 0.8498703241348267\n",
      "Step 5110/10000- lr: [4.937393987878787e-06] - Loss total: 2.659782648086548, Last rpr Loss: 1.0038256645202637, Last lagvar Loss: 0.8423172831535339\n",
      "Step 5111/10000- lr: [4.936383890909091e-06] - Loss total: 2.6597094535827637, Last rpr Loss: 0.9963682889938354, Last lagvar Loss: 0.8497745394706726\n",
      "Step 5112/10000- lr: [4.935373793939394e-06] - Loss total: 2.6596343517303467, Last rpr Loss: 1.0035182237625122, Last lagvar Loss: 0.8426157236099243\n",
      "Step 5113/10000- lr: [4.934363696969697e-06] - Loss total: 2.659557580947876, Last rpr Loss: 0.9971017241477966, Last lagvar Loss: 0.8490285277366638\n",
      "Step 5114/10000- lr: [4.9333535999999995e-06] - Loss total: 2.6594810485839844, Last rpr Loss: 1.0024733543395996, Last lagvar Loss: 0.8436472415924072\n",
      "Step 5115/10000- lr: [4.932343503030304e-06] - Loss total: 2.659405469894409, Last rpr Loss: 0.9981791973114014, Last lagvar Loss: 0.8479377031326294\n",
      "Step 5116/10000- lr: [4.931333406060606e-06] - Loss total: 2.659330129623413, Last rpr Loss: 1.0010976791381836, Last lagvar Loss: 0.8450122475624084\n",
      "Step 5117/10000- lr: [4.930323309090909e-06] - Loss total: 2.659257173538208, Last rpr Loss: 0.9993962049484253, Last lagvar Loss: 0.8467108607292175\n",
      "Step 5118/10000- lr: [4.929313212121212e-06] - Loss total: 2.659184217453003, Last rpr Loss: 0.9998711347579956, Last lagvar Loss: 0.8462328910827637\n",
      "Step 5119/10000- lr: [4.928303115151515e-06] - Loss total: 2.6591131687164307, Last rpr Loss: 1.0005486011505127, Last lagvar Loss: 0.8455530405044556\n",
      "Step 5120/10000- lr: [4.9272930181818174e-06] - Loss total: 2.6590416431427, Last rpr Loss: 0.9989731907844543, Last lagvar Loss: 0.8471280336380005\n",
      "Step 5121/10000- lr: [4.9262829212121216e-06] - Loss total: 2.658971071243286, Last rpr Loss: 1.0014491081237793, Last lagvar Loss: 0.8446497917175293\n",
      "Step 5122/10000- lr: [4.925272824242424e-06] - Loss total: 2.658900499343872, Last rpr Loss: 0.9983580708503723, Last lagvar Loss: 0.8477411270141602\n",
      "Step 5123/10000- lr: [4.924262727272727e-06] - Loss total: 2.6588289737701416, Last rpr Loss: 1.0019574165344238, Last lagvar Loss: 0.8441389203071594\n",
      "Step 5124/10000- lr: [4.92325263030303e-06] - Loss total: 2.6587584018707275, Last rpr Loss: 0.9980101585388184, Last lagvar Loss: 0.8480867147445679\n",
      "Step 5125/10000- lr: [4.922242533333334e-06] - Loss total: 2.6586861610412598, Last rpr Loss: 1.0020887851715088, Last lagvar Loss: 0.8440037965774536\n",
      "Step 5126/10000- lr: [4.921232436363636e-06] - Loss total: 2.6586148738861084, Last rpr Loss: 0.9979140758514404, Last lagvar Loss: 0.8481788635253906\n",
      "Step 5127/10000- lr: [4.9202223393939395e-06] - Loss total: 2.6585428714752197, Last rpr Loss: 1.0019872188568115, Last lagvar Loss: 0.8441008925437927\n",
      "Step 5128/10000- lr: [4.919212242424242e-06] - Loss total: 2.658470630645752, Last rpr Loss: 0.9980402588844299, Last lagvar Loss: 0.8480476140975952\n",
      "Step 5129/10000- lr: [4.918202145454545e-06] - Loss total: 2.658398389816284, Last rpr Loss: 1.0017752647399902, Last lagvar Loss: 0.8443078994750977\n",
      "Step 5130/10000- lr: [4.917192048484848e-06] - Loss total: 2.6583263874053955, Last rpr Loss: 0.9983260035514832, Last lagvar Loss: 0.8477563261985779\n",
      "Step 5131/10000- lr: [4.916181951515152e-06] - Loss total: 2.6582539081573486, Last rpr Loss: 1.0015068054199219, Last lagvar Loss: 0.8445712327957153\n",
      "Step 5132/10000- lr: [4.915171854545454e-06] - Loss total: 2.658181667327881, Last rpr Loss: 0.9986834526062012, Last lagvar Loss: 0.847393274307251\n",
      "Step 5133/10000- lr: [4.9141617575757575e-06] - Loss total: 2.6581099033355713, Last rpr Loss: 1.001205563545227, Last lagvar Loss: 0.8448672890663147\n",
      "Step 5134/10000- lr: [4.913151660606062e-06] - Loss total: 2.6580376625061035, Last rpr Loss: 0.9990060329437256, Last lagvar Loss: 0.847065806388855\n",
      "Step 5135/10000- lr: [4.912141563636364e-06] - Loss total: 2.657965898513794, Last rpr Loss: 1.0008957386016846, Last lagvar Loss: 0.8451728820800781\n",
      "Step 5136/10000- lr: [4.911131466666667e-06] - Loss total: 2.6578941345214844, Last rpr Loss: 0.9992707967758179, Last lagvar Loss: 0.8467967510223389\n",
      "Step 5137/10000- lr: [4.91012136969697e-06] - Loss total: 2.657822847366333, Last rpr Loss: 1.0006033182144165, Last lagvar Loss: 0.8454615473747253\n",
      "Step 5138/10000- lr: [4.909111272727273e-06] - Loss total: 2.6577513217926025, Last rpr Loss: 0.99949049949646, Last lagvar Loss: 0.8465733528137207\n",
      "Step 5139/10000- lr: [4.9081011757575755e-06] - Loss total: 2.6576802730560303, Last rpr Loss: 1.0003658533096313, Last lagvar Loss: 0.8456957340240479\n",
      "Step 5140/10000- lr: [4.90709107878788e-06] - Loss total: 2.657608985900879, Last rpr Loss: 0.9996852874755859, Last lagvar Loss: 0.8463751673698425\n",
      "Step 5141/10000- lr: [4.906080981818182e-06] - Loss total: 2.6575379371643066, Last rpr Loss: 1.0002105236053467, Last lagvar Loss: 0.845848023891449\n",
      "Step 5142/10000- lr: [4.905070884848485e-06] - Loss total: 2.6574668884277344, Last rpr Loss: 0.9998569488525391, Last lagvar Loss: 0.8462003469467163\n",
      "Step 5143/10000- lr: [4.904060787878788e-06] - Loss total: 2.657395601272583, Last rpr Loss: 1.0000985860824585, Last lagvar Loss: 0.8459571599960327\n",
      "Step 5144/10000- lr: [4.903050690909092e-06] - Loss total: 2.657325029373169, Last rpr Loss: 0.9999898672103882, Last lagvar Loss: 0.8460645079612732\n",
      "Step 5145/10000- lr: [4.902040593939394e-06] - Loss total: 2.657254695892334, Last rpr Loss: 0.9999969005584717, Last lagvar Loss: 0.8460561037063599\n",
      "Step 5146/10000- lr: [4.9010304969696976e-06] - Loss total: 2.657183885574341, Last rpr Loss: 1.00006902217865, Last lagvar Loss: 0.8459826111793518\n",
      "Step 5147/10000- lr: [4.9000204e-06] - Loss total: 2.657113790512085, Last rpr Loss: 0.9999006986618042, Last lagvar Loss: 0.8461496233940125\n",
      "Step 5148/10000- lr: [4.899010303030303e-06] - Loss total: 2.65704345703125, Last rpr Loss: 1.0001327991485596, Last lagvar Loss: 0.8459160327911377\n",
      "Step 5149/10000- lr: [4.898000206060606e-06] - Loss total: 2.656973123550415, Last rpr Loss: 0.9998171329498291, Last lagvar Loss: 0.8462303876876831\n",
      "Step 5150/10000- lr: [4.89699010909091e-06] - Loss total: 2.656903028488159, Last rpr Loss: 1.0002084970474243, Last lagvar Loss: 0.8458372950553894\n",
      "Step 5151/10000- lr: [4.895980012121212e-06] - Loss total: 2.6568329334259033, Last rpr Loss: 0.9997515082359314, Last lagvar Loss: 0.846293032169342\n",
      "Step 5152/10000- lr: [4.8949699151515155e-06] - Loss total: 2.6567630767822266, Last rpr Loss: 1.0002919435501099, Last lagvar Loss: 0.8457506895065308\n",
      "Step 5153/10000- lr: [4.893959818181818e-06] - Loss total: 2.65669322013855, Last rpr Loss: 0.9996680617332458, Last lagvar Loss: 0.8463733196258545\n",
      "Step 5154/10000- lr: [4.892949721212122e-06] - Loss total: 2.656623125076294, Last rpr Loss: 1.000402569770813, Last lagvar Loss: 0.8456367254257202\n",
      "Step 5155/10000- lr: [4.8919396242424245e-06] - Loss total: 2.6565537452697754, Last rpr Loss: 0.9995519518852234, Last lagvar Loss: 0.8464862704277039\n",
      "Step 5156/10000- lr: [4.890929527272728e-06] - Loss total: 2.6564838886260986, Last rpr Loss: 1.00053071975708, Last lagvar Loss: 0.8455053567886353\n",
      "Step 5157/10000- lr: [4.88991943030303e-06] - Loss total: 2.65641450881958, Last rpr Loss: 0.9993923902511597, Last lagvar Loss: 0.8466427326202393\n",
      "Step 5158/10000- lr: [4.8889093333333335e-06] - Loss total: 2.6563456058502197, Last rpr Loss: 1.0007143020629883, Last lagvar Loss: 0.8453184366226196\n",
      "Step 5159/10000- lr: [4.887899236363636e-06] - Loss total: 2.656276226043701, Last rpr Loss: 0.9991552233695984, Last lagvar Loss: 0.8468770384788513\n",
      "Step 5160/10000- lr: [4.88688913939394e-06] - Loss total: 2.656207323074341, Last rpr Loss: 1.0009899139404297, Last lagvar Loss: 0.845039963722229\n",
      "Step 5161/10000- lr: [4.8858790424242425e-06] - Loss total: 2.6561386585235596, Last rpr Loss: 0.998826265335083, Last lagvar Loss: 0.8472037315368652\n",
      "Step 5162/10000- lr: [4.884868945454546e-06] - Loss total: 2.6560702323913574, Last rpr Loss: 1.0013928413391113, Last lagvar Loss: 0.8446347713470459\n",
      "Step 5163/10000- lr: [4.883858848484848e-06] - Loss total: 2.6560025215148926, Last rpr Loss: 0.9983422160148621, Last lagvar Loss: 0.8476865887641907\n",
      "Step 5164/10000- lr: [4.882848751515152e-06] - Loss total: 2.655935049057007, Last rpr Loss: 1.002001166343689, Last lagvar Loss: 0.8440254926681519\n",
      "Step 5165/10000- lr: [4.881838654545455e-06] - Loss total: 2.6558687686920166, Last rpr Loss: 0.9976006746292114, Last lagvar Loss: 0.8484295606613159\n",
      "Step 5166/10000- lr: [4.880828557575758e-06] - Loss total: 2.6558029651641846, Last rpr Loss: 1.0029137134552002, Last lagvar Loss: 0.8431152105331421\n",
      "Step 5167/10000- lr: [4.8798184606060604e-06] - Loss total: 2.6557400226593018, Last rpr Loss: 0.9964761734008789, Last lagvar Loss: 0.8495612144470215\n",
      "Step 5168/10000- lr: [4.878808363636364e-06] - Loss total: 2.65567946434021, Last rpr Loss: 1.004306435585022, Last lagvar Loss: 0.8417329788208008\n",
      "Step 5169/10000- lr: [4.877798266666666e-06] - Loss total: 2.6556239128112793, Last rpr Loss: 0.9947390556335449, Last lagvar Loss: 0.8513187170028687\n",
      "Step 5170/10000- lr: [4.87678816969697e-06] - Loss total: 2.655573844909668, Last rpr Loss: 1.0064665079116821, Last lagvar Loss: 0.8396016955375671\n",
      "Step 5171/10000- lr: [4.875778072727273e-06] - Loss total: 2.6555371284484863, Last rpr Loss: 0.9920486211776733, Last lagvar Loss: 0.8540605306625366\n",
      "Step 5172/10000- lr: [4.874767975757576e-06] - Loss total: 2.6555099487304688, Last rpr Loss: 1.009809970855713, Last lagvar Loss: 0.8363301753997803\n",
      "Step 5173/10000- lr: [4.873757878787878e-06] - Loss total: 2.6555187702178955, Last rpr Loss: 0.9879087209701538, Last lagvar Loss: 0.8583247661590576\n",
      "Step 5174/10000- lr: [4.8727477818181825e-06] - Loss total: 2.6555404663085938, Last rpr Loss: 1.0149316787719727, Last lagvar Loss: 0.831378161907196\n",
      "Step 5175/10000- lr: [4.871737684848485e-06] - Loss total: 2.6556551456451416, Last rpr Loss: 0.9816830158233643, Last lagvar Loss: 0.8648389577865601\n",
      "Step 5176/10000- lr: [4.870727587878788e-06] - Loss total: 2.655759811401367, Last rpr Loss: 1.0223603248596191, Last lagvar Loss: 0.8243149518966675\n",
      "Step 5177/10000- lr: [4.869717490909091e-06] - Loss total: 2.6560840606689453, Last rpr Loss: 0.9730985164642334, Last lagvar Loss: 0.8740201592445374\n",
      "Step 5178/10000- lr: [4.868707393939394e-06] - Loss total: 2.656240224838257, Last rpr Loss: 1.031661033630371, Last lagvar Loss: 0.8156466484069824\n",
      "Step 5179/10000- lr: [4.867697296969696e-06] - Loss total: 2.6561830043792725, Last rpr Loss: 0.9700409770011902, Last lagvar Loss: 0.8773236274719238\n",
      "Step 5180/10000- lr: [4.8666872000000005e-06] - Loss total: 2.6557998657226562, Last rpr Loss: 1.0277267694473267, Last lagvar Loss: 0.8192529678344727\n",
      "Step 5181/10000- lr: [4.865677103030303e-06] - Loss total: 2.65563702583313, Last rpr Loss: 0.9748750925064087, Last lagvar Loss: 0.8720484972000122\n",
      "Step 5182/10000- lr: [4.864667006060606e-06] - Loss total: 2.65527081489563, Last rpr Loss: 1.0214146375656128, Last lagvar Loss: 0.8251544237136841\n",
      "Step 5183/10000- lr: [4.863656909090909e-06] - Loss total: 2.6550214290618896, Last rpr Loss: 0.9832925796508789, Last lagvar Loss: 0.863116979598999\n",
      "Step 5184/10000- lr: [4.862646812121213e-06] - Loss total: 2.6547513008117676, Last rpr Loss: 1.0120774507522583, Last lagvar Loss: 0.8341007232666016\n",
      "Step 5185/10000- lr: [4.861636715151515e-06] - Loss total: 2.654564380645752, Last rpr Loss: 0.9935150146484375, Last lagvar Loss: 0.8525474667549133\n",
      "Step 5186/10000- lr: [4.8606266181818185e-06] - Loss total: 2.6544418334960938, Last rpr Loss: 1.0016918182373047, Last lagvar Loss: 0.8443055152893066\n",
      "Step 5187/10000- lr: [4.859616521212121e-06] - Loss total: 2.6543800830841064, Last rpr Loss: 1.0026731491088867, Last lagvar Loss: 0.8433281779289246\n",
      "Step 5188/10000- lr: [4.858606424242424e-06] - Loss total: 2.6543641090393066, Last rpr Loss: 0.9932520985603333, Last lagvar Loss: 0.8528057932853699\n",
      "Step 5189/10000- lr: [4.857596327272727e-06] - Loss total: 2.6543660163879395, Last rpr Loss: 1.0098943710327148, Last lagvar Loss: 0.8362244367599487\n",
      "Step 5190/10000- lr: [4.856586230303031e-06] - Loss total: 2.6543807983398438, Last rpr Loss: 0.9875798225402832, Last lagvar Loss: 0.8586330413818359\n",
      "Step 5191/10000- lr: [4.855576133333333e-06] - Loss total: 2.6543591022491455, Last rpr Loss: 1.0143301486968994, Last lagvar Loss: 0.8319153785705566\n",
      "Step 5192/10000- lr: [4.8545660363636364e-06] - Loss total: 2.6543424129486084, Last rpr Loss: 0.9850043654441833, Last lagvar Loss: 0.861305832862854\n",
      "Step 5193/10000- lr: [4.853555939393939e-06] - Loss total: 2.654254674911499, Last rpr Loss: 1.0149579048156738, Last lagvar Loss: 0.8313124179840088\n",
      "Step 5194/10000- lr: [4.852545842424243e-06] - Loss total: 2.6541748046875, Last rpr Loss: 0.9858390092849731, Last lagvar Loss: 0.8604329824447632\n",
      "Step 5195/10000- lr: [4.851535745454545e-06] - Loss total: 2.6540398597717285, Last rpr Loss: 1.0125033855438232, Last lagvar Loss: 0.8336799144744873\n",
      "Step 5196/10000- lr: [4.850525648484849e-06] - Loss total: 2.6539180278778076, Last rpr Loss: 0.9893918037414551, Last lagvar Loss: 0.8567450046539307\n",
      "Step 5197/10000- lr: [4.849515551515151e-06] - Loss total: 2.6537861824035645, Last rpr Loss: 1.0079776048660278, Last lagvar Loss: 0.8380804061889648\n",
      "Step 5198/10000- lr: [4.848505454545454e-06] - Loss total: 2.653674364089966, Last rpr Loss: 0.9947589635848999, Last lagvar Loss: 0.8512552976608276\n",
      "Step 5199/10000- lr: [4.847495357575757e-06] - Loss total: 2.6535801887512207, Last rpr Loss: 1.0025196075439453, Last lagvar Loss: 0.8434615135192871\n",
      "Step 5200/10000- lr: [4.846485260606061e-06] - Loss total: 2.65350604057312, Last rpr Loss: 1.0002005100250244, Last lagvar Loss: 0.845771849155426\n",
      "Step 5201/10000- lr: [4.845475163636363e-06] - Loss total: 2.6534478664398193, Last rpr Loss: 0.9974685311317444, Last lagvar Loss: 0.8485120534896851\n",
      "Step 5202/10000- lr: [4.844465066666667e-06] - Loss total: 2.653399705886841, Last rpr Loss: 1.004478096961975, Last lagvar Loss: 0.8415169715881348\n",
      "Step 5203/10000- lr: [4.843454969696969e-06] - Loss total: 2.6533565521240234, Last rpr Loss: 0.9939680695533752, Last lagvar Loss: 0.8520545959472656\n",
      "Step 5204/10000- lr: [4.842444872727273e-06] - Loss total: 2.653308391571045, Last rpr Loss: 1.0071765184402466, Last lagvar Loss: 0.8388571739196777\n",
      "Step 5205/10000- lr: [4.841434775757576e-06] - Loss total: 2.6532585620880127, Last rpr Loss: 0.9921218156814575, Last lagvar Loss: 0.8539361357688904\n",
      "Step 5206/10000- lr: [4.840424678787879e-06] - Loss total: 2.65319561958313, Last rpr Loss: 1.0081565380096436, Last lagvar Loss: 0.8378936052322388\n",
      "Step 5207/10000- lr: [4.839414581818181e-06] - Loss total: 2.653130531311035, Last rpr Loss: 0.9918893575668335, Last lagvar Loss: 0.854170560836792\n",
      "Step 5208/10000- lr: [4.838404484848485e-06] - Loss total: 2.653052568435669, Last rpr Loss: 1.0075671672821045, Last lagvar Loss: 0.8384697437286377\n",
      "Step 5209/10000- lr: [4.837394387878787e-06] - Loss total: 2.652974843978882, Last rpr Loss: 0.9931018352508545, Last lagvar Loss: 0.8529306650161743\n",
      "Step 5210/10000- lr: [4.836384290909091e-06] - Loss total: 2.6528921127319336, Last rpr Loss: 1.0058798789978027, Last lagvar Loss: 0.840126633644104\n",
      "Step 5211/10000- lr: [4.835374193939394e-06] - Loss total: 2.6528122425079346, Last rpr Loss: 0.9952294826507568, Last lagvar Loss: 0.8507657647132874\n",
      "Step 5212/10000- lr: [4.834364096969697e-06] - Loss total: 2.652733087539673, Last rpr Loss: 1.0037322044372559, Last lagvar Loss: 0.8422446846961975\n",
      "Step 5213/10000- lr: [4.833353999999999e-06] - Loss total: 2.652658224105835, Last rpr Loss: 0.9975795745849609, Last lagvar Loss: 0.848388671875\n",
      "Step 5214/10000- lr: [4.8323439030303035e-06] - Loss total: 2.6525869369506836, Last rpr Loss: 1.0013664960861206, Last lagvar Loss: 0.8445932865142822\n",
      "Step 5215/10000- lr: [4.831333806060606e-06] - Loss total: 2.6525189876556396, Last rpr Loss: 0.9998049736022949, Last lagvar Loss: 0.8461520671844482\n",
      "Step 5216/10000- lr: [4.830323709090909e-06] - Loss total: 2.6524548530578613, Last rpr Loss: 0.9992159605026245, Last lagvar Loss: 0.8467410802841187\n",
      "Step 5217/10000- lr: [4.829313612121212e-06] - Loss total: 2.6523919105529785, Last rpr Loss: 1.0016019344329834, Last lagvar Loss: 0.8443558216094971\n",
      "Step 5218/10000- lr: [4.828303515151515e-06] - Loss total: 2.652330160140991, Last rpr Loss: 0.9975912570953369, Last lagvar Loss: 0.8483716249465942\n",
      "Step 5219/10000- lr: [4.827293418181819e-06] - Loss total: 2.652269124984741, Last rpr Loss: 1.0028759241104126, Last lagvar Loss: 0.8430871367454529\n",
      "Step 5220/10000- lr: [4.826283321212121e-06] - Loss total: 2.652208089828491, Last rpr Loss: 0.9965205192565918, Last lagvar Loss: 0.8494495153427124\n",
      "Step 5221/10000- lr: [4.825273224242425e-06] - Loss total: 2.6521456241607666, Last rpr Loss: 1.003793478012085, Last lagvar Loss: 0.8421748876571655\n",
      "Step 5222/10000- lr: [4.824263127272727e-06] - Loss total: 2.6520841121673584, Last rpr Loss: 0.9959723949432373, Last lagvar Loss: 0.8500020503997803\n",
      "Step 5223/10000- lr: [4.823253030303031e-06] - Loss total: 2.652020215988159, Last rpr Loss: 1.0042403936386108, Last lagvar Loss: 0.8417304754257202\n",
      "Step 5224/10000- lr: [4.822242933333334e-06] - Loss total: 2.6519558429718018, Last rpr Loss: 0.9957491159439087, Last lagvar Loss: 0.850226104259491\n",
      "Step 5225/10000- lr: [4.821232836363637e-06] - Loss total: 2.651890516281128, Last rpr Loss: 1.0042804479599, Last lagvar Loss: 0.8416894674301147\n",
      "Step 5226/10000- lr: [4.820222739393939e-06] - Loss total: 2.651825428009033, Last rpr Loss: 0.9957890510559082, Last lagvar Loss: 0.8501840829849243\n",
      "Step 5227/10000- lr: [4.819212642424243e-06] - Loss total: 2.651759147644043, Last rpr Loss: 1.004124402999878, Last lagvar Loss: 0.8418422937393188\n",
      "Step 5228/10000- lr: [4.818202545454545e-06] - Loss total: 2.651693344116211, Last rpr Loss: 0.995983362197876, Last lagvar Loss: 0.8499857187271118\n",
      "Step 5229/10000- lr: [4.817192448484849e-06] - Loss total: 2.6516263484954834, Last rpr Loss: 1.0038516521453857, Last lagvar Loss: 0.8421104550361633\n",
      "Step 5230/10000- lr: [4.816182351515152e-06] - Loss total: 2.6515607833862305, Last rpr Loss: 0.9962615966796875, Last lagvar Loss: 0.8497027158737183\n",
      "Step 5231/10000- lr: [4.815172254545455e-06] - Loss total: 2.651494264602661, Last rpr Loss: 1.0035300254821777, Last lagvar Loss: 0.8424277305603027\n",
      "Step 5232/10000- lr: [4.814162157575757e-06] - Loss total: 2.65142822265625, Last rpr Loss: 0.9965755343437195, Last lagvar Loss: 0.8493840098381042\n",
      "Step 5233/10000- lr: [4.8131520606060615e-06] - Loss total: 2.651362419128418, Last rpr Loss: 1.0032689571380615, Last lagvar Loss: 0.8426847457885742\n",
      "Step 5234/10000- lr: [4.812141963636364e-06] - Loss total: 2.651296854019165, Last rpr Loss: 0.9968404769897461, Last lagvar Loss: 0.8491148948669434\n",
      "Step 5235/10000- lr: [4.811131866666667e-06] - Loss total: 2.651231050491333, Last rpr Loss: 1.003096580505371, Last lagvar Loss: 0.8428537249565125\n",
      "Step 5236/10000- lr: [4.81012176969697e-06] - Loss total: 2.6511662006378174, Last rpr Loss: 0.99701327085495, Last lagvar Loss: 0.8489390015602112\n",
      "Step 5237/10000- lr: [4.809111672727273e-06] - Loss total: 2.6511013507843018, Last rpr Loss: 1.0029616355895996, Last lagvar Loss: 0.8429862260818481\n",
      "Step 5238/10000- lr: [4.808101575757575e-06] - Loss total: 2.6510367393493652, Last rpr Loss: 0.9970689415931702, Last lagvar Loss: 0.8488813042640686\n",
      "Step 5239/10000- lr: [4.8070914787878795e-06] - Loss total: 2.650972366333008, Last rpr Loss: 1.00294828414917, Last lagvar Loss: 0.8429982662200928\n",
      "Step 5240/10000- lr: [4.806081381818182e-06] - Loss total: 2.6509084701538086, Last rpr Loss: 0.9969756007194519, Last lagvar Loss: 0.8489738702774048\n",
      "Step 5241/10000- lr: [4.805071284848485e-06] - Loss total: 2.6508445739746094, Last rpr Loss: 1.0030908584594727, Last lagvar Loss: 0.8428553938865662\n",
      "Step 5242/10000- lr: [4.804061187878788e-06] - Loss total: 2.6507816314697266, Last rpr Loss: 0.9967566728591919, Last lagvar Loss: 0.8491933941841125\n",
      "Step 5243/10000- lr: [4.803051090909092e-06] - Loss total: 2.6507184505462646, Last rpr Loss: 1.0033917427062988, Last lagvar Loss: 0.8425556421279907\n",
      "Step 5244/10000- lr: [4.802040993939394e-06] - Loss total: 2.6506567001342773, Last rpr Loss: 0.9963783621788025, Last lagvar Loss: 0.8495742082595825\n",
      "Step 5245/10000- lr: [4.801030896969697e-06] - Loss total: 2.650594472885132, Last rpr Loss: 1.0038998126983643, Last lagvar Loss: 0.8420507311820984\n",
      "Step 5246/10000- lr: [4.8000208e-06] - Loss total: 2.6505343914031982, Last rpr Loss: 0.9957669973373413, Last lagvar Loss: 0.850191056728363\n",
      "Step 5247/10000- lr: [4.799010703030303e-06] - Loss total: 2.6504745483398438, Last rpr Loss: 1.004650354385376, Last lagvar Loss: 0.8413070440292358\n",
      "Step 5248/10000- lr: [4.7980006060606056e-06] - Loss total: 2.6504173278808594, Last rpr Loss: 0.9948610067367554, Last lagvar Loss: 0.8511077761650085\n",
      "Step 5249/10000- lr: [4.79699050909091e-06] - Loss total: 2.650360584259033, Last rpr Loss: 1.0057069063186646, Last lagvar Loss: 0.840263307094574\n",
      "Step 5250/10000- lr: [4.795980412121212e-06] - Loss total: 2.65030837059021, Last rpr Loss: 0.9935950636863708, Last lagvar Loss: 0.8523933291435242\n",
      "Step 5251/10000- lr: [4.794970315151515e-06] - Loss total: 2.650257110595703, Last rpr Loss: 1.007191777229309, Last lagvar Loss: 0.8388020992279053\n",
      "Step 5252/10000- lr: [4.793960218181818e-06] - Loss total: 2.650214910507202, Last rpr Loss: 0.9918426275253296, Last lagvar Loss: 0.8541809320449829\n",
      "Step 5253/10000- lr: [4.792950121212122e-06] - Loss total: 2.650172472000122, Last rpr Loss: 1.0092520713806152, Last lagvar Loss: 0.8367842435836792\n",
      "Step 5254/10000- lr: [4.791940024242424e-06] - Loss total: 2.650146245956421, Last rpr Loss: 0.9894533157348633, Last lagvar Loss: 0.8566325902938843\n",
      "Step 5255/10000- lr: [4.790929927272728e-06] - Loss total: 2.650118112564087, Last rpr Loss: 1.012015461921692, Last lagvar Loss: 0.8340952396392822\n",
      "Step 5256/10000- lr: [4.78991983030303e-06] - Loss total: 2.6501216888427734, Last rpr Loss: 0.9862958192825317, Last lagvar Loss: 0.8598979711532593\n",
      "Step 5257/10000- lr: [4.788909733333333e-06] - Loss total: 2.6501121520996094, Last rpr Loss: 1.0155675411224365, Last lagvar Loss: 0.8306666612625122\n",
      "Step 5258/10000- lr: [4.787899636363636e-06] - Loss total: 2.650161027908325, Last rpr Loss: 0.9823510050773621, Last lagvar Loss: 0.8640180826187134\n",
      "Step 5259/10000- lr: [4.78688953939394e-06] - Loss total: 2.6501665115356445, Last rpr Loss: 1.0198110342025757, Last lagvar Loss: 0.8266087770462036\n",
      "Step 5260/10000- lr: [4.785879442424242e-06] - Loss total: 2.650268793106079, Last rpr Loss: 0.977963387966156, Last lagvar Loss: 0.8686516284942627\n",
      "Step 5261/10000- lr: [4.784869345454546e-06] - Loss total: 2.6502573490142822, Last rpr Loss: 1.02402663230896, Last lagvar Loss: 0.8226146697998047\n",
      "Step 5262/10000- lr: [4.783859248484848e-06] - Loss total: 2.6503772735595703, Last rpr Loss: 0.9742686748504639, Last lagvar Loss: 0.8725915551185608\n",
      "Step 5263/10000- lr: [4.782849151515152e-06] - Loss total: 2.650275945663452, Last rpr Loss: 1.0265955924987793, Last lagvar Loss: 0.8201916217803955\n",
      "Step 5264/10000- lr: [4.781839054545455e-06] - Loss total: 2.650306463241577, Last rpr Loss: 0.9733487367630005, Last lagvar Loss: 0.8735674023628235\n",
      "Step 5265/10000- lr: [4.780828957575758e-06] - Loss total: 2.6500601768493652, Last rpr Loss: 1.0252742767333984, Last lagvar Loss: 0.8214173913002014\n",
      "Step 5266/10000- lr: [4.77981886060606e-06] - Loss total: 2.649909734725952, Last rpr Loss: 0.9773319959640503, Last lagvar Loss: 0.8692983388900757\n",
      "Step 5267/10000- lr: [4.778808763636364e-06] - Loss total: 2.649596929550171, Last rpr Loss: 1.0187733173370361, Last lagvar Loss: 0.8275711536407471\n",
      "Step 5268/10000- lr: [4.777798666666666e-06] - Loss total: 2.649360179901123, Last rpr Loss: 0.9862052202224731, Last lagvar Loss: 0.8599779605865479\n",
      "Step 5269/10000- lr: [4.77678856969697e-06] - Loss total: 2.6491401195526123, Last rpr Loss: 1.0085296630859375, Last lagvar Loss: 0.8374780416488647\n",
      "Step 5270/10000- lr: [4.7757784727272726e-06] - Loss total: 2.649000883102417, Last rpr Loss: 0.9971166849136353, Last lagvar Loss: 0.8488167524337769\n",
      "Step 5271/10000- lr: [4.774768375757576e-06] - Loss total: 2.648932695388794, Last rpr Loss: 0.9979165196418762, Last lagvar Loss: 0.8480098843574524\n",
      "Step 5272/10000- lr: [4.773758278787878e-06] - Loss total: 2.6489176750183105, Last rpr Loss: 1.0066108703613281, Last lagvar Loss: 0.8393611907958984\n",
      "Step 5273/10000- lr: [4.772748181818182e-06] - Loss total: 2.6489338874816895, Last rpr Loss: 0.9898306727409363, Last lagvar Loss: 0.8562284708023071\n",
      "Step 5274/10000- lr: [4.771738084848485e-06] - Loss total: 2.648937225341797, Last rpr Loss: 1.012681484222412, Last lagvar Loss: 0.833436131477356\n",
      "Step 5275/10000- lr: [4.770727987878788e-06] - Loss total: 2.6489386558532715, Last rpr Loss: 0.9857138991355896, Last lagvar Loss: 0.860480546951294\n",
      "Step 5276/10000- lr: [4.7697178909090905e-06] - Loss total: 2.6488747596740723, Last rpr Loss: 1.0146445035934448, Last lagvar Loss: 0.8315346240997314\n",
      "Step 5277/10000- lr: [4.768707793939394e-06] - Loss total: 2.6488051414489746, Last rpr Loss: 0.985929548740387, Last lagvar Loss: 0.860254168510437\n",
      "Step 5278/10000- lr: [4.767697696969696e-06] - Loss total: 2.6486783027648926, Last rpr Loss: 1.012498140335083, Last lagvar Loss: 0.8336063623428345\n",
      "Step 5279/10000- lr: [4.7666876e-06] - Loss total: 2.6485588550567627, Last rpr Loss: 0.9898412227630615, Last lagvar Loss: 0.8562129735946655\n",
      "Step 5280/10000- lr: [4.765677503030303e-06] - Loss total: 2.6484320163726807, Last rpr Loss: 1.007328748703003, Last lagvar Loss: 0.8386503458023071\n",
      "Step 5281/10000- lr: [4.764667406060606e-06] - Loss total: 2.6483261585235596, Last rpr Loss: 0.9957084059715271, Last lagvar Loss: 0.8502299785614014\n",
      "Step 5282/10000- lr: [4.7636573090909085e-06] - Loss total: 2.6482431888580322, Last rpr Loss: 1.0011929273605347, Last lagvar Loss: 0.8447209596633911\n",
      "Step 5283/10000- lr: [4.762647212121213e-06] - Loss total: 2.6481826305389404, Last rpr Loss: 1.0015743970870972, Last lagvar Loss: 0.844340443611145\n",
      "Step 5284/10000- lr: [4.761637115151515e-06] - Loss total: 2.6481375694274902, Last rpr Loss: 0.9959396123886108, Last lagvar Loss: 0.8499943017959595\n",
      "Step 5285/10000- lr: [4.760627018181818e-06] - Loss total: 2.648098945617676, Last rpr Loss: 1.0059738159179688, Last lagvar Loss: 0.8399807214736938\n",
      "Step 5286/10000- lr: [4.759616921212121e-06] - Loss total: 2.648061513900757, Last rpr Loss: 0.9926319122314453, Last lagvar Loss: 0.8533521890640259\n",
      "Step 5287/10000- lr: [4.758606824242424e-06] - Loss total: 2.648012161254883, Last rpr Loss: 1.0081602334976196, Last lagvar Loss: 0.8378305435180664\n",
      "Step 5288/10000- lr: [4.757596727272727e-06] - Loss total: 2.6479578018188477, Last rpr Loss: 0.9916241765022278, Last lagvar Loss: 0.8543810844421387\n",
      "Step 5289/10000- lr: [4.756586630303031e-06] - Loss total: 2.647886276245117, Last rpr Loss: 1.0080575942993164, Last lagvar Loss: 0.8379302024841309\n",
      "Step 5290/10000- lr: [4.755576533333333e-06] - Loss total: 2.647813081741333, Last rpr Loss: 0.9926817417144775, Last lagvar Loss: 0.853300929069519\n",
      "Step 5291/10000- lr: [4.754566436363636e-06] - Loss total: 2.647730827331543, Last rpr Loss: 1.0061887502670288, Last lagvar Loss: 0.8397660851478577\n",
      "Step 5292/10000- lr: [4.753556339393939e-06] - Loss total: 2.647651195526123, Last rpr Loss: 0.9951213002204895, Last lagvar Loss: 0.8508201837539673\n",
      "Step 5293/10000- lr: [4.752546242424243e-06] - Loss total: 2.6475741863250732, Last rpr Loss: 1.0033615827560425, Last lagvar Loss: 0.842559814453125\n",
      "Step 5294/10000- lr: [4.751536145454545e-06] - Loss total: 2.6475024223327637, Last rpr Loss: 0.998124361038208, Last lagvar Loss: 0.8477887511253357\n",
      "Step 5295/10000- lr: [4.7505260484848486e-06] - Loss total: 2.6474363803863525, Last rpr Loss: 1.0003947019577026, Last lagvar Loss: 0.845512866973877\n",
      "Step 5296/10000- lr: [4.749515951515151e-06] - Loss total: 2.6473758220672607, Last rpr Loss: 1.000960111618042, Last lagvar Loss: 0.8449478149414062\n",
      "Step 5297/10000- lr: [4.748505854545454e-06] - Loss total: 2.6473186016082764, Last rpr Loss: 0.9979123473167419, Last lagvar Loss: 0.8480007648468018\n",
      "Step 5298/10000- lr: [4.7474957575757576e-06] - Loss total: 2.6472630500793457, Last rpr Loss: 1.0030791759490967, Last lagvar Loss: 0.842837929725647\n",
      "Step 5299/10000- lr: [4.746485660606061e-06] - Loss total: 2.647207736968994, Last rpr Loss: 0.9962482452392578, Last lagvar Loss: 0.8496774435043335\n",
      "Step 5300/10000- lr: [4.745475563636363e-06] - Loss total: 2.647150993347168, Last rpr Loss: 1.0042569637298584, Last lagvar Loss: 0.8416699171066284\n",
      "Step 5301/10000- lr: [4.7444654666666665e-06] - Loss total: 2.647092580795288, Last rpr Loss: 0.9954513311386108, Last lagvar Loss: 0.8504823446273804\n",
      "Step 5302/10000- lr: [4.743455369696969e-06] - Loss total: 2.647031307220459, Last rpr Loss: 1.0045660734176636, Last lagvar Loss: 0.8413634300231934\n",
      "Step 5303/10000- lr: [4.742445272727273e-06] - Loss total: 2.6469688415527344, Last rpr Loss: 0.9954650402069092, Last lagvar Loss: 0.8504675626754761\n",
      "Step 5304/10000- lr: [4.7414351757575755e-06] - Loss total: 2.646904468536377, Last rpr Loss: 1.0041849613189697, Last lagvar Loss: 0.84173983335495\n",
      "Step 5305/10000- lr: [4.740425078787879e-06] - Loss total: 2.6468396186828613, Last rpr Loss: 0.9961194396018982, Last lagvar Loss: 0.8498049974441528\n",
      "Step 5306/10000- lr: [4.739414981818182e-06] - Loss total: 2.64677357673645, Last rpr Loss: 1.0033679008483887, Last lagvar Loss: 0.8425484895706177\n",
      "Step 5307/10000- lr: [4.7384048848484845e-06] - Loss total: 2.6467084884643555, Last rpr Loss: 0.9971461296081543, Last lagvar Loss: 0.8487684726715088\n",
      "Step 5308/10000- lr: [4.737394787878789e-06] - Loss total: 2.64664363861084, Last rpr Loss: 1.002327799797058, Last lagvar Loss: 0.8435806632041931\n",
      "Step 5309/10000- lr: [4.736384690909091e-06] - Loss total: 2.6465792655944824, Last rpr Loss: 0.9982730150222778, Last lagvar Loss: 0.8476337790489197\n",
      "Step 5310/10000- lr: [4.735374593939394e-06] - Loss total: 2.6465158462524414, Last rpr Loss: 1.0012179613113403, Last lagvar Loss: 0.8446853160858154\n",
      "Step 5311/10000- lr: [4.734364496969697e-06] - Loss total: 2.646453619003296, Last rpr Loss: 0.9993224143981934, Last lagvar Loss: 0.8465800285339355\n",
      "Step 5312/10000- lr: [4.733354400000001e-06] - Loss total: 2.6463916301727295, Last rpr Loss: 1.0001806020736694, Last lagvar Loss: 0.8457207679748535\n",
      "Step 5313/10000- lr: [4.732344303030303e-06] - Loss total: 2.6463303565979004, Last rpr Loss: 1.000218391418457, Last lagvar Loss: 0.8456826210021973\n",
      "Step 5314/10000- lr: [4.731334206060607e-06] - Loss total: 2.6462697982788086, Last rpr Loss: 0.9993345141410828, Last lagvar Loss: 0.8465671539306641\n",
      "Step 5315/10000- lr: [4.730324109090909e-06] - Loss total: 2.646209239959717, Last rpr Loss: 1.0009496212005615, Last lagvar Loss: 0.8449516296386719\n",
      "Step 5316/10000- lr: [4.729314012121212e-06] - Loss total: 2.646148920059204, Last rpr Loss: 0.9987038969993591, Last lagvar Loss: 0.8471989631652832\n",
      "Step 5317/10000- lr: [4.728303915151515e-06] - Loss total: 2.6460886001586914, Last rpr Loss: 1.001516580581665, Last lagvar Loss: 0.8443857431411743\n",
      "Step 5318/10000- lr: [4.727293818181819e-06] - Loss total: 2.646028518676758, Last rpr Loss: 0.9982619285583496, Last lagvar Loss: 0.847642183303833\n",
      "Step 5319/10000- lr: [4.726283721212121e-06] - Loss total: 2.645968198776245, Last rpr Loss: 1.001926064491272, Last lagvar Loss: 0.843977153301239\n",
      "Step 5320/10000- lr: [4.7252736242424246e-06] - Loss total: 2.6459078788757324, Last rpr Loss: 0.9979404211044312, Last lagvar Loss: 0.8479647636413574\n",
      "Step 5321/10000- lr: [4.724263527272727e-06] - Loss total: 2.6458473205566406, Last rpr Loss: 1.0022051334381104, Last lagvar Loss: 0.8436988592147827\n",
      "Step 5322/10000- lr: [4.723253430303031e-06] - Loss total: 2.645787000656128, Last rpr Loss: 0.9976931214332581, Last lagvar Loss: 0.8482129573822021\n",
      "Step 5323/10000- lr: [4.7222433333333335e-06] - Loss total: 2.6457269191741943, Last rpr Loss: 1.002396583557129, Last lagvar Loss: 0.8435079455375671\n",
      "Step 5324/10000- lr: [4.721233236363637e-06] - Loss total: 2.6456663608551025, Last rpr Loss: 0.9974796772003174, Last lagvar Loss: 0.8484272956848145\n",
      "Step 5325/10000- lr: [4.720223139393939e-06] - Loss total: 2.64560604095459, Last rpr Loss: 1.00258469581604, Last lagvar Loss: 0.8433204293251038\n",
      "Step 5326/10000- lr: [4.7192130424242425e-06] - Loss total: 2.6455459594726562, Last rpr Loss: 0.9972806572914124, Last lagvar Loss: 0.8486272096633911\n",
      "Step 5327/10000- lr: [4.718202945454545e-06] - Loss total: 2.6454858779907227, Last rpr Loss: 1.0027921199798584, Last lagvar Loss: 0.8431138396263123\n",
      "Step 5328/10000- lr: [4.717192848484849e-06] - Loss total: 2.645425796508789, Last rpr Loss: 0.9970579147338867, Last lagvar Loss: 0.8488511443138123\n",
      "Step 5329/10000- lr: [4.7161827515151515e-06] - Loss total: 2.6453661918640137, Last rpr Loss: 1.0030698776245117, Last lagvar Loss: 0.8428375124931335\n",
      "Step 5330/10000- lr: [4.715172654545455e-06] - Loss total: 2.6453068256378174, Last rpr Loss: 0.9967572689056396, Last lagvar Loss: 0.8491538166999817\n",
      "Step 5331/10000- lr: [4.714162557575757e-06] - Loss total: 2.645247459411621, Last rpr Loss: 1.0034379959106445, Last lagvar Loss: 0.8424718379974365\n",
      "Step 5332/10000- lr: [4.713152460606061e-06] - Loss total: 2.645188808441162, Last rpr Loss: 0.9963284134864807, Last lagvar Loss: 0.8495861291885376\n",
      "Step 5333/10000- lr: [4.712142363636364e-06] - Loss total: 2.6451308727264404, Last rpr Loss: 1.00393807888031, Last lagvar Loss: 0.8419755697250366\n",
      "Step 5334/10000- lr: [4.711132266666667e-06] - Loss total: 2.645073890686035, Last rpr Loss: 0.9957256317138672, Last lagvar Loss: 0.8501948714256287\n",
      "Step 5335/10000- lr: [4.7101221696969695e-06] - Loss total: 2.64501690864563, Last rpr Loss: 1.0046318769454956, Last lagvar Loss: 0.8412885665893555\n",
      "Step 5336/10000- lr: [4.709112072727273e-06] - Loss total: 2.6449620723724365, Last rpr Loss: 0.9948936700820923, Last lagvar Loss: 0.8510366678237915\n",
      "Step 5337/10000- lr: [4.708101975757575e-06] - Loss total: 2.6449081897735596, Last rpr Loss: 1.0055993795394897, Last lagvar Loss: 0.8403328657150269\n",
      "Step 5338/10000- lr: [4.707091878787879e-06] - Loss total: 2.644857168197632, Last rpr Loss: 0.993767261505127, Last lagvar Loss: 0.8521798253059387\n",
      "Step 5339/10000- lr: [4.706081781818182e-06] - Loss total: 2.6448071002960205, Last rpr Loss: 1.0069243907928467, Last lagvar Loss: 0.8390278220176697\n",
      "Step 5340/10000- lr: [4.705071684848485e-06] - Loss total: 2.644763469696045, Last rpr Loss: 0.9922322034835815, Last lagvar Loss: 0.8537431955337524\n",
      "Step 5341/10000- lr: [4.7040615878787875e-06] - Loss total: 2.6447203159332275, Last rpr Loss: 1.0087153911590576, Last lagvar Loss: 0.8372707366943359\n",
      "Step 5342/10000- lr: [4.703051490909092e-06] - Loss total: 2.644688844680786, Last rpr Loss: 0.9901647567749023, Last lagvar Loss: 0.8558589220046997\n",
      "Step 5343/10000- lr: [4.702041393939394e-06] - Loss total: 2.64465594291687, Last rpr Loss: 1.0110903978347778, Last lagvar Loss: 0.8349528312683105\n",
      "Step 5344/10000- lr: [4.701031296969697e-06] - Loss total: 2.6446456909179688, Last rpr Loss: 0.9874434471130371, Last lagvar Loss: 0.8586612343788147\n",
      "Step 5345/10000- lr: [4.7000212e-06] - Loss total: 2.644627571105957, Last rpr Loss: 1.014158010482788, Last lagvar Loss: 0.8319787383079529\n",
      "Step 5346/10000- lr: [4.699011103030303e-06] - Loss total: 2.6446499824523926, Last rpr Loss: 0.9840244054794312, Last lagvar Loss: 0.8622108101844788\n",
      "Step 5347/10000- lr: [4.698001006060606e-06] - Loss total: 2.644646406173706, Last rpr Loss: 1.017878532409668, Last lagvar Loss: 0.8284004926681519\n",
      "Step 5348/10000- lr: [4.6969909090909095e-06] - Loss total: 2.64471173286438, Last rpr Loss: 0.9800699949264526, Last lagvar Loss: 0.8663551807403564\n",
      "Step 5349/10000- lr: [4.695980812121212e-06] - Loss total: 2.6447079181671143, Last rpr Loss: 1.0218734741210938, Last lagvar Loss: 0.8245906829833984\n",
      "Step 5350/10000- lr: [4.694970715151515e-06] - Loss total: 2.6448047161102295, Last rpr Loss: 0.9762557148933411, Last lagvar Loss: 0.8703910112380981\n",
      "Step 5351/10000- lr: [4.693960618181818e-06] - Loss total: 2.6447553634643555, Last rpr Loss: 1.025097370147705, Last lagvar Loss: 0.8215367794036865\n",
      "Step 5352/10000- lr: [4.692950521212122e-06] - Loss total: 2.644822359085083, Last rpr Loss: 0.9740309119224548, Last lagvar Loss: 0.8727579712867737\n",
      "Step 5353/10000- lr: [4.691940424242424e-06] - Loss total: 2.644667863845825, Last rpr Loss: 1.02577805519104, Last lagvar Loss: 0.8208861351013184\n",
      "Step 5354/10000- lr: [4.6909303272727275e-06] - Loss total: 2.644611120223999, Last rpr Loss: 0.9753422141075134, Last lagvar Loss: 0.8713493347167969\n",
      "Step 5355/10000- lr: [4.68992023030303e-06] - Loss total: 2.644353151321411, Last rpr Loss: 1.0222342014312744, Last lagvar Loss: 0.8242279291152954\n",
      "Step 5356/10000- lr: [4.688910133333333e-06] - Loss total: 2.6441643238067627, Last rpr Loss: 0.9812724590301514, Last lagvar Loss: 0.8650756478309631\n",
      "Step 5357/10000- lr: [4.6879000363636365e-06] - Loss total: 2.6439104080200195, Last rpr Loss: 1.0144095420837402, Last lagvar Loss: 0.8317217826843262\n",
      "Step 5358/10000- lr: [4.68688993939394e-06] - Loss total: 2.643721103668213, Last rpr Loss: 0.9906216263771057, Last lagvar Loss: 0.8553853034973145\n",
      "Step 5359/10000- lr: [4.685879842424242e-06] - Loss total: 2.6435773372650146, Last rpr Loss: 1.004462718963623, Last lagvar Loss: 0.8414510488510132\n",
      "Step 5360/10000- lr: [4.6848697454545455e-06] - Loss total: 2.6434950828552246, Last rpr Loss: 1.000466227531433, Last lagvar Loss: 0.8454247713088989\n",
      "Step 5361/10000- lr: [4.683859648484848e-06] - Loss total: 2.6434621810913086, Last rpr Loss: 0.9953166246414185, Last lagvar Loss: 0.8506025075912476\n",
      "Step 5362/10000- lr: [4.682849551515152e-06] - Loss total: 2.6434576511383057, Last rpr Loss: 1.0082709789276123, Last lagvar Loss: 0.8377000689506531\n",
      "Step 5363/10000- lr: [4.6818394545454545e-06] - Loss total: 2.6434667110443115, Last rpr Loss: 0.9889432787895203, Last lagvar Loss: 0.8571034669876099\n",
      "Step 5364/10000- lr: [4.680829357575758e-06] - Loss total: 2.6434519290924072, Last rpr Loss: 1.0128203630447388, Last lagvar Loss: 0.8332635164260864\n",
      "Step 5365/10000- lr: [4.67981926060606e-06] - Loss total: 2.643432378768921, Last rpr Loss: 0.9861977696418762, Last lagvar Loss: 0.8599356412887573\n",
      "Step 5366/10000- lr: [4.6788091636363635e-06] - Loss total: 2.643359899520874, Last rpr Loss: 1.0137195587158203, Last lagvar Loss: 0.8323892951011658\n",
      "Step 5367/10000- lr: [4.677799066666667e-06] - Loss total: 2.6432838439941406, Last rpr Loss: 0.9871236681938171, Last lagvar Loss: 0.8589765429496765\n",
      "Step 5368/10000- lr: [4.67678896969697e-06] - Loss total: 2.643170118331909, Last rpr Loss: 1.0112214088439941, Last lagvar Loss: 0.8348135352134705\n",
      "Step 5369/10000- lr: [4.6757788727272724e-06] - Loss total: 2.643064022064209, Last rpr Loss: 0.9909490346908569, Last lagvar Loss: 0.8550426959991455\n",
      "Step 5370/10000- lr: [4.674768775757576e-06] - Loss total: 2.642956018447876, Last rpr Loss: 1.006460428237915, Last lagvar Loss: 0.8394755125045776\n",
      "Step 5371/10000- lr: [4.673758678787878e-06] - Loss total: 2.6428651809692383, Last rpr Loss: 0.9962027072906494, Last lagvar Loss: 0.8497022390365601\n",
      "Step 5372/10000- lr: [4.672748581818182e-06] - Loss total: 2.6427910327911377, Last rpr Loss: 1.0010789632797241, Last lagvar Loss: 0.8448082804679871\n",
      "Step 5373/10000- lr: [4.671738484848485e-06] - Loss total: 2.642733335494995, Last rpr Loss: 1.0013422966003418, Last lagvar Loss: 0.8445453643798828\n",
      "Step 5374/10000- lr: [4.670728387878788e-06] - Loss total: 2.6426875591278076, Last rpr Loss: 0.9964823126792908, Last lagvar Loss: 0.849419355392456\n",
      "Step 5375/10000- lr: [4.66971829090909e-06] - Loss total: 2.642646551132202, Last rpr Loss: 1.0052356719970703, Last lagvar Loss: 0.840681254863739\n",
      "Step 5376/10000- lr: [4.668708193939394e-06] - Loss total: 2.6426069736480713, Last rpr Loss: 0.9934636354446411, Last lagvar Loss: 0.8524764776229858\n",
      "Step 5377/10000- lr: [4.667698096969697e-06] - Loss total: 2.6425604820251465, Last rpr Loss: 1.0073230266571045, Last lagvar Loss: 0.8386240005493164\n",
      "Step 5378/10000- lr: [4.666688e-06] - Loss total: 2.642510175704956, Last rpr Loss: 0.992313027381897, Last lagvar Loss: 0.8536478281021118\n",
      "Step 5379/10000- lr: [4.665677903030303e-06] - Loss total: 2.6424481868743896, Last rpr Loss: 1.0075743198394775, Last lagvar Loss: 0.8383767008781433\n",
      "Step 5380/10000- lr: [4.664667806060606e-06] - Loss total: 2.6423840522766113, Last rpr Loss: 0.9928516149520874, Last lagvar Loss: 0.8530985116958618\n",
      "Step 5381/10000- lr: [4.663657709090908e-06] - Loss total: 2.6423118114471436, Last rpr Loss: 1.0063488483428955, Last lagvar Loss: 0.8395819664001465\n",
      "Step 5382/10000- lr: [4.6626476121212125e-06] - Loss total: 2.6422410011291504, Last rpr Loss: 0.9946063160896301, Last lagvar Loss: 0.8513151407241821\n",
      "Step 5383/10000- lr: [4.661637515151515e-06] - Loss total: 2.642169237136841, Last rpr Loss: 1.0042155981063843, Last lagvar Loss: 0.8416883945465088\n",
      "Step 5384/10000- lr: [4.660627418181818e-06] - Loss total: 2.6421005725860596, Last rpr Loss: 0.996991753578186, Last lagvar Loss: 0.8489035964012146\n",
      "Step 5385/10000- lr: [4.659617321212121e-06] - Loss total: 2.642035722732544, Last rpr Loss: 1.0017614364624023, Last lagvar Loss: 0.8441250920295715\n",
      "Step 5386/10000- lr: [4.658607224242424e-06] - Loss total: 2.6419742107391357, Last rpr Loss: 0.9994307160377502, Last lagvar Loss: 0.8464527726173401\n",
      "Step 5387/10000- lr: [4.657597127272727e-06] - Loss total: 2.641916275024414, Last rpr Loss: 0.9994857311248779, Last lagvar Loss: 0.8463973999023438\n",
      "Step 5388/10000- lr: [4.6565870303030305e-06] - Loss total: 2.641860246658325, Last rpr Loss: 1.001477599143982, Last lagvar Loss: 0.8444068431854248\n",
      "Step 5389/10000- lr: [4.655576933333333e-06] - Loss total: 2.6418063640594482, Last rpr Loss: 0.9976969361305237, Last lagvar Loss: 0.8481923341751099\n",
      "Step 5390/10000- lr: [4.654566836363636e-06] - Loss total: 2.641752243041992, Last rpr Loss: 1.002927303314209, Last lagvar Loss: 0.8429641127586365\n",
      "Step 5391/10000- lr: [4.65355673939394e-06] - Loss total: 2.6416983604431152, Last rpr Loss: 0.9965243339538574, Last lagvar Loss: 0.8493731617927551\n",
      "Step 5392/10000- lr: [4.652546642424243e-06] - Loss total: 2.6416430473327637, Last rpr Loss: 1.0037562847137451, Last lagvar Loss: 0.8421412110328674\n",
      "Step 5393/10000- lr: [4.651536545454546e-06] - Loss total: 2.641587495803833, Last rpr Loss: 0.9959712624549866, Last lagvar Loss: 0.849931001663208\n",
      "Step 5394/10000- lr: [4.6505264484848484e-06] - Loss total: 2.6415302753448486, Last rpr Loss: 1.0040334463119507, Last lagvar Loss: 0.8418659567832947\n",
      "Step 5395/10000- lr: [4.649516351515152e-06] - Loss total: 2.641472578048706, Last rpr Loss: 0.9959573149681091, Last lagvar Loss: 0.8499447107315063\n",
      "Step 5396/10000- lr: [4.648506254545455e-06] - Loss total: 2.6414129734039307, Last rpr Loss: 1.0038782358169556, Last lagvar Loss: 0.8420191407203674\n",
      "Step 5397/10000- lr: [4.647496157575758e-06] - Loss total: 2.6413538455963135, Last rpr Loss: 0.9963182210922241, Last lagvar Loss: 0.8495798707008362\n",
      "Step 5398/10000- lr: [4.646486060606061e-06] - Loss total: 2.64129376411438, Last rpr Loss: 1.0034229755401611, Last lagvar Loss: 0.842470109462738\n",
      "Step 5399/10000- lr: [4.645475963636364e-06] - Loss total: 2.6412341594696045, Last rpr Loss: 0.9968766570091248, Last lagvar Loss: 0.8490161299705505\n",
      "Step 5400/10000- lr: [4.644465866666666e-06] - Loss total: 2.641174077987671, Last rpr Loss: 1.00278902053833, Last lagvar Loss: 0.8430989980697632\n",
      "Step 5401/10000- lr: [4.6434557696969705e-06] - Loss total: 2.6411144733428955, Last rpr Loss: 0.9975219964981079, Last lagvar Loss: 0.8483656644821167\n",
      "Step 5402/10000- lr: [4.642445672727273e-06] - Loss total: 2.64105486869812, Last rpr Loss: 1.0020947456359863, Last lagvar Loss: 0.8437890410423279\n",
      "Step 5403/10000- lr: [4.641435575757576e-06] - Loss total: 2.640995979309082, Last rpr Loss: 0.9981808662414551, Last lagvar Loss: 0.8477026224136353\n",
      "Step 5404/10000- lr: [4.640425478787879e-06] - Loss total: 2.640936851501465, Last rpr Loss: 1.001450538635254, Last lagvar Loss: 0.8444303274154663\n",
      "Step 5405/10000- lr: [4.639415381818182e-06] - Loss total: 2.640878200531006, Last rpr Loss: 0.9987964630126953, Last lagvar Loss: 0.8470841646194458\n",
      "Step 5406/10000- lr: [4.638405284848485e-06] - Loss total: 2.6408205032348633, Last rpr Loss: 1.0008928775787354, Last lagvar Loss: 0.844986081123352\n",
      "Step 5407/10000- lr: [4.6373951878787885e-06] - Loss total: 2.6407623291015625, Last rpr Loss: 0.999329686164856, Last lagvar Loss: 0.8465490937232971\n",
      "Step 5408/10000- lr: [4.636385090909091e-06] - Loss total: 2.640704393386841, Last rpr Loss: 1.0004222393035889, Last lagvar Loss: 0.8454555869102478\n",
      "Step 5409/10000- lr: [4.635374993939394e-06] - Loss total: 2.6406469345092773, Last rpr Loss: 0.9997690916061401, Last lagvar Loss: 0.846108615398407\n",
      "Step 5410/10000- lr: [4.634364896969697e-06] - Loss total: 2.6405892372131348, Last rpr Loss: 1.000035285949707, Last lagvar Loss: 0.8458420038223267\n",
      "Step 5411/10000- lr: [4.633354800000001e-06] - Loss total: 2.6405317783355713, Last rpr Loss: 1.0001144409179688, Last lagvar Loss: 0.8457627296447754\n",
      "Step 5412/10000- lr: [4.632344703030303e-06] - Loss total: 2.640474557876587, Last rpr Loss: 0.9997130632400513, Last lagvar Loss: 0.8461641073226929\n",
      "Step 5413/10000- lr: [4.6313346060606065e-06] - Loss total: 2.6404173374176025, Last rpr Loss: 1.0003912448883057, Last lagvar Loss: 0.8454855680465698\n",
      "Step 5414/10000- lr: [4.630324509090909e-06] - Loss total: 2.640360116958618, Last rpr Loss: 0.9994374513626099, Last lagvar Loss: 0.8464396595954895\n",
      "Step 5415/10000- lr: [4.629314412121212e-06] - Loss total: 2.640302896499634, Last rpr Loss: 1.000638484954834, Last lagvar Loss: 0.845238208770752\n",
      "Step 5416/10000- lr: [4.6283043151515154e-06] - Loss total: 2.6402456760406494, Last rpr Loss: 0.99919593334198, Last lagvar Loss: 0.8466812968254089\n",
      "Step 5417/10000- lr: [4.627294218181819e-06] - Loss total: 2.640188455581665, Last rpr Loss: 1.0008797645568848, Last lagvar Loss: 0.8449969291687012\n",
      "Step 5418/10000- lr: [4.626284121212121e-06] - Loss total: 2.6401309967041016, Last rpr Loss: 0.9989631175994873, Last lagvar Loss: 0.8469142913818359\n",
      "Step 5419/10000- lr: [4.6252740242424244e-06] - Loss total: 2.6400740146636963, Last rpr Loss: 1.0011374950408936, Last lagvar Loss: 0.8447392582893372\n",
      "Step 5420/10000- lr: [4.624263927272727e-06] - Loss total: 2.64001727104187, Last rpr Loss: 0.9986942410469055, Last lagvar Loss: 0.8471837043762207\n",
      "Step 5421/10000- lr: [4.623253830303031e-06] - Loss total: 2.6399600505828857, Last rpr Loss: 1.0014314651489258, Last lagvar Loss: 0.8444456458091736\n",
      "Step 5422/10000- lr: [4.622243733333333e-06] - Loss total: 2.6399033069610596, Last rpr Loss: 0.9983603954315186, Last lagvar Loss: 0.8475184440612793\n",
      "Step 5423/10000- lr: [4.621233636363637e-06] - Loss total: 2.6398465633392334, Last rpr Loss: 1.0018038749694824, Last lagvar Loss: 0.8440743088722229\n",
      "Step 5424/10000- lr: [4.620223539393939e-06] - Loss total: 2.6397905349731445, Last rpr Loss: 0.9979276061058044, Last lagvar Loss: 0.8479530811309814\n",
      "Step 5425/10000- lr: [4.619213442424242e-06] - Loss total: 2.6397340297698975, Last rpr Loss: 1.002294898033142, Last lagvar Loss: 0.8435854315757751\n",
      "Step 5426/10000- lr: [4.618203345454546e-06] - Loss total: 2.639678716659546, Last rpr Loss: 0.9973495006561279, Last lagvar Loss: 0.8485344052314758\n",
      "Step 5427/10000- lr: [4.617193248484849e-06] - Loss total: 2.6396231651306152, Last rpr Loss: 1.0029830932617188, Last lagvar Loss: 0.8429011106491089\n",
      "Step 5428/10000- lr: [4.616183151515151e-06] - Loss total: 2.6395695209503174, Last rpr Loss: 0.9965356588363647, Last lagvar Loss: 0.8493543863296509\n",
      "Step 5429/10000- lr: [4.615173054545455e-06] - Loss total: 2.6395161151885986, Last rpr Loss: 1.0039551258087158, Last lagvar Loss: 0.8419366478919983\n",
      "Step 5430/10000- lr: [4.614162957575757e-06] - Loss total: 2.639465093612671, Last rpr Loss: 0.9953848123550415, Last lagvar Loss: 0.8505169153213501\n",
      "Step 5431/10000- lr: [4.613152860606061e-06] - Loss total: 2.6394155025482178, Last rpr Loss: 1.0053237676620483, Last lagvar Loss: 0.8405827283859253\n",
      "Step 5432/10000- lr: [4.612142763636364e-06] - Loss total: 2.639371156692505, Last rpr Loss: 0.9937455654144287, Last lagvar Loss: 0.8521788120269775\n",
      "Step 5433/10000- lr: [4.611132666666667e-06] - Loss total: 2.639329195022583, Last rpr Loss: 1.007285714149475, Last lagvar Loss: 0.8386499285697937\n",
      "Step 5434/10000- lr: [4.610122569696969e-06] - Loss total: 2.6392977237701416, Last rpr Loss: 0.9913904070854187, Last lagvar Loss: 0.8545786142349243\n",
      "Step 5435/10000- lr: [4.609112472727273e-06] - Loss total: 2.639270067214966, Last rpr Loss: 1.0100996494293213, Last lagvar Loss: 0.835893452167511\n",
      "Step 5436/10000- lr: [4.608102375757576e-06] - Loss total: 2.639266014099121, Last rpr Loss: 0.9880411624908447, Last lagvar Loss: 0.8580158948898315\n",
      "Step 5437/10000- lr: [4.607092278787879e-06] - Loss total: 2.6392643451690674, Last rpr Loss: 1.0140700340270996, Last lagvar Loss: 0.832035481929779\n",
      "Step 5438/10000- lr: [4.606082181818182e-06] - Loss total: 2.6393139362335205, Last rpr Loss: 0.983373761177063, Last lagvar Loss: 0.8628550171852112\n",
      "Step 5439/10000- lr: [4.605072084848485e-06] - Loss total: 2.6393520832061768, Last rpr Loss: 1.0194557905197144, Last lagvar Loss: 0.8268582224845886\n",
      "Step 5440/10000- lr: [4.604061987878787e-06] - Loss total: 2.6394946575164795, Last rpr Loss: 0.9772809743881226, Last lagvar Loss: 0.8692580461502075\n",
      "Step 5441/10000- lr: [4.6030518909090914e-06] - Loss total: 2.639566659927368, Last rpr Loss: 1.026073932647705, Last lagvar Loss: 0.8205785751342773\n",
      "Step 5442/10000- lr: [4.602041793939394e-06] - Loss total: 2.6398234367370605, Last rpr Loss: 0.9704345464706421, Last lagvar Loss: 0.8765676617622375\n",
      "Step 5443/10000- lr: [4.601031696969697e-06] - Loss total: 2.6398417949676514, Last rpr Loss: 1.0323998928070068, Last lagvar Loss: 0.8146508932113647\n",
      "Step 5444/10000- lr: [4.6000216e-06] - Loss total: 2.6398558616638184, Last rpr Loss: 0.9683417081832886, Last lagvar Loss: 0.878814697265625\n",
      "Step 5445/10000- lr: [4.599011503030303e-06] - Loss total: 2.639519453048706, Last rpr Loss: 1.0294893980026245, Last lagvar Loss: 0.8173452615737915\n",
      "Step 5446/10000- lr: [4.598001406060606e-06] - Loss total: 2.6393373012542725, Last rpr Loss: 0.9737797379493713, Last lagvar Loss: 0.8729569911956787\n",
      "Step 5447/10000- lr: [4.596991309090909e-06] - Loss total: 2.6389594078063965, Last rpr Loss: 1.0214719772338867, Last lagvar Loss: 0.8249089121818542\n",
      "Step 5448/10000- lr: [4.595981212121212e-06] - Loss total: 2.638685703277588, Last rpr Loss: 0.9844534397125244, Last lagvar Loss: 0.8617242574691772\n",
      "Step 5449/10000- lr: [4.594971115151515e-06] - Loss total: 2.638439416885376, Last rpr Loss: 1.0093836784362793, Last lagvar Loss: 0.8365890979766846\n",
      "Step 5450/10000- lr: [4.5939610181818176e-06] - Loss total: 2.638293504714966, Last rpr Loss: 0.9972511529922485, Last lagvar Loss: 0.8486358523368835\n",
      "Step 5451/10000- lr: [4.592950921212122e-06] - Loss total: 2.6382365226745605, Last rpr Loss: 0.9969714879989624, Last lagvar Loss: 0.8489155769348145\n",
      "Step 5452/10000- lr: [4.591940824242424e-06] - Loss total: 2.6382429599761963, Last rpr Loss: 1.0081143379211426, Last lagvar Loss: 0.8378357887268066\n",
      "Step 5453/10000- lr: [4.590930727272727e-06] - Loss total: 2.6382851600646973, Last rpr Loss: 0.9877870082855225, Last lagvar Loss: 0.8582718372344971\n",
      "Step 5454/10000- lr: [4.58992063030303e-06] - Loss total: 2.638305902481079, Last rpr Loss: 1.0149519443511963, Last lagvar Loss: 0.8311792016029358\n",
      "Step 5455/10000- lr: [4.588910533333334e-06] - Loss total: 2.63832426071167, Last rpr Loss: 0.9833213090896606, Last lagvar Loss: 0.8628978133201599\n",
      "Step 5456/10000- lr: [4.587900436363636e-06] - Loss total: 2.6382553577423096, Last rpr Loss: 1.016972303390503, Last lagvar Loss: 0.8292238712310791\n",
      "Step 5457/10000- lr: [4.58689033939394e-06] - Loss total: 2.638180732727051, Last rpr Loss: 0.9839801788330078, Last lagvar Loss: 0.8622092008590698\n",
      "Step 5458/10000- lr: [4.585880242424242e-06] - Loss total: 2.638036012649536, Last rpr Loss: 1.0139312744140625, Last lagvar Loss: 0.8321583271026611\n",
      "Step 5459/10000- lr: [4.584870145454545e-06] - Loss total: 2.6379034519195557, Last rpr Loss: 0.989043116569519, Last lagvar Loss: 0.8569769859313965\n",
      "Step 5460/10000- lr: [4.583860048484848e-06] - Loss total: 2.6377687454223633, Last rpr Loss: 1.0073719024658203, Last lagvar Loss: 0.838563084602356\n",
      "Step 5461/10000- lr: [4.582849951515152e-06] - Loss total: 2.637664318084717, Last rpr Loss: 0.9962756633758545, Last lagvar Loss: 0.8496139645576477\n",
      "Step 5462/10000- lr: [4.581839854545454e-06] - Loss total: 2.6375911235809326, Last rpr Loss: 1.0000101327896118, Last lagvar Loss: 0.8458623290061951\n",
      "Step 5463/10000- lr: [4.580829757575758e-06] - Loss total: 2.637545585632324, Last rpr Loss: 1.003166675567627, Last lagvar Loss: 0.8427169919013977\n",
      "Step 5464/10000- lr: [4.57981966060606e-06] - Loss total: 2.6375174522399902, Last rpr Loss: 0.9940704703330994, Last lagvar Loss: 0.8518444299697876\n",
      "Step 5465/10000- lr: [4.578809563636364e-06] - Loss total: 2.6374905109405518, Last rpr Loss: 1.007929801940918, Last lagvar Loss: 0.8380136489868164\n",
      "Step 5466/10000- lr: [4.577799466666667e-06] - Loss total: 2.6374619007110596, Last rpr Loss: 0.9907286167144775, Last lagvar Loss: 0.855247974395752\n",
      "Step 5467/10000- lr: [4.57678936969697e-06] - Loss total: 2.6374123096466064, Last rpr Loss: 1.0097837448120117, Last lagvar Loss: 0.8361947536468506\n",
      "Step 5468/10000- lr: [4.575779272727272e-06] - Loss total: 2.637355089187622, Last rpr Loss: 0.9904063940048218, Last lagvar Loss: 0.8555777072906494\n",
      "Step 5469/10000- lr: [4.574769175757576e-06] - Loss total: 2.637277126312256, Last rpr Loss: 1.0087491273880005, Last lagvar Loss: 0.8372071981430054\n",
      "Step 5470/10000- lr: [4.573759078787878e-06] - Loss total: 2.637197971343994, Last rpr Loss: 0.9925950169563293, Last lagvar Loss: 0.8533437848091125\n",
      "Step 5471/10000- lr: [4.572748981818182e-06] - Loss total: 2.6371145248413086, Last rpr Loss: 1.0056780576705933, Last lagvar Loss: 0.8402288556098938\n",
      "Step 5472/10000- lr: [4.5717388848484846e-06] - Loss total: 2.6370372772216797, Last rpr Loss: 0.9961717128753662, Last lagvar Loss: 0.8497171401977539\n",
      "Step 5473/10000- lr: [4.570728787878788e-06] - Loss total: 2.636967897415161, Last rpr Loss: 1.001837134361267, Last lagvar Loss: 0.8440371751785278\n",
      "Step 5474/10000- lr: [4.56971869090909e-06] - Loss total: 2.6369073390960693, Last rpr Loss: 0.999981701374054, Last lagvar Loss: 0.8458889722824097\n",
      "Step 5475/10000- lr: [4.568708593939394e-06] - Loss total: 2.6368539333343506, Last rpr Loss: 0.9982957243919373, Last lagvar Loss: 0.8475785851478577\n",
      "Step 5476/10000- lr: [4.567698496969698e-06] - Loss total: 2.636805534362793, Last rpr Loss: 1.0031464099884033, Last lagvar Loss: 0.8427347540855408\n",
      "Step 5477/10000- lr: [4.5666884e-06] - Loss total: 2.6367580890655518, Last rpr Loss: 0.9957766532897949, Last lagvar Loss: 0.8501155376434326\n",
      "Step 5478/10000- lr: [4.565678303030303e-06] - Loss total: 2.636709213256836, Last rpr Loss: 1.0050097703933716, Last lagvar Loss: 0.8408880829811096\n",
      "Step 5479/10000- lr: [4.564668206060606e-06] - Loss total: 2.6366589069366455, Last rpr Loss: 0.994584858417511, Last lagvar Loss: 0.8513211607933044\n",
      "Step 5480/10000- lr: [4.56365810909091e-06] - Loss total: 2.6366028785705566, Last rpr Loss: 1.0054936408996582, Last lagvar Loss: 0.8404098749160767\n",
      "Step 5481/10000- lr: [4.562648012121212e-06] - Loss total: 2.6365444660186768, Last rpr Loss: 0.9946572780609131, Last lagvar Loss: 0.8512474298477173\n",
      "Step 5482/10000- lr: [4.561637915151516e-06] - Loss total: 2.6364831924438477, Last rpr Loss: 1.0048478841781616, Last lagvar Loss: 0.841048002243042\n",
      "Step 5483/10000- lr: [4.560627818181818e-06] - Loss total: 2.636420726776123, Last rpr Loss: 0.9956745505332947, Last lagvar Loss: 0.850217342376709\n",
      "Step 5484/10000- lr: [4.559617721212121e-06] - Loss total: 2.636357545852661, Last rpr Loss: 1.0034862756729126, Last lagvar Loss: 0.842396080493927\n",
      "Step 5485/10000- lr: [4.558607624242425e-06] - Loss total: 2.6362955570220947, Last rpr Loss: 0.997279942035675, Last lagvar Loss: 0.8485978245735168\n",
      "Step 5486/10000- lr: [4.557597527272728e-06] - Loss total: 2.636235237121582, Last rpr Loss: 1.001814842224121, Last lagvar Loss: 0.8440571427345276\n",
      "Step 5487/10000- lr: [4.55658743030303e-06] - Loss total: 2.636176347732544, Last rpr Loss: 0.9990586042404175, Last lagvar Loss: 0.8468109369277954\n",
      "Step 5488/10000- lr: [4.555577333333334e-06] - Loss total: 2.6361193656921387, Last rpr Loss: 1.0001630783081055, Last lagvar Loss: 0.8457049131393433\n",
      "Step 5489/10000- lr: [4.554567236363636e-06] - Loss total: 2.636063814163208, Last rpr Loss: 1.0005912780761719, Last lagvar Loss: 0.845276951789856\n",
      "Step 5490/10000- lr: [4.55355713939394e-06] - Loss total: 2.6360092163085938, Last rpr Loss: 0.9987848997116089, Last lagvar Loss: 0.8470848798751831\n",
      "Step 5491/10000- lr: [4.552547042424243e-06] - Loss total: 2.635955333709717, Last rpr Loss: 1.001727819442749, Last lagvar Loss: 0.8441428542137146\n",
      "Step 5492/10000- lr: [4.551536945454546e-06] - Loss total: 2.635901689529419, Last rpr Loss: 0.9977924823760986, Last lagvar Loss: 0.8480812311172485\n",
      "Step 5493/10000- lr: [4.550526848484848e-06] - Loss total: 2.635847568511963, Last rpr Loss: 1.0024722814559937, Last lagvar Loss: 0.8434016704559326\n",
      "Step 5494/10000- lr: [4.549516751515152e-06] - Loss total: 2.6357929706573486, Last rpr Loss: 0.9972457885742188, Last lagvar Loss: 0.8486310243606567\n",
      "Step 5495/10000- lr: [4.548506654545455e-06] - Loss total: 2.635737895965576, Last rpr Loss: 1.0028170347213745, Last lagvar Loss: 0.843058705329895\n",
      "Step 5496/10000- lr: [4.547496557575758e-06] - Loss total: 2.6356825828552246, Last rpr Loss: 0.997094988822937, Last lagvar Loss: 0.8487825393676758\n",
      "Step 5497/10000- lr: [4.5464864606060606e-06] - Loss total: 2.635627031326294, Last rpr Loss: 1.002842664718628, Last lagvar Loss: 0.843032956123352\n",
      "Step 5498/10000- lr: [4.545476363636364e-06] - Loss total: 2.635570764541626, Last rpr Loss: 0.9972286224365234, Last lagvar Loss: 0.8486477136611938\n",
      "Step 5499/10000- lr: [4.544466266666666e-06] - Loss total: 2.635514259338379, Last rpr Loss: 1.0026447772979736, Last lagvar Loss: 0.8432291746139526\n",
      "Step 5500/10000- lr: [4.54345616969697e-06] - Loss total: 2.635457992553711, Last rpr Loss: 0.9975335597991943, Last lagvar Loss: 0.8483404517173767\n",
      "Step 5501/10000- lr: [4.542446072727273e-06] - Loss total: 2.635401487350464, Last rpr Loss: 1.002281665802002, Last lagvar Loss: 0.8435900807380676\n",
      "Step 5502/10000- lr: [4.541435975757576e-06] - Loss total: 2.635344982147217, Last rpr Loss: 0.9979014992713928, Last lagvar Loss: 0.8479700684547424\n",
      "Step 5503/10000- lr: [4.5404258787878785e-06] - Loss total: 2.6352882385253906, Last rpr Loss: 1.0018590688705444, Last lagvar Loss: 0.8440102338790894\n",
      "Step 5504/10000- lr: [4.539415781818182e-06] - Loss total: 2.6352322101593018, Last rpr Loss: 0.9983032941818237, Last lagvar Loss: 0.8475660085678101\n",
      "Step 5505/10000- lr: [4.538405684848485e-06] - Loss total: 2.635176420211792, Last rpr Loss: 1.0014424324035645, Last lagvar Loss: 0.8444252014160156\n",
      "Step 5506/10000- lr: [4.537395587878788e-06] - Loss total: 2.635120153427124, Last rpr Loss: 0.9987016916275024, Last lagvar Loss: 0.8471658229827881\n",
      "Step 5507/10000- lr: [4.536385490909091e-06] - Loss total: 2.6350643634796143, Last rpr Loss: 1.0010902881622314, Last lagvar Loss: 0.8447760343551636\n",
      "Step 5508/10000- lr: [4.535375393939394e-06] - Loss total: 2.6350090503692627, Last rpr Loss: 0.9990493655204773, Last lagvar Loss: 0.8468167781829834\n",
      "Step 5509/10000- lr: [4.5343652969696965e-06] - Loss total: 2.634953022003174, Last rpr Loss: 1.0007836818695068, Last lagvar Loss: 0.845081627368927\n",
      "Step 5510/10000- lr: [4.533355200000001e-06] - Loss total: 2.6348979473114014, Last rpr Loss: 0.999334454536438, Last lagvar Loss: 0.8465307354927063\n",
      "Step 5511/10000- lr: [4.532345103030303e-06] - Loss total: 2.6348423957824707, Last rpr Loss: 1.0005383491516113, Last lagvar Loss: 0.8453262448310852\n",
      "Step 5512/10000- lr: [4.531335006060606e-06] - Loss total: 2.634787082672119, Last rpr Loss: 0.9995462894439697, Last lagvar Loss: 0.846318244934082\n",
      "Step 5513/10000- lr: [4.530324909090909e-06] - Loss total: 2.6347317695617676, Last rpr Loss: 1.0003373622894287, Last lagvar Loss: 0.8455268144607544\n",
      "Step 5514/10000- lr: [4.529314812121213e-06] - Loss total: 2.634676694869995, Last rpr Loss: 0.9997081756591797, Last lagvar Loss: 0.8461558818817139\n",
      "Step 5515/10000- lr: [4.528304715151515e-06] - Loss total: 2.6346213817596436, Last rpr Loss: 1.0001826286315918, Last lagvar Loss: 0.8456809520721436\n",
      "Step 5516/10000- lr: [4.527294618181819e-06] - Loss total: 2.63456654548645, Last rpr Loss: 0.9998325109481812, Last lagvar Loss: 0.8460310697555542\n",
      "Step 5517/10000- lr: [4.526284521212121e-06] - Loss total: 2.6345112323760986, Last rpr Loss: 1.0000832080841064, Last lagvar Loss: 0.8457801342010498\n",
      "Step 5518/10000- lr: [4.525274424242424e-06] - Loss total: 2.6344563961029053, Last rpr Loss: 0.9999327659606934, Last lagvar Loss: 0.8459304571151733\n",
      "Step 5519/10000- lr: [4.524264327272727e-06] - Loss total: 2.634401321411133, Last rpr Loss: 1.000006914138794, Last lagvar Loss: 0.8458560705184937\n",
      "Step 5520/10000- lr: [4.523254230303031e-06] - Loss total: 2.6343460083007812, Last rpr Loss: 1.000006079673767, Last lagvar Loss: 0.845856785774231\n",
      "Step 5521/10000- lr: [4.522244133333333e-06] - Loss total: 2.634290933609009, Last rpr Loss: 0.99993896484375, Last lagvar Loss: 0.8459237813949585\n",
      "Step 5522/10000- lr: [4.5212340363636366e-06] - Loss total: 2.6342360973358154, Last rpr Loss: 1.0000628232955933, Last lagvar Loss: 0.8457996249198914\n",
      "Step 5523/10000- lr: [4.520223939393939e-06] - Loss total: 2.634181261062622, Last rpr Loss: 0.9998811483383179, Last lagvar Loss: 0.8459811806678772\n",
      "Step 5524/10000- lr: [4.519213842424243e-06] - Loss total: 2.6341261863708496, Last rpr Loss: 1.0001178979873657, Last lagvar Loss: 0.8457441926002502\n",
      "Step 5525/10000- lr: [4.5182037454545455e-06] - Loss total: 2.6340715885162354, Last rpr Loss: 0.9998236894607544, Last lagvar Loss: 0.8460383415222168\n",
      "Step 5526/10000- lr: [4.517193648484849e-06] - Loss total: 2.634016752243042, Last rpr Loss: 1.0001804828643799, Last lagvar Loss: 0.8456813097000122\n",
      "Step 5527/10000- lr: [4.516183551515151e-06] - Loss total: 2.6339616775512695, Last rpr Loss: 0.999756932258606, Last lagvar Loss: 0.8461048603057861\n",
      "Step 5528/10000- lr: [4.5151734545454545e-06] - Loss total: 2.633906841278076, Last rpr Loss: 1.0002543926239014, Last lagvar Loss: 0.8456071615219116\n",
      "Step 5529/10000- lr: [4.514163357575757e-06] - Loss total: 2.633852005004883, Last rpr Loss: 0.9996761083602905, Last lagvar Loss: 0.8461854457855225\n",
      "Step 5530/10000- lr: [4.513153260606061e-06] - Loss total: 2.6337969303131104, Last rpr Loss: 1.0003501176834106, Last lagvar Loss: 0.8455110788345337\n",
      "Step 5531/10000- lr: [4.5121431636363635e-06] - Loss total: 2.633742570877075, Last rpr Loss: 0.9995641112327576, Last lagvar Loss: 0.8462972640991211\n",
      "Step 5532/10000- lr: [4.511133066666667e-06] - Loss total: 2.633687734603882, Last rpr Loss: 1.0004751682281494, Last lagvar Loss: 0.8453860282897949\n",
      "Step 5533/10000- lr: [4.510122969696969e-06] - Loss total: 2.6336333751678467, Last rpr Loss: 0.9994120597839355, Last lagvar Loss: 0.8464491367340088\n",
      "Step 5534/10000- lr: [4.509112872727273e-06] - Loss total: 2.6335785388946533, Last rpr Loss: 1.000662088394165, Last lagvar Loss: 0.8451988101005554\n",
      "Step 5535/10000- lr: [4.508102775757576e-06] - Loss total: 2.633524179458618, Last rpr Loss: 0.9991903305053711, Last lagvar Loss: 0.8466709852218628\n",
      "Step 5536/10000- lr: [4.507092678787879e-06] - Loss total: 2.633469581604004, Last rpr Loss: 1.0009269714355469, Last lagvar Loss: 0.8449341058731079\n",
      "Step 5537/10000- lr: [4.5060825818181815e-06] - Loss total: 2.6334152221679688, Last rpr Loss: 0.9988706111907959, Last lagvar Loss: 0.8469911813735962\n",
      "Step 5538/10000- lr: [4.505072484848485e-06] - Loss total: 2.633361339569092, Last rpr Loss: 1.0013220310211182, Last lagvar Loss: 0.8445398807525635\n",
      "Step 5539/10000- lr: [4.504062387878787e-06] - Loss total: 2.633307456970215, Last rpr Loss: 0.998384416103363, Last lagvar Loss: 0.8474786877632141\n",
      "Step 5540/10000- lr: [4.503052290909091e-06] - Loss total: 2.633254289627075, Last rpr Loss: 1.0019199848175049, Last lagvar Loss: 0.8439435362815857\n",
      "Step 5541/10000- lr: [4.502042193939394e-06] - Loss total: 2.633201837539673, Last rpr Loss: 0.9976435899734497, Last lagvar Loss: 0.8482228517532349\n",
      "Step 5542/10000- lr: [4.501032096969697e-06] - Loss total: 2.633150100708008, Last rpr Loss: 1.0028377771377563, Last lagvar Loss: 0.843030571937561\n",
      "Step 5543/10000- lr: [4.5000219999999995e-06] - Loss total: 2.6331002712249756, Last rpr Loss: 0.9965023398399353, Last lagvar Loss: 0.8493719100952148\n",
      "Step 5544/10000- lr: [4.4990119030303036e-06] - Loss total: 2.6330525875091553, Last rpr Loss: 1.0042568445205688, Last lagvar Loss: 0.8416228890419006\n",
      "Step 5545/10000- lr: [4.498001806060606e-06] - Loss total: 2.6330089569091797, Last rpr Loss: 0.994733452796936, Last lagvar Loss: 0.8511595129966736\n",
      "Step 5546/10000- lr: [4.496991709090909e-06] - Loss total: 2.6329703330993652, Last rpr Loss: 1.0064671039581299, Last lagvar Loss: 0.839439868927002\n",
      "Step 5547/10000- lr: [4.495981612121212e-06] - Loss total: 2.6329431533813477, Last rpr Loss: 0.9919730424880981, Last lagvar Loss: 0.8539644479751587\n",
      "Step 5548/10000- lr: [4.494971515151515e-06] - Loss total: 2.632925271987915, Last rpr Loss: 1.009925127029419, Last lagvar Loss: 0.8360470533370972\n",
      "Step 5549/10000- lr: [4.493961418181817e-06] - Loss total: 2.6329376697540283, Last rpr Loss: 0.987662672996521, Last lagvar Loss: 0.8583827018737793\n",
      "Step 5550/10000- lr: [4.4929513212121215e-06] - Loss total: 2.6329662799835205, Last rpr Loss: 1.015283465385437, Last lagvar Loss: 0.8308428525924683\n",
      "Step 5551/10000- lr: [4.491941224242424e-06] - Loss total: 2.6330745220184326, Last rpr Loss: 0.9810707569122314, Last lagvar Loss: 0.8652304410934448\n",
      "Step 5552/10000- lr: [4.490931127272727e-06] - Loss total: 2.633192300796509, Last rpr Loss: 1.0232735872268677, Last lagvar Loss: 0.8231971263885498\n",
      "Step 5553/10000- lr: [4.48992103030303e-06] - Loss total: 2.6335065364837646, Last rpr Loss: 0.9716235995292664, Last lagvar Loss: 0.8752392530441284\n",
      "Step 5554/10000- lr: [4.488910933333334e-06] - Loss total: 2.633720874786377, Last rpr Loss: 1.0339089632034302, Last lagvar Loss: 0.8132162094116211\n",
      "Step 5555/10000- lr: [4.487900836363636e-06] - Loss total: 2.6336512565612793, Last rpr Loss: 0.9680570363998413, Last lagvar Loss: 0.8790695071220398\n",
      "Step 5556/10000- lr: [4.4868907393939395e-06] - Loss total: 2.6333372592926025, Last rpr Loss: 1.029953122138977, Last lagvar Loss: 0.8168812990188599\n",
      "Step 5557/10000- lr: [4.485880642424242e-06] - Loss total: 2.6332380771636963, Last rpr Loss: 0.9720608592033386, Last lagvar Loss: 0.874746561050415\n",
      "Step 5558/10000- lr: [4.484870545454545e-06] - Loss total: 2.6329426765441895, Last rpr Loss: 1.025146722793579, Last lagvar Loss: 0.8213909864425659\n",
      "Step 5559/10000- lr: [4.483860448484848e-06] - Loss total: 2.632760763168335, Last rpr Loss: 0.9784284234046936, Last lagvar Loss: 0.8679914474487305\n",
      "Step 5560/10000- lr: [4.482850351515152e-06] - Loss total: 2.6324985027313232, Last rpr Loss: 1.0176289081573486, Last lagvar Loss: 0.8285667896270752\n",
      "Step 5561/10000- lr: [4.481840254545455e-06] - Loss total: 2.6323063373565674, Last rpr Loss: 0.9872100353240967, Last lagvar Loss: 0.8588470220565796\n",
      "Step 5562/10000- lr: [4.4808301575757575e-06] - Loss total: 2.6321370601654053, Last rpr Loss: 1.0081251859664917, Last lagvar Loss: 0.8378089666366577\n",
      "Step 5563/10000- lr: [4.479820060606062e-06] - Loss total: 2.632024049758911, Last rpr Loss: 0.996457040309906, Last lagvar Loss: 0.8494167327880859\n",
      "Step 5564/10000- lr: [4.478809963636364e-06] - Loss total: 2.6319572925567627, Last rpr Loss: 0.9991922974586487, Last lagvar Loss: 0.8466669917106628\n",
      "Step 5565/10000- lr: [4.477799866666667e-06] - Loss total: 2.631927251815796, Last rpr Loss: 1.0045955181121826, Last lagvar Loss: 0.8412868976593018\n",
      "Step 5566/10000- lr: [4.47678976969697e-06] - Loss total: 2.6319215297698975, Last rpr Loss: 0.9921405911445618, Last lagvar Loss: 0.8537916541099548\n",
      "Step 5567/10000- lr: [4.475779672727273e-06] - Loss total: 2.6319193840026855, Last rpr Loss: 1.0107115507125854, Last lagvar Loss: 0.8352717161178589\n",
      "Step 5568/10000- lr: [4.4747695757575754e-06] - Loss total: 2.631922960281372, Last rpr Loss: 0.9874371290206909, Last lagvar Loss: 0.8586064577102661\n",
      "Step 5569/10000- lr: [4.4737594787878796e-06] - Loss total: 2.6318962574005127, Last rpr Loss: 1.0137807130813599, Last lagvar Loss: 0.8322861194610596\n",
      "Step 5570/10000- lr: [4.472749381818182e-06] - Loss total: 2.631870985031128, Last rpr Loss: 0.9856231212615967, Last lagvar Loss: 0.8604758977890015\n",
      "Step 5571/10000- lr: [4.471739284848485e-06] - Loss total: 2.6318001747131348, Last rpr Loss: 1.0140070915222168, Last lagvar Loss: 0.8320692181587219\n",
      "Step 5572/10000- lr: [4.470729187878788e-06] - Loss total: 2.63173246383667, Last rpr Loss: 0.986630916595459, Last lagvar Loss: 0.8594337105751038\n",
      "Step 5573/10000- lr: [4.469719090909092e-06] - Loss total: 2.6316323280334473, Last rpr Loss: 1.0118695497512817, Last lagvar Loss: 0.8341439366340637\n",
      "Step 5574/10000- lr: [4.468708993939394e-06] - Loss total: 2.6315395832061768, Last rpr Loss: 0.9898853302001953, Last lagvar Loss: 0.8560881614685059\n",
      "Step 5575/10000- lr: [4.4676988969696975e-06] - Loss total: 2.631441116333008, Last rpr Loss: 1.0079745054244995, Last lagvar Loss: 0.837950587272644\n",
      "Step 5576/10000- lr: [4.4666888e-06] - Loss total: 2.631354570388794, Last rpr Loss: 0.994337797164917, Last lagvar Loss: 0.8515531420707703\n",
      "Step 5577/10000- lr: [4.465678703030303e-06] - Loss total: 2.6312777996063232, Last rpr Loss: 1.003265380859375, Last lagvar Loss: 0.8426001667976379\n",
      "Step 5578/10000- lr: [4.464668606060606e-06] - Loss total: 2.631214141845703, Last rpr Loss: 0.9990280270576477, Last lagvar Loss: 0.8468265533447266\n",
      "Step 5579/10000- lr: [4.46365850909091e-06] - Loss total: 2.6311614513397217, Last rpr Loss: 0.9988815784454346, Last lagvar Loss: 0.8469728827476501\n",
      "Step 5580/10000- lr: [4.462648412121212e-06] - Loss total: 2.6311163902282715, Last rpr Loss: 1.0029404163360596, Last lagvar Loss: 0.8429219722747803\n",
      "Step 5581/10000- lr: [4.4616383151515155e-06] - Loss total: 2.6310770511627197, Last rpr Loss: 0.9955358505249023, Last lagvar Loss: 0.8503403663635254\n",
      "Step 5582/10000- lr: [4.460628218181818e-06] - Loss total: 2.6310372352600098, Last rpr Loss: 1.0056297779083252, Last lagvar Loss: 0.8402583599090576\n",
      "Step 5583/10000- lr: [4.459618121212122e-06] - Loss total: 2.630997657775879, Last rpr Loss: 0.9934590458869934, Last lagvar Loss: 0.8524439334869385\n",
      "Step 5584/10000- lr: [4.4586080242424245e-06] - Loss total: 2.6309516429901123, Last rpr Loss: 1.0070843696594238, Last lagvar Loss: 0.8388241529464722\n",
      "Step 5585/10000- lr: [4.457597927272728e-06] - Loss total: 2.63090443611145, Last rpr Loss: 0.9926009178161621, Last lagvar Loss: 0.8533147573471069\n",
      "Step 5586/10000- lr: [4.45658783030303e-06] - Loss total: 2.630849599838257, Last rpr Loss: 1.0073492527008057, Last lagvar Loss: 0.8385629653930664\n",
      "Step 5587/10000- lr: [4.4555777333333335e-06] - Loss total: 2.6307942867279053, Last rpr Loss: 0.9929466247558594, Last lagvar Loss: 0.8529632687568665\n",
      "Step 5588/10000- lr: [4.454567636363636e-06] - Loss total: 2.6307332515716553, Last rpr Loss: 1.0065767765045166, Last lagvar Loss: 0.8393236398696899\n",
      "Step 5589/10000- lr: [4.45355753939394e-06] - Loss total: 2.6306726932525635, Last rpr Loss: 0.9940444827079773, Last lagvar Loss: 0.8518483638763428\n",
      "Step 5590/10000- lr: [4.4525474424242425e-06] - Loss total: 2.630610227584839, Last rpr Loss: 1.0051836967468262, Last lagvar Loss: 0.8406977653503418\n",
      "Step 5591/10000- lr: [4.451537345454546e-06] - Loss total: 2.630549430847168, Last rpr Loss: 0.9956088066101074, Last lagvar Loss: 0.8502646088600159\n",
      "Step 5592/10000- lr: [4.450527248484848e-06] - Loss total: 2.6304891109466553, Last rpr Loss: 1.003498911857605, Last lagvar Loss: 0.8423653841018677\n",
      "Step 5593/10000- lr: [4.449517151515152e-06] - Loss total: 2.6304309368133545, Last rpr Loss: 0.9973210096359253, Last lagvar Loss: 0.8485375046730042\n",
      "Step 5594/10000- lr: [4.448507054545455e-06] - Loss total: 2.6303741931915283, Last rpr Loss: 1.001771330833435, Last lagvar Loss: 0.8440821766853333\n",
      "Step 5595/10000- lr: [4.447496957575758e-06] - Loss total: 2.6303188800811768, Last rpr Loss: 0.9989783763885498, Last lagvar Loss: 0.8468726873397827\n",
      "Step 5596/10000- lr: [4.4464868606060604e-06] - Loss total: 2.630265474319458, Last rpr Loss: 1.0002365112304688, Last lagvar Loss: 0.8456130623817444\n",
      "Step 5597/10000- lr: [4.445476763636364e-06] - Loss total: 2.630213499069214, Last rpr Loss: 1.0004329681396484, Last lagvar Loss: 0.8454164266586304\n",
      "Step 5598/10000- lr: [4.444466666666666e-06] - Loss total: 2.630162239074707, Last rpr Loss: 0.9989982843399048, Last lagvar Loss: 0.8468519449234009\n",
      "Step 5599/10000- lr: [4.44345656969697e-06] - Loss total: 2.6301109790802, Last rpr Loss: 1.0015190839767456, Last lagvar Loss: 0.844332218170166\n",
      "Step 5600/10000- lr: [4.442446472727273e-06] - Loss total: 2.6300606727600098, Last rpr Loss: 0.9980072379112244, Last lagvar Loss: 0.8478460311889648\n",
      "Step 5601/10000- lr: [4.441436375757576e-06] - Loss total: 2.630009889602661, Last rpr Loss: 1.002343773841858, Last lagvar Loss: 0.8435106873512268\n",
      "Step 5602/10000- lr: [4.440426278787878e-06] - Loss total: 2.629960060119629, Last rpr Loss: 0.9972890615463257, Last lagvar Loss: 0.8485677242279053\n",
      "Step 5603/10000- lr: [4.4394161818181825e-06] - Loss total: 2.6299092769622803, Last rpr Loss: 1.0029523372650146, Last lagvar Loss: 0.8429052233695984\n",
      "Step 5604/10000- lr: [4.438406084848485e-06] - Loss total: 2.6298584938049316, Last rpr Loss: 0.9968050718307495, Last lagvar Loss: 0.8490548133850098\n",
      "Step 5605/10000- lr: [4.437395987878788e-06] - Loss total: 2.629807472229004, Last rpr Loss: 1.0033552646636963, Last lagvar Loss: 0.8425047397613525\n",
      "Step 5606/10000- lr: [4.436385890909091e-06] - Loss total: 2.6297566890716553, Last rpr Loss: 0.9964586496353149, Last lagvar Loss: 0.849403440952301\n",
      "Step 5607/10000- lr: [4.435375793939394e-06] - Loss total: 2.6297054290771484, Last rpr Loss: 1.003638744354248, Last lagvar Loss: 0.8422234058380127\n",
      "Step 5608/10000- lr: [4.434365696969696e-06] - Loss total: 2.6296544075012207, Last rpr Loss: 0.9961873292922974, Last lagvar Loss: 0.8496765494346619\n",
      "Step 5609/10000- lr: [4.4333556000000005e-06] - Loss total: 2.629603147506714, Last rpr Loss: 1.0039113759994507, Last lagvar Loss: 0.8419524431228638\n",
      "Step 5610/10000- lr: [4.432345503030303e-06] - Loss total: 2.6295526027679443, Last rpr Loss: 0.9959619641304016, Last lagvar Loss: 0.8499037027359009\n",
      "Step 5611/10000- lr: [4.431335406060606e-06] - Loss total: 2.6295015811920166, Last rpr Loss: 1.004165768623352, Last lagvar Loss: 0.8416998386383057\n",
      "Step 5612/10000- lr: [4.430325309090909e-06] - Loss total: 2.629451036453247, Last rpr Loss: 0.9956744909286499, Last lagvar Loss: 0.8501935005187988\n",
      "Step 5613/10000- lr: [4.429315212121213e-06] - Loss total: 2.6294002532958984, Last rpr Loss: 1.004463791847229, Last lagvar Loss: 0.8414043188095093\n",
      "Step 5614/10000- lr: [4.428305115151515e-06] - Loss total: 2.6293506622314453, Last rpr Loss: 0.9953213930130005, Last lagvar Loss: 0.8505498170852661\n",
      "Step 5615/10000- lr: [4.4272950181818185e-06] - Loss total: 2.629300355911255, Last rpr Loss: 1.004885196685791, Last lagvar Loss: 0.8409870266914368\n",
      "Step 5616/10000- lr: [4.426284921212121e-06] - Loss total: 2.6292524337768555, Last rpr Loss: 0.9948288202285767, Last lagvar Loss: 0.851047694683075\n",
      "Step 5617/10000- lr: [4.425274824242424e-06] - Loss total: 2.6292033195495605, Last rpr Loss: 1.0054562091827393, Last lagvar Loss: 0.8404222130775452\n",
      "Step 5618/10000- lr: [4.424264727272727e-06] - Loss total: 2.6291563510894775, Last rpr Loss: 0.9941689968109131, Last lagvar Loss: 0.8517155647277832\n",
      "Step 5619/10000- lr: [4.423254630303031e-06] - Loss total: 2.6291093826293945, Last rpr Loss: 1.0062205791473389, Last lagvar Loss: 0.8396674394607544\n",
      "Step 5620/10000- lr: [4.422244533333333e-06] - Loss total: 2.629065752029419, Last rpr Loss: 0.9932801723480225, Last lagvar Loss: 0.8526171445846558\n",
      "Step 5621/10000- lr: [4.4212344363636364e-06] - Loss total: 2.6290206909179688, Last rpr Loss: 1.007256269454956, Last lagvar Loss: 0.8386470675468445\n",
      "Step 5622/10000- lr: [4.420224339393939e-06] - Loss total: 2.628981590270996, Last rpr Loss: 0.9920839071273804, Last lagvar Loss: 0.8538337349891663\n",
      "Step 5623/10000- lr: [4.419214242424243e-06] - Loss total: 2.6289408206939697, Last rpr Loss: 1.008619785308838, Last lagvar Loss: 0.837307333946228\n",
      "Step 5624/10000- lr: [4.418204145454545e-06] - Loss total: 2.628908634185791, Last rpr Loss: 0.9905228614807129, Last lagvar Loss: 0.8554263114929199\n",
      "Step 5625/10000- lr: [4.417194048484849e-06] - Loss total: 2.628873586654663, Last rpr Loss: 1.0103859901428223, Last lagvar Loss: 0.8355780839920044\n",
      "Step 5626/10000- lr: [4.416183951515151e-06] - Loss total: 2.628852128982544, Last rpr Loss: 0.9885402917861938, Last lagvar Loss: 0.8574575781822205\n",
      "Step 5627/10000- lr: [4.415173854545454e-06] - Loss total: 2.6288249492645264, Last rpr Loss: 1.0125972032546997, Last lagvar Loss: 0.8334227800369263\n",
      "Step 5628/10000- lr: [4.414163757575757e-06] - Loss total: 2.6288199424743652, Last rpr Loss: 0.9860973954200745, Last lagvar Loss: 0.8599737882614136\n",
      "Step 5629/10000- lr: [4.413153660606061e-06] - Loss total: 2.628800630569458, Last rpr Loss: 1.0152606964111328, Last lagvar Loss: 0.8308401703834534\n",
      "Step 5630/10000- lr: [4.412143563636363e-06] - Loss total: 2.6288163661956787, Last rpr Loss: 0.9832483530044556, Last lagvar Loss: 0.8629261255264282\n",
      "Step 5631/10000- lr: [4.411133466666667e-06] - Loss total: 2.628801107406616, Last rpr Loss: 1.0182080268859863, Last lagvar Loss: 0.8279992938041687\n",
      "Step 5632/10000- lr: [4.410123369696969e-06] - Loss total: 2.6288368701934814, Last rpr Loss: 0.9802870154380798, Last lagvar Loss: 0.8660154938697815\n",
      "Step 5633/10000- lr: [4.409113272727273e-06] - Loss total: 2.6288115978240967, Last rpr Loss: 1.021000623703003, Last lagvar Loss: 0.8253228068351746\n",
      "Step 5634/10000- lr: [4.408103175757576e-06] - Loss total: 2.6288509368896484, Last rpr Loss: 0.977857232093811, Last lagvar Loss: 0.8685656785964966\n",
      "Step 5635/10000- lr: [4.407093078787879e-06] - Loss total: 2.628788709640503, Last rpr Loss: 1.0228095054626465, Last lagvar Loss: 0.8235952854156494\n",
      "Step 5636/10000- lr: [4.406082981818181e-06] - Loss total: 2.628793716430664, Last rpr Loss: 0.9769371151924133, Last lagvar Loss: 0.8695327043533325\n",
      "Step 5637/10000- lr: [4.405072884848485e-06] - Loss total: 2.6286709308624268, Last rpr Loss: 1.0225448608398438, Last lagvar Loss: 0.8238434791564941\n",
      "Step 5638/10000- lr: [4.404062787878787e-06] - Loss total: 2.628603219985962, Last rpr Loss: 0.9786183834075928, Last lagvar Loss: 0.8677594661712646\n",
      "Step 5639/10000- lr: [4.403052690909091e-06] - Loss total: 2.6284306049346924, Last rpr Loss: 1.019400715827942, Last lagvar Loss: 0.8268449306488037\n",
      "Step 5640/10000- lr: [4.402042593939394e-06] - Loss total: 2.628297805786133, Last rpr Loss: 0.9832892417907715, Last lagvar Loss: 0.8628771305084229\n",
      "Step 5641/10000- lr: [4.401032496969697e-06] - Loss total: 2.628127336502075, Last rpr Loss: 1.013509750366211, Last lagvar Loss: 0.8325287103652954\n",
      "Step 5642/10000- lr: [4.400022399999999e-06] - Loss total: 2.6279914379119873, Last rpr Loss: 0.9901379346847534, Last lagvar Loss: 0.8558157682418823\n",
      "Step 5643/10000- lr: [4.3990123030303034e-06] - Loss total: 2.627873182296753, Last rpr Loss: 1.0061755180358887, Last lagvar Loss: 0.8397070169448853\n",
      "Step 5644/10000- lr: [4.398002206060606e-06] - Loss total: 2.6277878284454346, Last rpr Loss: 0.9975295662879944, Last lagvar Loss: 0.848318338394165\n",
      "Step 5645/10000- lr: [4.396992109090909e-06] - Loss total: 2.6277308464050293, Last rpr Loss: 0.999092698097229, Last lagvar Loss: 0.8467487096786499\n",
      "Step 5646/10000- lr: [4.3959820121212124e-06] - Loss total: 2.6276960372924805, Last rpr Loss: 1.003948450088501, Last lagvar Loss: 0.8419091701507568\n",
      "Step 5647/10000- lr: [4.394971915151515e-06] - Loss total: 2.6276743412017822, Last rpr Loss: 0.993496835231781, Last lagvar Loss: 0.8523916006088257\n",
      "Step 5648/10000- lr: [4.393961818181819e-06] - Loss total: 2.627654790878296, Last rpr Loss: 1.0085047483444214, Last lagvar Loss: 0.8374149203300476\n",
      "Step 5649/10000- lr: [4.392951721212121e-06] - Loss total: 2.627636671066284, Last rpr Loss: 0.9899944067001343, Last lagvar Loss: 0.8559601306915283\n",
      "Step 5650/10000- lr: [4.391941624242425e-06] - Loss total: 2.6276016235351562, Last rpr Loss: 1.0108752250671387, Last lagvar Loss: 0.8350942134857178\n",
      "Step 5651/10000- lr: [4.390931527272727e-06] - Loss total: 2.6275646686553955, Last rpr Loss: 0.9887169599533081, Last lagvar Loss: 0.857268214225769\n",
      "Step 5652/10000- lr: [4.389921430303031e-06] - Loss total: 2.627504348754883, Last rpr Loss: 1.0110825300216675, Last lagvar Loss: 0.8348913788795471\n",
      "Step 5653/10000- lr: [4.388911333333334e-06] - Loss total: 2.62744402885437, Last rpr Loss: 0.9894791841506958, Last lagvar Loss: 0.8564860820770264\n",
      "Step 5654/10000- lr: [4.387901236363637e-06] - Loss total: 2.6273674964904785, Last rpr Loss: 1.0094631910324097, Last lagvar Loss: 0.8364740014076233\n",
      "Step 5655/10000- lr: [4.386891139393939e-06] - Loss total: 2.627293825149536, Last rpr Loss: 0.9918006658554077, Last lagvar Loss: 0.8541141748428345\n",
      "Step 5656/10000- lr: [4.385881042424243e-06] - Loss total: 2.6272172927856445, Last rpr Loss: 1.0066274404525757, Last lagvar Loss: 0.8392593860626221\n",
      "Step 5657/10000- lr: [4.384870945454545e-06] - Loss total: 2.6271462440490723, Last rpr Loss: 0.9949901700019836, Last lagvar Loss: 0.8508764505386353\n",
      "Step 5658/10000- lr: [4.383860848484849e-06] - Loss total: 2.627079963684082, Last rpr Loss: 1.0033015012741089, Last lagvar Loss: 0.8425484299659729\n",
      "Step 5659/10000- lr: [4.382850751515152e-06] - Loss total: 2.6270201206207275, Last rpr Loss: 0.9983409643173218, Last lagvar Loss: 0.8474999666213989\n",
      "Step 5660/10000- lr: [4.381840654545455e-06] - Loss total: 2.626966714859009, Last rpr Loss: 1.00011146068573, Last lagvar Loss: 0.8457261919975281\n",
      "Step 5661/10000- lr: [4.380830557575757e-06] - Loss total: 2.626917839050293, Last rpr Loss: 1.001287579536438, Last lagvar Loss: 0.844551682472229\n",
      "Step 5662/10000- lr: [4.3798204606060615e-06] - Loss total: 2.6268718242645264, Last rpr Loss: 0.997496485710144, Last lagvar Loss: 0.8483481407165527\n",
      "Step 5663/10000- lr: [4.378810363636364e-06] - Loss total: 2.6268279552459717, Last rpr Loss: 1.0035064220428467, Last lagvar Loss: 0.8423442840576172\n",
      "Step 5664/10000- lr: [4.377800266666667e-06] - Loss total: 2.626784563064575, Last rpr Loss: 0.9956653714179993, Last lagvar Loss: 0.8501932621002197\n",
      "Step 5665/10000- lr: [4.37679016969697e-06] - Loss total: 2.626739263534546, Last rpr Loss: 1.0049210786819458, Last lagvar Loss: 0.8409427404403687\n",
      "Step 5666/10000- lr: [4.375780072727273e-06] - Loss total: 2.6266939640045166, Last rpr Loss: 0.9946317672729492, Last lagvar Loss: 0.8512380123138428\n",
      "Step 5667/10000- lr: [4.374769975757575e-06] - Loss total: 2.62664532661438, Last rpr Loss: 1.005581259727478, Last lagvar Loss: 0.8402900695800781\n",
      "Step 5668/10000- lr: [4.3737598787878794e-06] - Loss total: 2.626596450805664, Last rpr Loss: 0.9943079948425293, Last lagvar Loss: 0.8515657186508179\n",
      "Step 5669/10000- lr: [4.372749781818182e-06] - Loss total: 2.626544952392578, Last rpr Loss: 1.005610704421997, Last lagvar Loss: 0.8402606844902039\n",
      "Step 5670/10000- lr: [4.371739684848485e-06] - Loss total: 2.626492977142334, Last rpr Loss: 0.9945318698883057, Last lagvar Loss: 0.8513385653495789\n",
      "Step 5671/10000- lr: [4.370729587878788e-06] - Loss total: 2.626439094543457, Last rpr Loss: 1.0051780939102173, Last lagvar Loss: 0.8406877517700195\n",
      "Step 5672/10000- lr: [4.369719490909092e-06] - Loss total: 2.62638521194458, Last rpr Loss: 0.9951326251029968, Last lagvar Loss: 0.8507304787635803\n",
      "Step 5673/10000- lr: [4.368709393939394e-06] - Loss total: 2.626330614089966, Last rpr Loss: 1.0044574737548828, Last lagvar Loss: 0.8414003849029541\n",
      "Step 5674/10000- lr: [4.367699296969697e-06] - Loss total: 2.6262764930725098, Last rpr Loss: 0.9959293603897095, Last lagvar Loss: 0.8499252200126648\n",
      "Step 5675/10000- lr: [4.3666892e-06] - Loss total: 2.6262223720550537, Last rpr Loss: 1.0036027431488037, Last lagvar Loss: 0.8422470688819885\n",
      "Step 5676/10000- lr: [4.365679103030303e-06] - Loss total: 2.626168966293335, Last rpr Loss: 0.9968115091323853, Last lagvar Loss: 0.8490354418754578\n",
      "Step 5677/10000- lr: [4.3646690060606055e-06] - Loss total: 2.6261157989501953, Last rpr Loss: 1.0027294158935547, Last lagvar Loss: 0.843113899230957\n",
      "Step 5678/10000- lr: [4.36365890909091e-06] - Loss total: 2.626063346862793, Last rpr Loss: 0.9976665377616882, Last lagvar Loss: 0.8481746912002563\n",
      "Step 5679/10000- lr: [4.362648812121212e-06] - Loss total: 2.626011371612549, Last rpr Loss: 1.0019195079803467, Last lagvar Loss: 0.8439191579818726\n",
      "Step 5680/10000- lr: [4.361638715151515e-06] - Loss total: 2.625959873199463, Last rpr Loss: 0.9984246492385864, Last lagvar Loss: 0.8474128246307373\n",
      "Step 5681/10000- lr: [4.360628618181818e-06] - Loss total: 2.625908613204956, Last rpr Loss: 1.0012233257293701, Last lagvar Loss: 0.8446125984191895\n",
      "Step 5682/10000- lr: [4.359618521212122e-06] - Loss total: 2.6258575916290283, Last rpr Loss: 0.9990667104721069, Last lagvar Loss: 0.8467684984207153\n",
      "Step 5683/10000- lr: [4.358608424242424e-06] - Loss total: 2.625807762145996, Last rpr Loss: 1.0006351470947266, Last lagvar Loss: 0.8451993465423584\n",
      "Step 5684/10000- lr: [4.357598327272728e-06] - Loss total: 2.6257569789886475, Last rpr Loss: 0.9995925426483154, Last lagvar Loss: 0.8462415933609009\n",
      "Step 5685/10000- lr: [4.35658823030303e-06] - Loss total: 2.625706911087036, Last rpr Loss: 1.0001552104949951, Last lagvar Loss: 0.8456783294677734\n",
      "Step 5686/10000- lr: [4.355578133333333e-06] - Loss total: 2.625657320022583, Last rpr Loss: 1.0000146627426147, Last lagvar Loss: 0.8458187580108643\n",
      "Step 5687/10000- lr: [4.354568036363636e-06] - Loss total: 2.6256070137023926, Last rpr Loss: 0.9997725486755371, Last lagvar Loss: 0.8460607528686523\n",
      "Step 5688/10000- lr: [4.35355793939394e-06] - Loss total: 2.6255576610565186, Last rpr Loss: 1.0003646612167358, Last lagvar Loss: 0.8454685211181641\n",
      "Step 5689/10000- lr: [4.352547842424242e-06] - Loss total: 2.6255078315734863, Last rpr Loss: 0.9994581937789917, Last lagvar Loss: 0.846375048160553\n",
      "Step 5690/10000- lr: [4.351537745454546e-06] - Loss total: 2.625457763671875, Last rpr Loss: 1.0006660223007202, Last lagvar Loss: 0.8451671004295349\n",
      "Step 5691/10000- lr: [4.350527648484848e-06] - Loss total: 2.62540864944458, Last rpr Loss: 0.9991747140884399, Last lagvar Loss: 0.8466585278511047\n",
      "Step 5692/10000- lr: [4.349517551515152e-06] - Loss total: 2.625359296798706, Last rpr Loss: 1.0009405612945557, Last lagvar Loss: 0.8448926210403442\n",
      "Step 5693/10000- lr: [4.348507454545455e-06] - Loss total: 2.625309944152832, Last rpr Loss: 0.9988980293273926, Last lagvar Loss: 0.8469353914260864\n",
      "Step 5694/10000- lr: [4.347497357575758e-06] - Loss total: 2.625260829925537, Last rpr Loss: 1.0012269020080566, Last lagvar Loss: 0.8446065187454224\n",
      "Step 5695/10000- lr: [4.34648726060606e-06] - Loss total: 2.625211477279663, Last rpr Loss: 0.9985941648483276, Last lagvar Loss: 0.8472397327423096\n",
      "Step 5696/10000- lr: [4.3454771636363636e-06] - Loss total: 2.6251628398895264, Last rpr Loss: 1.0015573501586914, Last lagvar Loss: 0.8442767858505249\n",
      "Step 5697/10000- lr: [4.344467066666666e-06] - Loss total: 2.6251137256622314, Last rpr Loss: 0.9982204437255859, Last lagvar Loss: 0.8476142883300781\n",
      "Step 5698/10000- lr: [4.34345696969697e-06] - Loss total: 2.6250650882720947, Last rpr Loss: 1.0019800662994385, Last lagvar Loss: 0.8438552021980286\n",
      "Step 5699/10000- lr: [4.3424468727272726e-06] - Loss total: 2.625016927719116, Last rpr Loss: 0.9977422952651978, Last lagvar Loss: 0.8480943441390991\n",
      "Step 5700/10000- lr: [4.341436775757576e-06] - Loss total: 2.6249687671661377, Last rpr Loss: 1.0025286674499512, Last lagvar Loss: 0.8433090448379517\n",
      "Step 5701/10000- lr: [4.340426678787878e-06] - Loss total: 2.6249215602874756, Last rpr Loss: 0.9971027374267578, Last lagvar Loss: 0.8487372398376465\n",
      "Step 5702/10000- lr: [4.339416581818182e-06] - Loss total: 2.62487530708313, Last rpr Loss: 1.0032756328582764, Last lagvar Loss: 0.8425664305686951\n",
      "Step 5703/10000- lr: [4.338406484848485e-06] - Loss total: 2.6248295307159424, Last rpr Loss: 0.996221661567688, Last lagvar Loss: 0.8496245741844177\n",
      "Step 5704/10000- lr: [4.337396387878788e-06] - Loss total: 2.6247854232788086, Last rpr Loss: 1.0043258666992188, Last lagvar Loss: 0.8415247201919556\n",
      "Step 5705/10000- lr: [4.3363862909090905e-06] - Loss total: 2.6247429847717285, Last rpr Loss: 0.9949725866317749, Last lagvar Loss: 0.8508858680725098\n",
      "Step 5706/10000- lr: [4.335376193939394e-06] - Loss total: 2.6247031688690186, Last rpr Loss: 1.0058051347732544, Last lagvar Loss: 0.8400617241859436\n",
      "Step 5707/10000- lr: [4.334366096969696e-06] - Loss total: 2.6246678829193115, Last rpr Loss: 0.993215799331665, Last lagvar Loss: 0.8526661396026611\n",
      "Step 5708/10000- lr: [4.333356e-06] - Loss total: 2.6246354579925537, Last rpr Loss: 1.007899284362793, Last lagvar Loss: 0.8379991054534912\n",
      "Step 5709/10000- lr: [4.332345903030303e-06] - Loss total: 2.6246142387390137, Last rpr Loss: 0.9907181262969971, Last lagvar Loss: 0.8552098274230957\n",
      "Step 5710/10000- lr: [4.331335806060606e-06] - Loss total: 2.6245968341827393, Last rpr Loss: 1.0108685493469238, Last lagvar Loss: 0.8350908756256104\n",
      "Step 5711/10000- lr: [4.3303257090909085e-06] - Loss total: 2.624603271484375, Last rpr Loss: 0.9872002005577087, Last lagvar Loss: 0.8588178157806396\n",
      "Step 5712/10000- lr: [4.329315612121213e-06] - Loss total: 2.6246116161346436, Last rpr Loss: 1.0150047540664673, Last lagvar Loss: 0.8310709595680237\n",
      "Step 5713/10000- lr: [4.328305515151515e-06] - Loss total: 2.6246702671051025, Last rpr Loss: 0.9823873043060303, Last lagvar Loss: 0.8638018369674683\n",
      "Step 5714/10000- lr: [4.327295418181818e-06] - Loss total: 2.624716281890869, Last rpr Loss: 1.0205050706863403, Last lagvar Loss: 0.8257796764373779\n",
      "Step 5715/10000- lr: [4.326285321212121e-06] - Loss total: 2.6248619556427, Last rpr Loss: 0.9762376546859741, Last lagvar Loss: 0.8702518939971924\n",
      "Step 5716/10000- lr: [4.325275224242424e-06] - Loss total: 2.6249353885650635, Last rpr Loss: 1.0270686149597168, Last lagvar Loss: 0.8195425271987915\n",
      "Step 5717/10000- lr: [4.3242651272727265e-06] - Loss total: 2.6251766681671143, Last rpr Loss: 0.9695829153060913, Last lagvar Loss: 0.8773339986801147\n",
      "Step 5718/10000- lr: [4.323255030303031e-06] - Loss total: 2.6251909732818604, Last rpr Loss: 1.0330562591552734, Last lagvar Loss: 0.8139166235923767\n",
      "Step 5719/10000- lr: [4.322244933333333e-06] - Loss total: 2.6252262592315674, Last rpr Loss: 0.9674457311630249, Last lagvar Loss: 0.8796228170394897\n",
      "Step 5720/10000- lr: [4.321234836363636e-06] - Loss total: 2.6249256134033203, Last rpr Loss: 1.0305471420288086, Last lagvar Loss: 0.816247820854187\n",
      "Step 5721/10000- lr: [4.320224739393939e-06] - Loss total: 2.6247596740722656, Last rpr Loss: 0.9727382659912109, Last lagvar Loss: 0.8739451169967651\n",
      "Step 5722/10000- lr: [4.319214642424243e-06] - Loss total: 2.624396800994873, Last rpr Loss: 1.022420883178711, Last lagvar Loss: 0.8239283561706543\n",
      "Step 5723/10000- lr: [4.318204545454545e-06] - Loss total: 2.624131441116333, Last rpr Loss: 0.9837258458137512, Last lagvar Loss: 0.8624035120010376\n",
      "Step 5724/10000- lr: [4.3171944484848486e-06] - Loss total: 2.623892307281494, Last rpr Loss: 1.0097812414169312, Last lagvar Loss: 0.8361483812332153\n",
      "Step 5725/10000- lr: [4.316184351515151e-06] - Loss total: 2.6237552165985107, Last rpr Loss: 0.9971699714660645, Last lagvar Loss: 0.8486679792404175\n",
      "Step 5726/10000- lr: [4.315174254545454e-06] - Loss total: 2.6237094402313232, Last rpr Loss: 0.9966901540756226, Last lagvar Loss: 0.8491494655609131\n",
      "Step 5727/10000- lr: [4.314164157575757e-06] - Loss total: 2.6237289905548096, Last rpr Loss: 1.0086870193481445, Last lagvar Loss: 0.8372223377227783\n",
      "Step 5728/10000- lr: [4.313154060606061e-06] - Loss total: 2.6237833499908447, Last rpr Loss: 0.9870710372924805, Last lagvar Loss: 0.8589428067207336\n",
      "Step 5729/10000- lr: [4.312143963636363e-06] - Loss total: 2.623812675476074, Last rpr Loss: 1.0156832933425903, Last lagvar Loss: 0.8304093480110168\n",
      "Step 5730/10000- lr: [4.3111338666666665e-06] - Loss total: 2.6238327026367188, Last rpr Loss: 0.9827829599380493, Last lagvar Loss: 0.8633801937103271\n",
      "Step 5731/10000- lr: [4.310123769696971e-06] - Loss total: 2.6237642765045166, Last rpr Loss: 1.0172274112701416, Last lagvar Loss: 0.8289129137992859\n",
      "Step 5732/10000- lr: [4.309113672727273e-06] - Loss total: 2.623685121536255, Last rpr Loss: 0.9841207265853882, Last lagvar Loss: 0.8619886636734009\n",
      "Step 5733/10000- lr: [4.308103575757576e-06] - Loss total: 2.623547077178955, Last rpr Loss: 1.0133607387542725, Last lagvar Loss: 0.8326528072357178\n",
      "Step 5734/10000- lr: [4.307093478787879e-06] - Loss total: 2.6234219074249268, Last rpr Loss: 0.9900619387626648, Last lagvar Loss: 0.8558719158172607\n",
      "Step 5735/10000- lr: [4.306083381818182e-06] - Loss total: 2.6233067512512207, Last rpr Loss: 1.0059690475463867, Last lagvar Loss: 0.8398947715759277\n",
      "Step 5736/10000- lr: [4.3050732848484845e-06] - Loss total: 2.623225450515747, Last rpr Loss: 0.9979909062385559, Last lagvar Loss: 0.8478378057479858\n",
      "Step 5737/10000- lr: [4.304063187878789e-06] - Loss total: 2.6231765747070312, Last rpr Loss: 0.9981411695480347, Last lagvar Loss: 0.8476862907409668\n",
      "Step 5738/10000- lr: [4.303053090909091e-06] - Loss total: 2.623152494430542, Last rpr Loss: 1.004995346069336, Last lagvar Loss: 0.8408564329147339\n",
      "Step 5739/10000- lr: [4.302042993939394e-06] - Loss total: 2.6231396198272705, Last rpr Loss: 0.9924267530441284, Last lagvar Loss: 0.8534596562385559\n",
      "Step 5740/10000- lr: [4.301032896969697e-06] - Loss total: 2.6231205463409424, Last rpr Loss: 1.0091919898986816, Last lagvar Loss: 0.8367237448692322\n",
      "Step 5741/10000- lr: [4.300022800000001e-06] - Loss total: 2.6230931282043457, Last rpr Loss: 0.9899607300758362, Last lagvar Loss: 0.8559752106666565\n",
      "Step 5742/10000- lr: [4.299012703030303e-06] - Loss total: 2.6230409145355225, Last rpr Loss: 1.0100375413894653, Last lagvar Loss: 0.8358930349349976\n",
      "Step 5743/10000- lr: [4.298002606060607e-06] - Loss total: 2.6229805946350098, Last rpr Loss: 0.9907615780830383, Last lagvar Loss: 0.855155885219574\n",
      "Step 5744/10000- lr: [4.296992509090909e-06] - Loss total: 2.6229050159454346, Last rpr Loss: 1.007845163345337, Last lagvar Loss: 0.8380424976348877\n",
      "Step 5745/10000- lr: [4.295982412121212e-06] - Loss total: 2.6228320598602295, Last rpr Loss: 0.9940410256385803, Last lagvar Loss: 0.8518201112747192\n",
      "Step 5746/10000- lr: [4.294972315151515e-06] - Loss total: 2.6227619647979736, Last rpr Loss: 1.0037784576416016, Last lagvar Loss: 0.842059314250946\n",
      "Step 5747/10000- lr: [4.293962218181819e-06] - Loss total: 2.6227025985717773, Last rpr Loss: 0.9983667731285095, Last lagvar Loss: 0.847458004951477\n",
      "Step 5748/10000- lr: [4.292952121212121e-06] - Loss total: 2.622653007507324, Last rpr Loss: 0.9994739294052124, Last lagvar Loss: 0.8463480472564697\n",
      "Step 5749/10000- lr: [4.2919420242424246e-06] - Loss total: 2.6226112842559814, Last rpr Loss: 1.002289056777954, Last lagvar Loss: 0.8435386419296265\n",
      "Step 5750/10000- lr: [4.290931927272727e-06] - Loss total: 2.6225733757019043, Last rpr Loss: 0.9961807727813721, Last lagvar Loss: 0.8496565818786621\n",
      "Step 5751/10000- lr: [4.289921830303031e-06] - Loss total: 2.6225366592407227, Last rpr Loss: 1.0049077272415161, Last lagvar Loss: 0.8409402966499329\n",
      "Step 5752/10000- lr: [4.2889117333333335e-06] - Loss total: 2.622497081756592, Last rpr Loss: 0.9944149851799011, Last lagvar Loss: 0.8514405488967896\n",
      "Step 5753/10000- lr: [4.287901636363637e-06] - Loss total: 2.6224522590637207, Last rpr Loss: 1.0058516263961792, Last lagvar Loss: 0.8400065898895264\n",
      "Step 5754/10000- lr: [4.286891539393939e-06] - Loss total: 2.6224043369293213, Last rpr Loss: 0.9942712187767029, Last lagvar Loss: 0.8515855073928833\n",
      "Step 5755/10000- lr: [4.2858814424242425e-06] - Loss total: 2.6223509311676025, Last rpr Loss: 1.005235195159912, Last lagvar Loss: 0.8406150341033936\n",
      "Step 5756/10000- lr: [4.284871345454545e-06] - Loss total: 2.6222965717315674, Last rpr Loss: 0.9954696893692017, Last lagvar Loss: 0.850372850894928\n",
      "Step 5757/10000- lr: [4.283861248484849e-06] - Loss total: 2.622241735458374, Last rpr Loss: 1.0035300254821777, Last lagvar Loss: 0.8423038721084595\n",
      "Step 5758/10000- lr: [4.2828511515151515e-06] - Loss total: 2.622188091278076, Last rpr Loss: 0.9974439144134521, Last lagvar Loss: 0.8483828902244568\n",
      "Step 5759/10000- lr: [4.281841054545455e-06] - Loss total: 2.622136354446411, Last rpr Loss: 1.001415729522705, Last lagvar Loss: 0.8444061279296875\n",
      "Step 5760/10000- lr: [4.280830957575757e-06] - Loss total: 2.622086763381958, Last rpr Loss: 0.999570369720459, Last lagvar Loss: 0.8462492227554321\n",
      "Step 5761/10000- lr: [4.279820860606061e-06] - Loss total: 2.622040271759033, Last rpr Loss: 0.9994544386863708, Last lagvar Loss: 0.8463650941848755\n",
      "Step 5762/10000- lr: [4.278810763636364e-06] - Loss total: 2.621994972229004, Last rpr Loss: 1.0013856887817383, Last lagvar Loss: 0.844435453414917\n",
      "Step 5763/10000- lr: [4.277800666666667e-06] - Loss total: 2.621950387954712, Last rpr Loss: 0.9979228973388672, Last lagvar Loss: 0.8479006290435791\n",
      "Step 5764/10000- lr: [4.2767905696969695e-06] - Loss total: 2.621906280517578, Last rpr Loss: 1.0026047229766846, Last lagvar Loss: 0.8432213068008423\n",
      "Step 5765/10000- lr: [4.275780472727273e-06] - Loss total: 2.621861696243286, Last rpr Loss: 0.9970141649246216, Last lagvar Loss: 0.8488140106201172\n",
      "Step 5766/10000- lr: [4.274770375757575e-06] - Loss total: 2.6218156814575195, Last rpr Loss: 1.00313401222229, Last lagvar Loss: 0.8426950573921204\n",
      "Step 5767/10000- lr: [4.273760278787879e-06] - Loss total: 2.6217689514160156, Last rpr Loss: 0.9967743158340454, Last lagvar Loss: 0.8490551710128784\n",
      "Step 5768/10000- lr: [4.272750181818182e-06] - Loss total: 2.6217217445373535, Last rpr Loss: 1.0030722618103027, Last lagvar Loss: 0.8427561521530151\n",
      "Step 5769/10000- lr: [4.271740084848485e-06] - Loss total: 2.621673822402954, Last rpr Loss: 0.9970731139183044, Last lagvar Loss: 0.8487540483474731\n",
      "Step 5770/10000- lr: [4.2707299878787874e-06] - Loss total: 2.6216251850128174, Last rpr Loss: 1.0025975704193115, Last lagvar Loss: 0.8432275056838989\n",
      "Step 5771/10000- lr: [4.2697198909090916e-06] - Loss total: 2.6215765476226807, Last rpr Loss: 0.9977126121520996, Last lagvar Loss: 0.848110556602478\n",
      "Step 5772/10000- lr: [4.268709793939394e-06] - Loss total: 2.621527910232544, Last rpr Loss: 1.0018775463104248, Last lagvar Loss: 0.8439435958862305\n",
      "Step 5773/10000- lr: [4.267699696969697e-06] - Loss total: 2.6214797496795654, Last rpr Loss: 0.9985265135765076, Last lagvar Loss: 0.8472929000854492\n",
      "Step 5774/10000- lr: [4.2666896e-06] - Loss total: 2.621432065963745, Last rpr Loss: 1.00104820728302, Last lagvar Loss: 0.8447698354721069\n",
      "Step 5775/10000- lr: [4.265679503030303e-06] - Loss total: 2.621384620666504, Last rpr Loss: 0.9993513822555542, Last lagvar Loss: 0.8464657068252563\n",
      "Step 5776/10000- lr: [4.264669406060605e-06] - Loss total: 2.621337413787842, Last rpr Loss: 1.000239610671997, Last lagvar Loss: 0.8455770015716553\n",
      "Step 5777/10000- lr: [4.2636593090909095e-06] - Loss total: 2.621290922164917, Last rpr Loss: 1.0000725984573364, Last lagvar Loss: 0.8457437753677368\n",
      "Step 5778/10000- lr: [4.262649212121212e-06] - Loss total: 2.621244192123413, Last rpr Loss: 0.999575138092041, Last lagvar Loss: 0.8462412357330322\n",
      "Step 5779/10000- lr: [4.261639115151515e-06] - Loss total: 2.6211979389190674, Last rpr Loss: 1.0006530284881592, Last lagvar Loss: 0.8451634645462036\n",
      "Step 5780/10000- lr: [4.260629018181818e-06] - Loss total: 2.621151924133301, Last rpr Loss: 0.9990738034248352, Last lagvar Loss: 0.8467429280281067\n",
      "Step 5781/10000- lr: [4.259618921212122e-06] - Loss total: 2.621105670928955, Last rpr Loss: 1.00108802318573, Last lagvar Loss: 0.8447290062904358\n",
      "Step 5782/10000- lr: [4.258608824242424e-06] - Loss total: 2.6210598945617676, Last rpr Loss: 0.998727560043335, Last lagvar Loss: 0.8470896482467651\n",
      "Step 5783/10000- lr: [4.2575987272727275e-06] - Loss total: 2.621013641357422, Last rpr Loss: 1.0013691186904907, Last lagvar Loss: 0.8444482684135437\n",
      "Step 5784/10000- lr: [4.25658863030303e-06] - Loss total: 2.620967388153076, Last rpr Loss: 0.9985164999961853, Last lagvar Loss: 0.8473010063171387\n",
      "Step 5785/10000- lr: [4.255578533333333e-06] - Loss total: 2.6209213733673096, Last rpr Loss: 1.0015259981155396, Last lagvar Loss: 0.8442915678024292\n",
      "Step 5786/10000- lr: [4.254568436363636e-06] - Loss total: 2.6208748817443848, Last rpr Loss: 0.9984043836593628, Last lagvar Loss: 0.8474130630493164\n",
      "Step 5787/10000- lr: [4.25355833939394e-06] - Loss total: 2.620828866958618, Last rpr Loss: 1.0015883445739746, Last lagvar Loss: 0.8442290425300598\n",
      "Step 5788/10000- lr: [4.252548242424242e-06] - Loss total: 2.6207826137542725, Last rpr Loss: 0.9983618259429932, Last lagvar Loss: 0.8474555015563965\n",
      "Step 5789/10000- lr: [4.2515381454545455e-06] - Loss total: 2.6207363605499268, Last rpr Loss: 1.0016084909439087, Last lagvar Loss: 0.8442085981369019\n",
      "Step 5790/10000- lr: [4.250528048484848e-06] - Loss total: 2.62069034576416, Last rpr Loss: 0.9983513355255127, Last lagvar Loss: 0.8474656343460083\n",
      "Step 5791/10000- lr: [4.249517951515152e-06] - Loss total: 2.6206440925598145, Last rpr Loss: 1.0016119480133057, Last lagvar Loss: 0.8442046642303467\n",
      "Step 5792/10000- lr: [4.2485078545454545e-06] - Loss total: 2.6205976009368896, Last rpr Loss: 0.9983614683151245, Last lagvar Loss: 0.8474550247192383\n",
      "Step 5793/10000- lr: [4.247497757575758e-06] - Loss total: 2.620551586151123, Last rpr Loss: 1.0016101598739624, Last lagvar Loss: 0.8442060947418213\n",
      "Step 5794/10000- lr: [4.24648766060606e-06] - Loss total: 2.6205055713653564, Last rpr Loss: 0.9983553886413574, Last lagvar Loss: 0.8474608659744263\n",
      "Step 5795/10000- lr: [4.2454775636363634e-06] - Loss total: 2.62045955657959, Last rpr Loss: 1.0016319751739502, Last lagvar Loss: 0.8441840410232544\n",
      "Step 5796/10000- lr: [4.244467466666666e-06] - Loss total: 2.6204140186309814, Last rpr Loss: 0.9983154535293579, Last lagvar Loss: 0.8475005626678467\n",
      "Step 5797/10000- lr: [4.24345736969697e-06] - Loss total: 2.6203677654266357, Last rpr Loss: 1.001691222190857, Last lagvar Loss: 0.8441246747970581\n",
      "Step 5798/10000- lr: [4.2424472727272724e-06] - Loss total: 2.6203222274780273, Last rpr Loss: 0.9982312321662903, Last lagvar Loss: 0.8475847244262695\n",
      "Step 5799/10000- lr: [4.241437175757576e-06] - Loss total: 2.62027645111084, Last rpr Loss: 1.0018022060394287, Last lagvar Loss: 0.8440138697624207\n",
      "Step 5800/10000- lr: [4.240427078787878e-06] - Loss total: 2.6202311515808105, Last rpr Loss: 0.9980828762054443, Last lagvar Loss: 0.8477332592010498\n",
      "Step 5801/10000- lr: [4.239416981818182e-06] - Loss total: 2.620185613632202, Last rpr Loss: 1.0019898414611816, Last lagvar Loss: 0.8438265919685364\n",
      "Step 5802/10000- lr: [4.238406884848485e-06] - Loss total: 2.6201400756835938, Last rpr Loss: 0.9978565573692322, Last lagvar Loss: 0.8479602336883545\n",
      "Step 5803/10000- lr: [4.237396787878788e-06] - Loss total: 2.6200954914093018, Last rpr Loss: 1.0022683143615723, Last lagvar Loss: 0.8435490131378174\n",
      "Step 5804/10000- lr: [4.23638669090909e-06] - Loss total: 2.6200504302978516, Last rpr Loss: 0.997525691986084, Last lagvar Loss: 0.8482924699783325\n",
      "Step 5805/10000- lr: [4.235376593939394e-06] - Loss total: 2.6200058460235596, Last rpr Loss: 1.0026623010635376, Last lagvar Loss: 0.8431568741798401\n",
      "Step 5806/10000- lr: [4.234366496969696e-06] - Loss total: 2.619961977005005, Last rpr Loss: 0.9970500469207764, Last lagvar Loss: 0.8487704992294312\n",
      "Step 5807/10000- lr: [4.2333564e-06] - Loss total: 2.61991810798645, Last rpr Loss: 1.003221035003662, Last lagvar Loss: 0.8426014184951782\n",
      "Step 5808/10000- lr: [4.232346303030303e-06] - Loss total: 2.61987566947937, Last rpr Loss: 0.9963977336883545, Last lagvar Loss: 0.8494272828102112\n",
      "Step 5809/10000- lr: [4.231336206060606e-06] - Loss total: 2.619832992553711, Last rpr Loss: 1.0039904117584229, Last lagvar Loss: 0.8418378829956055\n",
      "Step 5810/10000- lr: [4.230326109090908e-06] - Loss total: 2.6197924613952637, Last rpr Loss: 0.9954870343208313, Last lagvar Loss: 0.8503458499908447\n",
      "Step 5811/10000- lr: [4.2293160121212125e-06] - Loss total: 2.6197524070739746, Last rpr Loss: 1.0050671100616455, Last lagvar Loss: 0.840771496295929\n",
      "Step 5812/10000- lr: [4.228305915151515e-06] - Loss total: 2.619715690612793, Last rpr Loss: 0.9942252039909363, Last lagvar Loss: 0.8516218662261963\n",
      "Step 5813/10000- lr: [4.227295818181818e-06] - Loss total: 2.6196796894073486, Last rpr Loss: 1.0065476894378662, Last lagvar Loss: 0.8393094539642334\n",
      "Step 5814/10000- lr: [4.226285721212121e-06] - Loss total: 2.619649887084961, Last rpr Loss: 0.9924878478050232, Last lagvar Loss: 0.8533848524093628\n",
      "Step 5815/10000- lr: [4.225275624242424e-06] - Loss total: 2.619621515274048, Last rpr Loss: 1.008587121963501, Last lagvar Loss: 0.8373031616210938\n",
      "Step 5816/10000- lr: [4.224265527272726e-06] - Loss total: 2.6196043491363525, Last rpr Loss: 0.9901010990142822, Last lagvar Loss: 0.8558181524276733\n",
      "Step 5817/10000- lr: [4.2232554303030305e-06] - Loss total: 2.619588851928711, Last rpr Loss: 1.011354923248291, Last lagvar Loss: 0.8345949053764343\n",
      "Step 5818/10000- lr: [4.222245333333334e-06] - Loss total: 2.6195945739746094, Last rpr Loss: 0.9868919253349304, Last lagvar Loss: 0.8591110706329346\n",
      "Step 5819/10000- lr: [4.221235236363636e-06] - Loss total: 2.619598388671875, Last rpr Loss: 1.0150442123413086, Last lagvar Loss: 0.8310093879699707\n",
      "Step 5820/10000- lr: [4.22022513939394e-06] - Loss total: 2.6196446418762207, Last rpr Loss: 0.9827045202255249, Last lagvar Loss: 0.8634438514709473\n",
      "Step 5821/10000- lr: [4.219215042424243e-06] - Loss total: 2.6196722984313965, Last rpr Loss: 1.0196967124938965, Last lagvar Loss: 0.8265268206596375\n",
      "Step 5822/10000- lr: [4.218204945454546e-06] - Loss total: 2.6197760105133057, Last rpr Loss: 0.9776594042778015, Last lagvar Loss: 0.8687191009521484\n",
      "Step 5823/10000- lr: [4.2171948484848484e-06] - Loss total: 2.619814395904541, Last rpr Loss: 1.0249215364456177, Last lagvar Loss: 0.8215420246124268\n",
      "Step 5824/10000- lr: [4.216184751515152e-06] - Loss total: 2.619969367980957, Last rpr Loss: 0.9725399017333984, Last lagvar Loss: 0.8741327524185181\n",
      "Step 5825/10000- lr: [4.215174654545454e-06] - Loss total: 2.6199591159820557, Last rpr Loss: 1.0293796062469482, Last lagvar Loss: 0.817325234413147\n",
      "Step 5826/10000- lr: [4.214164557575758e-06] - Loss total: 2.620084762573242, Last rpr Loss: 0.9693194627761841, Last lagvar Loss: 0.8775658011436462\n",
      "Step 5827/10000- lr: [4.213154460606061e-06] - Loss total: 2.619929552078247, Last rpr Loss: 1.030524730682373, Last lagvar Loss: 0.8162394762039185\n",
      "Step 5828/10000- lr: [4.212144363636364e-06] - Loss total: 2.6198811531066895, Last rpr Loss: 0.9709351062774658, Last lagvar Loss: 0.8758304119110107\n",
      "Step 5829/10000- lr: [4.211134266666666e-06] - Loss total: 2.6195743083953857, Last rpr Loss: 1.0257477760314941, Last lagvar Loss: 0.8207387924194336\n",
      "Step 5830/10000- lr: [4.2101241696969705e-06] - Loss total: 2.619342565536499, Last rpr Loss: 0.9790948629379272, Last lagvar Loss: 0.8672013282775879\n",
      "Step 5831/10000- lr: [4.209114072727273e-06] - Loss total: 2.6190543174743652, Last rpr Loss: 1.0149775743484497, Last lagvar Loss: 0.8310636878013611\n",
      "Step 5832/10000- lr: [4.208103975757576e-06] - Loss total: 2.6188573837280273, Last rpr Loss: 0.9918102025985718, Last lagvar Loss: 0.8540726900100708\n",
      "Step 5833/10000- lr: [4.207093878787879e-06] - Loss total: 2.618744373321533, Last rpr Loss: 1.0016963481903076, Last lagvar Loss: 0.8441153764724731\n",
      "Step 5834/10000- lr: [4.206083781818182e-06] - Loss total: 2.618717670440674, Last rpr Loss: 1.004494071006775, Last lagvar Loss: 0.8413355946540833\n",
      "Step 5835/10000- lr: [4.205073684848484e-06] - Loss total: 2.6187491416931152, Last rpr Loss: 0.9904358386993408, Last lagvar Loss: 0.8554704189300537\n",
      "Step 5836/10000- lr: [4.2040635878787885e-06] - Loss total: 2.6187922954559326, Last rpr Loss: 1.0133793354034424, Last lagvar Loss: 0.8326188325881958\n",
      "Step 5837/10000- lr: [4.203053490909091e-06] - Loss total: 2.6188347339630127, Last rpr Loss: 0.9841135144233704, Last lagvar Loss: 0.8619716763496399\n",
      "Step 5838/10000- lr: [4.202043393939394e-06] - Loss total: 2.6188056468963623, Last rpr Loss: 1.0167162418365479, Last lagvar Loss: 0.8293850421905518\n",
      "Step 5839/10000- lr: [4.201033296969697e-06] - Loss total: 2.6187591552734375, Last rpr Loss: 0.9837432503700256, Last lagvar Loss: 0.8623547554016113\n",
      "Step 5840/10000- lr: [4.200023200000001e-06] - Loss total: 2.6186416149139404, Last rpr Loss: 1.0143595933914185, Last lagvar Loss: 0.8316614627838135\n",
      "Step 5841/10000- lr: [4.199013103030303e-06] - Loss total: 2.6185264587402344, Last rpr Loss: 0.9886123538017273, Last lagvar Loss: 0.8573344349861145\n",
      "Step 5842/10000- lr: [4.1980030060606065e-06] - Loss total: 2.6184065341949463, Last rpr Loss: 1.007716178894043, Last lagvar Loss: 0.8381521105766296\n",
      "Step 5843/10000- lr: [4.196992909090909e-06] - Loss total: 2.618316173553467, Last rpr Loss: 0.9963094592094421, Last lagvar Loss: 0.8495100736618042\n",
      "Step 5844/10000- lr: [4.195982812121212e-06] - Loss total: 2.6182587146759033, Last rpr Loss: 0.9996963143348694, Last lagvar Loss: 0.8461087942123413\n",
      "Step 5845/10000- lr: [4.194972715151515e-06] - Loss total: 2.618229627609253, Last rpr Loss: 1.0037232637405396, Last lagvar Loss: 0.8420970439910889\n",
      "Step 5846/10000- lr: [4.193962618181819e-06] - Loss total: 2.6182167530059814, Last rpr Loss: 0.9933397769927979, Last lagvar Loss: 0.8525112867355347\n",
      "Step 5847/10000- lr: [4.192952521212121e-06] - Loss total: 2.618203639984131, Last rpr Loss: 1.0085586309432983, Last lagvar Loss: 0.837324857711792\n",
      "Step 5848/10000- lr: [4.191942424242424e-06] - Loss total: 2.6181836128234863, Last rpr Loss: 0.9903128147125244, Last lagvar Loss: 0.8555934429168701\n",
      "Step 5849/10000- lr: [4.190932327272727e-06] - Loss total: 2.618140459060669, Last rpr Loss: 1.009880542755127, Last lagvar Loss: 0.8360269665718079\n",
      "Step 5850/10000- lr: [4.189922230303031e-06] - Loss total: 2.6180875301361084, Last rpr Loss: 0.990766704082489, Last lagvar Loss: 0.8551300764083862\n",
      "Step 5851/10000- lr: [4.188912133333333e-06] - Loss total: 2.61801815032959, Last rpr Loss: 1.0079455375671387, Last lagvar Loss: 0.8379242420196533\n",
      "Step 5852/10000- lr: [4.187902036363637e-06] - Loss total: 2.6179487705230713, Last rpr Loss: 0.9939197301864624, Last lagvar Loss: 0.8519231081008911\n",
      "Step 5853/10000- lr: [4.186891939393939e-06] - Loss total: 2.61788272857666, Last rpr Loss: 1.0039138793945312, Last lagvar Loss: 0.8419054746627808\n",
      "Step 5854/10000- lr: [4.185881842424242e-06] - Loss total: 2.617826461791992, Last rpr Loss: 0.9983128309249878, Last lagvar Loss: 0.8474929332733154\n",
      "Step 5855/10000- lr: [4.184871745454545e-06] - Loss total: 2.6177804470062256, Last rpr Loss: 0.9994560480117798, Last lagvar Loss: 0.8463468551635742\n",
      "Step 5856/10000- lr: [4.183861648484849e-06] - Loss total: 2.6177430152893066, Last rpr Loss: 1.0023750066757202, Last lagvar Loss: 0.8434338569641113\n",
      "Step 5857/10000- lr: [4.182851551515151e-06] - Loss total: 2.6177098751068115, Last rpr Loss: 0.9960410594940186, Last lagvar Loss: 0.8497776985168457\n",
      "Step 5858/10000- lr: [4.181841454545455e-06] - Loss total: 2.6176764965057373, Last rpr Loss: 1.0050058364868164, Last lagvar Loss: 0.8408237099647522\n",
      "Step 5859/10000- lr: [4.180831357575757e-06] - Loss total: 2.617640733718872, Last rpr Loss: 0.9943726658821106, Last lagvar Loss: 0.8514635562896729\n",
      "Step 5860/10000- lr: [4.179821260606061e-06] - Loss total: 2.61759877204895, Last rpr Loss: 1.005805492401123, Last lagvar Loss: 0.840032696723938\n",
      "Step 5861/10000- lr: [4.178811163636364e-06] - Loss total: 2.617553472518921, Last rpr Loss: 0.9944484233856201, Last lagvar Loss: 0.8513864278793335\n",
      "Step 5862/10000- lr: [4.177801066666667e-06] - Loss total: 2.6175029277801514, Last rpr Loss: 1.0049487352371216, Last lagvar Loss: 0.8408788442611694\n",
      "Step 5863/10000- lr: [4.176790969696969e-06] - Loss total: 2.6174519062042236, Last rpr Loss: 0.9959023594856262, Last lagvar Loss: 0.8499164581298828\n",
      "Step 5864/10000- lr: [4.175780872727273e-06] - Loss total: 2.617400646209717, Last rpr Loss: 1.0029921531677246, Last lagvar Loss: 0.842818558216095\n",
      "Step 5865/10000- lr: [4.174770775757575e-06] - Loss total: 2.61735200881958, Last rpr Loss: 0.998116135597229, Last lagvar Loss: 0.8476881980895996\n",
      "Step 5866/10000- lr: [4.173760678787879e-06] - Loss total: 2.6173059940338135, Last rpr Loss: 1.0006660223007202, Last lagvar Loss: 0.8451350927352905\n",
      "Step 5867/10000- lr: [4.172750581818182e-06] - Loss total: 2.617262840270996, Last rpr Loss: 1.0003643035888672, Last lagvar Loss: 0.8454362154006958\n",
      "Step 5868/10000- lr: [4.171740484848485e-06] - Loss total: 2.6172213554382324, Last rpr Loss: 0.9986608028411865, Last lagvar Loss: 0.8471412062644958\n",
      "Step 5869/10000- lr: [4.170730387878787e-06] - Loss total: 2.6171810626983643, Last rpr Loss: 1.0020954608917236, Last lagvar Loss: 0.8437093496322632\n",
      "Step 5870/10000- lr: [4.1697202909090914e-06] - Loss total: 2.617141008377075, Last rpr Loss: 0.9973278045654297, Last lagvar Loss: 0.8484796285629272\n",
      "Step 5871/10000- lr: [4.168710193939394e-06] - Loss total: 2.617100477218628, Last rpr Loss: 1.0030579566955566, Last lagvar Loss: 0.8427516222000122\n",
      "Step 5872/10000- lr: [4.167700096969697e-06] - Loss total: 2.6170589923858643, Last rpr Loss: 0.9967535734176636, Last lagvar Loss: 0.8490571975708008\n",
      "Step 5873/10000- lr: [4.1666899999999996e-06] - Loss total: 2.617015838623047, Last rpr Loss: 1.0032191276550293, Last lagvar Loss: 0.8425913453102112\n",
      "Step 5874/10000- lr: [4.165679903030303e-06] - Loss total: 2.6169722080230713, Last rpr Loss: 0.9969080090522766, Last lagvar Loss: 0.8489011526107788\n",
      "Step 5875/10000- lr: [4.164669806060605e-06] - Loss total: 2.6169273853302, Last rpr Loss: 1.0027391910552979, Last lagvar Loss: 0.8430677652359009\n",
      "Step 5876/10000- lr: [4.163659709090909e-06] - Loss total: 2.616882562637329, Last rpr Loss: 0.997612476348877, Last lagvar Loss: 0.8481922149658203\n",
      "Step 5877/10000- lr: [4.162649612121212e-06] - Loss total: 2.616837739944458, Last rpr Loss: 1.0018682479858398, Last lagvar Loss: 0.843934178352356\n",
      "Step 5878/10000- lr: [4.161639515151515e-06] - Loss total: 2.616793155670166, Last rpr Loss: 0.9986122250556946, Last lagvar Loss: 0.8471881151199341\n",
      "Step 5879/10000- lr: [4.1606294181818175e-06] - Loss total: 2.6167490482330322, Last rpr Loss: 1.0008604526519775, Last lagvar Loss: 0.8449385166168213\n",
      "Step 5880/10000- lr: [4.159619321212122e-06] - Loss total: 2.616706132888794, Last rpr Loss: 0.9996245503425598, Last lagvar Loss: 0.8461735844612122\n",
      "Step 5881/10000- lr: [4.158609224242424e-06] - Loss total: 2.6166629791259766, Last rpr Loss: 0.9999127388000488, Last lagvar Loss: 0.8458850383758545\n",
      "Step 5882/10000- lr: [4.157599127272727e-06] - Loss total: 2.6166205406188965, Last rpr Loss: 1.0004940032958984, Last lagvar Loss: 0.8453037738800049\n",
      "Step 5883/10000- lr: [4.15658903030303e-06] - Loss total: 2.6165783405303955, Last rpr Loss: 0.9991334080696106, Last lagvar Loss: 0.8466648459434509\n",
      "Step 5884/10000- lr: [4.155578933333333e-06] - Loss total: 2.6165363788604736, Last rpr Loss: 1.0011396408081055, Last lagvar Loss: 0.8446589708328247\n",
      "Step 5885/10000- lr: [4.1545688363636355e-06] - Loss total: 2.6164944171905518, Last rpr Loss: 0.998609185218811, Last lagvar Loss: 0.8471899628639221\n",
      "Step 5886/10000- lr: [4.15355873939394e-06] - Loss total: 2.616452932357788, Last rpr Loss: 1.0015077590942383, Last lagvar Loss: 0.8442917466163635\n",
      "Step 5887/10000- lr: [4.152548642424242e-06] - Loss total: 2.616410493850708, Last rpr Loss: 0.9983632564544678, Last lagvar Loss: 0.8474363684654236\n",
      "Step 5888/10000- lr: [4.151538545454545e-06] - Loss total: 2.616368055343628, Last rpr Loss: 1.0016443729400635, Last lagvar Loss: 0.8441551923751831\n",
      "Step 5889/10000- lr: [4.150528448484848e-06] - Loss total: 2.616325616836548, Last rpr Loss: 0.9983397722244263, Last lagvar Loss: 0.8474595546722412\n",
      "Step 5890/10000- lr: [4.149518351515152e-06] - Loss total: 2.6162831783294678, Last rpr Loss: 1.0015923976898193, Last lagvar Loss: 0.844206690788269\n",
      "Step 5891/10000- lr: [4.148508254545454e-06] - Loss total: 2.6162405014038086, Last rpr Loss: 0.9984713792800903, Last lagvar Loss: 0.8473272323608398\n",
      "Step 5892/10000- lr: [4.147498157575758e-06] - Loss total: 2.6161978244781494, Last rpr Loss: 1.001403570175171, Last lagvar Loss: 0.8443945646286011\n",
      "Step 5893/10000- lr: [4.14648806060606e-06] - Loss total: 2.616154909133911, Last rpr Loss: 0.9987045526504517, Last lagvar Loss: 0.8470930457115173\n",
      "Step 5894/10000- lr: [4.145477963636363e-06] - Loss total: 2.616112470626831, Last rpr Loss: 1.0011334419250488, Last lagvar Loss: 0.8446636199951172\n",
      "Step 5895/10000- lr: [4.144467866666666e-06] - Loss total: 2.6160693168640137, Last rpr Loss: 0.9989898204803467, Last lagvar Loss: 0.8468066453933716\n",
      "Step 5896/10000- lr: [4.14345776969697e-06] - Loss total: 2.6160271167755127, Last rpr Loss: 1.0008299350738525, Last lagvar Loss: 0.8449661135673523\n",
      "Step 5897/10000- lr: [4.142447672727272e-06] - Loss total: 2.6159846782684326, Last rpr Loss: 0.9992846250534058, Last lagvar Loss: 0.8465110063552856\n",
      "Step 5898/10000- lr: [4.1414375757575756e-06] - Loss total: 2.6159420013427734, Last rpr Loss: 1.0005534887313843, Last lagvar Loss: 0.8452417850494385\n",
      "Step 5899/10000- lr: [4.140427478787878e-06] - Loss total: 2.6158993244171143, Last rpr Loss: 0.9995477199554443, Last lagvar Loss: 0.8462473154067993\n",
      "Step 5900/10000- lr: [4.139417381818182e-06] - Loss total: 2.6158573627471924, Last rpr Loss: 1.0003070831298828, Last lagvar Loss: 0.8454877734184265\n",
      "Step 5901/10000- lr: [4.1384072848484846e-06] - Loss total: 2.6158154010772705, Last rpr Loss: 0.9997841119766235, Last lagvar Loss: 0.8460103273391724\n",
      "Step 5902/10000- lr: [4.137397187878788e-06] - Loss total: 2.6157727241516113, Last rpr Loss: 1.0000885725021362, Last lagvar Loss: 0.8457058072090149\n",
      "Step 5903/10000- lr: [4.136387090909091e-06] - Loss total: 2.6157307624816895, Last rpr Loss: 0.9999853372573853, Last lagvar Loss: 0.8458088040351868\n",
      "Step 5904/10000- lr: [4.1353769939393935e-06] - Loss total: 2.6156888008117676, Last rpr Loss: 0.9999061822891235, Last lagvar Loss: 0.8458877801895142\n",
      "Step 5905/10000- lr: [4.134366896969698e-06] - Loss total: 2.6156466007232666, Last rpr Loss: 1.0001463890075684, Last lagvar Loss: 0.845647394657135\n",
      "Step 5906/10000- lr: [4.1333568e-06] - Loss total: 2.6156046390533447, Last rpr Loss: 0.9997608065605164, Last lagvar Loss: 0.8460329174995422\n",
      "Step 5907/10000- lr: [4.132346703030303e-06] - Loss total: 2.6155624389648438, Last rpr Loss: 1.0002754926681519, Last lagvar Loss: 0.845518171787262\n",
      "Step 5908/10000- lr: [4.131336606060606e-06] - Loss total: 2.615520477294922, Last rpr Loss: 0.9996450543403625, Last lagvar Loss: 0.8461484313011169\n",
      "Step 5909/10000- lr: [4.13032650909091e-06] - Loss total: 2.615478515625, Last rpr Loss: 1.0003814697265625, Last lagvar Loss: 0.8454117774963379\n",
      "Step 5910/10000- lr: [4.129316412121212e-06] - Loss total: 2.615436553955078, Last rpr Loss: 0.9995414018630981, Last lagvar Loss: 0.8462518453598022\n",
      "Step 5911/10000- lr: [4.128306315151516e-06] - Loss total: 2.6153948307037354, Last rpr Loss: 1.000490665435791, Last lagvar Loss: 0.8453023433685303\n",
      "Step 5912/10000- lr: [4.127296218181818e-06] - Loss total: 2.6153528690338135, Last rpr Loss: 0.9994379281997681, Last lagvar Loss: 0.8463551998138428\n",
      "Step 5913/10000- lr: [4.126286121212121e-06] - Loss total: 2.6153111457824707, Last rpr Loss: 1.0005873441696167, Last lagvar Loss: 0.8452056646347046\n",
      "Step 5914/10000- lr: [4.125276024242424e-06] - Loss total: 2.615269184112549, Last rpr Loss: 0.9993383884429932, Last lagvar Loss: 0.8464545011520386\n",
      "Step 5915/10000- lr: [4.124265927272728e-06] - Loss total: 2.615227460861206, Last rpr Loss: 1.0006914138793945, Last lagvar Loss: 0.8451013565063477\n",
      "Step 5916/10000- lr: [4.12325583030303e-06] - Loss total: 2.6151859760284424, Last rpr Loss: 0.9992231130599976, Last lagvar Loss: 0.8465697765350342\n",
      "Step 5917/10000- lr: [4.122245733333334e-06] - Loss total: 2.6151440143585205, Last rpr Loss: 1.0008220672607422, Last lagvar Loss: 0.844970703125\n",
      "Step 5918/10000- lr: [4.121235636363636e-06] - Loss total: 2.6151020526885986, Last rpr Loss: 0.9990760087966919, Last lagvar Loss: 0.8467167615890503\n",
      "Step 5919/10000- lr: [4.12022553939394e-06] - Loss total: 2.615060567855835, Last rpr Loss: 1.0009901523590088, Last lagvar Loss: 0.8448026180267334\n",
      "Step 5920/10000- lr: [4.119215442424243e-06] - Loss total: 2.6150195598602295, Last rpr Loss: 0.9988853335380554, Last lagvar Loss: 0.8469074964523315\n",
      "Step 5921/10000- lr: [4.118205345454546e-06] - Loss total: 2.6149778366088867, Last rpr Loss: 1.001212239265442, Last lagvar Loss: 0.844580888748169\n",
      "Step 5922/10000- lr: [4.117195248484848e-06] - Loss total: 2.614936351776123, Last rpr Loss: 0.9986290335655212, Last lagvar Loss: 0.8471642136573792\n",
      "Step 5923/10000- lr: [4.1161851515151516e-06] - Loss total: 2.6148953437805176, Last rpr Loss: 1.0015060901641846, Last lagvar Loss: 0.8442873358726501\n",
      "Step 5924/10000- lr: [4.115175054545454e-06] - Loss total: 2.614854097366333, Last rpr Loss: 0.9982861280441284, Last lagvar Loss: 0.8475080728530884\n",
      "Step 5925/10000- lr: [4.114164957575758e-06] - Loss total: 2.6148133277893066, Last rpr Loss: 1.0019071102142334, Last lagvar Loss: 0.8438878059387207\n",
      "Step 5926/10000- lr: [4.1131548606060606e-06] - Loss total: 2.6147725582122803, Last rpr Loss: 0.997806191444397, Last lagvar Loss: 0.847989559173584\n",
      "Step 5927/10000- lr: [4.112144763636364e-06] - Loss total: 2.614732265472412, Last rpr Loss: 1.0024704933166504, Last lagvar Loss: 0.8433266282081604\n",
      "Step 5928/10000- lr: [4.111134666666666e-06] - Loss total: 2.6146934032440186, Last rpr Loss: 0.9971482157707214, Last lagvar Loss: 0.8486509323120117\n",
      "Step 5929/10000- lr: [4.11012456969697e-06] - Loss total: 2.6146538257598877, Last rpr Loss: 1.0032542943954468, Last lagvar Loss: 0.8425475358963013\n",
      "Step 5930/10000- lr: [4.109114472727273e-06] - Loss total: 2.6146163940429688, Last rpr Loss: 0.9962270259857178, Last lagvar Loss: 0.8495785593986511\n",
      "Step 5931/10000- lr: [4.108104375757576e-06] - Loss total: 2.614579439163208, Last rpr Loss: 1.0043460130691528, Last lagvar Loss: 0.8414645195007324\n",
      "Step 5932/10000- lr: [4.1070942787878785e-06] - Loss total: 2.6145453453063965, Last rpr Loss: 0.9949216842651367, Last lagvar Loss: 0.8508962392807007\n",
      "Step 5933/10000- lr: [4.106084181818182e-06] - Loss total: 2.6145131587982178, Last rpr Loss: 1.0059025287628174, Last lagvar Loss: 0.8399248123168945\n",
      "Step 5934/10000- lr: [4.105074084848484e-06] - Loss total: 2.6144859790802, Last rpr Loss: 0.993066132068634, Last lagvar Loss: 0.8527759909629822\n",
      "Step 5935/10000- lr: [4.104063987878788e-06] - Loss total: 2.614461898803711, Last rpr Loss: 1.008105993270874, Last lagvar Loss: 0.8377538919448853\n",
      "Step 5936/10000- lr: [4.103053890909091e-06] - Loss total: 2.6144490242004395, Last rpr Loss: 0.9904482364654541, Last lagvar Loss: 0.8554414510726929\n",
      "Step 5937/10000- lr: [4.102043793939394e-06] - Loss total: 2.6144402027130127, Last rpr Loss: 1.0112121105194092, Last lagvar Loss: 0.8347111940383911\n",
      "Step 5938/10000- lr: [4.1010336969696965e-06] - Loss total: 2.614455461502075, Last rpr Loss: 0.9867779016494751, Last lagvar Loss: 0.8592046499252319\n",
      "Step 5939/10000- lr: [4.100023600000001e-06] - Loss total: 2.614473342895508, Last rpr Loss: 1.015519618988037, Last lagvar Loss: 0.8305241465568542\n",
      "Step 5940/10000- lr: [4.099013503030303e-06] - Loss total: 2.61454176902771, Last rpr Loss: 0.9817787408828735, Last lagvar Loss: 0.8643801808357239\n",
      "Step 5941/10000- lr: [4.098003406060606e-06] - Loss total: 2.6145970821380615, Last rpr Loss: 1.0212006568908691, Last lagvar Loss: 0.8250579833984375\n",
      "Step 5942/10000- lr: [4.096993309090909e-06] - Loss total: 2.614751100540161, Last rpr Loss: 0.9754820466041565, Last lagvar Loss: 0.8709812164306641\n",
      "Step 5943/10000- lr: [4.095983212121212e-06] - Loss total: 2.614830493927002, Last rpr Loss: 1.0278441905975342, Last lagvar Loss: 0.818742036819458\n",
      "Step 5944/10000- lr: [4.0949731151515145e-06] - Loss total: 2.6150693893432617, Last rpr Loss: 0.9688786268234253, Last lagvar Loss: 0.878002405166626\n",
      "Step 5945/10000- lr: [4.093963018181819e-06] - Loss total: 2.615079164505005, Last rpr Loss: 1.0335817337036133, Last lagvar Loss: 0.8133460283279419\n",
      "Step 5946/10000- lr: [4.092952921212121e-06] - Loss total: 2.6150689125061035, Last rpr Loss: 0.9676052331924438, Last lagvar Loss: 0.8793609142303467\n",
      "Step 5947/10000- lr: [4.091942824242424e-06] - Loss total: 2.6147546768188477, Last rpr Loss: 1.0296878814697266, Last lagvar Loss: 0.816985011100769\n",
      "Step 5948/10000- lr: [4.090932727272727e-06] - Loss total: 2.6145565509796143, Last rpr Loss: 0.974327027797699, Last lagvar Loss: 0.8721891641616821\n",
      "Step 5949/10000- lr: [4.089922630303031e-06] - Loss total: 2.6142213344573975, Last rpr Loss: 1.020296573638916, Last lagvar Loss: 0.8259079456329346\n",
      "Step 5950/10000- lr: [4.088912533333333e-06] - Loss total: 2.613978624343872, Last rpr Loss: 0.9862423539161682, Last lagvar Loss: 0.8597536087036133\n",
      "Step 5951/10000- lr: [4.0879024363636366e-06] - Loss total: 2.613790512084961, Last rpr Loss: 1.0071321725845337, Last lagvar Loss: 0.8387103080749512\n",
      "Step 5952/10000- lr: [4.086892339393939e-06] - Loss total: 2.6136999130249023, Last rpr Loss: 0.9997029900550842, Last lagvar Loss: 0.8460869789123535\n",
      "Step 5953/10000- lr: [4.085882242424242e-06] - Loss total: 2.6136908531188965, Last rpr Loss: 0.9943781495094299, Last lagvar Loss: 0.8514435291290283\n",
      "Step 5954/10000- lr: [4.084872145454545e-06] - Loss total: 2.6137304306030273, Last rpr Loss: 1.0105527639389038, Last lagvar Loss: 0.8353528380393982\n",
      "Step 5955/10000- lr: [4.083862048484849e-06] - Loss total: 2.61379075050354, Last rpr Loss: 0.9856826663017273, Last lagvar Loss: 0.860325813293457\n",
      "Step 5956/10000- lr: [4.082851951515151e-06] - Loss total: 2.61380934715271, Last rpr Loss: 1.0164783000946045, Last lagvar Loss: 0.8295922875404358\n",
      "Step 5957/10000- lr: [4.0818418545454545e-06] - Loss total: 2.613814115524292, Last rpr Loss: 0.9826502203941345, Last lagvar Loss: 0.8634663224220276\n",
      "Step 5958/10000- lr: [4.080831757575757e-06] - Loss total: 2.6137328147888184, Last rpr Loss: 1.0167310237884521, Last lagvar Loss: 0.8293430209159851\n",
      "Step 5959/10000- lr: [4.079821660606061e-06] - Loss total: 2.613642930984497, Last rpr Loss: 0.9852375984191895, Last lagvar Loss: 0.8607848882675171\n",
      "Step 5960/10000- lr: [4.0788115636363635e-06] - Loss total: 2.6135125160217285, Last rpr Loss: 1.0117535591125488, Last lagvar Loss: 0.8341748714447021\n",
      "Step 5961/10000- lr: [4.077801466666667e-06] - Loss total: 2.613400936126709, Last rpr Loss: 0.9919888973236084, Last lagvar Loss: 0.853865385055542\n",
      "Step 5962/10000- lr: [4.076791369696969e-06] - Loss total: 2.6133110523223877, Last rpr Loss: 1.0038554668426514, Last lagvar Loss: 0.8419474363327026\n",
      "Step 5963/10000- lr: [4.0757812727272725e-06] - Loss total: 2.613255500793457, Last rpr Loss: 1.0000734329223633, Last lagvar Loss: 0.845713198184967\n",
      "Step 5964/10000- lr: [4.074771175757575e-06] - Loss total: 2.6132290363311768, Last rpr Loss: 0.9962507486343384, Last lagvar Loss: 0.8495495915412903\n",
      "Step 5965/10000- lr: [4.073761078787879e-06] - Loss total: 2.6132187843322754, Last rpr Loss: 1.0065916776657104, Last lagvar Loss: 0.8392406105995178\n",
      "Step 5966/10000- lr: [4.0727509818181815e-06] - Loss total: 2.6132125854492188, Last rpr Loss: 0.9913111925125122, Last lagvar Loss: 0.8545546531677246\n",
      "Step 5967/10000- lr: [4.071740884848485e-06] - Loss total: 2.613191604614258, Last rpr Loss: 1.0098220109939575, Last lagvar Loss: 0.8360649943351746\n",
      "Step 5968/10000- lr: [4.070730787878787e-06] - Loss total: 2.6131603717803955, Last rpr Loss: 0.9899193644523621, Last lagvar Loss: 0.8559758067131042\n",
      "Step 5969/10000- lr: [4.069720690909091e-06] - Loss total: 2.613105058670044, Last rpr Loss: 1.0095418691635132, Last lagvar Loss: 0.8363379240036011\n",
      "Step 5970/10000- lr: [4.068710593939394e-06] - Loss total: 2.613044023513794, Last rpr Loss: 0.9917606115341187, Last lagvar Loss: 0.8540970683097839\n",
      "Step 5971/10000- lr: [4.067700496969697e-06] - Loss total: 2.612975597381592, Last rpr Loss: 1.0064387321472168, Last lagvar Loss: 0.8393893241882324\n",
      "Step 5972/10000- lr: [4.0666903999999994e-06] - Loss total: 2.61291241645813, Last rpr Loss: 0.9957075119018555, Last lagvar Loss: 0.8500965237617493\n",
      "Step 5973/10000- lr: [4.065680303030303e-06] - Loss total: 2.6128578186035156, Last rpr Loss: 1.0019428730010986, Last lagvar Loss: 0.8438462018966675\n",
      "Step 5974/10000- lr: [4.064670206060605e-06] - Loss total: 2.612813949584961, Last rpr Loss: 1.0002126693725586, Last lagvar Loss: 0.8455722332000732\n",
      "Step 5975/10000- lr: [4.063660109090909e-06] - Loss total: 2.612778902053833, Last rpr Loss: 0.9977356195449829, Last lagvar Loss: 0.8480541706085205\n",
      "Step 5976/10000- lr: [4.062650012121212e-06] - Loss total: 2.612748622894287, Last rpr Loss: 1.0038175582885742, Last lagvar Loss: 0.8419826626777649\n",
      "Step 5977/10000- lr: [4.061639915151515e-06] - Loss total: 2.6127192974090576, Last rpr Loss: 0.9950164556503296, Last lagvar Loss: 0.8507939577102661\n",
      "Step 5978/10000- lr: [4.060629818181817e-06] - Loss total: 2.6126861572265625, Last rpr Loss: 1.0056787729263306, Last lagvar Loss: 0.8401398062705994\n",
      "Step 5979/10000- lr: [4.0596197212121215e-06] - Loss total: 2.612649440765381, Last rpr Loss: 0.994114100933075, Last lagvar Loss: 0.851706862449646\n",
      "Step 5980/10000- lr: [4.058609624242424e-06] - Loss total: 2.6126065254211426, Last rpr Loss: 1.0056953430175781, Last lagvar Loss: 0.8401229381561279\n",
      "Step 5981/10000- lr: [4.057599527272727e-06] - Loss total: 2.612560987472534, Last rpr Loss: 0.9948570728302002, Last lagvar Loss: 0.8509545922279358\n",
      "Step 5982/10000- lr: [4.05658943030303e-06] - Loss total: 2.6125118732452393, Last rpr Loss: 1.0042588710784912, Last lagvar Loss: 0.8415439128875732\n",
      "Step 5983/10000- lr: [4.055579333333333e-06] - Loss total: 2.612464189529419, Last rpr Loss: 0.9967516660690308, Last lagvar Loss: 0.8490426540374756\n",
      "Step 5984/10000- lr: [4.054569236363636e-06] - Loss total: 2.6124181747436523, Last rpr Loss: 1.0020331144332886, Last lagvar Loss: 0.8437546491622925\n",
      "Step 5985/10000- lr: [4.0535591393939395e-06] - Loss total: 2.6123745441436768, Last rpr Loss: 0.999113917350769, Last lagvar Loss: 0.8466700911521912\n",
      "Step 5986/10000- lr: [4.052549042424242e-06] - Loss total: 2.6123340129852295, Last rpr Loss: 0.9997327327728271, Last lagvar Loss: 0.8460503816604614\n",
      "Step 5987/10000- lr: [4.051538945454545e-06] - Loss total: 2.612295627593994, Last rpr Loss: 1.0012359619140625, Last lagvar Loss: 0.844548761844635\n",
      "Step 5988/10000- lr: [4.050528848484849e-06] - Loss total: 2.612258195877075, Last rpr Loss: 0.9979524612426758, Last lagvar Loss: 0.8478348255157471\n",
      "Step 5989/10000- lr: [4.049518751515152e-06] - Loss total: 2.6122210025787354, Last rpr Loss: 1.0026577711105347, Last lagvar Loss: 0.843132495880127\n",
      "Step 5990/10000- lr: [4.048508654545455e-06] - Loss total: 2.6121838092803955, Last rpr Loss: 0.9969359636306763, Last lagvar Loss: 0.8488566875457764\n",
      "Step 5991/10000- lr: [4.0474985575757575e-06] - Loss total: 2.612144947052002, Last rpr Loss: 1.0032511949539185, Last lagvar Loss: 0.8425426483154297\n",
      "Step 5992/10000- lr: [4.046488460606061e-06] - Loss total: 2.61210560798645, Last rpr Loss: 0.9967005252838135, Last lagvar Loss: 0.8490933179855347\n",
      "Step 5993/10000- lr: [4.045478363636363e-06] - Loss total: 2.6120643615722656, Last rpr Loss: 1.003106713294983, Last lagvar Loss: 0.8426859974861145\n",
      "Step 5994/10000- lr: [4.044468266666667e-06] - Loss total: 2.612022638320923, Last rpr Loss: 0.9971438646316528, Last lagvar Loss: 0.8486468195915222\n",
      "Step 5995/10000- lr: [4.04345816969697e-06] - Loss total: 2.611980676651001, Last rpr Loss: 1.0024060010910034, Last lagvar Loss: 0.8433822989463806\n",
      "Step 5996/10000- lr: [4.042448072727273e-06] - Loss total: 2.6119384765625, Last rpr Loss: 0.9980534315109253, Last lagvar Loss: 0.8477325439453125\n",
      "Step 5997/10000- lr: [4.0414379757575754e-06] - Loss total: 2.6118969917297363, Last rpr Loss: 1.001394510269165, Last lagvar Loss: 0.8443896174430847\n",
      "Step 5998/10000- lr: [4.0404278787878796e-06] - Loss total: 2.6118557453155518, Last rpr Loss: 0.9991174936294556, Last lagvar Loss: 0.84666508436203\n",
      "Step 5999/10000- lr: [4.039417781818182e-06] - Loss total: 2.6118149757385254, Last rpr Loss: 1.0003572702407837, Last lagvar Loss: 0.8454246520996094\n",
      "Step 6000/10000- lr: [4.038407684848485e-06] - Loss total: 2.6117751598358154, Last rpr Loss: 1.000117540359497, Last lagvar Loss: 0.8456642627716064\n",
      "Step 6001/10000- lr: [4.037397587878788e-06] - Loss total: 2.6117355823516846, Last rpr Loss: 0.9994603395462036, Last lagvar Loss: 0.8463215231895447\n",
      "Step 6002/10000- lr: [4.036387490909091e-06] - Loss total: 2.611696243286133, Last rpr Loss: 1.0008928775787354, Last lagvar Loss: 0.8448896408081055\n",
      "Step 6003/10000- lr: [4.035377393939393e-06] - Loss total: 2.611656665802002, Last rpr Loss: 0.9987891912460327, Last lagvar Loss: 0.8469938039779663\n",
      "Step 6004/10000- lr: [4.0343672969696975e-06] - Loss total: 2.61161732673645, Last rpr Loss: 1.0014073848724365, Last lagvar Loss: 0.8443762063980103\n",
      "Step 6005/10000- lr: [4.0333572e-06] - Loss total: 2.6115782260894775, Last rpr Loss: 0.9984033107757568, Last lagvar Loss: 0.8473806381225586\n",
      "Step 6006/10000- lr: [4.032347103030303e-06] - Loss total: 2.6115384101867676, Last rpr Loss: 1.0016486644744873, Last lagvar Loss: 0.844135582447052\n",
      "Step 6007/10000- lr: [4.031337006060606e-06] - Loss total: 2.6114988327026367, Last rpr Loss: 0.9982994794845581, Last lagvar Loss: 0.8474847078323364\n",
      "Step 6008/10000- lr: [4.03032690909091e-06] - Loss total: 2.6114587783813477, Last rpr Loss: 1.0016529560089111, Last lagvar Loss: 0.8441312313079834\n",
      "Step 6009/10000- lr: [4.029316812121212e-06] - Loss total: 2.6114184856414795, Last rpr Loss: 0.9984047412872314, Last lagvar Loss: 0.8473789691925049\n",
      "Step 6010/10000- lr: [4.0283067151515155e-06] - Loss total: 2.6113781929016113, Last rpr Loss: 1.0014748573303223, Last lagvar Loss: 0.8443086743354797\n",
      "Step 6011/10000- lr: [4.027296618181818e-06] - Loss total: 2.611337900161743, Last rpr Loss: 0.99863201379776, Last lagvar Loss: 0.8471509218215942\n",
      "Step 6012/10000- lr: [4.026286521212121e-06] - Loss total: 2.611297130584717, Last rpr Loss: 1.0012028217315674, Last lagvar Loss: 0.8445796370506287\n",
      "Step 6013/10000- lr: [4.025276424242424e-06] - Loss total: 2.6112568378448486, Last rpr Loss: 0.9989331960678101, Last lagvar Loss: 0.8468489050865173\n",
      "Step 6014/10000- lr: [4.024266327272728e-06] - Loss total: 2.6112165451049805, Last rpr Loss: 1.0008800029754639, Last lagvar Loss: 0.8449018001556396\n",
      "Step 6015/10000- lr: [4.02325623030303e-06] - Loss total: 2.6111764907836914, Last rpr Loss: 0.9992654323577881, Last lagvar Loss: 0.8465160131454468\n",
      "Step 6016/10000- lr: [4.0222461333333335e-06] - Loss total: 2.611135959625244, Last rpr Loss: 1.0005418062210083, Last lagvar Loss: 0.8452393412590027\n",
      "Step 6017/10000- lr: [4.021236036363636e-06] - Loss total: 2.611095905303955, Last rpr Loss: 0.9995856285095215, Last lagvar Loss: 0.8461952209472656\n",
      "Step 6018/10000- lr: [4.02022593939394e-06] - Loss total: 2.611055374145508, Last rpr Loss: 1.0002448558807373, Last lagvar Loss: 0.8455360531806946\n",
      "Step 6019/10000- lr: [4.0192158424242425e-06] - Loss total: 2.611015558242798, Last rpr Loss: 0.9998641014099121, Last lagvar Loss: 0.845916748046875\n",
      "Step 6020/10000- lr: [4.018205745454546e-06] - Loss total: 2.6109752655029297, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8457849621772766\n",
      "Step 6021/10000- lr: [4.017195648484848e-06] - Loss total: 2.6109347343444824, Last rpr Loss: 1.000091314315796, Last lagvar Loss: 0.8456894159317017\n",
      "Step 6022/10000- lr: [4.0161855515151514e-06] - Loss total: 2.6108949184417725, Last rpr Loss: 0.9997876882553101, Last lagvar Loss: 0.845993161201477\n",
      "Step 6023/10000- lr: [4.015175454545454e-06] - Loss total: 2.6108548641204834, Last rpr Loss: 1.0002741813659668, Last lagvar Loss: 0.8455066680908203\n",
      "Step 6024/10000- lr: [4.014165357575758e-06] - Loss total: 2.6108145713806152, Last rpr Loss: 0.999627411365509, Last lagvar Loss: 0.8461536169052124\n",
      "Step 6025/10000- lr: [4.01315526060606e-06] - Loss total: 2.610774517059326, Last rpr Loss: 1.0004198551177979, Last lagvar Loss: 0.8453612327575684\n",
      "Step 6026/10000- lr: [4.012145163636364e-06] - Loss total: 2.610734224319458, Last rpr Loss: 0.9995013475418091, Last lagvar Loss: 0.8462797999382019\n",
      "Step 6027/10000- lr: [4.011135066666666e-06] - Loss total: 2.610694169998169, Last rpr Loss: 1.0005253553390503, Last lagvar Loss: 0.8452560305595398\n",
      "Step 6028/10000- lr: [4.01012496969697e-06] - Loss total: 2.610653877258301, Last rpr Loss: 0.999406635761261, Last lagvar Loss: 0.8463747501373291\n",
      "Step 6029/10000- lr: [4.009114872727273e-06] - Loss total: 2.6106135845184326, Last rpr Loss: 1.0006132125854492, Last lagvar Loss: 0.8451682925224304\n",
      "Step 6030/10000- lr: [4.008104775757576e-06] - Loss total: 2.6105730533599854, Last rpr Loss: 0.999321460723877, Last lagvar Loss: 0.846460223197937\n",
      "Step 6031/10000- lr: [4.007094678787878e-06] - Loss total: 2.6105329990386963, Last rpr Loss: 1.000699758529663, Last lagvar Loss: 0.8450820446014404\n",
      "Step 6032/10000- lr: [4.006084581818182e-06] - Loss total: 2.61049222946167, Last rpr Loss: 0.9992387294769287, Last lagvar Loss: 0.8465431332588196\n",
      "Step 6033/10000- lr: [4.005074484848485e-06] - Loss total: 2.610452175140381, Last rpr Loss: 1.0007822513580322, Last lagvar Loss: 0.8449998497962952\n",
      "Step 6034/10000- lr: [4.004064387878788e-06] - Loss total: 2.6104116439819336, Last rpr Loss: 0.999146580696106, Last lagvar Loss: 0.846635639667511\n",
      "Step 6035/10000- lr: [4.003054290909091e-06] - Loss total: 2.6103713512420654, Last rpr Loss: 1.0008811950683594, Last lagvar Loss: 0.8449013233184814\n",
      "Step 6036/10000- lr: [4.002044193939394e-06] - Loss total: 2.6103310585021973, Last rpr Loss: 0.9990421533584595, Last lagvar Loss: 0.8467405438423157\n",
      "Step 6037/10000- lr: [4.001034096969696e-06] - Loss total: 2.610290765762329, Last rpr Loss: 1.0010005235671997, Last lagvar Loss: 0.8447824716567993\n",
      "Step 6038/10000- lr: [4.0000240000000005e-06] - Loss total: 2.6102499961853027, Last rpr Loss: 0.9989074468612671, Last lagvar Loss: 0.8468757271766663\n",
      "Step 6039/10000- lr: [3.999013903030303e-06] - Loss total: 2.6102097034454346, Last rpr Loss: 1.0011591911315918, Last lagvar Loss: 0.844624400138855\n",
      "Step 6040/10000- lr: [3.998003806060606e-06] - Loss total: 2.6101691722869873, Last rpr Loss: 0.9987242817878723, Last lagvar Loss: 0.8470596075057983\n",
      "Step 6041/10000- lr: [3.996993709090909e-06] - Loss total: 2.6101293563842773, Last rpr Loss: 1.0013712644577026, Last lagvar Loss: 0.8444131016731262\n",
      "Step 6042/10000- lr: [3.995983612121212e-06] - Loss total: 2.610089063644409, Last rpr Loss: 0.9984767436981201, Last lagvar Loss: 0.8473080396652222\n",
      "Step 6043/10000- lr: [3.994973515151515e-06] - Loss total: 2.61004900932312, Last rpr Loss: 1.0016522407531738, Last lagvar Loss: 0.8441334962844849\n",
      "Step 6044/10000- lr: [3.9939634181818184e-06] - Loss total: 2.610008716583252, Last rpr Loss: 0.9981458187103271, Last lagvar Loss: 0.8476405143737793\n",
      "Step 6045/10000- lr: [3.992953321212121e-06] - Loss total: 2.609969139099121, Last rpr Loss: 1.0020389556884766, Last lagvar Loss: 0.8437484502792358\n",
      "Step 6046/10000- lr: [3.991943224242424e-06] - Loss total: 2.609929323196411, Last rpr Loss: 0.9977033138275146, Last lagvar Loss: 0.8480852246284485\n",
      "Step 6047/10000- lr: [3.990933127272727e-06] - Loss total: 2.6098899841308594, Last rpr Loss: 1.0025601387023926, Last lagvar Loss: 0.8432302474975586\n",
      "Step 6048/10000- lr: [3.989923030303031e-06] - Loss total: 2.609851121902466, Last rpr Loss: 0.9970971941947937, Last lagvar Loss: 0.8486950397491455\n",
      "Step 6049/10000- lr: [3.988912933333333e-06] - Loss total: 2.6098129749298096, Last rpr Loss: 1.0032761096954346, Last lagvar Loss: 0.8425192832946777\n",
      "Step 6050/10000- lr: [3.987902836363636e-06] - Loss total: 2.6097750663757324, Last rpr Loss: 0.9962502717971802, Last lagvar Loss: 0.84954833984375\n",
      "Step 6051/10000- lr: [3.986892739393939e-06] - Loss total: 2.60973858833313, Last rpr Loss: 1.004262924194336, Last lagvar Loss: 0.8415408134460449\n",
      "Step 6052/10000- lr: [3.985882642424242e-06] - Loss total: 2.609703779220581, Last rpr Loss: 0.9950926303863525, Last lagvar Loss: 0.8507171869277954\n",
      "Step 6053/10000- lr: [3.984872545454545e-06] - Loss total: 2.609670400619507, Last rpr Loss: 1.0056285858154297, Last lagvar Loss: 0.8401898145675659\n",
      "Step 6054/10000- lr: [3.983862448484849e-06] - Loss total: 2.609640598297119, Last rpr Loss: 0.9934804439544678, Last lagvar Loss: 0.8523497581481934\n",
      "Step 6055/10000- lr: [3.982852351515151e-06] - Loss total: 2.6096134185791016, Last rpr Loss: 1.0075311660766602, Last lagvar Loss: 0.8383142948150635\n",
      "Step 6056/10000- lr: [3.981842254545454e-06] - Loss total: 2.6095941066741943, Last rpr Loss: 0.9912453293800354, Last lagvar Loss: 0.8546222448348999\n",
      "Step 6057/10000- lr: [3.980832157575757e-06] - Loss total: 2.6095778942108154, Last rpr Loss: 1.0101567506790161, Last lagvar Loss: 0.8357380628585815\n",
      "Step 6058/10000- lr: [3.979822060606061e-06] - Loss total: 2.6095778942108154, Last rpr Loss: 0.9881699085235596, Last lagvar Loss: 0.8577671051025391\n",
      "Step 6059/10000- lr: [3.978811963636363e-06] - Loss total: 2.6095798015594482, Last rpr Loss: 1.0137299299240112, Last lagvar Loss: 0.8322539925575256\n",
      "Step 6060/10000- lr: [3.977801866666667e-06] - Loss total: 2.6096153259277344, Last rpr Loss: 0.9840567708015442, Last lagvar Loss: 0.862006425857544\n",
      "Step 6061/10000- lr: [3.976791769696969e-06] - Loss total: 2.6096441745758057, Last rpr Loss: 1.0183970928192139, Last lagvar Loss: 0.827741265296936\n",
      "Step 6062/10000- lr: [3.975781672727272e-06] - Loss total: 2.6097371578216553, Last rpr Loss: 0.9788692593574524, Last lagvar Loss: 0.8674077391624451\n",
      "Step 6063/10000- lr: [3.974771575757576e-06] - Loss total: 2.609788656234741, Last rpr Loss: 1.0239688158035278, Last lagvar Loss: 0.8224076628684998\n",
      "Step 6064/10000- lr: [3.973761478787879e-06] - Loss total: 2.6099469661712646, Last rpr Loss: 0.9731277227401733, Last lagvar Loss: 0.8734567165374756\n",
      "Step 6065/10000- lr: [3.972751381818181e-06] - Loss total: 2.6099767684936523, Last rpr Loss: 1.0293700695037842, Last lagvar Loss: 0.8172889947891235\n",
      "Step 6066/10000- lr: [3.971741284848485e-06] - Loss total: 2.610142707824707, Last rpr Loss: 0.9686248302459717, Last lagvar Loss: 0.878251314163208\n",
      "Step 6067/10000- lr: [3.970731187878787e-06] - Loss total: 2.610042095184326, Last rpr Loss: 1.0320689678192139, Last lagvar Loss: 0.8147443532943726\n",
      "Step 6068/10000- lr: [3.969721090909091e-06] - Loss total: 2.6100571155548096, Last rpr Loss: 0.9685676693916321, Last lagvar Loss: 0.8783056735992432\n",
      "Step 6069/10000- lr: [3.968710993939394e-06] - Loss total: 2.609764575958252, Last rpr Loss: 1.0287500619888306, Last lagvar Loss: 0.8178590536117554\n",
      "Step 6070/10000- lr: [3.967700896969697e-06] - Loss total: 2.6095478534698486, Last rpr Loss: 0.975733757019043, Last lagvar Loss: 0.8706934452056885\n",
      "Step 6071/10000- lr: [3.966690799999999e-06] - Loss total: 2.6092169284820557, Last rpr Loss: 1.0182567834854126, Last lagvar Loss: 0.8278689384460449\n",
      "Step 6072/10000- lr: [3.965680703030303e-06] - Loss total: 2.6089813709259033, Last rpr Loss: 0.9889926910400391, Last lagvar Loss: 0.856928825378418\n",
      "Step 6073/10000- lr: [3.964670606060607e-06] - Loss total: 2.608830213546753, Last rpr Loss: 1.0037946701049805, Last lagvar Loss: 0.8420134782791138\n",
      "Step 6074/10000- lr: [3.963660509090909e-06] - Loss total: 2.6087849140167236, Last rpr Loss: 1.0033177137374878, Last lagvar Loss: 0.8424868583679199\n",
      "Step 6075/10000- lr: [3.962650412121212e-06] - Loss total: 2.6088178157806396, Last rpr Loss: 0.9908040761947632, Last lagvar Loss: 0.8550761938095093\n",
      "Step 6076/10000- lr: [3.961640315151515e-06] - Loss total: 2.6088759899139404, Last rpr Loss: 1.0137310028076172, Last lagvar Loss: 0.8322563171386719\n",
      "Step 6077/10000- lr: [3.960630218181819e-06] - Loss total: 2.6089344024658203, Last rpr Loss: 0.9833171367645264, Last lagvar Loss: 0.8627709746360779\n",
      "Step 6078/10000- lr: [3.959620121212121e-06] - Loss total: 2.6089138984680176, Last rpr Loss: 1.0176787376403809, Last lagvar Loss: 0.8284339904785156\n",
      "Step 6079/10000- lr: [3.958610024242425e-06] - Loss total: 2.6088671684265137, Last rpr Loss: 0.9829010963439941, Last lagvar Loss: 0.8632044196128845\n",
      "Step 6080/10000- lr: [3.957599927272727e-06] - Loss total: 2.6087393760681152, Last rpr Loss: 1.014845371246338, Last lagvar Loss: 0.8311716318130493\n",
      "Step 6081/10000- lr: [3.95658983030303e-06] - Loss total: 2.6086137294769287, Last rpr Loss: 0.9886842370033264, Last lagvar Loss: 0.8572443723678589\n",
      "Step 6082/10000- lr: [3.955579733333333e-06] - Loss total: 2.6084909439086914, Last rpr Loss: 1.0070745944976807, Last lagvar Loss: 0.8387705683708191\n",
      "Step 6083/10000- lr: [3.954569636363637e-06] - Loss total: 2.6084067821502686, Last rpr Loss: 0.9975643157958984, Last lagvar Loss: 0.8482360243797302\n",
      "Step 6084/10000- lr: [3.953559539393939e-06] - Loss total: 2.608362913131714, Last rpr Loss: 0.998012900352478, Last lagvar Loss: 0.8477856516838074\n",
      "Step 6085/10000- lr: [3.952549442424243e-06] - Loss total: 2.608349561691284, Last rpr Loss: 1.005669116973877, Last lagvar Loss: 0.8401602506637573\n",
      "Step 6086/10000- lr: [3.951539345454545e-06] - Loss total: 2.608348846435547, Last rpr Loss: 0.991411566734314, Last lagvar Loss: 0.8544586896896362\n",
      "Step 6087/10000- lr: [3.950529248484849e-06] - Loss total: 2.6083364486694336, Last rpr Loss: 1.010195016860962, Last lagvar Loss: 0.8357083797454834\n",
      "Step 6088/10000- lr: [3.949519151515152e-06] - Loss total: 2.6083099842071533, Last rpr Loss: 0.9892443418502808, Last lagvar Loss: 0.8566727042198181\n",
      "Step 6089/10000- lr: [3.948509054545455e-06] - Loss total: 2.6082534790039062, Last rpr Loss: 1.0102150440216064, Last lagvar Loss: 0.8356884717941284\n",
      "Step 6090/10000- lr: [3.947498957575757e-06] - Loss total: 2.6081864833831787, Last rpr Loss: 0.9913293719291687, Last lagvar Loss: 0.8545466661453247\n",
      "Step 6091/10000- lr: [3.946488860606061e-06] - Loss total: 2.608109951019287, Last rpr Loss: 1.0065698623657227, Last lagvar Loss: 0.839271068572998\n",
      "Step 6092/10000- lr: [3.945478763636364e-06] - Loss total: 2.608042001724243, Last rpr Loss: 0.996039867401123, Last lagvar Loss: 0.849773108959198\n",
      "Step 6093/10000- lr: [3.944468666666667e-06] - Loss total: 2.6079862117767334, Last rpr Loss: 1.001259207725525, Last lagvar Loss: 0.8445396423339844\n",
      "Step 6094/10000- lr: [3.94345856969697e-06] - Loss total: 2.607945203781128, Last rpr Loss: 1.0012643337249756, Last lagvar Loss: 0.8445349335670471\n",
      "Step 6095/10000- lr: [3.942448472727273e-06] - Loss total: 2.6079142093658447, Last rpr Loss: 0.9964638948440552, Last lagvar Loss: 0.8493461608886719\n",
      "Step 6096/10000- lr: [3.941438375757575e-06] - Loss total: 2.607886791229248, Last rpr Loss: 1.0051195621490479, Last lagvar Loss: 0.840705931186676\n",
      "Step 6097/10000- lr: [3.9404282787878794e-06] - Loss total: 2.6078579425811768, Last rpr Loss: 0.9937939047813416, Last lagvar Loss: 0.8520431518554688\n",
      "Step 6098/10000- lr: [3.939418181818182e-06] - Loss total: 2.607820510864258, Last rpr Loss: 1.0065571069717407, Last lagvar Loss: 0.8392854332923889\n",
      "Step 6099/10000- lr: [3.938408084848485e-06] - Loss total: 2.6077778339385986, Last rpr Loss: 0.9936985969543457, Last lagvar Loss: 0.8521404266357422\n",
      "Step 6100/10000- lr: [3.9373979878787876e-06] - Loss total: 2.6077263355255127, Last rpr Loss: 1.0055639743804932, Last lagvar Loss: 0.8402659893035889\n",
      "Step 6101/10000- lr: [3.936387890909091e-06] - Loss total: 2.6076748371124268, Last rpr Loss: 0.9956260919570923, Last lagvar Loss: 0.8501914739608765\n",
      "Step 6102/10000- lr: [3.935377793939394e-06] - Loss total: 2.607623338699341, Last rpr Loss: 1.0029733180999756, Last lagvar Loss: 0.842833399772644\n",
      "Step 6103/10000- lr: [3.934367696969697e-06] - Loss total: 2.6075756549835205, Last rpr Loss: 0.9985116720199585, Last lagvar Loss: 0.847287654876709\n",
      "Step 6104/10000- lr: [3.9333576e-06] - Loss total: 2.6075329780578613, Last rpr Loss: 0.9999715685844421, Last lagvar Loss: 0.8458253741264343\n",
      "Step 6105/10000- lr: [3.932347503030303e-06] - Loss total: 2.6074941158294678, Last rpr Loss: 1.0013097524642944, Last lagvar Loss: 0.8444888591766357\n",
      "Step 6106/10000- lr: [3.9313374060606055e-06] - Loss total: 2.6074581146240234, Last rpr Loss: 0.9975377321243286, Last lagvar Loss: 0.8482649922370911\n",
      "Step 6107/10000- lr: [3.93032730909091e-06] - Loss total: 2.607421636581421, Last rpr Loss: 1.003232479095459, Last lagvar Loss: 0.842574954032898\n",
      "Step 6108/10000- lr: [3.929317212121212e-06] - Loss total: 2.6073849201202393, Last rpr Loss: 0.9962639808654785, Last lagvar Loss: 0.8495463728904724\n",
      "Step 6109/10000- lr: [3.928307115151515e-06] - Loss total: 2.6073453426361084, Last rpr Loss: 1.0038820505142212, Last lagvar Loss: 0.84192955493927\n",
      "Step 6110/10000- lr: [3.927297018181818e-06] - Loss total: 2.607304573059082, Last rpr Loss: 0.9962723255157471, Last lagvar Loss: 0.8495374917984009\n",
      "Step 6111/10000- lr: [3.926286921212121e-06] - Loss total: 2.6072611808776855, Last rpr Loss: 1.0033276081085205, Last lagvar Loss: 0.8424791693687439\n",
      "Step 6112/10000- lr: [3.925276824242424e-06] - Loss total: 2.60721755027771, Last rpr Loss: 0.9972571134567261, Last lagvar Loss: 0.848545491695404\n",
      "Step 6113/10000- lr: [3.924266727272728e-06] - Loss total: 2.6071739196777344, Last rpr Loss: 1.0019845962524414, Last lagvar Loss: 0.8438143134117126\n",
      "Step 6114/10000- lr: [3.92325663030303e-06] - Loss total: 2.607131242752075, Last rpr Loss: 0.9987402558326721, Last lagvar Loss: 0.8470555543899536\n",
      "Step 6115/10000- lr: [3.922246533333333e-06] - Loss total: 2.6070902347564697, Last rpr Loss: 1.0004154443740845, Last lagvar Loss: 0.8453788757324219\n",
      "Step 6116/10000- lr: [3.921236436363636e-06] - Loss total: 2.6070504188537598, Last rpr Loss: 1.00026535987854, Last lagvar Loss: 0.8455284833908081\n",
      "Step 6117/10000- lr: [3.92022633939394e-06] - Loss total: 2.607011079788208, Last rpr Loss: 0.9990469217300415, Last lagvar Loss: 0.8467473983764648\n",
      "Step 6118/10000- lr: [3.919216242424242e-06] - Loss total: 2.6069729328155518, Last rpr Loss: 1.0014524459838867, Last lagvar Loss: 0.8443431854248047\n",
      "Step 6119/10000- lr: [3.918206145454546e-06] - Loss total: 2.6069347858428955, Last rpr Loss: 0.998140275478363, Last lagvar Loss: 0.8476561903953552\n",
      "Step 6120/10000- lr: [3.917196048484848e-06] - Loss total: 2.606896162033081, Last rpr Loss: 1.0020966529846191, Last lagvar Loss: 0.843700647354126\n",
      "Step 6121/10000- lr: [3.916185951515151e-06] - Loss total: 2.6068570613861084, Last rpr Loss: 0.9977995157241821, Last lagvar Loss: 0.8479979038238525\n",
      "Step 6122/10000- lr: [3.915175854545455e-06] - Loss total: 2.6068172454833984, Last rpr Loss: 1.0021458864212036, Last lagvar Loss: 0.843651294708252\n",
      "Step 6123/10000- lr: [3.914165757575758e-06] - Loss total: 2.6067774295806885, Last rpr Loss: 0.9979771971702576, Last lagvar Loss: 0.8478188514709473\n",
      "Step 6124/10000- lr: [3.91315566060606e-06] - Loss total: 2.6067371368408203, Last rpr Loss: 1.0017504692077637, Last lagvar Loss: 0.8440446257591248\n",
      "Step 6125/10000- lr: [3.9121455636363636e-06] - Loss total: 2.606696605682373, Last rpr Loss: 0.9985126256942749, Last lagvar Loss: 0.8472810387611389\n",
      "Step 6126/10000- lr: [3.911135466666666e-06] - Loss total: 2.606657028198242, Last rpr Loss: 1.001102089881897, Last lagvar Loss: 0.8446904420852661\n",
      "Step 6127/10000- lr: [3.91012536969697e-06] - Loss total: 2.606616973876953, Last rpr Loss: 0.9992239475250244, Last lagvar Loss: 0.8465675711631775\n",
      "Step 6128/10000- lr: [3.9091152727272725e-06] - Loss total: 2.6065773963928223, Last rpr Loss: 1.0003825426101685, Last lagvar Loss: 0.8454083204269409\n",
      "Step 6129/10000- lr: [3.908105175757576e-06] - Loss total: 2.6065382957458496, Last rpr Loss: 0.9999312162399292, Last lagvar Loss: 0.845859169960022\n",
      "Step 6130/10000- lr: [3.907095078787878e-06] - Loss total: 2.606499433517456, Last rpr Loss: 0.999732255935669, Last lagvar Loss: 0.8460578918457031\n",
      "Step 6131/10000- lr: [3.9060849818181815e-06] - Loss total: 2.6064605712890625, Last rpr Loss: 1.0005167722702026, Last lagvar Loss: 0.8452733755111694\n",
      "Step 6132/10000- lr: [3.905074884848485e-06] - Loss total: 2.606421947479248, Last rpr Loss: 0.9992378354072571, Last lagvar Loss: 0.8465523719787598\n",
      "Step 6133/10000- lr: [3.904064787878788e-06] - Loss total: 2.6063835620880127, Last rpr Loss: 1.0009043216705322, Last lagvar Loss: 0.8448858261108398\n",
      "Step 6134/10000- lr: [3.9030546909090905e-06] - Loss total: 2.606344699859619, Last rpr Loss: 0.9989469051361084, Last lagvar Loss: 0.8468432426452637\n",
      "Step 6135/10000- lr: [3.902044593939394e-06] - Loss total: 2.606306314468384, Last rpr Loss: 1.0010902881622314, Last lagvar Loss: 0.8446998000144958\n",
      "Step 6136/10000- lr: [3.901034496969696e-06] - Loss total: 2.6062674522399902, Last rpr Loss: 0.9988517761230469, Last lagvar Loss: 0.8469380140304565\n",
      "Step 6137/10000- lr: [3.9000244e-06] - Loss total: 2.606229066848755, Last rpr Loss: 1.0011011362075806, Last lagvar Loss: 0.8446885347366333\n",
      "Step 6138/10000- lr: [3.899014303030303e-06] - Loss total: 2.6061906814575195, Last rpr Loss: 0.9989140033721924, Last lagvar Loss: 0.8468751907348633\n",
      "Step 6139/10000- lr: [3.898004206060606e-06] - Loss total: 2.606151580810547, Last rpr Loss: 1.000983476638794, Last lagvar Loss: 0.8448054790496826\n",
      "Step 6140/10000- lr: [3.8969941090909085e-06] - Loss total: 2.6061129570007324, Last rpr Loss: 0.9990811347961426, Last lagvar Loss: 0.8467072248458862\n",
      "Step 6141/10000- lr: [3.895984012121213e-06] - Loss total: 2.606074333190918, Last rpr Loss: 1.0007816553115845, Last lagvar Loss: 0.8450062870979309\n",
      "Step 6142/10000- lr: [3.894973915151515e-06] - Loss total: 2.6060359477996826, Last rpr Loss: 0.9993097186088562, Last lagvar Loss: 0.846477746963501\n",
      "Step 6143/10000- lr: [3.893963818181818e-06] - Loss total: 2.605997323989868, Last rpr Loss: 1.0005381107330322, Last lagvar Loss: 0.8452489376068115\n",
      "Step 6144/10000- lr: [3.892953721212121e-06] - Loss total: 2.605958938598633, Last rpr Loss: 0.9995599985122681, Last lagvar Loss: 0.8462265729904175\n",
      "Step 6145/10000- lr: [3.891943624242424e-06] - Loss total: 2.6059205532073975, Last rpr Loss: 1.000291109085083, Last lagvar Loss: 0.8454952836036682\n",
      "Step 6146/10000- lr: [3.8909335272727265e-06] - Loss total: 2.605882406234741, Last rpr Loss: 0.9997992515563965, Last lagvar Loss: 0.8459867835044861\n",
      "Step 6147/10000- lr: [3.889923430303031e-06] - Loss total: 2.6058437824249268, Last rpr Loss: 1.0000656843185425, Last lagvar Loss: 0.8457200527191162\n",
      "Step 6148/10000- lr: [3.888913333333333e-06] - Loss total: 2.6058056354522705, Last rpr Loss: 1.0000029802322388, Last lagvar Loss: 0.8457825183868408\n",
      "Step 6149/10000- lr: [3.887903236363636e-06] - Loss total: 2.6057677268981934, Last rpr Loss: 0.9998854994773865, Last lagvar Loss: 0.8458998203277588\n",
      "Step 6150/10000- lr: [3.886893139393939e-06] - Loss total: 2.605729579925537, Last rpr Loss: 1.0001674890518188, Last lagvar Loss: 0.8456175327301025\n",
      "Step 6151/10000- lr: [3.885883042424243e-06] - Loss total: 2.60569167137146, Last rpr Loss: 0.9997386932373047, Last lagvar Loss: 0.8460460901260376\n",
      "Step 6152/10000- lr: [3.884872945454545e-06] - Loss total: 2.6056535243988037, Last rpr Loss: 1.0002925395965576, Last lagvar Loss: 0.8454920649528503\n",
      "Step 6153/10000- lr: [3.8838628484848485e-06] - Loss total: 2.6056158542633057, Last rpr Loss: 0.9996253252029419, Last lagvar Loss: 0.846159040927887\n",
      "Step 6154/10000- lr: [3.882852751515151e-06] - Loss total: 2.6055779457092285, Last rpr Loss: 1.0003877878189087, Last lagvar Loss: 0.8453963994979858\n",
      "Step 6155/10000- lr: [3.881842654545454e-06] - Loss total: 2.6055400371551514, Last rpr Loss: 0.9995560050010681, Last lagvar Loss: 0.8462278842926025\n",
      "Step 6156/10000- lr: [3.880832557575757e-06] - Loss total: 2.6055023670196533, Last rpr Loss: 1.000445008277893, Last lagvar Loss: 0.8453388214111328\n",
      "Step 6157/10000- lr: [3.879822460606061e-06] - Loss total: 2.605464458465576, Last rpr Loss: 0.9995037317276001, Last lagvar Loss: 0.8462799787521362\n",
      "Step 6158/10000- lr: [3.878812363636364e-06] - Loss total: 2.605426788330078, Last rpr Loss: 1.0004963874816895, Last lagvar Loss: 0.845287024974823\n",
      "Step 6159/10000- lr: [3.8778022666666665e-06] - Loss total: 2.60538911819458, Last rpr Loss: 0.9994583129882812, Last lagvar Loss: 0.8463248014450073\n",
      "Step 6160/10000- lr: [3.87679216969697e-06] - Loss total: 2.605351448059082, Last rpr Loss: 1.000535011291504, Last lagvar Loss: 0.8452479839324951\n",
      "Step 6161/10000- lr: [3.875782072727273e-06] - Loss total: 2.605313777923584, Last rpr Loss: 0.9994184374809265, Last lagvar Loss: 0.8463643193244934\n",
      "Step 6162/10000- lr: [3.874771975757576e-06] - Loss total: 2.605276107788086, Last rpr Loss: 1.0005741119384766, Last lagvar Loss: 0.8452084064483643\n",
      "Step 6163/10000- lr: [3.873761878787879e-06] - Loss total: 2.605238676071167, Last rpr Loss: 0.9993829727172852, Last lagvar Loss: 0.8463994264602661\n",
      "Step 6164/10000- lr: [3.872751781818182e-06] - Loss total: 2.605201005935669, Last rpr Loss: 1.0006128549575806, Last lagvar Loss: 0.8451693654060364\n",
      "Step 6165/10000- lr: [3.8717416848484845e-06] - Loss total: 2.60516357421875, Last rpr Loss: 0.9993366003036499, Last lagvar Loss: 0.8464453220367432\n",
      "Step 6166/10000- lr: [3.870731587878789e-06] - Loss total: 2.60512638092041, Last rpr Loss: 1.0006717443466187, Last lagvar Loss: 0.8451101183891296\n",
      "Step 6167/10000- lr: [3.869721490909091e-06] - Loss total: 2.605088949203491, Last rpr Loss: 0.9992698431015015, Last lagvar Loss: 0.8465118408203125\n",
      "Step 6168/10000- lr: [3.868711393939394e-06] - Loss total: 2.6050517559051514, Last rpr Loss: 1.0007437467575073, Last lagvar Loss: 0.8450377583503723\n",
      "Step 6169/10000- lr: [3.867701296969697e-06] - Loss total: 2.6050140857696533, Last rpr Loss: 0.9991832971572876, Last lagvar Loss: 0.8465981483459473\n",
      "Step 6170/10000- lr: [3.8666912e-06] - Loss total: 2.6049766540527344, Last rpr Loss: 1.0008482933044434, Last lagvar Loss: 0.844933032989502\n",
      "Step 6171/10000- lr: [3.865681103030303e-06] - Loss total: 2.6049396991729736, Last rpr Loss: 0.9990670680999756, Last lagvar Loss: 0.8467141389846802\n",
      "Step 6172/10000- lr: [3.8646710060606066e-06] - Loss total: 2.604902982711792, Last rpr Loss: 1.0009832382202148, Last lagvar Loss: 0.8447978496551514\n",
      "Step 6173/10000- lr: [3.863660909090909e-06] - Loss total: 2.604865550994873, Last rpr Loss: 0.9989057779312134, Last lagvar Loss: 0.8468753099441528\n",
      "Step 6174/10000- lr: [3.862650812121212e-06] - Loss total: 2.604828357696533, Last rpr Loss: 1.0011731386184692, Last lagvar Loss: 0.8446080684661865\n",
      "Step 6175/10000- lr: [3.861640715151515e-06] - Loss total: 2.6047918796539307, Last rpr Loss: 0.9986827373504639, Last lagvar Loss: 0.8470985293388367\n",
      "Step 6176/10000- lr: [3.860630618181819e-06] - Loss total: 2.604754686355591, Last rpr Loss: 1.0014326572418213, Last lagvar Loss: 0.8443487882614136\n",
      "Step 6177/10000- lr: [3.859620521212121e-06] - Loss total: 2.6047184467315674, Last rpr Loss: 0.9983847141265869, Last lagvar Loss: 0.8473970890045166\n",
      "Step 6178/10000- lr: [3.8586104242424245e-06] - Loss total: 2.6046817302703857, Last rpr Loss: 1.0017809867858887, Last lagvar Loss: 0.8440014123916626\n",
      "Step 6179/10000- lr: [3.857600327272727e-06] - Loss total: 2.6046457290649414, Last rpr Loss: 0.9979737997055054, Last lagvar Loss: 0.8478090763092041\n",
      "Step 6180/10000- lr: [3.85659023030303e-06] - Loss total: 2.604609727859497, Last rpr Loss: 1.0022636651992798, Last lagvar Loss: 0.8435202836990356\n",
      "Step 6181/10000- lr: [3.8555801333333335e-06] - Loss total: 2.604573965072632, Last rpr Loss: 0.9974104762077332, Last lagvar Loss: 0.8483748435974121\n",
      "Step 6182/10000- lr: [3.854570036363637e-06] - Loss total: 2.604539394378662, Last rpr Loss: 1.0029250383377075, Last lagvar Loss: 0.8428621292114258\n",
      "Step 6183/10000- lr: [3.853559939393939e-06] - Loss total: 2.6045050621032715, Last rpr Loss: 0.9966294169425964, Last lagvar Loss: 0.8491604924201965\n",
      "Step 6184/10000- lr: [3.8525498424242425e-06] - Loss total: 2.604471445083618, Last rpr Loss: 1.0038506984710693, Last lagvar Loss: 0.8419426679611206\n",
      "Step 6185/10000- lr: [3.851539745454545e-06] - Loss total: 2.6044399738311768, Last rpr Loss: 0.9955331087112427, Last lagvar Loss: 0.850265622138977\n",
      "Step 6186/10000- lr: [3.850529648484849e-06] - Loss total: 2.6044094562530518, Last rpr Loss: 1.0051474571228027, Last lagvar Loss: 0.8406578302383423\n",
      "Step 6187/10000- lr: [3.8495195515151515e-06] - Loss total: 2.6043827533721924, Last rpr Loss: 0.9939963817596436, Last lagvar Loss: 0.8518192172050476\n",
      "Step 6188/10000- lr: [3.848509454545455e-06] - Loss total: 2.604358196258545, Last rpr Loss: 1.0069679021835327, Last lagvar Loss: 0.838860273361206\n",
      "Step 6189/10000- lr: [3.847499357575757e-06] - Loss total: 2.6043405532836914, Last rpr Loss: 0.9918415546417236, Last lagvar Loss: 0.8540067076683044\n",
      "Step 6190/10000- lr: [3.8464892606060605e-06] - Loss total: 2.6043264865875244, Last rpr Loss: 1.0095157623291016, Last lagvar Loss: 0.8363559246063232\n",
      "Step 6191/10000- lr: [3.845479163636364e-06] - Loss total: 2.6043269634246826, Last rpr Loss: 0.9888428449630737, Last lagvar Loss: 0.8570681810379028\n",
      "Step 6192/10000- lr: [3.844469066666667e-06] - Loss total: 2.6043310165405273, Last rpr Loss: 1.013033151626587, Last lagvar Loss: 0.8329205513000488\n",
      "Step 6193/10000- lr: [3.8434589696969695e-06] - Loss total: 2.6043660640716553, Last rpr Loss: 0.9847505688667297, Last lagvar Loss: 0.8612787127494812\n",
      "Step 6194/10000- lr: [3.842448872727273e-06] - Loss total: 2.604398488998413, Last rpr Loss: 1.017723560333252, Last lagvar Loss: 0.8283778429031372\n",
      "Step 6195/10000- lr: [3.841438775757575e-06] - Loss total: 2.6044912338256836, Last rpr Loss: 0.9794626235961914, Last lagvar Loss: 0.866775631904602\n",
      "Step 6196/10000- lr: [3.840428678787879e-06] - Loss total: 2.60455322265625, Last rpr Loss: 1.023496150970459, Last lagvar Loss: 0.822844386100769\n",
      "Step 6197/10000- lr: [3.839418581818182e-06] - Loss total: 2.604719638824463, Last rpr Loss: 0.9733964204788208, Last lagvar Loss: 0.873159646987915\n",
      "Step 6198/10000- lr: [3.838408484848485e-06] - Loss total: 2.604771137237549, Last rpr Loss: 1.02937912940979, Last lagvar Loss: 0.8172658681869507\n",
      "Step 6199/10000- lr: [3.8373983878787874e-06] - Loss total: 2.6049625873565674, Last rpr Loss: 0.9682705402374268, Last lagvar Loss: 0.8786168098449707\n",
      "Step 6200/10000- lr: [3.8363882909090916e-06] - Loss total: 2.6048877239227295, Last rpr Loss: 1.0327785015106201, Last lagvar Loss: 0.8140631914138794\n",
      "Step 6201/10000- lr: [3.835378193939394e-06] - Loss total: 2.604933261871338, Last rpr Loss: 0.9675081968307495, Last lagvar Loss: 0.8794243335723877\n",
      "Step 6202/10000- lr: [3.834368096969697e-06] - Loss total: 2.6046440601348877, Last rpr Loss: 1.0299768447875977, Last lagvar Loss: 0.8166837692260742\n",
      "Step 6203/10000- lr: [3.833358e-06] - Loss total: 2.6044304370880127, Last rpr Loss: 0.974473774433136, Last lagvar Loss: 0.8720039129257202\n",
      "Step 6204/10000- lr: [3.832347903030303e-06] - Loss total: 2.6040804386138916, Last rpr Loss: 1.0192837715148926, Last lagvar Loss: 0.8268611431121826\n",
      "Step 6205/10000- lr: [3.831337806060605e-06] - Loss total: 2.603830575942993, Last rpr Loss: 0.9883599281311035, Last lagvar Loss: 0.8575596809387207\n",
      "Step 6206/10000- lr: [3.8303277090909095e-06] - Loss total: 2.603673219680786, Last rpr Loss: 1.0039503574371338, Last lagvar Loss: 0.8418418169021606\n",
      "Step 6207/10000- lr: [3.829317612121212e-06] - Loss total: 2.603634834289551, Last rpr Loss: 1.003648042678833, Last lagvar Loss: 0.8421410322189331\n",
      "Step 6208/10000- lr: [3.828307515151515e-06] - Loss total: 2.6036837100982666, Last rpr Loss: 0.9900881052017212, Last lagvar Loss: 0.8557877540588379\n",
      "Step 6209/10000- lr: [3.827297418181818e-06] - Loss total: 2.60375714302063, Last rpr Loss: 1.0146286487579346, Last lagvar Loss: 0.8313641548156738\n",
      "Step 6210/10000- lr: [3.826287321212122e-06] - Loss total: 2.603827953338623, Last rpr Loss: 0.9824044704437256, Last lagvar Loss: 0.8636966347694397\n",
      "Step 6211/10000- lr: [3.825277224242424e-06] - Loss total: 2.603804349899292, Last rpr Loss: 1.018322229385376, Last lagvar Loss: 0.8277925848960876\n",
      "Step 6212/10000- lr: [3.8242671272727275e-06] - Loss total: 2.6037495136260986, Last rpr Loss: 0.9826632142066956, Last lagvar Loss: 0.863430380821228\n",
      "Step 6213/10000- lr: [3.82325703030303e-06] - Loss total: 2.603611469268799, Last rpr Loss: 1.0145182609558105, Last lagvar Loss: 0.83146733045578\n",
      "Step 6214/10000- lr: [3.822246933333333e-06] - Loss total: 2.6034817695617676, Last rpr Loss: 0.9896035194396973, Last lagvar Loss: 0.8562827110290527\n",
      "Step 6215/10000- lr: [3.821236836363636e-06] - Loss total: 2.603368043899536, Last rpr Loss: 1.005638837814331, Last lagvar Loss: 0.8401657342910767\n",
      "Step 6216/10000- lr: [3.82022673939394e-06] - Loss total: 2.6033029556274414, Last rpr Loss: 0.9993802309036255, Last lagvar Loss: 0.8463925123214722\n",
      "Step 6217/10000- lr: [3.819216642424242e-06] - Loss total: 2.603282928466797, Last rpr Loss: 0.9960143566131592, Last lagvar Loss: 0.8497737050056458\n",
      "Step 6218/10000- lr: [3.8182065454545455e-06] - Loss total: 2.603288412094116, Last rpr Loss: 1.0075753927230835, Last lagvar Loss: 0.8382567763328552\n",
      "Step 6219/10000- lr: [3.817196448484848e-06] - Loss total: 2.603299140930176, Last rpr Loss: 0.9897792339324951, Last lagvar Loss: 0.8560986518859863\n",
      "Step 6220/10000- lr: [3.816186351515152e-06] - Loss total: 2.6032841205596924, Last rpr Loss: 1.0112583637237549, Last lagvar Loss: 0.8346431851387024\n",
      "Step 6221/10000- lr: [3.8151762545454544e-06] - Loss total: 2.6032497882843018, Last rpr Loss: 0.9888888597488403, Last lagvar Loss: 0.8570107221603394\n",
      "Step 6222/10000- lr: [3.8141661575757577e-06] - Loss total: 2.6031830310821533, Last rpr Loss: 1.0097696781158447, Last lagvar Loss: 0.8360986709594727\n",
      "Step 6223/10000- lr: [3.81315606060606e-06] - Loss total: 2.603111743927002, Last rpr Loss: 0.9925858378410339, Last lagvar Loss: 0.8532429337501526\n",
      "Step 6224/10000- lr: [3.8121459636363634e-06] - Loss total: 2.6030421257019043, Last rpr Loss: 1.0046567916870117, Last lagvar Loss: 0.84113609790802\n",
      "Step 6225/10000- lr: [3.811135866666666e-06] - Loss total: 2.6029884815216064, Last rpr Loss: 0.9984205961227417, Last lagvar Loss: 0.8473522067070007\n",
      "Step 6226/10000- lr: [3.81012576969697e-06] - Loss total: 2.602952241897583, Last rpr Loss: 0.9986562728881836, Last lagvar Loss: 0.8471155762672424\n",
      "Step 6227/10000- lr: [3.8091156727272724e-06] - Loss total: 2.6029295921325684, Last rpr Loss: 1.0037487745285034, Last lagvar Loss: 0.8420363664627075\n",
      "Step 6228/10000- lr: [3.8081055757575757e-06] - Loss total: 2.602912425994873, Last rpr Loss: 0.9943007826805115, Last lagvar Loss: 0.8515021800994873\n",
      "Step 6229/10000- lr: [3.807095478787878e-06] - Loss total: 2.6028897762298584, Last rpr Loss: 1.0067131519317627, Last lagvar Loss: 0.8391038179397583\n",
      "Step 6230/10000- lr: [3.8060853818181822e-06] - Loss total: 2.602860450744629, Last rpr Loss: 0.9929172992706299, Last lagvar Loss: 0.8529037237167358\n",
      "Step 6231/10000- lr: [3.8050752848484847e-06] - Loss total: 2.602818012237549, Last rpr Loss: 1.0066417455673218, Last lagvar Loss: 0.8391730189323425\n",
      "Step 6232/10000- lr: [3.804065187878788e-06] - Loss total: 2.602771282196045, Last rpr Loss: 0.9944446086883545, Last lagvar Loss: 0.8513563871383667\n",
      "Step 6233/10000- lr: [3.8030550909090904e-06] - Loss total: 2.602721691131592, Last rpr Loss: 1.00408935546875, Last lagvar Loss: 0.8416968584060669\n",
      "Step 6234/10000- lr: [3.8020449939393937e-06] - Loss total: 2.6026759147644043, Last rpr Loss: 0.9976981282234192, Last lagvar Loss: 0.8480759859085083\n",
      "Step 6235/10000- lr: [3.801034896969696e-06] - Loss total: 2.6026360988616943, Last rpr Loss: 1.0005053281784058, Last lagvar Loss: 0.8452634215354919\n",
      "Step 6236/10000- lr: [3.8000248000000002e-06] - Loss total: 2.602602481842041, Last rpr Loss: 1.0011262893676758, Last lagvar Loss: 0.8446433544158936\n",
      "Step 6237/10000- lr: [3.7990147030303026e-06] - Loss total: 2.602572441101074, Last rpr Loss: 0.9974383115768433, Last lagvar Loss: 0.8483363389968872\n",
      "Step 6238/10000- lr: [3.798004606060606e-06] - Loss total: 2.602544069290161, Last rpr Loss: 1.0035169124603271, Last lagvar Loss: 0.8422641158103943\n",
      "Step 6239/10000- lr: [3.7969945090909084e-06] - Loss total: 2.6025137901306152, Last rpr Loss: 0.9958497285842896, Last lagvar Loss: 0.84993577003479\n",
      "Step 6240/10000- lr: [3.7959844121212125e-06] - Loss total: 2.602480173110962, Last rpr Loss: 1.0042970180511475, Last lagvar Loss: 0.8414896726608276\n",
      "Step 6241/10000- lr: [3.794974315151515e-06] - Loss total: 2.6024436950683594, Last rpr Loss: 0.9959345459938049, Last lagvar Loss: 0.8498499393463135\n",
      "Step 6242/10000- lr: [3.793964218181818e-06] - Loss total: 2.602404832839966, Last rpr Loss: 1.0035218000411987, Last lagvar Loss: 0.8422582149505615\n",
      "Step 6243/10000- lr: [3.7929541212121215e-06] - Loss total: 2.602365255355835, Last rpr Loss: 0.9972996115684509, Last lagvar Loss: 0.8484748601913452\n",
      "Step 6244/10000- lr: [3.791944024242424e-06] - Loss total: 2.6023261547088623, Last rpr Loss: 1.0017457008361816, Last lagvar Loss: 0.8440241813659668\n",
      "Step 6245/10000- lr: [3.790933927272728e-06] - Loss total: 2.6022887229919434, Last rpr Loss: 0.9992528557777405, Last lagvar Loss: 0.8465142250061035\n",
      "Step 6246/10000- lr: [3.7899238303030304e-06] - Loss total: 2.6022541522979736, Last rpr Loss: 0.9997344017028809, Last lagvar Loss: 0.8460321426391602\n",
      "Step 6247/10000- lr: [3.7889137333333337e-06] - Loss total: 2.6022205352783203, Last rpr Loss: 1.001068115234375, Last lagvar Loss: 0.8446993231773376\n",
      "Step 6248/10000- lr: [3.787903636363636e-06] - Loss total: 2.6021878719329834, Last rpr Loss: 0.9981957674026489, Last lagvar Loss: 0.8475736379623413\n",
      "Step 6249/10000- lr: [3.7868935393939394e-06] - Loss total: 2.6021552085876465, Last rpr Loss: 1.0022283792495728, Last lagvar Loss: 0.8435426950454712\n",
      "Step 6250/10000- lr: [3.7858834424242427e-06] - Loss total: 2.6021220684051514, Last rpr Loss: 0.9974958896636963, Last lagvar Loss: 0.8482763171195984\n",
      "Step 6251/10000- lr: [3.784873345454546e-06] - Loss total: 2.6020877361297607, Last rpr Loss: 1.0025420188903809, Last lagvar Loss: 0.8432303667068481\n",
      "Step 6252/10000- lr: [3.7838632484848484e-06] - Loss total: 2.6020524501800537, Last rpr Loss: 0.9976133704185486, Last lagvar Loss: 0.8481579422950745\n",
      "Step 6253/10000- lr: [3.7828531515151517e-06] - Loss total: 2.6020164489746094, Last rpr Loss: 1.0020947456359863, Last lagvar Loss: 0.8436751365661621\n",
      "Step 6254/10000- lr: [3.781843054545454e-06] - Loss total: 2.601980447769165, Last rpr Loss: 0.998330295085907, Last lagvar Loss: 0.8474376201629639\n",
      "Step 6255/10000- lr: [3.7808329575757582e-06] - Loss total: 2.6019446849823, Last rpr Loss: 1.0011684894561768, Last lagvar Loss: 0.8445979356765747\n",
      "Step 6256/10000- lr: [3.7798228606060607e-06] - Loss total: 2.6019093990325928, Last rpr Loss: 0.9993393421173096, Last lagvar Loss: 0.8464257717132568\n",
      "Step 6257/10000- lr: [3.778812763636364e-06] - Loss total: 2.601874589920044, Last rpr Loss: 1.0001137256622314, Last lagvar Loss: 0.8456509709358215\n",
      "Step 6258/10000- lr: [3.7778026666666664e-06] - Loss total: 2.6018402576446533, Last rpr Loss: 1.0003371238708496, Last lagvar Loss: 0.8454275131225586\n",
      "Step 6259/10000- lr: [3.7767925696969705e-06] - Loss total: 2.601806163787842, Last rpr Loss: 0.9992367029190063, Last lagvar Loss: 0.846528172492981\n",
      "Step 6260/10000- lr: [3.775782472727273e-06] - Loss total: 2.6017725467681885, Last rpr Loss: 1.0010621547698975, Last lagvar Loss: 0.844703197479248\n",
      "Step 6261/10000- lr: [3.7747723757575762e-06] - Loss total: 2.601738929748535, Last rpr Loss: 0.9987058639526367, Last lagvar Loss: 0.8470598459243774\n",
      "Step 6262/10000- lr: [3.7737622787878786e-06] - Loss total: 2.6017048358917236, Last rpr Loss: 1.0014020204544067, Last lagvar Loss: 0.8443639278411865\n",
      "Step 6263/10000- lr: [3.772752181818182e-06] - Loss total: 2.601670980453491, Last rpr Loss: 0.998562753200531, Last lagvar Loss: 0.8472030758857727\n",
      "Step 6264/10000- lr: [3.7717420848484844e-06] - Loss total: 2.6016364097595215, Last rpr Loss: 1.001366376876831, Last lagvar Loss: 0.8443991541862488\n",
      "Step 6265/10000- lr: [3.7707319878787885e-06] - Loss total: 2.601602077484131, Last rpr Loss: 0.9987461566925049, Last lagvar Loss: 0.8470187783241272\n",
      "Step 6266/10000- lr: [3.769721890909091e-06] - Loss total: 2.601567506790161, Last rpr Loss: 1.00105619430542, Last lagvar Loss: 0.8447082042694092\n",
      "Step 6267/10000- lr: [3.768711793939394e-06] - Loss total: 2.601532459259033, Last rpr Loss: 0.9991463422775269, Last lagvar Loss: 0.8466174602508545\n",
      "Step 6268/10000- lr: [3.7677016969696966e-06] - Loss total: 2.601498603820801, Last rpr Loss: 1.0005934238433838, Last lagvar Loss: 0.8451698422431946\n",
      "Step 6269/10000- lr: [3.7666916000000007e-06] - Loss total: 2.601463556289673, Last rpr Loss: 0.9996368885040283, Last lagvar Loss: 0.8461259603500366\n",
      "Step 6270/10000- lr: [3.765681503030303e-06] - Loss total: 2.6014297008514404, Last rpr Loss: 1.0001018047332764, Last lagvar Loss: 0.8456606864929199\n",
      "Step 6271/10000- lr: [3.7646714060606064e-06] - Loss total: 2.60139536857605, Last rpr Loss: 1.0001089572906494, Last lagvar Loss: 0.8456535339355469\n",
      "Step 6272/10000- lr: [3.763661309090909e-06] - Loss total: 2.6013615131378174, Last rpr Loss: 0.999681293964386, Last lagvar Loss: 0.8460810780525208\n",
      "Step 6273/10000- lr: [3.762651212121212e-06] - Loss total: 2.601327657699585, Last rpr Loss: 1.0004661083221436, Last lagvar Loss: 0.8452962040901184\n",
      "Step 6274/10000- lr: [3.7616411151515146e-06] - Loss total: 2.6012938022613525, Last rpr Loss: 0.9993923306465149, Last lagvar Loss: 0.8463701009750366\n",
      "Step 6275/10000- lr: [3.7606310181818187e-06] - Loss total: 2.60125994682312, Last rpr Loss: 1.0006778240203857, Last lagvar Loss: 0.845084547996521\n",
      "Step 6276/10000- lr: [3.759620921212121e-06] - Loss total: 2.6012260913848877, Last rpr Loss: 0.9992542266845703, Last lagvar Loss: 0.8465079665184021\n",
      "Step 6277/10000- lr: [3.7586108242424244e-06] - Loss total: 2.601191759109497, Last rpr Loss: 1.00075101852417, Last lagvar Loss: 0.8450111150741577\n",
      "Step 6278/10000- lr: [3.757600727272727e-06] - Loss total: 2.6011576652526855, Last rpr Loss: 0.9992432594299316, Last lagvar Loss: 0.8465187549591064\n",
      "Step 6279/10000- lr: [3.756590630303031e-06] - Loss total: 2.6011242866516113, Last rpr Loss: 1.0007065534591675, Last lagvar Loss: 0.8450552225112915\n",
      "Step 6280/10000- lr: [3.7555805333333334e-06] - Loss total: 2.6010899543762207, Last rpr Loss: 0.9993369579315186, Last lagvar Loss: 0.8464245796203613\n",
      "Step 6281/10000- lr: [3.7545704363636367e-06] - Loss total: 2.6010560989379883, Last rpr Loss: 1.0005824565887451, Last lagvar Loss: 0.8451788425445557\n",
      "Step 6282/10000- lr: [3.753560339393939e-06] - Loss total: 2.6010220050811768, Last rpr Loss: 0.9994913935661316, Last lagvar Loss: 0.8462696075439453\n",
      "Step 6283/10000- lr: [3.7525502424242424e-06] - Loss total: 2.6009879112243652, Last rpr Loss: 1.0003986358642578, Last lagvar Loss: 0.84536212682724\n",
      "Step 6284/10000- lr: [3.751540145454545e-06] - Loss total: 2.6009538173675537, Last rpr Loss: 0.9996736645698547, Last lagvar Loss: 0.8460869789123535\n",
      "Step 6285/10000- lr: [3.750530048484849e-06] - Loss total: 2.6009204387664795, Last rpr Loss: 1.000214695930481, Last lagvar Loss: 0.8455456495285034\n",
      "Step 6286/10000- lr: [3.7495199515151514e-06] - Loss total: 2.600886583328247, Last rpr Loss: 0.9998616576194763, Last lagvar Loss: 0.8458985090255737\n",
      "Step 6287/10000- lr: [3.7485098545454546e-06] - Loss total: 2.6008527278900146, Last rpr Loss: 1.0000425577163696, Last lagvar Loss: 0.8457173705101013\n",
      "Step 6288/10000- lr: [3.747499757575757e-06] - Loss total: 2.6008191108703613, Last rpr Loss: 1.0000234842300415, Last lagvar Loss: 0.8457363843917847\n",
      "Step 6289/10000- lr: [3.746489660606061e-06] - Loss total: 2.600785255432129, Last rpr Loss: 0.9998937249183655, Last lagvar Loss: 0.8458659648895264\n",
      "Step 6290/10000- lr: [3.7454795636363636e-06] - Loss total: 2.6007513999938965, Last rpr Loss: 1.000150203704834, Last lagvar Loss: 0.8456094264984131\n",
      "Step 6291/10000- lr: [3.744469466666667e-06] - Loss total: 2.6007180213928223, Last rpr Loss: 0.9997801780700684, Last lagvar Loss: 0.8459792137145996\n",
      "Step 6292/10000- lr: [3.7434593696969693e-06] - Loss total: 2.600684404373169, Last rpr Loss: 1.0002514123916626, Last lagvar Loss: 0.8455078601837158\n",
      "Step 6293/10000- lr: [3.7424492727272726e-06] - Loss total: 2.6006507873535156, Last rpr Loss: 0.9997014403343201, Last lagvar Loss: 0.8460578322410583\n",
      "Step 6294/10000- lr: [3.741439175757575e-06] - Loss total: 2.600616693496704, Last rpr Loss: 1.0003130435943604, Last lagvar Loss: 0.845445990562439\n",
      "Step 6295/10000- lr: [3.740429078787879e-06] - Loss total: 2.60058331489563, Last rpr Loss: 0.9996504187583923, Last lagvar Loss: 0.8461085557937622\n",
      "Step 6296/10000- lr: [3.7394189818181816e-06] - Loss total: 2.6005494594573975, Last rpr Loss: 1.0003471374511719, Last lagvar Loss: 0.8454116582870483\n",
      "Step 6297/10000- lr: [3.738408884848485e-06] - Loss total: 2.6005163192749023, Last rpr Loss: 0.9996331334114075, Last lagvar Loss: 0.8461255431175232\n",
      "Step 6298/10000- lr: [3.7373987878787873e-06] - Loss total: 2.600482702255249, Last rpr Loss: 1.0003552436828613, Last lagvar Loss: 0.8454033136367798\n",
      "Step 6299/10000- lr: [3.7363886909090914e-06] - Loss total: 2.6004490852355957, Last rpr Loss: 0.9996294975280762, Last lagvar Loss: 0.8461289405822754\n",
      "Step 6300/10000- lr: [3.735378593939394e-06] - Loss total: 2.6004154682159424, Last rpr Loss: 1.0003552436828613, Last lagvar Loss: 0.8454030156135559\n",
      "Step 6301/10000- lr: [3.734368496969697e-06] - Loss total: 2.600382089614868, Last rpr Loss: 0.9996330738067627, Last lagvar Loss: 0.8461250066757202\n",
      "Step 6302/10000- lr: [3.7333583999999996e-06] - Loss total: 2.600348711013794, Last rpr Loss: 1.000352382659912, Last lagvar Loss: 0.8454055786132812\n",
      "Step 6303/10000- lr: [3.732348303030303e-06] - Loss total: 2.6003150939941406, Last rpr Loss: 0.9996358752250671, Last lagvar Loss: 0.8461219668388367\n",
      "Step 6304/10000- lr: [3.7313382060606053e-06] - Loss total: 2.6002814769744873, Last rpr Loss: 1.000349998474121, Last lagvar Loss: 0.8454077243804932\n",
      "Step 6305/10000- lr: [3.7303281090909094e-06] - Loss total: 2.600248098373413, Last rpr Loss: 0.9996405839920044, Last lagvar Loss: 0.8461169600486755\n",
      "Step 6306/10000- lr: [3.729318012121212e-06] - Loss total: 2.600214719772339, Last rpr Loss: 1.0003433227539062, Last lagvar Loss: 0.8454141616821289\n",
      "Step 6307/10000- lr: [3.728307915151515e-06] - Loss total: 2.6001813411712646, Last rpr Loss: 0.9996438026428223, Last lagvar Loss: 0.8461135029792786\n",
      "Step 6308/10000- lr: [3.7272978181818175e-06] - Loss total: 2.6001479625701904, Last rpr Loss: 1.0003411769866943, Last lagvar Loss: 0.8454158306121826\n",
      "Step 6309/10000- lr: [3.7262877212121217e-06] - Loss total: 2.600114583969116, Last rpr Loss: 0.9996433258056641, Last lagvar Loss: 0.8461136817932129\n",
      "Step 6310/10000- lr: [3.725277624242424e-06] - Loss total: 2.600080966949463, Last rpr Loss: 1.0003451108932495, Last lagvar Loss: 0.8454117774963379\n",
      "Step 6311/10000- lr: [3.7242675272727274e-06] - Loss total: 2.6000475883483887, Last rpr Loss: 0.9996336698532104, Last lagvar Loss: 0.8461230993270874\n",
      "Step 6312/10000- lr: [3.72325743030303e-06] - Loss total: 2.6000144481658936, Last rpr Loss: 1.0003650188446045, Last lagvar Loss: 0.8453914523124695\n",
      "Step 6313/10000- lr: [3.722247333333333e-06] - Loss total: 2.5999810695648193, Last rpr Loss: 0.9996085166931152, Last lagvar Loss: 0.8461479544639587\n",
      "Step 6314/10000- lr: [3.7212372363636355e-06] - Loss total: 2.5999481678009033, Last rpr Loss: 1.000397801399231, Last lagvar Loss: 0.8453584909439087\n",
      "Step 6315/10000- lr: [3.7202271393939396e-06] - Loss total: 2.599914789199829, Last rpr Loss: 0.9995675086975098, Last lagvar Loss: 0.8461887836456299\n",
      "Step 6316/10000- lr: [3.719217042424242e-06] - Loss total: 2.599881649017334, Last rpr Loss: 1.0004477500915527, Last lagvar Loss: 0.8453084230422974\n",
      "Step 6317/10000- lr: [3.7182069454545453e-06] - Loss total: 2.599848508834839, Last rpr Loss: 0.999509334564209, Last lagvar Loss: 0.8462466597557068\n",
      "Step 6318/10000- lr: [3.7171968484848478e-06] - Loss total: 2.5998151302337646, Last rpr Loss: 1.0005121231079102, Last lagvar Loss: 0.8452436923980713\n",
      "Step 6319/10000- lr: [3.716186751515152e-06] - Loss total: 2.5997819900512695, Last rpr Loss: 0.9994252920150757, Last lagvar Loss: 0.8463305234909058\n",
      "Step 6320/10000- lr: [3.7151766545454543e-06] - Loss total: 2.5997488498687744, Last rpr Loss: 1.0006139278411865, Last lagvar Loss: 0.8451417684555054\n",
      "Step 6321/10000- lr: [3.7141665575757576e-06] - Loss total: 2.5997157096862793, Last rpr Loss: 0.9993107318878174, Last lagvar Loss: 0.8464450836181641\n",
      "Step 6322/10000- lr: [3.71315646060606e-06] - Loss total: 2.5996828079223633, Last rpr Loss: 1.0007508993148804, Last lagvar Loss: 0.8450048565864563\n",
      "Step 6323/10000- lr: [3.7121463636363633e-06] - Loss total: 2.5996499061584473, Last rpr Loss: 0.9991553425788879, Last lagvar Loss: 0.8466004133224487\n",
      "Step 6324/10000- lr: [3.7111362666666657e-06] - Loss total: 2.5996170043945312, Last rpr Loss: 1.0009334087371826, Last lagvar Loss: 0.8448224067687988\n",
      "Step 6325/10000- lr: [3.71012616969697e-06] - Loss total: 2.599583864212036, Last rpr Loss: 0.9989379644393921, Last lagvar Loss: 0.8468178510665894\n",
      "Step 6326/10000- lr: [3.7091160727272723e-06] - Loss total: 2.5995514392852783, Last rpr Loss: 1.0011811256408691, Last lagvar Loss: 0.8445749282836914\n",
      "Step 6327/10000- lr: [3.7081059757575756e-06] - Loss total: 2.5995187759399414, Last rpr Loss: 0.9986462593078613, Last lagvar Loss: 0.8471101522445679\n",
      "Step 6328/10000- lr: [3.707095878787878e-06] - Loss total: 2.5994861125946045, Last rpr Loss: 1.0015230178833008, Last lagvar Loss: 0.8442337512969971\n",
      "Step 6329/10000- lr: [3.706085781818182e-06] - Loss total: 2.599453926086426, Last rpr Loss: 0.9982494115829468, Last lagvar Loss: 0.8475080728530884\n",
      "Step 6330/10000- lr: [3.7050756848484854e-06] - Loss total: 2.599421739578247, Last rpr Loss: 1.001990795135498, Last lagvar Loss: 0.843767523765564\n",
      "Step 6331/10000- lr: [3.704065587878788e-06] - Loss total: 2.5993900299072266, Last rpr Loss: 0.9977000951766968, Last lagvar Loss: 0.8480594754219055\n",
      "Step 6332/10000- lr: [3.703055490909091e-06] - Loss total: 2.5993590354919434, Last rpr Loss: 1.002641201019287, Last lagvar Loss: 0.8431201577186584\n",
      "Step 6333/10000- lr: [3.7020453939393935e-06] - Loss total: 2.5993282794952393, Last rpr Loss: 0.9969233274459839, Last lagvar Loss: 0.8488403558731079\n",
      "Step 6334/10000- lr: [3.7010352969696977e-06] - Loss total: 2.5992987155914307, Last rpr Loss: 1.0035653114318848, Last lagvar Loss: 0.842201828956604\n",
      "Step 6335/10000- lr: [3.7000252e-06] - Loss total: 2.5992705821990967, Last rpr Loss: 0.9958312511444092, Last lagvar Loss: 0.8499407172203064\n",
      "Step 6336/10000- lr: [3.6990151030303034e-06] - Loss total: 2.599243640899658, Last rpr Loss: 1.0048643350601196, Last lagvar Loss: 0.8409141898155212\n",
      "Step 6337/10000- lr: [3.698005006060606e-06] - Loss total: 2.5992202758789062, Last rpr Loss: 0.9942770004272461, Last lagvar Loss: 0.8515112996101379\n",
      "Step 6338/10000- lr: [3.69699490909091e-06] - Loss total: 2.5991992950439453, Last rpr Loss: 1.0067219734191895, Last lagvar Loss: 0.8390789031982422\n",
      "Step 6339/10000- lr: [3.6959848121212123e-06] - Loss total: 2.5991857051849365, Last rpr Loss: 0.9920623898506165, Last lagvar Loss: 0.8537583947181702\n",
      "Step 6340/10000- lr: [3.6949747151515156e-06] - Loss total: 2.5991756916046143, Last rpr Loss: 1.0093555450439453, Last lagvar Loss: 0.8364896178245544\n",
      "Step 6341/10000- lr: [3.693964618181818e-06] - Loss total: 2.5991809368133545, Last rpr Loss: 0.9889353513717651, Last lagvar Loss: 0.8569499850273132\n",
      "Step 6342/10000- lr: [3.6929545212121213e-06] - Loss total: 2.5991909503936768, Last rpr Loss: 1.013047218322754, Last lagvar Loss: 0.832883358001709\n",
      "Step 6343/10000- lr: [3.6919444242424238e-06] - Loss total: 2.599233865737915, Last rpr Loss: 0.9846171140670776, Last lagvar Loss: 0.8613933324813843\n",
      "Step 6344/10000- lr: [3.690934327272728e-06] - Loss total: 2.599275827407837, Last rpr Loss: 1.0180344581604004, Last lagvar Loss: 0.8280548453330994\n",
      "Step 6345/10000- lr: [3.6899242303030303e-06] - Loss total: 2.5993831157684326, Last rpr Loss: 0.9789680242538452, Last lagvar Loss: 0.8672699928283691\n",
      "Step 6346/10000- lr: [3.6889141333333336e-06] - Loss total: 2.599459648132324, Last rpr Loss: 1.024221420288086, Last lagvar Loss: 0.8221308588981628\n",
      "Step 6347/10000- lr: [3.687904036363636e-06] - Loss total: 2.599648952484131, Last rpr Loss: 0.9724670052528381, Last lagvar Loss: 0.8741220235824585\n",
      "Step 6348/10000- lr: [3.68689393939394e-06] - Loss total: 2.599710702896118, Last rpr Loss: 1.0304771661758423, Last lagvar Loss: 0.8162086009979248\n",
      "Step 6349/10000- lr: [3.6858838424242426e-06] - Loss total: 2.599919319152832, Last rpr Loss: 0.9671320915222168, Last lagvar Loss: 0.8798117637634277\n",
      "Step 6350/10000- lr: [3.684873745454546e-06] - Loss total: 2.599828004837036, Last rpr Loss: 1.0337207317352295, Last lagvar Loss: 0.8131555318832397\n",
      "Step 6351/10000- lr: [3.6838636484848483e-06] - Loss total: 2.5996787548065186, Last rpr Loss: 0.9696041941642761, Last lagvar Loss: 0.8771530389785767\n",
      "Step 6352/10000- lr: [3.6828535515151516e-06] - Loss total: 2.599292516708374, Last rpr Loss: 1.0251922607421875, Last lagvar Loss: 0.8211864233016968\n",
      "Step 6353/10000- lr: [3.681843454545454e-06] - Loss total: 2.5990076065063477, Last rpr Loss: 0.9815678596496582, Last lagvar Loss: 0.8645458221435547\n",
      "Step 6354/10000- lr: [3.680833357575758e-06] - Loss total: 2.5987484455108643, Last rpr Loss: 1.0109745264053345, Last lagvar Loss: 0.8348985910415649\n",
      "Step 6355/10000- lr: [3.6798232606060605e-06] - Loss total: 2.5986123085021973, Last rpr Loss: 0.997098982334137, Last lagvar Loss: 0.848663330078125\n",
      "Step 6356/10000- lr: [3.678813163636364e-06] - Loss total: 2.5985894203186035, Last rpr Loss: 0.9957482814788818, Last lagvar Loss: 0.8500229120254517\n",
      "Step 6357/10000- lr: [3.6778030666666663e-06] - Loss total: 2.598644971847534, Last rpr Loss: 1.0105347633361816, Last lagvar Loss: 0.8353303670883179\n",
      "Step 6358/10000- lr: [3.6767929696969704e-06] - Loss total: 2.598736047744751, Last rpr Loss: 0.9847753047943115, Last lagvar Loss: 0.8612165451049805\n",
      "Step 6359/10000- lr: [3.675782872727273e-06] - Loss total: 2.598780870437622, Last rpr Loss: 1.0178805589675903, Last lagvar Loss: 0.8281949758529663\n",
      "Step 6360/10000- lr: [3.674772775757576e-06] - Loss total: 2.598801851272583, Last rpr Loss: 0.981109619140625, Last lagvar Loss: 0.865019679069519\n",
      "Step 6361/10000- lr: [3.6737626787878785e-06] - Loss total: 2.598712921142578, Last rpr Loss: 1.0177500247955322, Last lagvar Loss: 0.8283193707466125\n",
      "Step 6362/10000- lr: [3.672752581818182e-06] - Loss total: 2.5986075401306152, Last rpr Loss: 0.9849755764007568, Last lagvar Loss: 0.8610159158706665\n",
      "Step 6363/10000- lr: [3.6717424848484842e-06] - Loss total: 2.5984654426574707, Last rpr Loss: 1.0111186504364014, Last lagvar Loss: 0.8347561359405518\n",
      "Step 6364/10000- lr: [3.6707323878787883e-06] - Loss total: 2.598353862762451, Last rpr Loss: 0.993749737739563, Last lagvar Loss: 0.8520412445068359\n",
      "Step 6365/10000- lr: [3.6697222909090908e-06] - Loss total: 2.59828519821167, Last rpr Loss: 1.0013062953948975, Last lagvar Loss: 0.8444460034370422\n",
      "Step 6366/10000- lr: [3.668712193939394e-06] - Loss total: 2.5982632637023926, Last rpr Loss: 1.0032845735549927, Last lagvar Loss: 0.8424777984619141\n",
      "Step 6367/10000- lr: [3.6677020969696965e-06] - Loss total: 2.598271131515503, Last rpr Loss: 0.9927297830581665, Last lagvar Loss: 0.8530735969543457\n",
      "Step 6368/10000- lr: [3.6666920000000006e-06] - Loss total: 2.5982823371887207, Last rpr Loss: 1.0098555088043213, Last lagvar Loss: 0.8359950184822083\n",
      "Step 6369/10000- lr: [3.665681903030303e-06] - Loss total: 2.598283052444458, Last rpr Loss: 0.9886473417282104, Last lagvar Loss: 0.8572342991828918\n",
      "Step 6370/10000- lr: [3.6646718060606063e-06] - Loss total: 2.5982484817504883, Last rpr Loss: 1.0114158391952515, Last lagvar Loss: 0.834465503692627\n",
      "Step 6371/10000- lr: [3.6636617090909087e-06] - Loss total: 2.5981969833374023, Last rpr Loss: 0.9897950291633606, Last lagvar Loss: 0.856062650680542\n",
      "Step 6372/10000- lr: [3.662651612121212e-06] - Loss total: 2.5981247425079346, Last rpr Loss: 1.0081382989883423, Last lagvar Loss: 0.8376783132553101\n",
      "Step 6373/10000- lr: [3.6616415151515144e-06] - Loss total: 2.598057985305786, Last rpr Loss: 0.9946948289871216, Last lagvar Loss: 0.8510837554931641\n",
      "Step 6374/10000- lr: [3.6606314181818186e-06] - Loss total: 2.5980031490325928, Last rpr Loss: 1.0022995471954346, Last lagvar Loss: 0.8434547781944275\n",
      "Step 6375/10000- lr: [3.659621321212121e-06] - Loss total: 2.597966432571411, Last rpr Loss: 1.0006499290466309, Last lagvar Loss: 0.8450990915298462\n",
      "Step 6376/10000- lr: [3.6586112242424243e-06] - Loss total: 2.597944736480713, Last rpr Loss: 0.996707558631897, Last lagvar Loss: 0.8490520119667053\n",
      "Step 6377/10000- lr: [3.6576011272727267e-06] - Loss total: 2.5979299545288086, Last rpr Loss: 1.0052170753479004, Last lagvar Loss: 0.8405603766441345\n",
      "Step 6378/10000- lr: [3.656591030303031e-06] - Loss total: 2.597913980484009, Last rpr Loss: 0.9934089183807373, Last lagvar Loss: 0.8523840308189392\n",
      "Step 6379/10000- lr: [3.6555809333333333e-06] - Loss total: 2.5978879928588867, Last rpr Loss: 1.0070464611053467, Last lagvar Loss: 0.8387535214424133\n",
      "Step 6380/10000- lr: [3.6545708363636365e-06] - Loss total: 2.597853899002075, Last rpr Loss: 0.9931749105453491, Last lagvar Loss: 0.8526211977005005\n",
      "Step 6381/10000- lr: [3.653560739393939e-06] - Loss total: 2.5978100299835205, Last rpr Loss: 1.0059694051742554, Last lagvar Loss: 0.839815080165863\n",
      "Step 6382/10000- lr: [3.6525506424242422e-06] - Loss total: 2.597764253616333, Last rpr Loss: 0.9954816102981567, Last lagvar Loss: 0.8502872586250305\n",
      "Step 6383/10000- lr: [3.6515405454545447e-06] - Loss total: 2.5977206230163574, Last rpr Loss: 1.0028553009033203, Last lagvar Loss: 0.8429009914398193\n",
      "Step 6384/10000- lr: [3.650530448484849e-06] - Loss total: 2.597682237625122, Last rpr Loss: 0.9989587664604187, Last lagvar Loss: 0.8467898964881897\n",
      "Step 6385/10000- lr: [3.6495203515151512e-06] - Loss total: 2.5976500511169434, Last rpr Loss: 0.9992753863334656, Last lagvar Loss: 0.8464726209640503\n",
      "Step 6386/10000- lr: [3.6485102545454545e-06] - Loss total: 2.5976226329803467, Last rpr Loss: 1.0021564960479736, Last lagvar Loss: 0.8435957431793213\n",
      "Step 6387/10000- lr: [3.647500157575757e-06] - Loss total: 2.597597122192383, Last rpr Loss: 0.9966651201248169, Last lagvar Loss: 0.8490934371948242\n",
      "Step 6388/10000- lr: [3.646490060606061e-06] - Loss total: 2.5975708961486816, Last rpr Loss: 1.0040146112442017, Last lagvar Loss: 0.8417491912841797\n",
      "Step 6389/10000- lr: [3.6454799636363635e-06] - Loss total: 2.597541570663452, Last rpr Loss: 0.9957115650177002, Last lagvar Loss: 0.8500544428825378\n",
      "Step 6390/10000- lr: [3.6444698666666668e-06] - Loss total: 2.5975089073181152, Last rpr Loss: 1.004178762435913, Last lagvar Loss: 0.8415861129760742\n",
      "Step 6391/10000- lr: [3.643459769696969e-06] - Loss total: 2.597473621368408, Last rpr Loss: 0.9963191747665405, Last lagvar Loss: 0.849441647529602\n",
      "Step 6392/10000- lr: [3.6424496727272725e-06] - Loss total: 2.5974371433258057, Last rpr Loss: 1.0029592514038086, Last lagvar Loss: 0.8427964448928833\n",
      "Step 6393/10000- lr: [3.641439575757575e-06] - Loss total: 2.5974013805389404, Last rpr Loss: 0.9979665279388428, Last lagvar Loss: 0.847784161567688\n",
      "Step 6394/10000- lr: [3.640429478787879e-06] - Loss total: 2.5973665714263916, Last rpr Loss: 1.0010101795196533, Last lagvar Loss: 0.8447372913360596\n",
      "Step 6395/10000- lr: [3.6394193818181815e-06] - Loss total: 2.597334146499634, Last rpr Loss: 0.9999316930770874, Last lagvar Loss: 0.84581458568573\n",
      "Step 6396/10000- lr: [3.6384092848484847e-06] - Loss total: 2.5973031520843506, Last rpr Loss: 0.9991145730018616, Last lagvar Loss: 0.8466324210166931\n",
      "Step 6397/10000- lr: [3.637399187878787e-06] - Loss total: 2.597273826599121, Last rpr Loss: 1.001579999923706, Last lagvar Loss: 0.8441686630249023\n",
      "Step 6398/10000- lr: [3.6363890909090913e-06] - Loss total: 2.5972442626953125, Last rpr Loss: 0.9978469014167786, Last lagvar Loss: 0.8479037284851074\n",
      "Step 6399/10000- lr: [3.6353789939393937e-06] - Loss total: 2.5972139835357666, Last rpr Loss: 1.0024561882019043, Last lagvar Loss: 0.8432959318161011\n",
      "Step 6400/10000- lr: [3.634368896969697e-06] - Loss total: 2.5971834659576416, Last rpr Loss: 0.9974573850631714, Last lagvar Loss: 0.8482949137687683\n",
      "Step 6401/10000- lr: [3.6333587999999994e-06] - Loss total: 2.597151279449463, Last rpr Loss: 1.0024465322494507, Last lagvar Loss: 0.8433052897453308\n",
      "Step 6402/10000- lr: [3.6323487030303027e-06] - Loss total: 2.597118377685547, Last rpr Loss: 0.9978359937667847, Last lagvar Loss: 0.8479143381118774\n",
      "Step 6403/10000- lr: [3.631338606060605e-06] - Loss total: 2.597085475921631, Last rpr Loss: 1.0017673969268799, Last lagvar Loss: 0.8439812660217285\n",
      "Step 6404/10000- lr: [3.6303285090909093e-06] - Loss total: 2.597052574157715, Last rpr Loss: 0.9987105131149292, Last lagvar Loss: 0.8470364809036255\n",
      "Step 6405/10000- lr: [3.6293184121212117e-06] - Loss total: 2.597020149230957, Last rpr Loss: 1.0007506608963013, Last lagvar Loss: 0.8449951410293579\n",
      "Step 6406/10000- lr: [3.628308315151515e-06] - Loss total: 2.5969879627227783, Last rpr Loss: 0.9997552633285522, Last lagvar Loss: 0.8459897637367249\n",
      "Step 6407/10000- lr: [3.6272982181818174e-06] - Loss total: 2.596956729888916, Last rpr Loss: 0.9997348785400391, Last lagvar Loss: 0.8460102081298828\n",
      "Step 6408/10000- lr: [3.6262881212121215e-06] - Loss total: 2.596925735473633, Last rpr Loss: 1.000672698020935, Last lagvar Loss: 0.8450727462768555\n",
      "Step 6409/10000- lr: [3.625278024242424e-06] - Loss total: 2.5968945026397705, Last rpr Loss: 0.9989736080169678, Last lagvar Loss: 0.846772313117981\n",
      "Step 6410/10000- lr: [3.6242679272727272e-06] - Loss total: 2.5968637466430664, Last rpr Loss: 1.0012558698654175, Last lagvar Loss: 0.8444905281066895\n",
      "Step 6411/10000- lr: [3.6232578303030297e-06] - Loss total: 2.596832752227783, Last rpr Loss: 0.9986040592193604, Last lagvar Loss: 0.8471424579620361\n",
      "Step 6412/10000- lr: [3.622247733333333e-06] - Loss total: 2.596801519393921, Last rpr Loss: 1.001427173614502, Last lagvar Loss: 0.8443195223808289\n",
      "Step 6413/10000- lr: [3.6212376363636354e-06] - Loss total: 2.5967698097229004, Last rpr Loss: 0.9986147284507751, Last lagvar Loss: 0.847131609916687\n",
      "Step 6414/10000- lr: [3.6202275393939395e-06] - Loss total: 2.59673810005188, Last rpr Loss: 1.0012404918670654, Last lagvar Loss: 0.8445054292678833\n",
      "Step 6415/10000- lr: [3.6192174424242428e-06] - Loss total: 2.5967063903808594, Last rpr Loss: 0.9989268183708191, Last lagvar Loss: 0.8468185663223267\n",
      "Step 6416/10000- lr: [3.618207345454545e-06] - Loss total: 2.5966744422912598, Last rpr Loss: 1.0008375644683838, Last lagvar Loss: 0.8449072241783142\n",
      "Step 6417/10000- lr: [3.6171972484848493e-06] - Loss total: 2.59664249420166, Last rpr Loss: 0.9993947148323059, Last lagvar Loss: 0.8463496565818787\n",
      "Step 6418/10000- lr: [3.6161871515151518e-06] - Loss total: 2.5966110229492188, Last rpr Loss: 1.0003412961959839, Last lagvar Loss: 0.845402717590332\n",
      "Step 6419/10000- lr: [3.615177054545455e-06] - Loss total: 2.5965793132781982, Last rpr Loss: 0.9998975992202759, Last lagvar Loss: 0.8458461761474609\n",
      "Step 6420/10000- lr: [3.6141669575757575e-06] - Loss total: 2.596548080444336, Last rpr Loss: 0.9998619556427002, Last lagvar Loss: 0.8458818197250366\n",
      "Step 6421/10000- lr: [3.6131568606060607e-06] - Loss total: 2.5965166091918945, Last rpr Loss: 1.000322699546814, Last lagvar Loss: 0.8454209566116333\n",
      "Step 6422/10000- lr: [3.612146763636363e-06] - Loss total: 2.596485137939453, Last rpr Loss: 0.9994987845420837, Last lagvar Loss: 0.8462449312210083\n",
      "Step 6423/10000- lr: [3.6111366666666673e-06] - Loss total: 2.596453905105591, Last rpr Loss: 1.0006098747253418, Last lagvar Loss: 0.8451338410377502\n",
      "Step 6424/10000- lr: [3.6101265696969697e-06] - Loss total: 2.5964226722717285, Last rpr Loss: 0.9992917776107788, Last lagvar Loss: 0.846451997756958\n",
      "Step 6425/10000- lr: [3.609116472727273e-06] - Loss total: 2.596391439437866, Last rpr Loss: 1.0007405281066895, Last lagvar Loss: 0.8450033068656921\n",
      "Step 6426/10000- lr: [3.6081063757575754e-06] - Loss total: 2.596360206604004, Last rpr Loss: 0.9992401599884033, Last lagvar Loss: 0.8465036153793335\n",
      "Step 6427/10000- lr: [3.6070962787878796e-06] - Loss total: 2.5963284969329834, Last rpr Loss: 1.000730276107788, Last lagvar Loss: 0.8450132608413696\n",
      "Step 6428/10000- lr: [3.606086181818182e-06] - Loss total: 2.5962975025177, Last rpr Loss: 0.9993075728416443, Last lagvar Loss: 0.8464359045028687\n",
      "Step 6429/10000- lr: [3.6050760848484853e-06] - Loss total: 2.5962655544281006, Last rpr Loss: 1.0006208419799805, Last lagvar Loss: 0.8451225757598877\n",
      "Step 6430/10000- lr: [3.6040659878787877e-06] - Loss total: 2.596234083175659, Last rpr Loss: 0.9994515776634216, Last lagvar Loss: 0.8462914824485779\n",
      "Step 6431/10000- lr: [3.603055890909091e-06] - Loss total: 2.5962026119232178, Last rpr Loss: 1.0004408359527588, Last lagvar Loss: 0.8453022241592407\n",
      "Step 6432/10000- lr: [3.6020457939393934e-06] - Loss total: 2.5961711406707764, Last rpr Loss: 0.9996467232704163, Last lagvar Loss: 0.8460960388183594\n",
      "Step 6433/10000- lr: [3.6010356969696975e-06] - Loss total: 2.596139669418335, Last rpr Loss: 1.000235915184021, Last lagvar Loss: 0.8455065488815308\n",
      "Step 6434/10000- lr: [3.6000256e-06] - Loss total: 2.5961081981658936, Last rpr Loss: 0.9998478889465332, Last lagvar Loss: 0.8458945751190186\n",
      "Step 6435/10000- lr: [3.5990155030303032e-06] - Loss total: 2.5960769653320312, Last rpr Loss: 1.0000405311584473, Last lagvar Loss: 0.8457016944885254\n",
      "Step 6436/10000- lr: [3.5980054060606057e-06] - Loss total: 2.59604549407959, Last rpr Loss: 1.000040054321289, Last lagvar Loss: 0.8457021713256836\n",
      "Step 6437/10000- lr: [3.5969953090909098e-06] - Loss total: 2.5960137844085693, Last rpr Loss: 0.999879002571106, Last lagvar Loss: 0.8458631634712219\n",
      "Step 6438/10000- lr: [3.5959852121212122e-06] - Loss total: 2.595982789993286, Last rpr Loss: 1.0001745223999023, Last lagvar Loss: 0.8455674648284912\n",
      "Step 6439/10000- lr: [3.5949751151515155e-06] - Loss total: 2.5959510803222656, Last rpr Loss: 0.9997613430023193, Last lagvar Loss: 0.8459806442260742\n",
      "Step 6440/10000- lr: [3.593965018181818e-06] - Loss total: 2.5959198474884033, Last rpr Loss: 1.0002758502960205, Last lagvar Loss: 0.845466136932373\n",
      "Step 6441/10000- lr: [3.592954921212121e-06] - Loss total: 2.59588885307312, Last rpr Loss: 0.999674379825592, Last lagvar Loss: 0.846067488193512\n",
      "Step 6442/10000- lr: [3.5919448242424236e-06] - Loss total: 2.5958571434020996, Last rpr Loss: 1.0003407001495361, Last lagvar Loss: 0.8454010486602783\n",
      "Step 6443/10000- lr: [3.5909347272727278e-06] - Loss total: 2.5958261489868164, Last rpr Loss: 0.9996294975280762, Last lagvar Loss: 0.8461121916770935\n",
      "Step 6444/10000- lr: [3.58992463030303e-06] - Loss total: 2.595794439315796, Last rpr Loss: 1.0003676414489746, Last lagvar Loss: 0.8453739881515503\n",
      "Step 6445/10000- lr: [3.5889145333333335e-06] - Loss total: 2.5957634449005127, Last rpr Loss: 0.9996224641799927, Last lagvar Loss: 0.8461189866065979\n",
      "Step 6446/10000- lr: [3.587904436363636e-06] - Loss total: 2.5957322120666504, Last rpr Loss: 1.0003639459609985, Last lagvar Loss: 0.8453774452209473\n",
      "Step 6447/10000- lr: [3.58689433939394e-06] - Loss total: 2.595700979232788, Last rpr Loss: 0.9996371269226074, Last lagvar Loss: 0.8461042642593384\n",
      "Step 6448/10000- lr: [3.5858842424242424e-06] - Loss total: 2.5956695079803467, Last rpr Loss: 1.0003405809402466, Last lagvar Loss: 0.8454005718231201\n",
      "Step 6449/10000- lr: [3.5848741454545457e-06] - Loss total: 2.5956380367279053, Last rpr Loss: 0.9996670484542847, Last lagvar Loss: 0.8460739850997925\n",
      "Step 6450/10000- lr: [3.583864048484848e-06] - Loss total: 2.595607042312622, Last rpr Loss: 1.0003033876419067, Last lagvar Loss: 0.8454376459121704\n",
      "Step 6451/10000- lr: [3.5828539515151514e-06] - Loss total: 2.5955755710601807, Last rpr Loss: 0.9997049570083618, Last lagvar Loss: 0.8460358381271362\n",
      "Step 6452/10000- lr: [3.581843854545454e-06] - Loss total: 2.5955445766448975, Last rpr Loss: 1.000267744064331, Last lagvar Loss: 0.8454729318618774\n",
      "Step 6453/10000- lr: [3.580833757575758e-06] - Loss total: 2.595513343811035, Last rpr Loss: 0.9997415542602539, Last lagvar Loss: 0.8459990620613098\n",
      "Step 6454/10000- lr: [3.5798236606060604e-06] - Loss total: 2.595482110977173, Last rpr Loss: 1.0002297163009644, Last lagvar Loss: 0.8455107808113098\n",
      "Step 6455/10000- lr: [3.5788135636363637e-06] - Loss total: 2.5954508781433105, Last rpr Loss: 0.9997849464416504, Last lagvar Loss: 0.8459555506706238\n",
      "Step 6456/10000- lr: [3.577803466666666e-06] - Loss total: 2.5954198837280273, Last rpr Loss: 1.0001908540725708, Last lagvar Loss: 0.8455495834350586\n",
      "Step 6457/10000- lr: [3.5767933696969702e-06] - Loss total: 2.595388650894165, Last rpr Loss: 0.9998120069503784, Last lagvar Loss: 0.8459283113479614\n",
      "Step 6458/10000- lr: [3.5757832727272727e-06] - Loss total: 2.5953571796417236, Last rpr Loss: 1.0001615285873413, Last lagvar Loss: 0.8455785512924194\n",
      "Step 6459/10000- lr: [3.574773175757576e-06] - Loss total: 2.5953266620635986, Last rpr Loss: 0.9998453855514526, Last lagvar Loss: 0.8458945751190186\n",
      "Step 6460/10000- lr: [3.5737630787878784e-06] - Loss total: 2.5952954292297363, Last rpr Loss: 1.0001384019851685, Last lagvar Loss: 0.845601499080658\n",
      "Step 6461/10000- lr: [3.5727529818181817e-06] - Loss total: 2.595264196395874, Last rpr Loss: 0.9998579621315002, Last lagvar Loss: 0.8458818793296814\n",
      "Step 6462/10000- lr: [3.571742884848484e-06] - Loss total: 2.595233201980591, Last rpr Loss: 1.0001306533813477, Last lagvar Loss: 0.8456090092658997\n",
      "Step 6463/10000- lr: [3.570732787878788e-06] - Loss total: 2.5952024459838867, Last rpr Loss: 0.9998671412467957, Last lagvar Loss: 0.8458724617958069\n",
      "Step 6464/10000- lr: [3.5697226909090906e-06] - Loss total: 2.5951714515686035, Last rpr Loss: 1.000121831893921, Last lagvar Loss: 0.8456175923347473\n",
      "Step 6465/10000- lr: [3.568712593939394e-06] - Loss total: 2.5951404571533203, Last rpr Loss: 0.9998734593391418, Last lagvar Loss: 0.8458658456802368\n",
      "Step 6466/10000- lr: [3.5677024969696963e-06] - Loss total: 2.595109701156616, Last rpr Loss: 1.000123381614685, Last lagvar Loss: 0.8456159830093384\n",
      "Step 6467/10000- lr: [3.5666924000000005e-06] - Loss total: 2.595078706741333, Last rpr Loss: 0.999863862991333, Last lagvar Loss: 0.8458753228187561\n",
      "Step 6468/10000- lr: [3.565682303030303e-06] - Loss total: 2.595048189163208, Last rpr Loss: 1.000133752822876, Last lagvar Loss: 0.8456051349639893\n",
      "Step 6469/10000- lr: [3.564672206060606e-06] - Loss total: 2.5950167179107666, Last rpr Loss: 0.999847412109375, Last lagvar Loss: 0.8458915948867798\n",
      "Step 6470/10000- lr: [3.5636621090909086e-06] - Loss total: 2.5949862003326416, Last rpr Loss: 1.0001519918441772, Last lagvar Loss: 0.8455868363380432\n",
      "Step 6471/10000- lr: [3.562652012121212e-06] - Loss total: 2.5949554443359375, Last rpr Loss: 0.9998340606689453, Last lagvar Loss: 0.8459047079086304\n",
      "Step 6472/10000- lr: [3.5616419151515143e-06] - Loss total: 2.5949249267578125, Last rpr Loss: 1.0001733303070068, Last lagvar Loss: 0.8455653190612793\n",
      "Step 6473/10000- lr: [3.5606318181818184e-06] - Loss total: 2.59489369392395, Last rpr Loss: 0.9998095035552979, Last lagvar Loss: 0.8459290266036987\n",
      "Step 6474/10000- lr: [3.559621721212121e-06] - Loss total: 2.594863176345825, Last rpr Loss: 1.000197172164917, Last lagvar Loss: 0.8455413579940796\n",
      "Step 6475/10000- lr: [3.558611624242424e-06] - Loss total: 2.5948326587677, Last rpr Loss: 0.999779462814331, Last lagvar Loss: 0.8459588289260864\n",
      "Step 6476/10000- lr: [3.5576015272727266e-06] - Loss total: 2.594802141189575, Last rpr Loss: 1.000234603881836, Last lagvar Loss: 0.845503568649292\n",
      "Step 6477/10000- lr: [3.5565914303030307e-06] - Loss total: 2.59477162361145, Last rpr Loss: 0.9997303485870361, Last lagvar Loss: 0.846007764339447\n",
      "Step 6478/10000- lr: [3.555581333333333e-06] - Loss total: 2.594740867614746, Last rpr Loss: 1.0002896785736084, Last lagvar Loss: 0.84544837474823\n",
      "Step 6479/10000- lr: [3.5545712363636364e-06] - Loss total: 2.594710111618042, Last rpr Loss: 0.999671220779419, Last lagvar Loss: 0.8460667729377747\n",
      "Step 6480/10000- lr: [3.553561139393939e-06] - Loss total: 2.594679832458496, Last rpr Loss: 1.000362515449524, Last lagvar Loss: 0.8453752994537354\n",
      "Step 6481/10000- lr: [3.552551042424242e-06] - Loss total: 2.594649076461792, Last rpr Loss: 0.9995896816253662, Last lagvar Loss: 0.8461481928825378\n",
      "Step 6482/10000- lr: [3.5515409454545445e-06] - Loss total: 2.594618797302246, Last rpr Loss: 1.0004613399505615, Last lagvar Loss: 0.8452762961387634\n",
      "Step 6483/10000- lr: [3.5505308484848487e-06] - Loss total: 2.5945885181427, Last rpr Loss: 0.9994676113128662, Last lagvar Loss: 0.8462700843811035\n",
      "Step 6484/10000- lr: [3.549520751515151e-06] - Loss total: 2.594558000564575, Last rpr Loss: 1.000597357749939, Last lagvar Loss: 0.845140278339386\n",
      "Step 6485/10000- lr: [3.5485106545454544e-06] - Loss total: 2.5945279598236084, Last rpr Loss: 0.9993055462837219, Last lagvar Loss: 0.846432089805603\n",
      "Step 6486/10000- lr: [3.547500557575757e-06] - Loss total: 2.5944972038269043, Last rpr Loss: 1.0007922649383545, Last lagvar Loss: 0.8449455499649048\n",
      "Step 6487/10000- lr: [3.546490460606061e-06] - Loss total: 2.5944674015045166, Last rpr Loss: 0.9990806579589844, Last lagvar Loss: 0.8466572761535645\n",
      "Step 6488/10000- lr: [3.5454803636363634e-06] - Loss total: 2.594437599182129, Last rpr Loss: 1.0010597705841064, Last lagvar Loss: 0.8446782231330872\n",
      "Step 6489/10000- lr: [3.5444702666666666e-06] - Loss total: 2.594407558441162, Last rpr Loss: 0.998762845993042, Last lagvar Loss: 0.8469755053520203\n",
      "Step 6490/10000- lr: [3.543460169696969e-06] - Loss total: 2.5943775177001953, Last rpr Loss: 1.00143563747406, Last lagvar Loss: 0.8443031311035156\n",
      "Step 6491/10000- lr: [3.5424500727272723e-06] - Loss total: 2.594348430633545, Last rpr Loss: 0.9983118772506714, Last lagvar Loss: 0.8474276661872864\n",
      "Step 6492/10000- lr: [3.5414399757575748e-06] - Loss total: 2.5943191051483154, Last rpr Loss: 1.0019774436950684, Last lagvar Loss: 0.8437631130218506\n",
      "Step 6493/10000- lr: [3.540429878787879e-06] - Loss total: 2.5942904949188232, Last rpr Loss: 0.9976642727851868, Last lagvar Loss: 0.8480778336524963\n",
      "Step 6494/10000- lr: [3.5394197818181813e-06] - Loss total: 2.5942623615264893, Last rpr Loss: 1.0027492046356201, Last lagvar Loss: 0.8429950475692749\n",
      "Step 6495/10000- lr: [3.5384096848484846e-06] - Loss total: 2.594235420227051, Last rpr Loss: 0.9967343807220459, Last lagvar Loss: 0.849013090133667\n",
      "Step 6496/10000- lr: [3.537399587878787e-06] - Loss total: 2.5942094326019287, Last rpr Loss: 1.0038743019104004, Last lagvar Loss: 0.8418774604797363\n",
      "Step 6497/10000- lr: [3.536389490909091e-06] - Loss total: 2.5941860675811768, Last rpr Loss: 0.99538254737854, Last lagvar Loss: 0.8503762483596802\n",
      "Step 6498/10000- lr: [3.5353793939393936e-06] - Loss total: 2.5941646099090576, Last rpr Loss: 1.005502700805664, Last lagvar Loss: 0.840265154838562\n",
      "Step 6499/10000- lr: [3.534369296969697e-06] - Loss total: 2.5941483974456787, Last rpr Loss: 0.9934097528457642, Last lagvar Loss: 0.8523727655410767\n",
      "Step 6500/10000- lr: [3.5333592e-06] - Loss total: 2.5941359996795654, Last rpr Loss: 1.0078895092010498, Last lagvar Loss: 0.8379116654396057\n",
      "Step 6501/10000- lr: [3.5323491030303026e-06] - Loss total: 2.5941355228424072, Last rpr Loss: 0.9905396699905396, Last lagvar Loss: 0.855292797088623\n",
      "Step 6502/10000- lr: [3.5313390060606067e-06] - Loss total: 2.5941414833068848, Last rpr Loss: 1.0113394260406494, Last lagvar Loss: 0.8345307111740112\n",
      "Step 6503/10000- lr: [3.530328909090909e-06] - Loss total: 2.5941734313964844, Last rpr Loss: 0.9864170551300049, Last lagvar Loss: 0.8595193028450012\n",
      "Step 6504/10000- lr: [3.5293188121212124e-06] - Loss total: 2.594212293624878, Last rpr Loss: 1.016209363937378, Last lagvar Loss: 0.8297990560531616\n",
      "Step 6505/10000- lr: [3.528308715151515e-06] - Loss total: 2.5943071842193604, Last rpr Loss: 0.9807382225990295, Last lagvar Loss: 0.8654041290283203\n",
      "Step 6506/10000- lr: [3.527298618181819e-06] - Loss total: 2.5943922996520996, Last rpr Loss: 1.0226686000823975, Last lagvar Loss: 0.8235940337181091\n",
      "Step 6507/10000- lr: [3.5262885212121214e-06] - Loss total: 2.5945866107940674, Last rpr Loss: 0.973646879196167, Last lagvar Loss: 0.8728551864624023\n",
      "Step 6508/10000- lr: [3.5252784242424247e-06] - Loss total: 2.5946903228759766, Last rpr Loss: 1.0299636125564575, Last lagvar Loss: 0.8166764974594116\n",
      "Step 6509/10000- lr: [3.524268327272727e-06] - Loss total: 2.5949549674987793, Last rpr Loss: 0.9667649269104004, Last lagvar Loss: 0.8801913261413574\n",
      "Step 6510/10000- lr: [3.5232582303030304e-06] - Loss total: 2.5948126316070557, Last rpr Loss: 1.0332667827606201, Last lagvar Loss: 0.8135635852813721\n",
      "Step 6511/10000- lr: [3.522248133333333e-06] - Loss total: 2.5946953296661377, Last rpr Loss: 0.969525933265686, Last lagvar Loss: 0.8772168755531311\n",
      "Step 6512/10000- lr: [3.521238036363637e-06] - Loss total: 2.5943424701690674, Last rpr Loss: 1.025924801826477, Last lagvar Loss: 0.8204699754714966\n",
      "Step 6513/10000- lr: [3.5202279393939394e-06] - Loss total: 2.594080686569214, Last rpr Loss: 0.9801757335662842, Last lagvar Loss: 0.8659757971763611\n",
      "Step 6514/10000- lr: [3.5192178424242426e-06] - Loss total: 2.5938146114349365, Last rpr Loss: 1.0128886699676514, Last lagvar Loss: 0.8330109119415283\n",
      "Step 6515/10000- lr: [3.518207745454545e-06] - Loss total: 2.5936577320098877, Last rpr Loss: 0.9948791861534119, Last lagvar Loss: 0.8508845567703247\n",
      "Step 6516/10000- lr: [3.517197648484849e-06] - Loss total: 2.5936062335968018, Last rpr Loss: 0.9980533123016357, Last lagvar Loss: 0.8476862907409668\n",
      "Step 6517/10000- lr: [3.5161875515151516e-06] - Loss total: 2.5936386585235596, Last rpr Loss: 1.0083589553833008, Last lagvar Loss: 0.8374468088150024\n",
      "Step 6518/10000- lr: [3.515177454545455e-06] - Loss total: 2.593716859817505, Last rpr Loss: 0.9866570830345154, Last lagvar Loss: 0.8592597246170044\n",
      "Step 6519/10000- lr: [3.5141673575757573e-06] - Loss total: 2.5937728881835938, Last rpr Loss: 1.0164819955825806, Last lagvar Loss: 0.8295263648033142\n",
      "Step 6520/10000- lr: [3.5131572606060606e-06] - Loss total: 2.59381103515625, Last rpr Loss: 0.9819514751434326, Last lagvar Loss: 0.8641260862350464\n",
      "Step 6521/10000- lr: [3.512147163636363e-06] - Loss total: 2.5937514305114746, Last rpr Loss: 1.0175821781158447, Last lagvar Loss: 0.8284633159637451\n",
      "Step 6522/10000- lr: [3.511137066666667e-06] - Loss total: 2.5936708450317383, Last rpr Loss: 0.9844822287559509, Last lagvar Loss: 0.8615086674690247\n",
      "Step 6523/10000- lr: [3.5101269696969696e-06] - Loss total: 2.5935394763946533, Last rpr Loss: 1.0121684074401855, Last lagvar Loss: 0.8337141275405884\n",
      "Step 6524/10000- lr: [3.509116872727273e-06] - Loss total: 2.5934290885925293, Last rpr Loss: 0.9922282695770264, Last lagvar Loss: 0.8535681962966919\n",
      "Step 6525/10000- lr: [3.5081067757575753e-06] - Loss total: 2.5933494567871094, Last rpr Loss: 1.0030826330184937, Last lagvar Loss: 0.8426605463027954\n",
      "Step 6526/10000- lr: [3.5070966787878794e-06] - Loss total: 2.5933144092559814, Last rpr Loss: 1.0014574527740479, Last lagvar Loss: 0.8442789316177368\n",
      "Step 6527/10000- lr: [3.506086581818182e-06] - Loss total: 2.593313217163086, Last rpr Loss: 0.9944214224815369, Last lagvar Loss: 0.8513436913490295\n",
      "Step 6528/10000- lr: [3.505076484848485e-06] - Loss total: 2.593324661254883, Last rpr Loss: 1.0085418224334717, Last lagvar Loss: 0.8372671008110046\n",
      "Step 6529/10000- lr: [3.5040663878787876e-06] - Loss total: 2.593331813812256, Last rpr Loss: 0.9895275235176086, Last lagvar Loss: 0.8563171029090881\n",
      "Step 6530/10000- lr: [3.503056290909091e-06] - Loss total: 2.593311071395874, Last rpr Loss: 1.0110414028167725, Last lagvar Loss: 0.8348138928413391\n",
      "Step 6531/10000- lr: [3.5020461939393933e-06] - Loss total: 2.5932726860046387, Last rpr Loss: 0.9896374344825745, Last lagvar Loss: 0.8562054634094238\n",
      "Step 6532/10000- lr: [3.5010360969696974e-06] - Loss total: 2.5932106971740723, Last rpr Loss: 1.008716344833374, Last lagvar Loss: 0.8370924592018127\n",
      "Step 6533/10000- lr: [3.500026e-06] - Loss total: 2.5931479930877686, Last rpr Loss: 0.9937968254089355, Last lagvar Loss: 0.8519755601882935\n",
      "Step 6534/10000- lr: [3.499015903030303e-06] - Loss total: 2.593092441558838, Last rpr Loss: 1.0033899545669556, Last lagvar Loss: 0.8423541188240051\n",
      "Step 6535/10000- lr: [3.4980058060606055e-06] - Loss total: 2.593052864074707, Last rpr Loss: 0.9995265007019043, Last lagvar Loss: 0.8462057709693909\n",
      "Step 6536/10000- lr: [3.4969957090909096e-06] - Loss total: 2.5930283069610596, Last rpr Loss: 0.997791051864624, Last lagvar Loss: 0.8479455709457397\n",
      "Step 6537/10000- lr: [3.495985612121212e-06] - Loss total: 2.593013048171997, Last rpr Loss: 1.0042829513549805, Last lagvar Loss: 0.8414682149887085\n",
      "Step 6538/10000- lr: [3.4949755151515154e-06] - Loss total: 2.5929996967315674, Last rpr Loss: 0.994133710861206, Last lagvar Loss: 0.8516332507133484\n",
      "Step 6539/10000- lr: [3.4939654181818178e-06] - Loss total: 2.592979669570923, Last rpr Loss: 1.0065902471542358, Last lagvar Loss: 0.8391867280006409\n",
      "Step 6540/10000- lr: [3.492955321212121e-06] - Loss total: 2.5929527282714844, Last rpr Loss: 0.9933515787124634, Last lagvar Loss: 0.8524256348609924\n",
      "Step 6541/10000- lr: [3.4919452242424235e-06] - Loss total: 2.5929150581359863, Last rpr Loss: 1.0060796737670898, Last lagvar Loss: 0.8396894931793213\n",
      "Step 6542/10000- lr: [3.4909351272727276e-06] - Loss total: 2.5928750038146973, Last rpr Loss: 0.995114266872406, Last lagvar Loss: 0.8506413698196411\n",
      "Step 6543/10000- lr: [3.48992503030303e-06] - Loss total: 2.5928337574005127, Last rpr Loss: 1.0033979415893555, Last lagvar Loss: 0.8423448801040649\n",
      "Step 6544/10000- lr: [3.4889149333333333e-06] - Loss total: 2.592797040939331, Last rpr Loss: 0.9983183145523071, Last lagvar Loss: 0.847415566444397\n",
      "Step 6545/10000- lr: [3.4879048363636358e-06] - Loss total: 2.5927655696868896, Last rpr Loss: 0.9999398589134216, Last lagvar Loss: 0.8457911014556885\n",
      "Step 6546/10000- lr: [3.48689473939394e-06] - Loss total: 2.5927395820617676, Last rpr Loss: 1.0015524625778198, Last lagvar Loss: 0.8441809415817261\n",
      "Step 6547/10000- lr: [3.4858846424242423e-06] - Loss total: 2.5927162170410156, Last rpr Loss: 0.9971750974655151, Last lagvar Loss: 0.848563551902771\n",
      "Step 6548/10000- lr: [3.4848745454545456e-06] - Loss total: 2.5926928520202637, Last rpr Loss: 1.0036507844924927, Last lagvar Loss: 0.8420934081077576\n",
      "Step 6549/10000- lr: [3.483864448484848e-06] - Loss total: 2.592667818069458, Last rpr Loss: 0.9959409236907959, Last lagvar Loss: 0.849806547164917\n",
      "Step 6550/10000- lr: [3.4828543515151513e-06] - Loss total: 2.592639207839966, Last rpr Loss: 1.0040826797485352, Last lagvar Loss: 0.8416647911071777\n",
      "Step 6551/10000- lr: [3.4818442545454537e-06] - Loss total: 2.5926079750061035, Last rpr Loss: 0.9963151812553406, Last lagvar Loss: 0.8494293689727783\n",
      "Step 6552/10000- lr: [3.480834157575758e-06] - Loss total: 2.5925755500793457, Last rpr Loss: 1.0030605792999268, Last lagvar Loss: 0.8426792025566101\n",
      "Step 6553/10000- lr: [3.4798240606060603e-06] - Loss total: 2.5925424098968506, Last rpr Loss: 0.9977855086326599, Last lagvar Loss: 0.847949743270874\n",
      "Step 6554/10000- lr: [3.4788139636363636e-06] - Loss total: 2.592510938644409, Last rpr Loss: 1.0012414455413818, Last lagvar Loss: 0.8444901704788208\n",
      "Step 6555/10000- lr: [3.477803866666666e-06] - Loss total: 2.5924808979034424, Last rpr Loss: 0.9996733069419861, Last lagvar Loss: 0.8460566997528076\n",
      "Step 6556/10000- lr: [3.47679376969697e-06] - Loss total: 2.5924527645111084, Last rpr Loss: 0.999380350112915, Last lagvar Loss: 0.846349835395813\n",
      "Step 6557/10000- lr: [3.4757836727272725e-06] - Loss total: 2.592426061630249, Last rpr Loss: 1.0013368129730225, Last lagvar Loss: 0.8443949222564697\n",
      "Step 6558/10000- lr: [3.474773575757576e-06] - Loss total: 2.5923993587493896, Last rpr Loss: 0.998060941696167, Last lagvar Loss: 0.8476725220680237\n",
      "Step 6559/10000- lr: [3.4737634787878782e-06] - Loss total: 2.592372179031372, Last rpr Loss: 1.0022999048233032, Last lagvar Loss: 0.8434350490570068\n",
      "Step 6560/10000- lr: [3.4727533818181815e-06] - Loss total: 2.5923447608947754, Last rpr Loss: 0.9975671768188477, Last lagvar Loss: 0.8481682538986206\n",
      "Step 6561/10000- lr: [3.471743284848484e-06] - Loss total: 2.592315912246704, Last rpr Loss: 1.0023845434188843, Last lagvar Loss: 0.8433505296707153\n",
      "Step 6562/10000- lr: [3.470733187878788e-06] - Loss total: 2.5922863483428955, Last rpr Loss: 0.9978681802749634, Last lagvar Loss: 0.8478657007217407\n",
      "Step 6563/10000- lr: [3.4697230909090905e-06] - Loss total: 2.592257022857666, Last rpr Loss: 1.001749038696289, Last lagvar Loss: 0.8439831733703613\n",
      "Step 6564/10000- lr: [3.4687129939393938e-06] - Loss total: 2.5922272205352783, Last rpr Loss: 0.9987285137176514, Last lagvar Loss: 0.8470022678375244\n",
      "Step 6565/10000- lr: [3.4677028969696962e-06] - Loss total: 2.592198133468628, Last rpr Loss: 1.0007386207580566, Last lagvar Loss: 0.8449908494949341\n",
      "Step 6566/10000- lr: [3.4666928000000003e-06] - Loss total: 2.5921692848205566, Last rpr Loss: 0.9997701644897461, Last lagvar Loss: 0.8459588289260864\n",
      "Step 6567/10000- lr: [3.4656827030303028e-06] - Loss total: 2.5921413898468018, Last rpr Loss: 0.9997340440750122, Last lagvar Loss: 0.8459948301315308\n",
      "Step 6568/10000- lr: [3.464672606060606e-06] - Loss total: 2.5921132564544678, Last rpr Loss: 1.0006612539291382, Last lagvar Loss: 0.8450678586959839\n",
      "Step 6569/10000- lr: [3.4636625090909085e-06] - Loss total: 2.592085599899292, Last rpr Loss: 0.9990007281303406, Last lagvar Loss: 0.8467288613319397\n",
      "Step 6570/10000- lr: [3.4626524121212118e-06] - Loss total: 2.592057704925537, Last rpr Loss: 1.0012315511703491, Last lagvar Loss: 0.8444986343383789\n",
      "Step 6571/10000- lr: [3.461642315151514e-06] - Loss total: 2.5920300483703613, Last rpr Loss: 0.9986404180526733, Last lagvar Loss: 0.8470898866653442\n",
      "Step 6572/10000- lr: [3.4606322181818183e-06] - Loss total: 2.5920019149780273, Last rpr Loss: 1.0013861656188965, Last lagvar Loss: 0.8443441390991211\n",
      "Step 6573/10000- lr: [3.4596221212121207e-06] - Loss total: 2.591973304748535, Last rpr Loss: 0.9986658096313477, Last lagvar Loss: 0.8470642566680908\n",
      "Step 6574/10000- lr: [3.458612024242424e-06] - Loss total: 2.591945171356201, Last rpr Loss: 1.0011731386184692, Last lagvar Loss: 0.8445565104484558\n",
      "Step 6575/10000- lr: [3.4576019272727264e-06] - Loss total: 2.59191632270813, Last rpr Loss: 0.9990105628967285, Last lagvar Loss: 0.846718430519104\n",
      "Step 6576/10000- lr: [3.4565918303030306e-06] - Loss total: 2.591887950897217, Last rpr Loss: 1.000732183456421, Last lagvar Loss: 0.8449963331222534\n",
      "Step 6577/10000- lr: [3.455581733333333e-06] - Loss total: 2.5918593406677246, Last rpr Loss: 0.9995248317718506, Last lagvar Loss: 0.8462032675743103\n",
      "Step 6578/10000- lr: [3.4545716363636363e-06] - Loss total: 2.5918309688568115, Last rpr Loss: 1.0002118349075317, Last lagvar Loss: 0.8455160856246948\n",
      "Step 6579/10000- lr: [3.4535615393939387e-06] - Loss total: 2.5918028354644775, Last rpr Loss: 1.0000355243682861, Last lagvar Loss: 0.8456923365592957\n",
      "Step 6580/10000- lr: [3.452551442424242e-06] - Loss total: 2.5917751789093018, Last rpr Loss: 0.999738335609436, Last lagvar Loss: 0.8459894061088562\n",
      "Step 6581/10000- lr: [3.4515413454545444e-06] - Loss total: 2.591747283935547, Last rpr Loss: 1.0004289150238037, Last lagvar Loss: 0.8452988862991333\n",
      "Step 6582/10000- lr: [3.4505312484848485e-06] - Loss total: 2.591719150543213, Last rpr Loss: 0.999413251876831, Last lagvar Loss: 0.846314549446106\n",
      "Step 6583/10000- lr: [3.449521151515151e-06] - Loss total: 2.591691493988037, Last rpr Loss: 1.000672698020935, Last lagvar Loss: 0.8450550436973572\n",
      "Step 6584/10000- lr: [3.4485110545454542e-06] - Loss total: 2.5916635990142822, Last rpr Loss: 0.9992549419403076, Last lagvar Loss: 0.846472978591919\n",
      "Step 6585/10000- lr: [3.4475009575757584e-06] - Loss total: 2.5916354656219482, Last rpr Loss: 1.0007480382919312, Last lagvar Loss: 0.8449796438217163\n",
      "Step 6586/10000- lr: [3.446490860606061e-06] - Loss total: 2.5916075706481934, Last rpr Loss: 0.9992729425430298, Last lagvar Loss: 0.8464547395706177\n",
      "Step 6587/10000- lr: [3.445480763636364e-06] - Loss total: 2.5915796756744385, Last rpr Loss: 1.0006699562072754, Last lagvar Loss: 0.8450576066970825\n",
      "Step 6588/10000- lr: [3.4444706666666665e-06] - Loss total: 2.5915515422821045, Last rpr Loss: 0.9994086027145386, Last lagvar Loss: 0.8463186025619507\n",
      "Step 6589/10000- lr: [3.4434605696969698e-06] - Loss total: 2.5915234088897705, Last rpr Loss: 1.0004825592041016, Last lagvar Loss: 0.8452444672584534\n",
      "Step 6590/10000- lr: [3.4424504727272722e-06] - Loss total: 2.5914955139160156, Last rpr Loss: 0.9996280074119568, Last lagvar Loss: 0.8460988998413086\n",
      "Step 6591/10000- lr: [3.4414403757575763e-06] - Loss total: 2.5914673805236816, Last rpr Loss: 1.0002444982528687, Last lagvar Loss: 0.8454822301864624\n",
      "Step 6592/10000- lr: [3.4404302787878788e-06] - Loss total: 2.5914394855499268, Last rpr Loss: 0.9998572468757629, Last lagvar Loss: 0.8458694219589233\n",
      "Step 6593/10000- lr: [3.439420181818182e-06] - Loss total: 2.591411590576172, Last rpr Loss: 1.0000211000442505, Last lagvar Loss: 0.8457054495811462\n",
      "Step 6594/10000- lr: [3.4384100848484845e-06] - Loss total: 2.591383934020996, Last rpr Loss: 1.000061273574829, Last lagvar Loss: 0.8456652164459229\n",
      "Step 6595/10000- lr: [3.4373999878787886e-06] - Loss total: 2.591355562210083, Last rpr Loss: 0.9998381733894348, Last lagvar Loss: 0.8458881974220276\n",
      "Step 6596/10000- lr: [3.436389890909091e-06] - Loss total: 2.5913281440734863, Last rpr Loss: 1.0002286434173584, Last lagvar Loss: 0.8454976677894592\n",
      "Step 6597/10000- lr: [3.4353797939393943e-06] - Loss total: 2.5913002490997314, Last rpr Loss: 0.9997062683105469, Last lagvar Loss: 0.846019983291626\n",
      "Step 6598/10000- lr: [3.4343696969696967e-06] - Loss total: 2.5912723541259766, Last rpr Loss: 1.000331163406372, Last lagvar Loss: 0.8453950881958008\n",
      "Step 6599/10000- lr: [3.4333596e-06] - Loss total: 2.5912444591522217, Last rpr Loss: 0.9996349215507507, Last lagvar Loss: 0.8460911512374878\n",
      "Step 6600/10000- lr: [3.4323495030303024e-06] - Loss total: 2.591216564178467, Last rpr Loss: 1.0003706216812134, Last lagvar Loss: 0.8453553915023804\n",
      "Step 6601/10000- lr: [3.4313394060606066e-06] - Loss total: 2.59118914604187, Last rpr Loss: 0.9996219873428345, Last lagvar Loss: 0.8461039066314697\n",
      "Step 6602/10000- lr: [3.430329309090909e-06] - Loss total: 2.591161012649536, Last rpr Loss: 1.0003550052642822, Last lagvar Loss: 0.8453708291053772\n",
      "Step 6603/10000- lr: [3.4293192121212123e-06] - Loss total: 2.5911333560943604, Last rpr Loss: 0.9996539354324341, Last lagvar Loss: 0.8460718393325806\n",
      "Step 6604/10000- lr: [3.4283091151515147e-06] - Loss total: 2.5911056995391846, Last rpr Loss: 1.0003025531768799, Last lagvar Loss: 0.84542316198349\n",
      "Step 6605/10000- lr: [3.427299018181819e-06] - Loss total: 2.591078042984009, Last rpr Loss: 0.9997248649597168, Last lagvar Loss: 0.8460006713867188\n",
      "Step 6606/10000- lr: [3.4262889212121213e-06] - Loss total: 2.591050386428833, Last rpr Loss: 1.0002305507659912, Last lagvar Loss: 0.8454949259757996\n",
      "Step 6607/10000- lr: [3.4252788242424245e-06] - Loss total: 2.591022491455078, Last rpr Loss: 0.9997992515563965, Last lagvar Loss: 0.8459261655807495\n",
      "Step 6608/10000- lr: [3.424268727272727e-06] - Loss total: 2.5909945964813232, Last rpr Loss: 1.0001544952392578, Last lagvar Loss: 0.8455708026885986\n",
      "Step 6609/10000- lr: [3.4232586303030302e-06] - Loss total: 2.5909669399261475, Last rpr Loss: 0.9998756647109985, Last lagvar Loss: 0.8458493947982788\n",
      "Step 6610/10000- lr: [3.4222485333333327e-06] - Loss total: 2.5909392833709717, Last rpr Loss: 1.0000754594802856, Last lagvar Loss: 0.8456496000289917\n",
      "Step 6611/10000- lr: [3.421238436363637e-06] - Loss total: 2.590911626815796, Last rpr Loss: 0.9999520778656006, Last lagvar Loss: 0.845772922039032\n",
      "Step 6612/10000- lr: [3.4202283393939392e-06] - Loss total: 2.59088397026062, Last rpr Loss: 1.0000053644180298, Last lagvar Loss: 0.8457195162773132\n",
      "Step 6613/10000- lr: [3.4192182424242425e-06] - Loss total: 2.5908563137054443, Last rpr Loss: 1.0000125169754028, Last lagvar Loss: 0.8457123637199402\n",
      "Step 6614/10000- lr: [3.418208145454545e-06] - Loss total: 2.5908286571502686, Last rpr Loss: 0.9999505281448364, Last lagvar Loss: 0.8457741737365723\n",
      "Step 6615/10000- lr: [3.417198048484849e-06] - Loss total: 2.590801239013672, Last rpr Loss: 1.0000675916671753, Last lagvar Loss: 0.8456571102142334\n",
      "Step 6616/10000- lr: [3.4161879515151515e-06] - Loss total: 2.590773820877075, Last rpr Loss: 0.9999037981033325, Last lagvar Loss: 0.8458208441734314\n",
      "Step 6617/10000- lr: [3.4151778545454548e-06] - Loss total: 2.5907459259033203, Last rpr Loss: 1.0001018047332764, Last lagvar Loss: 0.845622718334198\n",
      "Step 6618/10000- lr: [3.414167757575757e-06] - Loss total: 2.5907185077667236, Last rpr Loss: 0.9998745918273926, Last lagvar Loss: 0.845849871635437\n",
      "Step 6619/10000- lr: [3.4131576606060605e-06] - Loss total: 2.590690851211548, Last rpr Loss: 1.000123143196106, Last lagvar Loss: 0.8456010818481445\n",
      "Step 6620/10000- lr: [3.412147563636363e-06] - Loss total: 2.590663433074951, Last rpr Loss: 0.9998603463172913, Last lagvar Loss: 0.845863938331604\n",
      "Step 6621/10000- lr: [3.411137466666667e-06] - Loss total: 2.5906357765197754, Last rpr Loss: 1.0001399517059326, Last lagvar Loss: 0.8455840945243835\n",
      "Step 6622/10000- lr: [3.4101273696969695e-06] - Loss total: 2.5906081199645996, Last rpr Loss: 0.9998456239700317, Last lagvar Loss: 0.8458784818649292\n",
      "Step 6623/10000- lr: [3.4091172727272727e-06] - Loss total: 2.590580940246582, Last rpr Loss: 1.0001475811004639, Last lagvar Loss: 0.8455765247344971\n",
      "Step 6624/10000- lr: [3.408107175757575e-06] - Loss total: 2.5905532836914062, Last rpr Loss: 0.99984210729599, Last lagvar Loss: 0.8458818197250366\n",
      "Step 6625/10000- lr: [3.4070970787878793e-06] - Loss total: 2.5905258655548096, Last rpr Loss: 1.0001490116119385, Last lagvar Loss: 0.8455748558044434\n",
      "Step 6626/10000- lr: [3.4060869818181817e-06] - Loss total: 2.590498208999634, Last rpr Loss: 0.9998411536216736, Last lagvar Loss: 0.8458826541900635\n",
      "Step 6627/10000- lr: [3.405076884848485e-06] - Loss total: 2.590470552444458, Last rpr Loss: 1.0001496076583862, Last lagvar Loss: 0.8455740213394165\n",
      "Step 6628/10000- lr: [3.4040667878787874e-06] - Loss total: 2.5904431343078613, Last rpr Loss: 0.9998384118080139, Last lagvar Loss: 0.8458852171897888\n",
      "Step 6629/10000- lr: [3.4030566909090907e-06] - Loss total: 2.5904159545898438, Last rpr Loss: 1.0001518726348877, Last lagvar Loss: 0.8455715179443359\n",
      "Step 6630/10000- lr: [3.402046593939393e-06] - Loss total: 2.590388536453247, Last rpr Loss: 0.9998380541801453, Last lagvar Loss: 0.8458853960037231\n",
      "Step 6631/10000- lr: [3.4010364969696973e-06] - Loss total: 2.5903608798980713, Last rpr Loss: 1.000157356262207, Last lagvar Loss: 0.845565915107727\n",
      "Step 6632/10000- lr: [3.4000263999999997e-06] - Loss total: 2.5903337001800537, Last rpr Loss: 0.9998306035995483, Last lagvar Loss: 0.8458926677703857\n",
      "Step 6633/10000- lr: [3.399016303030303e-06] - Loss total: 2.590306520462036, Last rpr Loss: 1.0001600980758667, Last lagvar Loss: 0.8455630540847778\n",
      "Step 6634/10000- lr: [3.3980062060606054e-06] - Loss total: 2.5902786254882812, Last rpr Loss: 0.9998283982276917, Last lagvar Loss: 0.8458946943283081\n",
      "Step 6635/10000- lr: [3.3969961090909095e-06] - Loss total: 2.5902514457702637, Last rpr Loss: 1.000169277191162, Last lagvar Loss: 0.8455536961555481\n",
      "Step 6636/10000- lr: [3.395986012121212e-06] - Loss total: 2.590224266052246, Last rpr Loss: 0.9998112320899963, Last lagvar Loss: 0.8459117412567139\n",
      "Step 6637/10000- lr: [3.3949759151515152e-06] - Loss total: 2.5901970863342285, Last rpr Loss: 1.0001871585845947, Last lagvar Loss: 0.8455357551574707\n",
      "Step 6638/10000- lr: [3.3939658181818177e-06] - Loss total: 2.5901691913604736, Last rpr Loss: 0.9997917413711548, Last lagvar Loss: 0.8459310531616211\n",
      "Step 6639/10000- lr: [3.392955721212121e-06] - Loss total: 2.590142011642456, Last rpr Loss: 1.0002124309539795, Last lagvar Loss: 0.8455101847648621\n",
      "Step 6640/10000- lr: [3.3919456242424234e-06] - Loss total: 2.5901148319244385, Last rpr Loss: 0.9997655153274536, Last lagvar Loss: 0.8459571599960327\n",
      "Step 6641/10000- lr: [3.3909355272727275e-06] - Loss total: 2.590087413787842, Last rpr Loss: 1.0002398490905762, Last lagvar Loss: 0.8454826474189758\n",
      "Step 6642/10000- lr: [3.38992543030303e-06] - Loss total: 2.5900604724884033, Last rpr Loss: 0.9997371435165405, Last lagvar Loss: 0.8459854125976562\n",
      "Step 6643/10000- lr: [3.388915333333333e-06] - Loss total: 2.5900330543518066, Last rpr Loss: 1.0002710819244385, Last lagvar Loss: 0.8454514145851135\n",
      "Step 6644/10000- lr: [3.3879052363636356e-06] - Loss total: 2.590005397796631, Last rpr Loss: 0.9996963739395142, Last lagvar Loss: 0.8460259437561035\n",
      "Step 6645/10000- lr: [3.3868951393939397e-06] - Loss total: 2.5899786949157715, Last rpr Loss: 1.0003185272216797, Last lagvar Loss: 0.8454037308692932\n",
      "Step 6646/10000- lr: [3.385885042424242e-06] - Loss total: 2.589951515197754, Last rpr Loss: 0.9996391534805298, Last lagvar Loss: 0.8460831046104431\n",
      "Step 6647/10000- lr: [3.3848749454545455e-06] - Loss total: 2.5899243354797363, Last rpr Loss: 1.000385046005249, Last lagvar Loss: 0.8453371524810791\n",
      "Step 6648/10000- lr: [3.383864848484848e-06] - Loss total: 2.5898966789245605, Last rpr Loss: 0.9995690584182739, Last lagvar Loss: 0.8461531400680542\n",
      "Step 6649/10000- lr: [3.382854751515151e-06] - Loss total: 2.589869737625122, Last rpr Loss: 1.000472068786621, Last lagvar Loss: 0.845250129699707\n",
      "Step 6650/10000- lr: [3.3818446545454536e-06] - Loss total: 2.5898425579071045, Last rpr Loss: 0.9994675517082214, Last lagvar Loss: 0.8462545871734619\n",
      "Step 6651/10000- lr: [3.3808345575757577e-06] - Loss total: 2.589815378189087, Last rpr Loss: 1.0005791187286377, Last lagvar Loss: 0.8451429605484009\n",
      "Step 6652/10000- lr: [3.37982446060606e-06] - Loss total: 2.5897881984710693, Last rpr Loss: 0.9993339776992798, Last lagvar Loss: 0.8463881015777588\n",
      "Step 6653/10000- lr: [3.3788143636363634e-06] - Loss total: 2.589761257171631, Last rpr Loss: 1.000738501548767, Last lagvar Loss: 0.8449835777282715\n",
      "Step 6654/10000- lr: [3.377804266666666e-06] - Loss total: 2.5897343158721924, Last rpr Loss: 0.9991573095321655, Last lagvar Loss: 0.8465649485588074\n",
      "Step 6655/10000- lr: [3.37679416969697e-06] - Loss total: 2.589707612991333, Last rpr Loss: 1.00094735622406, Last lagvar Loss: 0.8447749614715576\n",
      "Step 6656/10000- lr: [3.3757840727272724e-06] - Loss total: 2.5896806716918945, Last rpr Loss: 0.9989137053489685, Last lagvar Loss: 0.846808910369873\n",
      "Step 6657/10000- lr: [3.3747739757575757e-06] - Loss total: 2.5896542072296143, Last rpr Loss: 1.00123131275177, Last lagvar Loss: 0.8444916009902954\n",
      "Step 6658/10000- lr: [3.373763878787878e-06] - Loss total: 2.5896270275115967, Last rpr Loss: 0.9985818862915039, Last lagvar Loss: 0.8471415042877197\n",
      "Step 6659/10000- lr: [3.3727537818181814e-06] - Loss total: 2.5896008014678955, Last rpr Loss: 1.0016212463378906, Last lagvar Loss: 0.8441025614738464\n",
      "Step 6660/10000- lr: [3.371743684848484e-06] - Loss total: 2.5895743370056152, Last rpr Loss: 0.9981145858764648, Last lagvar Loss: 0.8476101160049438\n",
      "Step 6661/10000- lr: [3.370733587878788e-06] - Loss total: 2.5895485877990723, Last rpr Loss: 1.002166509628296, Last lagvar Loss: 0.8435593247413635\n",
      "Step 6662/10000- lr: [3.3697234909090904e-06] - Loss total: 2.5895230770111084, Last rpr Loss: 0.9974772930145264, Last lagvar Loss: 0.8482503294944763\n",
      "Step 6663/10000- lr: [3.3687133939393937e-06] - Loss total: 2.589498281478882, Last rpr Loss: 1.0029278993606567, Last lagvar Loss: 0.8428018093109131\n",
      "Step 6664/10000- lr: [3.367703296969696e-06] - Loss total: 2.5894742012023926, Last rpr Loss: 0.9965750575065613, Last lagvar Loss: 0.8491581082344055\n",
      "Step 6665/10000- lr: [3.3666932e-06] - Loss total: 2.589451789855957, Last rpr Loss: 1.0039973258972168, Last lagvar Loss: 0.8417398929595947\n",
      "Step 6666/10000- lr: [3.3656831030303026e-06] - Loss total: 2.589430809020996, Last rpr Loss: 0.9952998161315918, Last lagvar Loss: 0.8504443168640137\n",
      "Step 6667/10000- lr: [3.364673006060606e-06] - Loss total: 2.589411497116089, Last rpr Loss: 1.0055121183395386, Last lagvar Loss: 0.840239942073822\n",
      "Step 6668/10000- lr: [3.3636629090909083e-06] - Loss total: 2.5893967151641846, Last rpr Loss: 0.9934977889060974, Last lagvar Loss: 0.8522677421569824\n",
      "Step 6669/10000- lr: [3.3626528121212116e-06] - Loss total: 2.5893852710723877, Last rpr Loss: 1.0076568126678467, Last lagvar Loss: 0.8381242156028748\n",
      "Step 6670/10000- lr: [3.3616427151515157e-06] - Loss total: 2.5893828868865967, Last rpr Loss: 0.9909610748291016, Last lagvar Loss: 0.8548466563224792\n",
      "Step 6671/10000- lr: [3.360632618181818e-06] - Loss total: 2.5893843173980713, Last rpr Loss: 1.0106520652770996, Last lagvar Loss: 0.8351853489875793\n",
      "Step 6672/10000- lr: [3.3596225212121215e-06] - Loss total: 2.5894057750701904, Last rpr Loss: 0.9874398112297058, Last lagvar Loss: 0.8584498167037964\n",
      "Step 6673/10000- lr: [3.358612424242424e-06] - Loss total: 2.589430570602417, Last rpr Loss: 1.0147478580474854, Last lagvar Loss: 0.8311952352523804\n",
      "Step 6674/10000- lr: [3.357602327272728e-06] - Loss total: 2.5894949436187744, Last rpr Loss: 0.982738733291626, Last lagvar Loss: 0.8633029460906982\n",
      "Step 6675/10000- lr: [3.3565922303030304e-06] - Loss total: 2.589550018310547, Last rpr Loss: 1.020021915435791, Last lagvar Loss: 0.8261047601699829\n",
      "Step 6676/10000- lr: [3.3555821333333337e-06] - Loss total: 2.589677333831787, Last rpr Loss: 0.9770028591156006, Last lagvar Loss: 0.8692905306816101\n",
      "Step 6677/10000- lr: [3.354572036363636e-06] - Loss total: 2.5897469520568848, Last rpr Loss: 1.025916576385498, Last lagvar Loss: 0.8204752206802368\n",
      "Step 6678/10000- lr: [3.3535619393939394e-06] - Loss total: 2.589921712875366, Last rpr Loss: 0.9713724851608276, Last lagvar Loss: 0.8752371072769165\n",
      "Step 6679/10000- lr: [3.352551842424242e-06] - Loss total: 2.589923143386841, Last rpr Loss: 1.0304718017578125, Last lagvar Loss: 0.8161621689796448\n",
      "Step 6680/10000- lr: [3.351541745454546e-06] - Loss total: 2.5900235176086426, Last rpr Loss: 0.9687323570251465, Last lagvar Loss: 0.8780418634414673\n",
      "Step 6681/10000- lr: [3.3505316484848484e-06] - Loss total: 2.589839220046997, Last rpr Loss: 1.0301101207733154, Last lagvar Loss: 0.8164905309677124\n",
      "Step 6682/10000- lr: [3.3495215515151517e-06] - Loss total: 2.589709758758545, Last rpr Loss: 0.9729297757148743, Last lagvar Loss: 0.8735663890838623\n",
      "Step 6683/10000- lr: [3.348511454545454e-06] - Loss total: 2.5893940925598145, Last rpr Loss: 1.0219297409057617, Last lagvar Loss: 0.8242559432983398\n",
      "Step 6684/10000- lr: [3.3475013575757582e-06] - Loss total: 2.58914852142334, Last rpr Loss: 0.9849409461021423, Last lagvar Loss: 0.8610144853591919\n",
      "Step 6685/10000- lr: [3.3464912606060607e-06] - Loss total: 2.588954448699951, Last rpr Loss: 1.0075757503509521, Last lagvar Loss: 0.8382011651992798\n",
      "Step 6686/10000- lr: [3.345481163636364e-06] - Loss total: 2.5888760089874268, Last rpr Loss: 1.0002634525299072, Last lagvar Loss: 0.8454575538635254\n",
      "Step 6687/10000- lr: [3.3444710666666664e-06] - Loss total: 2.5888965129852295, Last rpr Loss: 0.9929589033126831, Last lagvar Loss: 0.8528114557266235\n",
      "Step 6688/10000- lr: [3.3434609696969696e-06] - Loss total: 2.588968276977539, Last rpr Loss: 1.0125139951705933, Last lagvar Loss: 0.8333606123924255\n",
      "Step 6689/10000- lr: [3.342450872727272e-06] - Loss total: 2.5890495777130127, Last rpr Loss: 0.9838259220123291, Last lagvar Loss: 0.8621612787246704\n",
      "Step 6690/10000- lr: [3.341440775757576e-06] - Loss total: 2.5890581607818604, Last rpr Loss: 1.0175576210021973, Last lagvar Loss: 0.8284663558006287\n",
      "Step 6691/10000- lr: [3.3404306787878786e-06] - Loss total: 2.5890302658081055, Last rpr Loss: 0.9829223155975342, Last lagvar Loss: 0.863100528717041\n",
      "Step 6692/10000- lr: [3.339420581818182e-06] - Loss total: 2.5889172554016113, Last rpr Loss: 1.014544129371643, Last lagvar Loss: 0.8313850164413452\n",
      "Step 6693/10000- lr: [3.3384104848484843e-06] - Loss total: 2.5888023376464844, Last rpr Loss: 0.9893949627876282, Last lagvar Loss: 0.8564417958259583\n",
      "Step 6694/10000- lr: [3.3374003878787885e-06] - Loss total: 2.588698387145996, Last rpr Loss: 1.005882740020752, Last lagvar Loss: 0.8398706316947937\n",
      "Step 6695/10000- lr: [3.336390290909091e-06] - Loss total: 2.588639736175537, Last rpr Loss: 0.9991973042488098, Last lagvar Loss: 0.8465223908424377\n",
      "Step 6696/10000- lr: [3.335380193939394e-06] - Loss total: 2.588627338409424, Last rpr Loss: 0.9961999654769897, Last lagvar Loss: 0.8495339155197144\n",
      "Step 6697/10000- lr: [3.3343700969696966e-06] - Loss total: 2.5886409282684326, Last rpr Loss: 1.0074448585510254, Last lagvar Loss: 0.8383312821388245\n",
      "Step 6698/10000- lr: [3.33336e-06] - Loss total: 2.588658094406128, Last rpr Loss: 0.9899486303329468, Last lagvar Loss: 0.8558722734451294\n",
      "Step 6699/10000- lr: [3.3323499030303023e-06] - Loss total: 2.588648557662964, Last rpr Loss: 1.0109622478485107, Last lagvar Loss: 0.8348773717880249\n",
      "Step 6700/10000- lr: [3.3313398060606064e-06] - Loss total: 2.5886175632476807, Last rpr Loss: 0.9893603324890137, Last lagvar Loss: 0.8564727306365967\n",
      "Step 6701/10000- lr: [3.330329709090909e-06] - Loss total: 2.588557720184326, Last rpr Loss: 1.0090162754058838, Last lagvar Loss: 0.8367819786071777\n",
      "Step 6702/10000- lr: [3.329319612121212e-06] - Loss total: 2.5884952545166016, Last rpr Loss: 0.9936749935150146, Last lagvar Loss: 0.8520837426185608\n",
      "Step 6703/10000- lr: [3.3283095151515146e-06] - Loss total: 2.5884408950805664, Last rpr Loss: 1.0033025741577148, Last lagvar Loss: 0.8424260020256042\n",
      "Step 6704/10000- lr: [3.3272994181818187e-06] - Loss total: 2.588404655456543, Last rpr Loss: 0.999971866607666, Last lagvar Loss: 0.8457460403442383\n",
      "Step 6705/10000- lr: [3.326289321212121e-06] - Loss total: 2.588386058807373, Last rpr Loss: 0.9971189498901367, Last lagvar Loss: 0.8486068844795227\n",
      "Step 6706/10000- lr: [3.3252792242424244e-06] - Loss total: 2.588376760482788, Last rpr Loss: 1.0050599575042725, Last lagvar Loss: 0.8406834006309509\n",
      "Step 6707/10000- lr: [3.324269127272727e-06] - Loss total: 2.588366985321045, Last rpr Loss: 0.9934263229370117, Last lagvar Loss: 0.8523344993591309\n",
      "Step 6708/10000- lr: [3.32325903030303e-06] - Loss total: 2.5883469581604004, Last rpr Loss: 1.0069859027862549, Last lagvar Loss: 0.8387809991836548\n",
      "Step 6709/10000- lr: [3.3222489333333325e-06] - Loss total: 2.588317394256592, Last rpr Loss: 0.9933560490608215, Last lagvar Loss: 0.8524065613746643\n",
      "Step 6710/10000- lr: [3.3212388363636367e-06] - Loss total: 2.5882773399353027, Last rpr Loss: 1.0055396556854248, Last lagvar Loss: 0.8402087688446045\n",
      "Step 6711/10000- lr: [3.320228739393939e-06] - Loss total: 2.5882370471954346, Last rpr Loss: 0.9961528778076172, Last lagvar Loss: 0.8495798110961914\n",
      "Step 6712/10000- lr: [3.3192186424242424e-06] - Loss total: 2.588200092315674, Last rpr Loss: 1.0019792318344116, Last lagvar Loss: 0.8437419533729553\n",
      "Step 6713/10000- lr: [3.318208545454545e-06] - Loss total: 2.588170289993286, Last rpr Loss: 0.9999983906745911, Last lagvar Loss: 0.8457188010215759\n",
      "Step 6714/10000- lr: [3.317198448484849e-06] - Loss total: 2.5881478786468506, Last rpr Loss: 0.9982300996780396, Last lagvar Loss: 0.8474901914596558\n",
      "Step 6715/10000- lr: [3.3161883515151514e-06] - Loss total: 2.5881283283233643, Last rpr Loss: 1.0031169652938843, Last lagvar Loss: 0.8426101207733154\n",
      "Step 6716/10000- lr: [3.3151782545454546e-06] - Loss total: 2.588108777999878, Last rpr Loss: 0.9959152340888977, Last lagvar Loss: 0.8498187065124512\n",
      "Step 6717/10000- lr: [3.314168157575757e-06] - Loss total: 2.588085412979126, Last rpr Loss: 1.0044078826904297, Last lagvar Loss: 0.841328501701355\n",
      "Step 6718/10000- lr: [3.3131580606060603e-06] - Loss total: 2.5880584716796875, Last rpr Loss: 0.9957353472709656, Last lagvar Loss: 0.8499999046325684\n",
      "Step 6719/10000- lr: [3.3121479636363628e-06] - Loss total: 2.5880277156829834, Last rpr Loss: 1.003673791885376, Last lagvar Loss: 0.8420562744140625\n",
      "Step 6720/10000- lr: [3.311137866666667e-06] - Loss total: 2.587996244430542, Last rpr Loss: 0.9973198175430298, Last lagvar Loss: 0.8484041094779968\n",
      "Step 6721/10000- lr: [3.3101277696969693e-06] - Loss total: 2.587965488433838, Last rpr Loss: 1.0015608072280884, Last lagvar Loss: 0.8441580533981323\n",
      "Step 6722/10000- lr: [3.3091176727272726e-06] - Loss total: 2.587937593460083, Last rpr Loss: 0.9996678233146667, Last lagvar Loss: 0.8460487127304077\n",
      "Step 6723/10000- lr: [3.308107575757575e-06] - Loss total: 2.5879123210906982, Last rpr Loss: 0.9992016553878784, Last lagvar Loss: 0.846515417098999\n",
      "Step 6724/10000- lr: [3.307097478787879e-06] - Loss total: 2.587888479232788, Last rpr Loss: 1.0016822814941406, Last lagvar Loss: 0.8440369963645935\n",
      "Step 6725/10000- lr: [3.3060873818181816e-06] - Loss total: 2.587865114212036, Last rpr Loss: 0.9976147413253784, Last lagvar Loss: 0.8481072783470154\n",
      "Step 6726/10000- lr: [3.305077284848485e-06] - Loss total: 2.587841033935547, Last rpr Loss: 1.0026724338531494, Last lagvar Loss: 0.843051016330719\n",
      "Step 6727/10000- lr: [3.3040671878787873e-06] - Loss total: 2.587815523147583, Last rpr Loss: 0.9972521662712097, Last lagvar Loss: 0.8484715223312378\n",
      "Step 6728/10000- lr: [3.3030570909090906e-06] - Loss total: 2.5877883434295654, Last rpr Loss: 1.0024887323379517, Last lagvar Loss: 0.843233585357666\n",
      "Step 6729/10000- lr: [3.302046993939394e-06] - Loss total: 2.5877604484558105, Last rpr Loss: 0.9979820251464844, Last lagvar Loss: 0.8477381467819214\n",
      "Step 6730/10000- lr: [3.301036896969697e-06] - Loss total: 2.5877325534820557, Last rpr Loss: 1.001424789428711, Last lagvar Loss: 0.8442931175231934\n",
      "Step 6731/10000- lr: [3.3000267999999996e-06] - Loss total: 2.587705612182617, Last rpr Loss: 0.9992823004722595, Last lagvar Loss: 0.8464339971542358\n",
      "Step 6732/10000- lr: [3.299016703030303e-06] - Loss total: 2.587679386138916, Last rpr Loss: 1.0000323057174683, Last lagvar Loss: 0.8456834554672241\n",
      "Step 6733/10000- lr: [3.2980066060606053e-06] - Loss total: 2.587653875350952, Last rpr Loss: 1.000585913658142, Last lagvar Loss: 0.8451300859451294\n",
      "Step 6734/10000- lr: [3.2969965090909094e-06] - Loss total: 2.5876288414001465, Last rpr Loss: 0.9988828897476196, Last lagvar Loss: 0.8468340635299683\n",
      "Step 6735/10000- lr: [3.295986412121212e-06] - Loss total: 2.587603807449341, Last rpr Loss: 1.0014560222625732, Last lagvar Loss: 0.844261646270752\n",
      "Step 6736/10000- lr: [3.294976315151515e-06] - Loss total: 2.5875790119171143, Last rpr Loss: 0.9983407258987427, Last lagvar Loss: 0.8473776578903198\n",
      "Step 6737/10000- lr: [3.2939662181818175e-06] - Loss total: 2.5875532627105713, Last rpr Loss: 1.001675009727478, Last lagvar Loss: 0.8440432548522949\n",
      "Step 6738/10000- lr: [3.292956121212121e-06] - Loss total: 2.587526798248291, Last rpr Loss: 0.9984616041183472, Last lagvar Loss: 0.8472563028335571\n",
      "Step 6739/10000- lr: [3.291946024242424e-06] - Loss total: 2.5875003337860107, Last rpr Loss: 1.0012747049331665, Last lagvar Loss: 0.8444421291351318\n",
      "Step 6740/10000- lr: [3.2909359272727274e-06] - Loss total: 2.5874741077423096, Last rpr Loss: 0.9990688562393188, Last lagvar Loss: 0.846647322177887\n",
      "Step 6741/10000- lr: [3.2899258303030298e-06] - Loss total: 2.5874478816986084, Last rpr Loss: 1.0005347728729248, Last lagvar Loss: 0.8451807498931885\n",
      "Step 6742/10000- lr: [3.288915733333333e-06] - Loss total: 2.5874221324920654, Last rpr Loss: 0.9998519420623779, Last lagvar Loss: 0.8458632230758667\n",
      "Step 6743/10000- lr: [3.2879056363636355e-06] - Loss total: 2.5873959064483643, Last rpr Loss: 0.9997609853744507, Last lagvar Loss: 0.845954179763794\n",
      "Step 6744/10000- lr: [3.2868955393939396e-06] - Loss total: 2.5873708724975586, Last rpr Loss: 1.0005292892456055, Last lagvar Loss: 0.8451859951019287\n",
      "Step 6745/10000- lr: [3.285885442424242e-06] - Loss total: 2.5873453617095947, Last rpr Loss: 0.999221682548523, Last lagvar Loss: 0.8464939594268799\n",
      "Step 6746/10000- lr: [3.2848753454545453e-06] - Loss total: 2.58732008934021, Last rpr Loss: 1.0009195804595947, Last lagvar Loss: 0.8447960615158081\n",
      "Step 6747/10000- lr: [3.2838652484848478e-06] - Loss total: 2.587294101715088, Last rpr Loss: 0.9990113377571106, Last lagvar Loss: 0.8467045426368713\n",
      "Step 6748/10000- lr: [3.282855151515151e-06] - Loss total: 2.587268352508545, Last rpr Loss: 1.0009640455245972, Last lagvar Loss: 0.8447515964508057\n",
      "Step 6749/10000- lr: [3.2818450545454543e-06] - Loss total: 2.587242841720581, Last rpr Loss: 0.9991275668144226, Last lagvar Loss: 0.8465879559516907\n",
      "Step 6750/10000- lr: [3.2808349575757576e-06] - Loss total: 2.587216854095459, Last rpr Loss: 1.0007151365280151, Last lagvar Loss: 0.8449999094009399\n",
      "Step 6751/10000- lr: [3.27982486060606e-06] - Loss total: 2.587191104888916, Last rpr Loss: 0.9994661808013916, Last lagvar Loss: 0.8462487459182739\n",
      "Step 6752/10000- lr: [3.2788147636363633e-06] - Loss total: 2.587165117263794, Last rpr Loss: 1.0003046989440918, Last lagvar Loss: 0.8454098105430603\n",
      "Step 6753/10000- lr: [3.2778046666666657e-06] - Loss total: 2.58713960647583, Last rpr Loss: 0.9998937845230103, Last lagvar Loss: 0.8458206653594971\n",
      "Step 6754/10000- lr: [3.27679456969697e-06] - Loss total: 2.587113618850708, Last rpr Loss: 0.9998869299888611, Last lagvar Loss: 0.8458274602890015\n",
      "Step 6755/10000- lr: [3.275784472727273e-06] - Loss total: 2.587088108062744, Last rpr Loss: 1.0002797842025757, Last lagvar Loss: 0.8454345464706421\n",
      "Step 6756/10000- lr: [3.2747743757575756e-06] - Loss total: 2.5870628356933594, Last rpr Loss: 0.9995777606964111, Last lagvar Loss: 0.8461366891860962\n",
      "Step 6757/10000- lr: [3.273764278787879e-06] - Loss total: 2.5870373249053955, Last rpr Loss: 1.0005165338516235, Last lagvar Loss: 0.8451979756355286\n",
      "Step 6758/10000- lr: [3.2727541818181813e-06] - Loss total: 2.5870113372802734, Last rpr Loss: 0.9994325637817383, Last lagvar Loss: 0.846281886100769\n",
      "Step 6759/10000- lr: [3.2717440848484854e-06] - Loss total: 2.5869858264923096, Last rpr Loss: 1.0005732774734497, Last lagvar Loss: 0.8451411128044128\n",
      "Step 6760/10000- lr: [3.270733987878788e-06] - Loss total: 2.586960554122925, Last rpr Loss: 0.9994531869888306, Last lagvar Loss: 0.8462611436843872\n",
      "Step 6761/10000- lr: [3.269723890909091e-06] - Loss total: 2.5869345664978027, Last rpr Loss: 1.0004730224609375, Last lagvar Loss: 0.8452411890029907\n",
      "Step 6762/10000- lr: [3.2687137939393935e-06] - Loss total: 2.586909055709839, Last rpr Loss: 0.999595046043396, Last lagvar Loss: 0.8461190462112427\n",
      "Step 6763/10000- lr: [3.2677036969696976e-06] - Loss total: 2.586883306503296, Last rpr Loss: 1.0002862215042114, Last lagvar Loss: 0.8454277515411377\n",
      "Step 6764/10000- lr: [3.2666936e-06] - Loss total: 2.586857795715332, Last rpr Loss: 0.9998130798339844, Last lagvar Loss: 0.8459007740020752\n",
      "Step 6765/10000- lr: [3.2656835030303034e-06] - Loss total: 2.586832046508789, Last rpr Loss: 1.0000677108764648, Last lagvar Loss: 0.8456461429595947\n",
      "Step 6766/10000- lr: [3.2646734060606058e-06] - Loss total: 2.586806535720825, Last rpr Loss: 1.000032663345337, Last lagvar Loss: 0.8456809520721436\n",
      "Step 6767/10000- lr: [3.263663309090909e-06] - Loss total: 2.5867810249328613, Last rpr Loss: 0.9998713731765747, Last lagvar Loss: 0.845842182636261\n",
      "Step 6768/10000- lr: [3.2626532121212115e-06] - Loss total: 2.5867552757263184, Last rpr Loss: 1.000197410583496, Last lagvar Loss: 0.8455162644386292\n",
      "Step 6769/10000- lr: [3.2616431151515156e-06] - Loss total: 2.5867300033569336, Last rpr Loss: 0.9997365474700928, Last lagvar Loss: 0.8459771275520325\n",
      "Step 6770/10000- lr: [3.260633018181818e-06] - Loss total: 2.5867040157318115, Last rpr Loss: 1.000292420387268, Last lagvar Loss: 0.8454211950302124\n",
      "Step 6771/10000- lr: [3.2596229212121213e-06] - Loss total: 2.5866787433624268, Last rpr Loss: 0.9996829032897949, Last lagvar Loss: 0.846030592918396\n",
      "Step 6772/10000- lr: [3.2586128242424237e-06] - Loss total: 2.586652994155884, Last rpr Loss: 1.0003092288970947, Last lagvar Loss: 0.845404326915741\n",
      "Step 6773/10000- lr: [3.257602727272728e-06] - Loss total: 2.58662748336792, Last rpr Loss: 0.9997003674507141, Last lagvar Loss: 0.846013069152832\n",
      "Step 6774/10000- lr: [3.2565926303030303e-06] - Loss total: 2.586602210998535, Last rpr Loss: 1.0002553462982178, Last lagvar Loss: 0.845457911491394\n",
      "Step 6775/10000- lr: [3.2555825333333336e-06] - Loss total: 2.5865767002105713, Last rpr Loss: 0.9997751712799072, Last lagvar Loss: 0.8459380865097046\n",
      "Step 6776/10000- lr: [3.254572436363636e-06] - Loss total: 2.586550712585449, Last rpr Loss: 1.0001710653305054, Last lagvar Loss: 0.8455421328544617\n",
      "Step 6777/10000- lr: [3.2535623393939393e-06] - Loss total: 2.5865254402160645, Last rpr Loss: 0.9998750686645508, Last lagvar Loss: 0.8458381295204163\n",
      "Step 6778/10000- lr: [3.2525522424242426e-06] - Loss total: 2.5864999294281006, Last rpr Loss: 1.0000667572021484, Last lagvar Loss: 0.8456462025642395\n",
      "Step 6779/10000- lr: [3.251542145454546e-06] - Loss total: 2.5864741802215576, Last rpr Loss: 0.9999744892120361, Last lagvar Loss: 0.845738410949707\n",
      "Step 6780/10000- lr: [3.2505320484848483e-06] - Loss total: 2.586448907852173, Last rpr Loss: 0.9999713897705078, Last lagvar Loss: 0.8457416296005249\n",
      "Step 6781/10000- lr: [3.2495219515151515e-06] - Loss total: 2.58642315864563, Last rpr Loss: 1.0000600814819336, Last lagvar Loss: 0.8456528782844543\n",
      "Step 6782/10000- lr: [3.248511854545454e-06] - Loss total: 2.586397409439087, Last rpr Loss: 0.999901533126831, Last lagvar Loss: 0.8458113670349121\n",
      "Step 6783/10000- lr: [3.247501757575758e-06] - Loss total: 2.586372137069702, Last rpr Loss: 1.000117540359497, Last lagvar Loss: 0.8455952405929565\n",
      "Step 6784/10000- lr: [3.2464916606060605e-06] - Loss total: 2.5863468647003174, Last rpr Loss: 0.9998542070388794, Last lagvar Loss: 0.8458585143089294\n",
      "Step 6785/10000- lr: [3.245481563636364e-06] - Loss total: 2.5863213539123535, Last rpr Loss: 1.000148057937622, Last lagvar Loss: 0.845564603805542\n",
      "Step 6786/10000- lr: [3.2444714666666662e-06] - Loss total: 2.5862956047058105, Last rpr Loss: 0.9998366832733154, Last lagvar Loss: 0.8458759784698486\n",
      "Step 6787/10000- lr: [3.2434613696969695e-06] - Loss total: 2.5862700939178467, Last rpr Loss: 1.0001564025878906, Last lagvar Loss: 0.8455561995506287\n",
      "Step 6788/10000- lr: [3.242451272727273e-06] - Loss total: 2.5862443447113037, Last rpr Loss: 0.9998444318771362, Last lagvar Loss: 0.8458681702613831\n",
      "Step 6789/10000- lr: [3.241441175757576e-06] - Loss total: 2.586219072341919, Last rpr Loss: 1.0001369714736938, Last lagvar Loss: 0.8455755710601807\n",
      "Step 6790/10000- lr: [3.2404310787878785e-06] - Loss total: 2.586193561553955, Last rpr Loss: 0.9998694658279419, Last lagvar Loss: 0.8458430767059326\n",
      "Step 6791/10000- lr: [3.2394209818181818e-06] - Loss total: 2.5861682891845703, Last rpr Loss: 1.000105619430542, Last lagvar Loss: 0.845606803894043\n",
      "Step 6792/10000- lr: [3.238410884848484e-06] - Loss total: 2.5861425399780273, Last rpr Loss: 0.9999083280563354, Last lagvar Loss: 0.8458040952682495\n",
      "Step 6793/10000- lr: [3.2374007878787883e-06] - Loss total: 2.5861170291900635, Last rpr Loss: 1.0000638961791992, Last lagvar Loss: 0.8456485271453857\n",
      "Step 6794/10000- lr: [3.2363906909090908e-06] - Loss total: 2.5860915184020996, Last rpr Loss: 0.9999499320983887, Last lagvar Loss: 0.8457623720169067\n",
      "Step 6795/10000- lr: [3.235380593939394e-06] - Loss total: 2.5860660076141357, Last rpr Loss: 1.0000202655792236, Last lagvar Loss: 0.845691978931427\n",
      "Step 6796/10000- lr: [3.2343704969696965e-06] - Loss total: 2.586040735244751, Last rpr Loss: 0.9999892115592957, Last lagvar Loss: 0.845723032951355\n",
      "Step 6797/10000- lr: [3.2333603999999997e-06] - Loss total: 2.586014986038208, Last rpr Loss: 0.9999903440475464, Last lagvar Loss: 0.8457218408584595\n",
      "Step 6798/10000- lr: [3.232350303030303e-06] - Loss total: 2.585989236831665, Last rpr Loss: 1.0000174045562744, Last lagvar Loss: 0.8456946611404419\n",
      "Step 6799/10000- lr: [3.2313402060606063e-06] - Loss total: 2.585963726043701, Last rpr Loss: 0.9999605417251587, Last lagvar Loss: 0.8457515239715576\n",
      "Step 6800/10000- lr: [3.2303301090909087e-06] - Loss total: 2.5859384536743164, Last rpr Loss: 1.0000412464141846, Last lagvar Loss: 0.8456708788871765\n",
      "Step 6801/10000- lr: [3.229320012121212e-06] - Loss total: 2.5859129428863525, Last rpr Loss: 0.9999403357505798, Last lagvar Loss: 0.8457717299461365\n",
      "Step 6802/10000- lr: [3.2283099151515144e-06] - Loss total: 2.5858874320983887, Last rpr Loss: 1.0000600814819336, Last lagvar Loss: 0.8456518650054932\n",
      "Step 6803/10000- lr: [3.2272998181818186e-06] - Loss total: 2.585862398147583, Last rpr Loss: 0.999930739402771, Last lagvar Loss: 0.8457813262939453\n",
      "Step 6804/10000- lr: [3.226289721212121e-06] - Loss total: 2.585836887359619, Last rpr Loss: 1.0000691413879395, Last lagvar Loss: 0.8456428050994873\n",
      "Step 6805/10000- lr: [3.2252796242424243e-06] - Loss total: 2.585810899734497, Last rpr Loss: 0.9999209046363831, Last lagvar Loss: 0.8457909822463989\n",
      "Step 6806/10000- lr: [3.2242695272727267e-06] - Loss total: 2.5857856273651123, Last rpr Loss: 1.0000700950622559, Last lagvar Loss: 0.8456418514251709\n",
      "Step 6807/10000- lr: [3.22325943030303e-06] - Loss total: 2.5857605934143066, Last rpr Loss: 0.999923825263977, Last lagvar Loss: 0.8457881212234497\n",
      "Step 6808/10000- lr: [3.2222493333333333e-06] - Loss total: 2.5857346057891846, Last rpr Loss: 1.0000603199005127, Last lagvar Loss: 0.8456514477729797\n",
      "Step 6809/10000- lr: [3.2212392363636365e-06] - Loss total: 2.585709571838379, Last rpr Loss: 0.9999358654022217, Last lagvar Loss: 0.8457759022712708\n",
      "Step 6810/10000- lr: [3.220229139393939e-06] - Loss total: 2.585684061050415, Last rpr Loss: 1.0000560283660889, Last lagvar Loss: 0.8456556797027588\n",
      "Step 6811/10000- lr: [3.2192190424242422e-06] - Loss total: 2.585658311843872, Last rpr Loss: 0.9999421238899231, Last lagvar Loss: 0.8457695841789246\n",
      "Step 6812/10000- lr: [3.2182089454545447e-06] - Loss total: 2.5856332778930664, Last rpr Loss: 1.000046968460083, Last lagvar Loss: 0.8456647396087646\n",
      "Step 6813/10000- lr: [3.217198848484849e-06] - Loss total: 2.5856080055236816, Last rpr Loss: 0.9999529123306274, Last lagvar Loss: 0.8457586765289307\n",
      "Step 6814/10000- lr: [3.2161887515151512e-06] - Loss total: 2.5855822563171387, Last rpr Loss: 1.000041127204895, Last lagvar Loss: 0.8456705808639526\n",
      "Step 6815/10000- lr: [3.2151786545454545e-06] - Loss total: 2.585556745529175, Last rpr Loss: 0.9999526739120483, Last lagvar Loss: 0.8457589149475098\n",
      "Step 6816/10000- lr: [3.214168557575757e-06] - Loss total: 2.58553147315979, Last rpr Loss: 1.0000288486480713, Last lagvar Loss: 0.8456826210021973\n",
      "Step 6817/10000- lr: [3.21315846060606e-06] - Loss total: 2.5855062007904053, Last rpr Loss: 0.999968945980072, Last lagvar Loss: 0.8457425832748413\n",
      "Step 6818/10000- lr: [3.2121483636363635e-06] - Loss total: 2.5854806900024414, Last rpr Loss: 1.0000157356262207, Last lagvar Loss: 0.8456956744194031\n",
      "Step 6819/10000- lr: [3.2111382666666668e-06] - Loss total: 2.5854554176330566, Last rpr Loss: 0.9999877214431763, Last lagvar Loss: 0.8457237482070923\n",
      "Step 6820/10000- lr: [3.210128169696969e-06] - Loss total: 2.5854299068450928, Last rpr Loss: 0.9999992251396179, Last lagvar Loss: 0.8457121849060059\n",
      "Step 6821/10000- lr: [3.2091180727272725e-06] - Loss total: 2.585404634475708, Last rpr Loss: 0.9999979734420776, Last lagvar Loss: 0.8457134366035461\n",
      "Step 6822/10000- lr: [3.208107975757575e-06] - Loss total: 2.5853793621063232, Last rpr Loss: 0.9999918341636658, Last lagvar Loss: 0.8457194566726685\n",
      "Step 6823/10000- lr: [3.207097878787879e-06] - Loss total: 2.5853538513183594, Last rpr Loss: 1.0000073909759521, Last lagvar Loss: 0.8457038402557373\n",
      "Step 6824/10000- lr: [3.2060877818181815e-06] - Loss total: 2.5853283405303955, Last rpr Loss: 0.9999780058860779, Last lagvar Loss: 0.8457332849502563\n",
      "Step 6825/10000- lr: [3.2050776848484847e-06] - Loss total: 2.58530330657959, Last rpr Loss: 1.000020146369934, Last lagvar Loss: 0.8456910848617554\n",
      "Step 6826/10000- lr: [3.204067587878787e-06] - Loss total: 2.585277795791626, Last rpr Loss: 0.9999657869338989, Last lagvar Loss: 0.8457453846931458\n",
      "Step 6827/10000- lr: [3.2030574909090904e-06] - Loss total: 2.585252523422241, Last rpr Loss: 1.0000276565551758, Last lagvar Loss: 0.8456835746765137\n",
      "Step 6828/10000- lr: [3.2020473939393937e-06] - Loss total: 2.5852272510528564, Last rpr Loss: 0.9999595284461975, Last lagvar Loss: 0.8457515835762024\n",
      "Step 6829/10000- lr: [3.201037296969697e-06] - Loss total: 2.5852019786834717, Last rpr Loss: 1.00004243850708, Last lagvar Loss: 0.8456686735153198\n",
      "Step 6830/10000- lr: [3.2000271999999994e-06] - Loss total: 2.5851762294769287, Last rpr Loss: 0.9999468922615051, Last lagvar Loss: 0.8457642197608948\n",
      "Step 6831/10000- lr: [3.1990171030303027e-06] - Loss total: 2.585151195526123, Last rpr Loss: 1.0000498294830322, Last lagvar Loss: 0.8456611633300781\n",
      "Step 6832/10000- lr: [3.198007006060605e-06] - Loss total: 2.5851259231567383, Last rpr Loss: 0.9999366998672485, Last lagvar Loss: 0.8457742929458618\n",
      "Step 6833/10000- lr: [3.1969969090909093e-06] - Loss total: 2.5851008892059326, Last rpr Loss: 1.000063180923462, Last lagvar Loss: 0.8456478118896484\n",
      "Step 6834/10000- lr: [3.1959868121212117e-06] - Loss total: 2.5850751399993896, Last rpr Loss: 0.9999202489852905, Last lagvar Loss: 0.845790684223175\n",
      "Step 6835/10000- lr: [3.194976715151515e-06] - Loss total: 2.585049867630005, Last rpr Loss: 1.0000807046890259, Last lagvar Loss: 0.8456300497055054\n",
      "Step 6836/10000- lr: [3.1939666181818174e-06] - Loss total: 2.585024833679199, Last rpr Loss: 0.9999017715454102, Last lagvar Loss: 0.8458091020584106\n",
      "Step 6837/10000- lr: [3.1929565212121215e-06] - Loss total: 2.5849995613098145, Last rpr Loss: 1.0000982284545898, Last lagvar Loss: 0.845612645149231\n",
      "Step 6838/10000- lr: [3.191946424242424e-06] - Loss total: 2.5849742889404297, Last rpr Loss: 0.9998853802680969, Last lagvar Loss: 0.8458253741264343\n",
      "Step 6839/10000- lr: [3.1909363272727272e-06] - Loss total: 2.584949016571045, Last rpr Loss: 1.000121831893921, Last lagvar Loss: 0.8455888032913208\n",
      "Step 6840/10000- lr: [3.1899262303030296e-06] - Loss total: 2.5849239826202393, Last rpr Loss: 0.9998564124107361, Last lagvar Loss: 0.8458543419837952\n",
      "Step 6841/10000- lr: [3.188916133333333e-06] - Loss total: 2.5848989486694336, Last rpr Loss: 1.0001519918441772, Last lagvar Loss: 0.8455587029457092\n",
      "Step 6842/10000- lr: [3.187906036363637e-06] - Loss total: 2.5848734378814697, Last rpr Loss: 0.9998171329498291, Last lagvar Loss: 0.8458935618400574\n",
      "Step 6843/10000- lr: [3.1868959393939395e-06] - Loss total: 2.584848403930664, Last rpr Loss: 1.0001935958862305, Last lagvar Loss: 0.8455171585083008\n",
      "Step 6844/10000- lr: [3.1858858424242428e-06] - Loss total: 2.5848228931427, Last rpr Loss: 0.9997782707214355, Last lagvar Loss: 0.8459323644638062\n",
      "Step 6845/10000- lr: [3.184875745454545e-06] - Loss total: 2.5847980976104736, Last rpr Loss: 1.0002444982528687, Last lagvar Loss: 0.8454660177230835\n",
      "Step 6846/10000- lr: [3.1838656484848485e-06] - Loss total: 2.584773063659668, Last rpr Loss: 0.9997199773788452, Last lagvar Loss: 0.8459905385971069\n",
      "Step 6847/10000- lr: [3.1828555515151517e-06] - Loss total: 2.5847482681274414, Last rpr Loss: 1.0003011226654053, Last lagvar Loss: 0.8454093933105469\n",
      "Step 6848/10000- lr: [3.181845454545455e-06] - Loss total: 2.5847222805023193, Last rpr Loss: 0.9996567964553833, Last lagvar Loss: 0.8460537791252136\n",
      "Step 6849/10000- lr: [3.1808353575757574e-06] - Loss total: 2.5846970081329346, Last rpr Loss: 1.0003727674484253, Last lagvar Loss: 0.8453377485275269\n",
      "Step 6850/10000- lr: [3.1798252606060607e-06] - Loss total: 2.584672212600708, Last rpr Loss: 0.9995708465576172, Last lagvar Loss: 0.846139669418335\n",
      "Step 6851/10000- lr: [3.178815163636363e-06] - Loss total: 2.5846471786499023, Last rpr Loss: 1.0004792213439941, Last lagvar Loss: 0.8452313542366028\n",
      "Step 6852/10000- lr: [3.1778050666666673e-06] - Loss total: 2.5846221446990967, Last rpr Loss: 0.9994502067565918, Last lagvar Loss: 0.8462604284286499\n",
      "Step 6853/10000- lr: [3.1767949696969697e-06] - Loss total: 2.584597110748291, Last rpr Loss: 1.0006208419799805, Last lagvar Loss: 0.8450895547866821\n",
      "Step 6854/10000- lr: [3.175784872727273e-06] - Loss total: 2.5845723152160645, Last rpr Loss: 0.99927818775177, Last lagvar Loss: 0.846432626247406\n",
      "Step 6855/10000- lr: [3.1747747757575754e-06] - Loss total: 2.5845468044281006, Last rpr Loss: 1.0008245706558228, Last lagvar Loss: 0.8448861837387085\n",
      "Step 6856/10000- lr: [3.1737646787878787e-06] - Loss total: 2.584522247314453, Last rpr Loss: 0.9990370273590088, Last lagvar Loss: 0.8466742038726807\n",
      "Step 6857/10000- lr: [3.172754581818182e-06] - Loss total: 2.5844972133636475, Last rpr Loss: 1.0011056661605835, Last lagvar Loss: 0.8446055054664612\n",
      "Step 6858/10000- lr: [3.1717444848484852e-06] - Loss total: 2.584472894668579, Last rpr Loss: 0.9987096190452576, Last lagvar Loss: 0.8470022678375244\n",
      "Step 6859/10000- lr: [3.1707343878787877e-06] - Loss total: 2.5844483375549316, Last rpr Loss: 1.0014891624450684, Last lagvar Loss: 0.8442229628562927\n",
      "Step 6860/10000- lr: [3.169724290909091e-06] - Loss total: 2.5844242572784424, Last rpr Loss: 0.9982576966285706, Last lagvar Loss: 0.8474555611610413\n",
      "Step 6861/10000- lr: [3.1687141939393934e-06] - Loss total: 2.584400177001953, Last rpr Loss: 1.0020287036895752, Last lagvar Loss: 0.8436851501464844\n",
      "Step 6862/10000- lr: [3.1677040969696975e-06] - Loss total: 2.584376335144043, Last rpr Loss: 0.9976149797439575, Last lagvar Loss: 0.848101019859314\n",
      "Step 6863/10000- lr: [3.166694e-06] - Loss total: 2.5843536853790283, Last rpr Loss: 1.0027947425842285, Last lagvar Loss: 0.8429228067398071\n",
      "Step 6864/10000- lr: [3.1656839030303032e-06] - Loss total: 2.584331750869751, Last rpr Loss: 0.9966987371444702, Last lagvar Loss: 0.8490227460861206\n",
      "Step 6865/10000- lr: [3.1646738060606056e-06] - Loss total: 2.58431077003479, Last rpr Loss: 1.0038871765136719, Last lagvar Loss: 0.8418376445770264\n",
      "Step 6866/10000- lr: [3.163663709090909e-06] - Loss total: 2.584291696548462, Last rpr Loss: 0.9953939318656921, Last lagvar Loss: 0.850338339805603\n",
      "Step 6867/10000- lr: [3.162653612121212e-06] - Loss total: 2.5842747688293457, Last rpr Loss: 1.005444884300232, Last lagvar Loss: 0.840294599533081\n",
      "Step 6868/10000- lr: [3.1616435151515155e-06] - Loss total: 2.5842621326446533, Last rpr Loss: 0.9935388565063477, Last lagvar Loss: 0.8522151708602905\n",
      "Step 6869/10000- lr: [3.160633418181818e-06] - Loss total: 2.5842525959014893, Last rpr Loss: 1.007659912109375, Last lagvar Loss: 0.8381088972091675\n",
      "Step 6870/10000- lr: [3.159623321212121e-06] - Loss total: 2.5842530727386475, Last rpr Loss: 0.9909012913703918, Last lagvar Loss: 0.8548964262008667\n",
      "Step 6871/10000- lr: [3.1586132242424236e-06] - Loss total: 2.5842583179473877, Last rpr Loss: 1.0107886791229248, Last lagvar Loss: 0.835038423538208\n",
      "Step 6872/10000- lr: [3.1576031272727277e-06] - Loss total: 2.5842840671539307, Last rpr Loss: 0.9872133135795593, Last lagvar Loss: 0.8586705923080444\n",
      "Step 6873/10000- lr: [3.15659303030303e-06] - Loss total: 2.5843138694763184, Last rpr Loss: 1.0150905847549438, Last lagvar Loss: 0.8308478593826294\n",
      "Step 6874/10000- lr: [3.1555829333333334e-06] - Loss total: 2.584386110305786, Last rpr Loss: 0.9822743535041809, Last lagvar Loss: 0.8637713193893433\n",
      "Step 6875/10000- lr: [3.154572836363636e-06] - Loss total: 2.5844478607177734, Last rpr Loss: 1.0206036567687988, Last lagvar Loss: 0.8255283832550049\n",
      "Step 6876/10000- lr: [3.153562739393939e-06] - Loss total: 2.584584951400757, Last rpr Loss: 0.9763278365135193, Last lagvar Loss: 0.8699830770492554\n",
      "Step 6877/10000- lr: [3.1525526424242424e-06] - Loss total: 2.584656000137329, Last rpr Loss: 1.0266032218933105, Last lagvar Loss: 0.819800853729248\n",
      "Step 6878/10000- lr: [3.1515425454545457e-06] - Loss total: 2.5848300457000732, Last rpr Loss: 0.9708012342453003, Last lagvar Loss: 0.8758233189582825\n",
      "Step 6879/10000- lr: [3.150532448484848e-06] - Loss total: 2.5848121643066406, Last rpr Loss: 1.0307183265686035, Last lagvar Loss: 0.8159025311470032\n",
      "Step 6880/10000- lr: [3.1495223515151514e-06] - Loss total: 2.5848782062530518, Last rpr Loss: 0.9690585136413574, Last lagvar Loss: 0.8776692748069763\n",
      "Step 6881/10000- lr: [3.148512254545454e-06] - Loss total: 2.5846593379974365, Last rpr Loss: 1.028972864151001, Last lagvar Loss: 0.8175368905067444\n",
      "Step 6882/10000- lr: [3.147502157575758e-06] - Loss total: 2.5844829082489014, Last rpr Loss: 0.975040078163147, Last lagvar Loss: 0.8713188767433167\n",
      "Step 6883/10000- lr: [3.1464920606060604e-06] - Loss total: 2.584174394607544, Last rpr Loss: 1.0189427137374878, Last lagvar Loss: 0.827107310295105\n",
      "Step 6884/10000- lr: [3.1454819636363637e-06] - Loss total: 2.583949565887451, Last rpr Loss: 0.9886533617973328, Last lagvar Loss: 0.8571882247924805\n",
      "Step 6885/10000- lr: [3.144471866666666e-06] - Loss total: 2.5838143825531006, Last rpr Loss: 1.0035594701766968, Last lagvar Loss: 0.8421623706817627\n",
      "Step 6886/10000- lr: [3.1434617696969694e-06] - Loss total: 2.5837948322296143, Last rpr Loss: 1.0041594505310059, Last lagvar Loss: 0.8415671586990356\n",
      "Step 6887/10000- lr: [3.1424516727272727e-06] - Loss total: 2.583857774734497, Last rpr Loss: 0.9895370006561279, Last lagvar Loss: 0.8562827110290527\n",
      "Step 6888/10000- lr: [3.141441575757576e-06] - Loss total: 2.5839359760284424, Last rpr Loss: 1.0150091648101807, Last lagvar Loss: 0.8309176564216614\n",
      "Step 6889/10000- lr: [3.1404314787878784e-06] - Loss total: 2.5839996337890625, Last rpr Loss: 0.982455313205719, Last lagvar Loss: 0.863566517829895\n",
      "Step 6890/10000- lr: [3.1394213818181816e-06] - Loss total: 2.5839650630950928, Last rpr Loss: 1.0175647735595703, Last lagvar Loss: 0.8284422159194946\n",
      "Step 6891/10000- lr: [3.138411284848484e-06] - Loss total: 2.5838940143585205, Last rpr Loss: 0.9843437671661377, Last lagvar Loss: 0.8616180419921875\n",
      "Step 6892/10000- lr: [3.137401187878788e-06] - Loss total: 2.583765745162964, Last rpr Loss: 1.011914849281311, Last lagvar Loss: 0.8339319229125977\n",
      "Step 6893/10000- lr: [3.1363910909090906e-06] - Loss total: 2.5836570262908936, Last rpr Loss: 0.9930217266082764, Last lagvar Loss: 0.8527385592460632\n",
      "Step 6894/10000- lr: [3.135380993939394e-06] - Loss total: 2.5835886001586914, Last rpr Loss: 1.001801609992981, Last lagvar Loss: 0.8439101576805115\n",
      "Step 6895/10000- lr: [3.1343708969696963e-06] - Loss total: 2.583570718765259, Last rpr Loss: 1.0031929016113281, Last lagvar Loss: 0.8425256013870239\n",
      "Step 6896/10000- lr: [3.1333608000000005e-06] - Loss total: 2.583587408065796, Last rpr Loss: 0.9927005171775818, Last lagvar Loss: 0.8530619144439697\n",
      "Step 6897/10000- lr: [3.132350703030303e-06] - Loss total: 2.583606004714966, Last rpr Loss: 1.009892225265503, Last lagvar Loss: 0.8359140157699585\n",
      "Step 6898/10000- lr: [3.131340606060606e-06] - Loss total: 2.5836095809936523, Last rpr Loss: 0.988754391670227, Last lagvar Loss: 0.8570820689201355\n",
      "Step 6899/10000- lr: [3.1303305090909086e-06] - Loss total: 2.58357310295105, Last rpr Loss: 1.010786771774292, Last lagvar Loss: 0.8350358605384827\n",
      "Step 6900/10000- lr: [3.129320412121212e-06] - Loss total: 2.5835189819335938, Last rpr Loss: 0.9909558296203613, Last lagvar Loss: 0.8548352122306824\n",
      "Step 6901/10000- lr: [3.1283103151515143e-06] - Loss total: 2.58345365524292, Last rpr Loss: 1.006385087966919, Last lagvar Loss: 0.8393614888191223\n",
      "Step 6902/10000- lr: [3.1273002181818184e-06] - Loss total: 2.5834007263183594, Last rpr Loss: 0.9970784783363342, Last lagvar Loss: 0.8486380577087402\n",
      "Step 6903/10000- lr: [3.126290121212121e-06] - Loss total: 2.583369255065918, Last rpr Loss: 0.9996073842048645, Last lagvar Loss: 0.8461004495620728\n",
      "Step 6904/10000- lr: [3.125280024242424e-06] - Loss total: 2.5833563804626465, Last rpr Loss: 1.0034127235412598, Last lagvar Loss: 0.8423062562942505\n",
      "Step 6905/10000- lr: [3.1242699272727266e-06] - Loss total: 2.5833518505096436, Last rpr Loss: 0.9942278861999512, Last lagvar Loss: 0.8515127897262573\n",
      "Step 6906/10000- lr: [3.1232598303030307e-06] - Loss total: 2.5833423137664795, Last rpr Loss: 1.0069509744644165, Last lagvar Loss: 0.838803768157959\n",
      "Step 6907/10000- lr: [3.122249733333333e-06] - Loss total: 2.5833232402801514, Last rpr Loss: 0.9926909804344177, Last lagvar Loss: 0.8530697822570801\n",
      "Step 6908/10000- lr: [3.1212396363636364e-06] - Loss total: 2.5832889080047607, Last rpr Loss: 1.0065490007400513, Last lagvar Loss: 0.8392000198364258\n",
      "Step 6909/10000- lr: [3.120229539393939e-06] - Loss total: 2.583249807357788, Last rpr Loss: 0.9949692487716675, Last lagvar Loss: 0.8507637977600098\n",
      "Step 6910/10000- lr: [3.119219442424242e-06] - Loss total: 2.5832107067108154, Last rpr Loss: 1.003096342086792, Last lagvar Loss: 0.8426200151443481\n",
      "Step 6911/10000- lr: [3.1182093454545445e-06] - Loss total: 2.583178758621216, Last rpr Loss: 0.9991573691368103, Last lagvar Loss: 0.846550703048706\n",
      "Step 6912/10000- lr: [3.1171992484848487e-06] - Loss total: 2.583155393600464, Last rpr Loss: 0.9988080263137817, Last lagvar Loss: 0.846900463104248\n",
      "Step 6913/10000- lr: [3.116189151515151e-06] - Loss total: 2.5831377506256104, Last rpr Loss: 1.0028774738311768, Last lagvar Loss: 0.8428375720977783\n",
      "Step 6914/10000- lr: [3.1151790545454544e-06] - Loss total: 2.5831220149993896, Last rpr Loss: 0.9959002137184143, Last lagvar Loss: 0.8498237133026123\n",
      "Step 6915/10000- lr: [3.114168957575757e-06] - Loss total: 2.5831024646759033, Last rpr Loss: 1.0045745372772217, Last lagvar Loss: 0.8411531448364258\n",
      "Step 6916/10000- lr: [3.113158860606061e-06] - Loss total: 2.583078145980835, Last rpr Loss: 0.9954458475112915, Last lagvar Loss: 0.8502823114395142\n",
      "Step 6917/10000- lr: [3.1121487636363634e-06] - Loss total: 2.5830490589141846, Last rpr Loss: 1.0039223432540894, Last lagvar Loss: 0.841799259185791\n",
      "Step 6918/10000- lr: [3.1111386666666666e-06] - Loss total: 2.5830187797546387, Last rpr Loss: 0.9971410036087036, Last lagvar Loss: 0.8485742211341858\n",
      "Step 6919/10000- lr: [3.110128569696969e-06] - Loss total: 2.5829899311065674, Last rpr Loss: 1.0016347169876099, Last lagvar Loss: 0.8440742492675781\n",
      "Step 6920/10000- lr: [3.1091184727272723e-06] - Loss total: 2.582963466644287, Last rpr Loss: 0.9997595548629761, Last lagvar Loss: 0.8459469676017761\n",
      "Step 6921/10000- lr: [3.1081083757575748e-06] - Loss total: 2.5829405784606934, Last rpr Loss: 0.9990123510360718, Last lagvar Loss: 0.846695065498352\n",
      "Step 6922/10000- lr: [3.107098278787879e-06] - Loss total: 2.5829198360443115, Last rpr Loss: 1.0019862651824951, Last lagvar Loss: 0.8437238931655884\n",
      "Step 6923/10000- lr: [3.1060881818181813e-06] - Loss total: 2.5828990936279297, Last rpr Loss: 0.99729323387146, Last lagvar Loss: 0.8484206199645996\n",
      "Step 6924/10000- lr: [3.1050780848484846e-06] - Loss total: 2.5828769207000732, Last rpr Loss: 1.0029464960098267, Last lagvar Loss: 0.8427680730819702\n",
      "Step 6925/10000- lr: [3.104067987878787e-06] - Loss total: 2.582852840423584, Last rpr Loss: 0.9970815181732178, Last lagvar Loss: 0.8486332893371582\n",
      "Step 6926/10000- lr: [3.103057890909091e-06] - Loss total: 2.58282732963562, Last rpr Loss: 1.0024770498275757, Last lagvar Loss: 0.8432347774505615\n",
      "Step 6927/10000- lr: [3.1020477939393944e-06] - Loss total: 2.58280086517334, Last rpr Loss: 0.9981682300567627, Last lagvar Loss: 0.8475412130355835\n",
      "Step 6928/10000- lr: [3.101037696969697e-06] - Loss total: 2.5827748775482178, Last rpr Loss: 1.0010381937026978, Last lagvar Loss: 0.8446686267852783\n",
      "Step 6929/10000- lr: [3.1000276e-06] - Loss total: 2.5827505588531494, Last rpr Loss: 0.9998182058334351, Last lagvar Loss: 0.8458876609802246\n",
      "Step 6930/10000- lr: [3.0990175030303026e-06] - Loss total: 2.5827267169952393, Last rpr Loss: 0.9994245767593384, Last lagvar Loss: 0.8462815284729004\n",
      "Step 6931/10000- lr: [3.0980074060606067e-06] - Loss total: 2.5827043056488037, Last rpr Loss: 1.0012049674987793, Last lagvar Loss: 0.8445020914077759\n",
      "Step 6932/10000- lr: [3.096997309090909e-06] - Loss total: 2.582681894302368, Last rpr Loss: 0.9983491897583008, Last lagvar Loss: 0.847359299659729\n",
      "Step 6933/10000- lr: [3.0959872121212124e-06] - Loss total: 2.5826590061187744, Last rpr Loss: 1.0018455982208252, Last lagvar Loss: 0.8438631296157837\n",
      "Step 6934/10000- lr: [3.094977115151515e-06] - Loss total: 2.5826351642608643, Last rpr Loss: 0.9981503486633301, Last lagvar Loss: 0.8475587964057922\n",
      "Step 6935/10000- lr: [3.093967018181818e-06] - Loss total: 2.582611083984375, Last rpr Loss: 1.0016329288482666, Last lagvar Loss: 0.8440749049186707\n",
      "Step 6936/10000- lr: [3.0929569212121214e-06] - Loss total: 2.5825865268707275, Last rpr Loss: 0.9987161755561829, Last lagvar Loss: 0.8469910025596619\n",
      "Step 6937/10000- lr: [3.0919468242424247e-06] - Loss total: 2.582562208175659, Last rpr Loss: 1.0008333921432495, Last lagvar Loss: 0.8448725938796997\n",
      "Step 6938/10000- lr: [3.090936727272727e-06] - Loss total: 2.582537889480591, Last rpr Loss: 0.9996604919433594, Last lagvar Loss: 0.8460450172424316\n",
      "Step 6939/10000- lr: [3.0899266303030304e-06] - Loss total: 2.5825142860412598, Last rpr Loss: 0.9998576641082764, Last lagvar Loss: 0.8458476066589355\n",
      "Step 6940/10000- lr: [3.088916533333333e-06] - Loss total: 2.582491159439087, Last rpr Loss: 1.000551462173462, Last lagvar Loss: 0.8451539874076843\n",
      "Step 6941/10000- lr: [3.087906436363637e-06] - Loss total: 2.582468271255493, Last rpr Loss: 0.9991121292114258, Last lagvar Loss: 0.8465938568115234\n",
      "Step 6942/10000- lr: [3.0868963393939393e-06] - Loss total: 2.582444906234741, Last rpr Loss: 1.0010755062103271, Last lagvar Loss: 0.8446305990219116\n",
      "Step 6943/10000- lr: [3.0858862424242426e-06] - Loss total: 2.5824215412139893, Last rpr Loss: 0.998831033706665, Last lagvar Loss: 0.8468754291534424\n",
      "Step 6944/10000- lr: [3.084876145454545e-06] - Loss total: 2.582397937774658, Last rpr Loss: 1.0011098384857178, Last lagvar Loss: 0.8445961475372314\n",
      "Step 6945/10000- lr: [3.083866048484849e-06] - Loss total: 2.582374095916748, Last rpr Loss: 0.9990267753601074, Last lagvar Loss: 0.8466790318489075\n",
      "Step 6946/10000- lr: [3.0828559515151516e-06] - Loss total: 2.582350015640259, Last rpr Loss: 1.0007411241531372, Last lagvar Loss: 0.8449640870094299\n",
      "Step 6947/10000- lr: [3.081845854545455e-06] - Loss total: 2.582326650619507, Last rpr Loss: 0.9995316863059998, Last lagvar Loss: 0.8461733460426331\n",
      "Step 6948/10000- lr: [3.0808357575757573e-06] - Loss total: 2.5823025703430176, Last rpr Loss: 1.0001704692840576, Last lagvar Loss: 0.8455342054367065\n",
      "Step 6949/10000- lr: [3.0798256606060606e-06] - Loss total: 2.5822789669036865, Last rpr Loss: 1.0001025199890137, Last lagvar Loss: 0.8456020355224609\n",
      "Step 6950/10000- lr: [3.078815563636363e-06] - Loss total: 2.5822558403015137, Last rpr Loss: 0.9996451139450073, Last lagvar Loss: 0.8460595607757568\n",
      "Step 6951/10000- lr: [3.077805466666667e-06] - Loss total: 2.582232713699341, Last rpr Loss: 1.0005214214324951, Last lagvar Loss: 0.8451833128929138\n",
      "Step 6952/10000- lr: [3.0767953696969696e-06] - Loss total: 2.582209348678589, Last rpr Loss: 0.9993430376052856, Last lagvar Loss: 0.8463618755340576\n",
      "Step 6953/10000- lr: [3.075785272727273e-06] - Loss total: 2.582185983657837, Last rpr Loss: 1.0006864070892334, Last lagvar Loss: 0.8450185060501099\n",
      "Step 6954/10000- lr: [3.0747751757575753e-06] - Loss total: 2.582162618637085, Last rpr Loss: 0.9993239641189575, Last lagvar Loss: 0.8463809490203857\n",
      "Step 6955/10000- lr: [3.0737650787878794e-06] - Loss total: 2.582139253616333, Last rpr Loss: 1.000596046447754, Last lagvar Loss: 0.8451085090637207\n",
      "Step 6956/10000- lr: [3.072754981818182e-06] - Loss total: 2.582115650177002, Last rpr Loss: 0.9995251893997192, Last lagvar Loss: 0.8461792469024658\n",
      "Step 6957/10000- lr: [3.071744884848485e-06] - Loss total: 2.582092046737671, Last rpr Loss: 1.0003256797790527, Last lagvar Loss: 0.8453785181045532\n",
      "Step 6958/10000- lr: [3.0707347878787875e-06] - Loss total: 2.582068681716919, Last rpr Loss: 0.9998331069946289, Last lagvar Loss: 0.8458709716796875\n",
      "Step 6959/10000- lr: [3.069724690909091e-06] - Loss total: 2.582045316696167, Last rpr Loss: 0.9999988675117493, Last lagvar Loss: 0.8457052111625671\n",
      "Step 6960/10000- lr: [3.0687145939393933e-06] - Loss total: 2.5820224285125732, Last rpr Loss: 1.0001317262649536, Last lagvar Loss: 0.8455719947814941\n",
      "Step 6961/10000- lr: [3.0677044969696974e-06] - Loss total: 2.581998825073242, Last rpr Loss: 0.9997338056564331, Last lagvar Loss: 0.8459702134132385\n",
      "Step 6962/10000- lr: [3.0666944e-06] - Loss total: 2.5819756984710693, Last rpr Loss: 1.0003330707550049, Last lagvar Loss: 0.845370888710022\n",
      "Step 6963/10000- lr: [3.065684303030303e-06] - Loss total: 2.5819520950317383, Last rpr Loss: 0.9996024370193481, Last lagvar Loss: 0.8461014032363892\n",
      "Step 6964/10000- lr: [3.0646742060606055e-06] - Loss total: 2.5819287300109863, Last rpr Loss: 1.000404715538025, Last lagvar Loss: 0.8452990651130676\n",
      "Step 6965/10000- lr: [3.0636641090909096e-06] - Loss total: 2.5819056034088135, Last rpr Loss: 0.9996094107627869, Last lagvar Loss: 0.8460943698883057\n",
      "Step 6966/10000- lr: [3.062654012121212e-06] - Loss total: 2.5818822383880615, Last rpr Loss: 1.0003427267074585, Last lagvar Loss: 0.8453609347343445\n",
      "Step 6967/10000- lr: [3.0616439151515153e-06] - Loss total: 2.5818588733673096, Last rpr Loss: 0.999714732170105, Last lagvar Loss: 0.8459887504577637\n",
      "Step 6968/10000- lr: [3.0606338181818178e-06] - Loss total: 2.5818355083465576, Last rpr Loss: 1.000194787979126, Last lagvar Loss: 0.8455085754394531\n",
      "Step 6969/10000- lr: [3.059623721212121e-06] - Loss total: 2.5818121433258057, Last rpr Loss: 0.9998821020126343, Last lagvar Loss: 0.8458212614059448\n",
      "Step 6970/10000- lr: [3.0586136242424235e-06] - Loss total: 2.581789016723633, Last rpr Loss: 1.0000152587890625, Last lagvar Loss: 0.8456880450248718\n",
      "Step 6971/10000- lr: [3.0576035272727276e-06] - Loss total: 2.58176589012146, Last rpr Loss: 1.0000537633895874, Last lagvar Loss: 0.8456494808197021\n",
      "Step 6972/10000- lr: [3.05659343030303e-06] - Loss total: 2.581742525100708, Last rpr Loss: 0.999871015548706, Last lagvar Loss: 0.845832109451294\n",
      "Step 6973/10000- lr: [3.0555833333333333e-06] - Loss total: 2.581719160079956, Last rpr Loss: 1.0001726150512695, Last lagvar Loss: 0.8455305099487305\n",
      "Step 6974/10000- lr: [3.0545732363636357e-06] - Loss total: 2.5816962718963623, Last rpr Loss: 0.9997822642326355, Last lagvar Loss: 0.8459208607673645\n",
      "Step 6975/10000- lr: [3.05356313939394e-06] - Loss total: 2.5816731452941895, Last rpr Loss: 1.000226378440857, Last lagvar Loss: 0.8454766273498535\n",
      "Step 6976/10000- lr: [3.0525530424242423e-06] - Loss total: 2.5816497802734375, Last rpr Loss: 0.9997647404670715, Last lagvar Loss: 0.8459383249282837\n",
      "Step 6977/10000- lr: [3.0515429454545456e-06] - Loss total: 2.5816261768341064, Last rpr Loss: 1.0002092123031616, Last lagvar Loss: 0.8454936742782593\n",
      "Step 6978/10000- lr: [3.050532848484848e-06] - Loss total: 2.5816032886505127, Last rpr Loss: 0.9998077750205994, Last lagvar Loss: 0.8458950519561768\n",
      "Step 6979/10000- lr: [3.0495227515151513e-06] - Loss total: 2.5815799236297607, Last rpr Loss: 1.0001481771469116, Last lagvar Loss: 0.8455545902252197\n",
      "Step 6980/10000- lr: [3.0485126545454537e-06] - Loss total: 2.581556797027588, Last rpr Loss: 0.9998780488967896, Last lagvar Loss: 0.8458247184753418\n",
      "Step 6981/10000- lr: [3.047502557575758e-06] - Loss total: 2.581533670425415, Last rpr Loss: 1.0000696182250977, Last lagvar Loss: 0.8456330299377441\n",
      "Step 6982/10000- lr: [3.0464924606060603e-06] - Loss total: 2.581510543823242, Last rpr Loss: 0.9999629259109497, Last lagvar Loss: 0.8457396030426025\n",
      "Step 6983/10000- lr: [3.0454823636363635e-06] - Loss total: 2.5814874172210693, Last rpr Loss: 0.9999874234199524, Last lagvar Loss: 0.8457150459289551\n",
      "Step 6984/10000- lr: [3.044472266666666e-06] - Loss total: 2.5814640522003174, Last rpr Loss: 1.0000431537628174, Last lagvar Loss: 0.8456593751907349\n",
      "Step 6985/10000- lr: [3.04346216969697e-06] - Loss total: 2.5814411640167236, Last rpr Loss: 0.9999176859855652, Last lagvar Loss: 0.8457847237586975\n",
      "Step 6986/10000- lr: [3.0424520727272725e-06] - Loss total: 2.581418037414551, Last rpr Loss: 1.0000920295715332, Last lagvar Loss: 0.8456102609634399\n",
      "Step 6987/10000- lr: [3.041441975757576e-06] - Loss total: 2.581395149230957, Last rpr Loss: 0.9998810291290283, Last lagvar Loss: 0.8458212614059448\n",
      "Step 6988/10000- lr: [3.0404318787878782e-06] - Loss total: 2.581371784210205, Last rpr Loss: 1.0001163482666016, Last lagvar Loss: 0.8455859422683716\n",
      "Step 6989/10000- lr: [3.0394217818181815e-06] - Loss total: 2.5813488960266113, Last rpr Loss: 0.9998714923858643, Last lagvar Loss: 0.8458306789398193\n",
      "Step 6990/10000- lr: [3.038411684848484e-06] - Loss total: 2.5813257694244385, Last rpr Loss: 1.0001111030578613, Last lagvar Loss: 0.8455909490585327\n",
      "Step 6991/10000- lr: [3.037401587878788e-06] - Loss total: 2.5813021659851074, Last rpr Loss: 0.9998957514762878, Last lagvar Loss: 0.845806360244751\n",
      "Step 6992/10000- lr: [3.0363914909090905e-06] - Loss total: 2.5812792778015137, Last rpr Loss: 1.000077247619629, Last lagvar Loss: 0.8456248044967651\n",
      "Step 6993/10000- lr: [3.0353813939393938e-06] - Loss total: 2.58125638961792, Last rpr Loss: 0.999931812286377, Last lagvar Loss: 0.8457701206207275\n",
      "Step 6994/10000- lr: [3.034371296969696e-06] - Loss total: 2.581233263015747, Last rpr Loss: 1.0000399351119995, Last lagvar Loss: 0.8456618785858154\n",
      "Step 6995/10000- lr: [3.0333612000000003e-06] - Loss total: 2.5812103748321533, Last rpr Loss: 0.9999659657478333, Last lagvar Loss: 0.8457359075546265\n",
      "Step 6996/10000- lr: [3.0323511030303028e-06] - Loss total: 2.5811872482299805, Last rpr Loss: 1.0000070333480835, Last lagvar Loss: 0.8456946611404419\n",
      "Step 6997/10000- lr: [3.031341006060606e-06] - Loss total: 2.5811641216278076, Last rpr Loss: 0.9999992847442627, Last lagvar Loss: 0.8457023501396179\n",
      "Step 6998/10000- lr: [3.0303309090909085e-06] - Loss total: 2.5811409950256348, Last rpr Loss: 0.9999758005142212, Last lagvar Loss: 0.8457258343696594\n",
      "Step 6999/10000- lr: [3.0293208121212117e-06] - Loss total: 2.581117868423462, Last rpr Loss: 1.0000269412994385, Last lagvar Loss: 0.8456745147705078\n",
      "Step 7000/10000- lr: [3.028310715151514e-06] - Loss total: 2.581094980239868, Last rpr Loss: 0.9999531507492065, Last lagvar Loss: 0.8457483649253845\n",
      "Step 7001/10000- lr: [3.0273006181818183e-06] - Loss total: 2.5810723304748535, Last rpr Loss: 1.0000410079956055, Last lagvar Loss: 0.8456604480743408\n",
      "Step 7002/10000- lr: [3.0262905212121207e-06] - Loss total: 2.5810494422912598, Last rpr Loss: 0.9999420642852783, Last lagvar Loss: 0.845759391784668\n",
      "Step 7003/10000- lr: [3.025280424242424e-06] - Loss total: 2.581026315689087, Last rpr Loss: 1.0000486373901367, Last lagvar Loss: 0.8456526398658752\n",
      "Step 7004/10000- lr: [3.0242703272727264e-06] - Loss total: 2.581002950668335, Last rpr Loss: 0.999948263168335, Last lagvar Loss: 0.8457530736923218\n",
      "Step 7005/10000- lr: [3.0232602303030306e-06] - Loss total: 2.580980062484741, Last rpr Loss: 1.0000406503677368, Last lagvar Loss: 0.8456606864929199\n",
      "Step 7006/10000- lr: [3.022250133333333e-06] - Loss total: 2.5809569358825684, Last rpr Loss: 0.9999538064002991, Last lagvar Loss: 0.8457473516464233\n",
      "Step 7007/10000- lr: [3.0212400363636363e-06] - Loss total: 2.5809340476989746, Last rpr Loss: 1.0000306367874146, Last lagvar Loss: 0.8456704020500183\n",
      "Step 7008/10000- lr: [3.0202299393939387e-06] - Loss total: 2.58091139793396, Last rpr Loss: 0.9999582767486572, Last lagvar Loss: 0.8457427620887756\n",
      "Step 7009/10000- lr: [3.019219842424242e-06] - Loss total: 2.580888509750366, Last rpr Loss: 1.0000228881835938, Last lagvar Loss: 0.8456781506538391\n",
      "Step 7010/10000- lr: [3.0182097454545444e-06] - Loss total: 2.5808651447296143, Last rpr Loss: 0.9999735355377197, Last lagvar Loss: 0.8457273840904236\n",
      "Step 7011/10000- lr: [3.0171996484848485e-06] - Loss total: 2.5808424949645996, Last rpr Loss: 1.0000144243240356, Last lagvar Loss: 0.8456864356994629\n",
      "Step 7012/10000- lr: [3.016189551515152e-06] - Loss total: 2.5808193683624268, Last rpr Loss: 0.9999837279319763, Last lagvar Loss: 0.8457170724868774\n",
      "Step 7013/10000- lr: [3.0151794545454542e-06] - Loss total: 2.580796718597412, Last rpr Loss: 0.9999970197677612, Last lagvar Loss: 0.8457037210464478\n",
      "Step 7014/10000- lr: [3.0141693575757584e-06] - Loss total: 2.5807738304138184, Last rpr Loss: 1.0000016689300537, Last lagvar Loss: 0.8456990718841553\n",
      "Step 7015/10000- lr: [3.0131592606060608e-06] - Loss total: 2.5807509422302246, Last rpr Loss: 0.9999810457229614, Last lagvar Loss: 0.845719575881958\n",
      "Step 7016/10000- lr: [3.012149163636364e-06] - Loss total: 2.580728054046631, Last rpr Loss: 1.0000131130218506, Last lagvar Loss: 0.8456875681877136\n",
      "Step 7017/10000- lr: [3.0111390666666665e-06] - Loss total: 2.580704927444458, Last rpr Loss: 0.9999687075614929, Last lagvar Loss: 0.8457318544387817\n",
      "Step 7018/10000- lr: [3.0101289696969698e-06] - Loss total: 2.5806820392608643, Last rpr Loss: 1.0000224113464355, Last lagvar Loss: 0.8456779718399048\n",
      "Step 7019/10000- lr: [3.009118872727272e-06] - Loss total: 2.5806591510772705, Last rpr Loss: 0.9999687671661377, Last lagvar Loss: 0.8457316160202026\n",
      "Step 7020/10000- lr: [3.0081087757575763e-06] - Loss total: 2.580636501312256, Last rpr Loss: 1.0000227689743042, Last lagvar Loss: 0.8456776142120361\n",
      "Step 7021/10000- lr: [3.0070986787878788e-06] - Loss total: 2.580613851547241, Last rpr Loss: 0.9999662041664124, Last lagvar Loss: 0.8457341194152832\n",
      "Step 7022/10000- lr: [3.006088581818182e-06] - Loss total: 2.5805907249450684, Last rpr Loss: 1.0000252723693848, Last lagvar Loss: 0.8456751108169556\n",
      "Step 7023/10000- lr: [3.0050784848484845e-06] - Loss total: 2.5805678367614746, Last rpr Loss: 0.9999643564224243, Last lagvar Loss: 0.8457359075546265\n",
      "Step 7024/10000- lr: [3.0040683878787886e-06] - Loss total: 2.58054518699646, Last rpr Loss: 1.0000226497650146, Last lagvar Loss: 0.845677375793457\n",
      "Step 7025/10000- lr: [3.003058290909091e-06] - Loss total: 2.580522298812866, Last rpr Loss: 0.9999673366546631, Last lagvar Loss: 0.8457328081130981\n",
      "Step 7026/10000- lr: [3.0020481939393943e-06] - Loss total: 2.5804996490478516, Last rpr Loss: 1.0000170469284058, Last lagvar Loss: 0.8456828594207764\n",
      "Step 7027/10000- lr: [3.0010380969696967e-06] - Loss total: 2.580476999282837, Last rpr Loss: 0.9999751448631287, Last lagvar Loss: 0.845724880695343\n",
      "Step 7028/10000- lr: [3.000028e-06] - Loss total: 2.5804543495178223, Last rpr Loss: 1.0000145435333252, Last lagvar Loss: 0.8456854820251465\n",
      "Step 7029/10000- lr: [2.9990179030303024e-06] - Loss total: 2.5804312229156494, Last rpr Loss: 0.9999786615371704, Last lagvar Loss: 0.8457212448120117\n",
      "Step 7030/10000- lr: [2.9980078060606066e-06] - Loss total: 2.5804085731506348, Last rpr Loss: 1.0000104904174805, Last lagvar Loss: 0.8456892371177673\n",
      "Step 7031/10000- lr: [2.996997709090909e-06] - Loss total: 2.580385684967041, Last rpr Loss: 0.9999793767929077, Last lagvar Loss: 0.8457203507423401\n",
      "Step 7032/10000- lr: [2.9959876121212123e-06] - Loss total: 2.5803630352020264, Last rpr Loss: 1.0000064373016357, Last lagvar Loss: 0.8456932306289673\n",
      "Step 7033/10000- lr: [2.9949775151515147e-06] - Loss total: 2.5803401470184326, Last rpr Loss: 0.9999845027923584, Last lagvar Loss: 0.8457151651382446\n",
      "Step 7034/10000- lr: [2.993967418181819e-06] - Loss total: 2.580317258834839, Last rpr Loss: 0.9999997615814209, Last lagvar Loss: 0.8456999063491821\n",
      "Step 7035/10000- lr: [2.9929573212121212e-06] - Loss total: 2.5802948474884033, Last rpr Loss: 0.9999918341636658, Last lagvar Loss: 0.8457076549530029\n",
      "Step 7036/10000- lr: [2.9919472242424245e-06] - Loss total: 2.5802719593048096, Last rpr Loss: 0.9999998807907104, Last lagvar Loss: 0.8456996083259583\n",
      "Step 7037/10000- lr: [2.990937127272727e-06] - Loss total: 2.580249071121216, Last rpr Loss: 0.9999902248382568, Last lagvar Loss: 0.8457092046737671\n",
      "Step 7038/10000- lr: [2.9899270303030302e-06] - Loss total: 2.580226421356201, Last rpr Loss: 1.000001072883606, Last lagvar Loss: 0.8456982970237732\n",
      "Step 7039/10000- lr: [2.9889169333333327e-06] - Loss total: 2.5802037715911865, Last rpr Loss: 0.9999868869781494, Last lagvar Loss: 0.845712423324585\n",
      "Step 7040/10000- lr: [2.9879068363636368e-06] - Loss total: 2.580181121826172, Last rpr Loss: 1.0000003576278687, Last lagvar Loss: 0.8456988334655762\n",
      "Step 7041/10000- lr: [2.9868967393939392e-06] - Loss total: 2.5801584720611572, Last rpr Loss: 0.9999883770942688, Last lagvar Loss: 0.8457107543945312\n",
      "Step 7042/10000- lr: [2.9858866424242425e-06] - Loss total: 2.5801355838775635, Last rpr Loss: 0.9999989867210388, Last lagvar Loss: 0.8457001447677612\n",
      "Step 7043/10000- lr: [2.984876545454545e-06] - Loss total: 2.580112934112549, Last rpr Loss: 0.9999922513961792, Last lagvar Loss: 0.8457068204879761\n",
      "Step 7044/10000- lr: [2.983866448484849e-06] - Loss total: 2.5800905227661133, Last rpr Loss: 0.9999970197677612, Last lagvar Loss: 0.8457019329071045\n",
      "Step 7045/10000- lr: [2.9828563515151515e-06] - Loss total: 2.5800678730010986, Last rpr Loss: 0.9999947547912598, Last lagvar Loss: 0.8457042574882507\n",
      "Step 7046/10000- lr: [2.9818462545454548e-06] - Loss total: 2.580045223236084, Last rpr Loss: 0.9999945163726807, Last lagvar Loss: 0.8457044363021851\n",
      "Step 7047/10000- lr: [2.980836157575757e-06] - Loss total: 2.5800223350524902, Last rpr Loss: 0.9999950528144836, Last lagvar Loss: 0.8457037210464478\n",
      "Step 7048/10000- lr: [2.9798260606060605e-06] - Loss total: 2.5799994468688965, Last rpr Loss: 0.9999880790710449, Last lagvar Loss: 0.8457106351852417\n",
      "Step 7049/10000- lr: [2.978815963636363e-06] - Loss total: 2.579976797103882, Last rpr Loss: 1.0000033378601074, Last lagvar Loss: 0.845695436000824\n",
      "Step 7050/10000- lr: [2.977805866666667e-06] - Loss total: 2.5799543857574463, Last rpr Loss: 0.999984085559845, Last lagvar Loss: 0.8457145690917969\n",
      "Step 7051/10000- lr: [2.9767957696969694e-06] - Loss total: 2.5799319744110107, Last rpr Loss: 1.0000085830688477, Last lagvar Loss: 0.8456900119781494\n",
      "Step 7052/10000- lr: [2.9757856727272727e-06] - Loss total: 2.579909324645996, Last rpr Loss: 0.9999791383743286, Last lagvar Loss: 0.8457194566726685\n",
      "Step 7053/10000- lr: [2.974775575757575e-06] - Loss total: 2.5798866748809814, Last rpr Loss: 1.0000114440917969, Last lagvar Loss: 0.8456870317459106\n",
      "Step 7054/10000- lr: [2.9737654787878793e-06] - Loss total: 2.579864025115967, Last rpr Loss: 0.9999750852584839, Last lagvar Loss: 0.8457235097885132\n",
      "Step 7055/10000- lr: [2.9727553818181817e-06] - Loss total: 2.579841375350952, Last rpr Loss: 1.0000187158584595, Last lagvar Loss: 0.8456797003746033\n",
      "Step 7056/10000- lr: [2.971745284848485e-06] - Loss total: 2.5798187255859375, Last rpr Loss: 0.9999659657478333, Last lagvar Loss: 0.8457324504852295\n",
      "Step 7057/10000- lr: [2.9707351878787874e-06] - Loss total: 2.579796314239502, Last rpr Loss: 1.0000237226486206, Last lagvar Loss: 0.8456746339797974\n",
      "Step 7058/10000- lr: [2.9697250909090907e-06] - Loss total: 2.5797736644744873, Last rpr Loss: 0.9999643564224243, Last lagvar Loss: 0.8457338809967041\n",
      "Step 7059/10000- lr: [2.968714993939393e-06] - Loss total: 2.5797512531280518, Last rpr Loss: 1.0000336170196533, Last lagvar Loss: 0.8456646203994751\n",
      "Step 7060/10000- lr: [2.9677048969696972e-06] - Loss total: 2.579728364944458, Last rpr Loss: 0.9999486804008484, Last lagvar Loss: 0.8457494974136353\n",
      "Step 7061/10000- lr: [2.9666947999999997e-06] - Loss total: 2.5797057151794434, Last rpr Loss: 1.000040054321289, Last lagvar Loss: 0.8456579446792603\n",
      "Step 7062/10000- lr: [2.965684703030303e-06] - Loss total: 2.579683542251587, Last rpr Loss: 0.9999426603317261, Last lagvar Loss: 0.8457553386688232\n",
      "Step 7063/10000- lr: [2.9646746060606054e-06] - Loss total: 2.5796611309051514, Last rpr Loss: 1.0000513792037964, Last lagvar Loss: 0.8456466197967529\n",
      "Step 7064/10000- lr: [2.9636645090909095e-06] - Loss total: 2.579638719558716, Last rpr Loss: 0.9999353885650635, Last lagvar Loss: 0.8457626104354858\n",
      "Step 7065/10000- lr: [2.962654412121212e-06] - Loss total: 2.579615831375122, Last rpr Loss: 1.0000605583190918, Last lagvar Loss: 0.8456373810768127\n",
      "Step 7066/10000- lr: [2.9616443151515152e-06] - Loss total: 2.5795931816101074, Last rpr Loss: 0.9999246597290039, Last lagvar Loss: 0.8457732200622559\n",
      "Step 7067/10000- lr: [2.9606342181818176e-06] - Loss total: 2.579570770263672, Last rpr Loss: 1.0000696182250977, Last lagvar Loss: 0.8456282615661621\n",
      "Step 7068/10000- lr: [2.959624121212121e-06] - Loss total: 2.5795483589172363, Last rpr Loss: 0.9999092817306519, Last lagvar Loss: 0.8457884192466736\n",
      "Step 7069/10000- lr: [2.9586140242424234e-06] - Loss total: 2.5795257091522217, Last rpr Loss: 1.0000877380371094, Last lagvar Loss: 0.8456099629402161\n",
      "Step 7070/10000- lr: [2.9576039272727275e-06] - Loss total: 2.579503297805786, Last rpr Loss: 0.9998918175697327, Last lagvar Loss: 0.8458058834075928\n",
      "Step 7071/10000- lr: [2.95659383030303e-06] - Loss total: 2.5794806480407715, Last rpr Loss: 1.000108003616333, Last lagvar Loss: 0.8455897569656372\n",
      "Step 7072/10000- lr: [2.955583733333333e-06] - Loss total: 2.579458236694336, Last rpr Loss: 0.9998713731765747, Last lagvar Loss: 0.8458260297775269\n",
      "Step 7073/10000- lr: [2.9545736363636356e-06] - Loss total: 2.5794355869293213, Last rpr Loss: 1.000129222869873, Last lagvar Loss: 0.8455682396888733\n",
      "Step 7074/10000- lr: [2.9535635393939397e-06] - Loss total: 2.579413652420044, Last rpr Loss: 0.9998464584350586, Last lagvar Loss: 0.845850944519043\n",
      "Step 7075/10000- lr: [2.952553442424242e-06] - Loss total: 2.5793910026550293, Last rpr Loss: 1.0001550912857056, Last lagvar Loss: 0.8455421924591064\n",
      "Step 7076/10000- lr: [2.9515433454545454e-06] - Loss total: 2.5793685913085938, Last rpr Loss: 0.9998162388801575, Last lagvar Loss: 0.8458812236785889\n",
      "Step 7077/10000- lr: [2.950533248484848e-06] - Loss total: 2.579345941543579, Last rpr Loss: 1.0001988410949707, Last lagvar Loss: 0.8454985022544861\n",
      "Step 7078/10000- lr: [2.949523151515151e-06] - Loss total: 2.5793237686157227, Last rpr Loss: 0.9997652769088745, Last lagvar Loss: 0.845932126045227\n",
      "Step 7079/10000- lr: [2.9485130545454536e-06] - Loss total: 2.579301118850708, Last rpr Loss: 1.0002498626708984, Last lagvar Loss: 0.8454474806785583\n",
      "Step 7080/10000- lr: [2.9475029575757577e-06] - Loss total: 2.5792787075042725, Last rpr Loss: 0.9997010231018066, Last lagvar Loss: 0.8459962606430054\n",
      "Step 7081/10000- lr: [2.94649286060606e-06] - Loss total: 2.579256296157837, Last rpr Loss: 1.0003242492675781, Last lagvar Loss: 0.8453729152679443\n",
      "Step 7082/10000- lr: [2.9454827636363634e-06] - Loss total: 2.5792341232299805, Last rpr Loss: 0.9996245503425598, Last lagvar Loss: 0.8460726737976074\n",
      "Step 7083/10000- lr: [2.944472666666666e-06] - Loss total: 2.579211473464966, Last rpr Loss: 1.0004173517227173, Last lagvar Loss: 0.84527987241745\n",
      "Step 7084/10000- lr: [2.94346256969697e-06] - Loss total: 2.5791893005371094, Last rpr Loss: 0.9995158910751343, Last lagvar Loss: 0.8461813926696777\n",
      "Step 7085/10000- lr: [2.9424524727272724e-06] - Loss total: 2.579167127609253, Last rpr Loss: 1.0005388259887695, Last lagvar Loss: 0.8451582789421082\n",
      "Step 7086/10000- lr: [2.9414423757575757e-06] - Loss total: 2.5791447162628174, Last rpr Loss: 0.999364972114563, Last lagvar Loss: 0.8463324308395386\n",
      "Step 7087/10000- lr: [2.940432278787878e-06] - Loss total: 2.579122304916382, Last rpr Loss: 1.0007171630859375, Last lagvar Loss: 0.844980001449585\n",
      "Step 7088/10000- lr: [2.9394221818181814e-06] - Loss total: 2.5791001319885254, Last rpr Loss: 0.9991663694381714, Last lagvar Loss: 0.8465311527252197\n",
      "Step 7089/10000- lr: [2.938412084848484e-06] - Loss total: 2.579077959060669, Last rpr Loss: 1.000952124595642, Last lagvar Loss: 0.844745397567749\n",
      "Step 7090/10000- lr: [2.937401987878788e-06] - Loss total: 2.57905650138855, Last rpr Loss: 0.9988816380500793, Last lagvar Loss: 0.8468164205551147\n",
      "Step 7091/10000- lr: [2.9363918909090904e-06] - Loss total: 2.5790340900421143, Last rpr Loss: 1.001286506652832, Last lagvar Loss: 0.8444117307662964\n",
      "Step 7092/10000- lr: [2.9353817939393936e-06] - Loss total: 2.579012155532837, Last rpr Loss: 0.9984921216964722, Last lagvar Loss: 0.8472069501876831\n",
      "Step 7093/10000- lr: [2.934371696969696e-06] - Loss total: 2.5789904594421387, Last rpr Loss: 1.001746654510498, Last lagvar Loss: 0.8439528942108154\n",
      "Step 7094/10000- lr: [2.9333616e-06] - Loss total: 2.5789692401885986, Last rpr Loss: 0.9979442358016968, Last lagvar Loss: 0.8477568030357361\n",
      "Step 7095/10000- lr: [2.9323515030303026e-06] - Loss total: 2.578948736190796, Last rpr Loss: 1.002396583557129, Last lagvar Loss: 0.8433055877685547\n",
      "Step 7096/10000- lr: [2.931341406060606e-06] - Loss total: 2.5789284706115723, Last rpr Loss: 0.9971755743026733, Last lagvar Loss: 0.8485293388366699\n",
      "Step 7097/10000- lr: [2.930331309090909e-06] - Loss total: 2.578908681869507, Last rpr Loss: 1.0033098459243774, Last lagvar Loss: 0.8423974514007568\n",
      "Step 7098/10000- lr: [2.9293212121212116e-06] - Loss total: 2.5788912773132324, Last rpr Loss: 0.996087908744812, Last lagvar Loss: 0.8496246337890625\n",
      "Step 7099/10000- lr: [2.9283111151515157e-06] - Loss total: 2.578874111175537, Last rpr Loss: 1.0046013593673706, Last lagvar Loss: 0.8411162495613098\n",
      "Step 7100/10000- lr: [2.927301018181818e-06] - Loss total: 2.5788607597351074, Last rpr Loss: 0.9945510625839233, Last lagvar Loss: 0.8511766195297241\n",
      "Step 7101/10000- lr: [2.9262909212121214e-06] - Loss total: 2.5788493156433105, Last rpr Loss: 1.0064336061477661, Last lagvar Loss: 0.8393043279647827\n",
      "Step 7102/10000- lr: [2.925280824242424e-06] - Loss total: 2.5788440704345703, Last rpr Loss: 0.9923741817474365, Last lagvar Loss: 0.853383481502533\n",
      "Step 7103/10000- lr: [2.924270727272728e-06] - Loss total: 2.578843116760254, Last rpr Loss: 1.009016990661621, Last lagvar Loss: 0.8367612957954407\n",
      "Step 7104/10000- lr: [2.9232606303030304e-06] - Loss total: 2.57885479927063, Last rpr Loss: 0.9893271923065186, Last lagvar Loss: 0.8564896583557129\n",
      "Step 7105/10000- lr: [2.9222505333333337e-06] - Loss total: 2.578871488571167, Last rpr Loss: 1.0125700235366821, Last lagvar Loss: 0.8332852125167847\n",
      "Step 7106/10000- lr: [2.921240436363636e-06] - Loss total: 2.5789151191711426, Last rpr Loss: 0.9852269291877747, Last lagvar Loss: 0.8607009649276733\n",
      "Step 7107/10000- lr: [2.9202303393939394e-06] - Loss total: 2.5789566040039062, Last rpr Loss: 1.017216444015503, Last lagvar Loss: 0.8287757039070129\n",
      "Step 7108/10000- lr: [2.919220242424242e-06] - Loss total: 2.5790486335754395, Last rpr Loss: 0.9801062941551208, Last lagvar Loss: 0.8660112619400024\n",
      "Step 7109/10000- lr: [2.918210145454546e-06] - Loss total: 2.579108715057373, Last rpr Loss: 1.0225930213928223, Last lagvar Loss: 0.8236070871353149\n",
      "Step 7110/10000- lr: [2.9172000484848484e-06] - Loss total: 2.579244375228882, Last rpr Loss: 0.9747980833053589, Last lagvar Loss: 0.871575117111206\n",
      "Step 7111/10000- lr: [2.9161899515151517e-06] - Loss total: 2.57926869392395, Last rpr Loss: 1.0271880626678467, Last lagvar Loss: 0.8192269802093506\n",
      "Step 7112/10000- lr: [2.915179854545454e-06] - Loss total: 2.5793652534484863, Last rpr Loss: 0.9716396927833557, Last lagvar Loss: 0.8749090433120728\n",
      "Step 7113/10000- lr: [2.9141697575757582e-06] - Loss total: 2.5792510509490967, Last rpr Loss: 1.0279102325439453, Last lagvar Loss: 0.8185319900512695\n",
      "Step 7114/10000- lr: [2.9131596606060607e-06] - Loss total: 2.5791726112365723, Last rpr Loss: 0.974187433719635, Last lagvar Loss: 0.8722032308578491\n",
      "Step 7115/10000- lr: [2.912149563636364e-06] - Loss total: 2.578923463821411, Last rpr Loss: 1.0216901302337646, Last lagvar Loss: 0.8244519233703613\n",
      "Step 7116/10000- lr: [2.9111394666666664e-06] - Loss total: 2.5787179470062256, Last rpr Loss: 0.9841257333755493, Last lagvar Loss: 0.8618266582489014\n",
      "Step 7117/10000- lr: [2.9101293696969696e-06] - Loss total: 2.5785319805145264, Last rpr Loss: 1.0091626644134521, Last lagvar Loss: 0.8366122245788574\n",
      "Step 7118/10000- lr: [2.909119272727272e-06] - Loss total: 2.5784387588500977, Last rpr Loss: 0.9981096982955933, Last lagvar Loss: 0.8475902080535889\n",
      "Step 7119/10000- lr: [2.908109175757576e-06] - Loss total: 2.5784342288970947, Last rpr Loss: 0.9953572750091553, Last lagvar Loss: 0.8503609299659729\n",
      "Step 7120/10000- lr: [2.9070990787878786e-06] - Loss total: 2.578486442565918, Last rpr Loss: 1.0101629495620728, Last lagvar Loss: 0.8356327414512634\n",
      "Step 7121/10000- lr: [2.906088981818182e-06] - Loss total: 2.578556537628174, Last rpr Loss: 0.9859201908111572, Last lagvar Loss: 0.8599738478660583\n",
      "Step 7122/10000- lr: [2.9050788848484843e-06] - Loss total: 2.578578472137451, Last rpr Loss: 1.0159235000610352, Last lagvar Loss: 0.8300151824951172\n",
      "Step 7123/10000- lr: [2.9040687878787885e-06] - Loss total: 2.578568458557129, Last rpr Loss: 0.9840362071990967, Last lagvar Loss: 0.86191725730896\n",
      "Step 7124/10000- lr: [2.903058690909091e-06] - Loss total: 2.578483819961548, Last rpr Loss: 1.0139729976654053, Last lagvar Loss: 0.8319101929664612\n",
      "Step 7125/10000- lr: [2.902048593939394e-06] - Loss total: 2.578390121459961, Last rpr Loss: 0.9894649982452393, Last lagvar Loss: 0.8563448190689087\n",
      "Step 7126/10000- lr: [2.9010384969696966e-06] - Loss total: 2.5782978534698486, Last rpr Loss: 1.0062038898468018, Last lagvar Loss: 0.8395291566848755\n",
      "Step 7127/10000- lr: [2.9000284e-06] - Loss total: 2.578242540359497, Last rpr Loss: 0.9985487461090088, Last lagvar Loss: 0.8471490740776062\n",
      "Step 7128/10000- lr: [2.8990183030303023e-06] - Loss total: 2.578226089477539, Last rpr Loss: 0.997056782245636, Last lagvar Loss: 0.848646879196167\n",
      "Step 7129/10000- lr: [2.8980082060606064e-06] - Loss total: 2.5782361030578613, Last rpr Loss: 1.0064512491226196, Last lagvar Loss: 0.839285135269165\n",
      "Step 7130/10000- lr: [2.896998109090909e-06] - Loss total: 2.578251361846924, Last rpr Loss: 0.9910064339637756, Last lagvar Loss: 0.8547697067260742\n",
      "Step 7131/10000- lr: [2.895988012121212e-06] - Loss total: 2.578246831893921, Last rpr Loss: 1.0099509954452515, Last lagvar Loss: 0.8358425498008728\n",
      "Step 7132/10000- lr: [2.8949779151515146e-06] - Loss total: 2.57822322845459, Last rpr Loss: 0.9902650117874146, Last lagvar Loss: 0.8555262684822083\n",
      "Step 7133/10000- lr: [2.8939678181818187e-06] - Loss total: 2.578173875808716, Last rpr Loss: 1.008297324180603, Last lagvar Loss: 0.8374648094177246\n",
      "Step 7134/10000- lr: [2.892957721212121e-06] - Loss total: 2.5781216621398926, Last rpr Loss: 0.9941565990447998, Last lagvar Loss: 0.8515728712081909\n",
      "Step 7135/10000- lr: [2.8919476242424244e-06] - Loss total: 2.578075647354126, Last rpr Loss: 1.003054141998291, Last lagvar Loss: 0.8426492214202881\n",
      "Step 7136/10000- lr: [2.890937527272727e-06] - Loss total: 2.578045606613159, Last rpr Loss: 0.999986469745636, Last lagvar Loss: 0.8457080125808716\n",
      "Step 7137/10000- lr: [2.88992743030303e-06] - Loss total: 2.578031063079834, Last rpr Loss: 0.9972904920578003, Last lagvar Loss: 0.8484115600585938\n",
      "Step 7138/10000- lr: [2.8889173333333325e-06] - Loss total: 2.578024387359619, Last rpr Loss: 1.0047340393066406, Last lagvar Loss: 0.8409829139709473\n",
      "Step 7139/10000- lr: [2.8879072363636367e-06] - Loss total: 2.5780160427093506, Last rpr Loss: 0.9938579797744751, Last lagvar Loss: 0.8518739342689514\n",
      "Step 7140/10000- lr: [2.886897139393939e-06] - Loss total: 2.577998399734497, Last rpr Loss: 1.0064606666564941, Last lagvar Loss: 0.8392744660377502\n",
      "Step 7141/10000- lr: [2.8858870424242424e-06] - Loss total: 2.577972173690796, Last rpr Loss: 0.9939572215080261, Last lagvar Loss: 0.8517735004425049\n",
      "Step 7142/10000- lr: [2.884876945454545e-06] - Loss total: 2.5779378414154053, Last rpr Loss: 1.004887342453003, Last lagvar Loss: 0.8408299684524536\n",
      "Step 7143/10000- lr: [2.883866848484849e-06] - Loss total: 2.577904224395752, Last rpr Loss: 0.9968439340591431, Last lagvar Loss: 0.8488603830337524\n",
      "Step 7144/10000- lr: [2.8828567515151513e-06] - Loss total: 2.5778748989105225, Last rpr Loss: 1.0012967586517334, Last lagvar Loss: 0.8443989157676697\n",
      "Step 7145/10000- lr: [2.8818466545454546e-06] - Loss total: 2.577852487564087, Last rpr Loss: 1.0005991458892822, Last lagvar Loss: 0.8450952768325806\n",
      "Step 7146/10000- lr: [2.880836557575757e-06] - Loss total: 2.5778348445892334, Last rpr Loss: 0.9977614283561707, Last lagvar Loss: 0.8479375839233398\n",
      "Step 7147/10000- lr: [2.8798264606060603e-06] - Loss total: 2.577819585800171, Last rpr Loss: 1.0033520460128784, Last lagvar Loss: 0.8423528671264648\n",
      "Step 7148/10000- lr: [2.8788163636363628e-06] - Loss total: 2.5778026580810547, Last rpr Loss: 0.9959524869918823, Last lagvar Loss: 0.8497578501701355\n",
      "Step 7149/10000- lr: [2.877806266666667e-06] - Loss total: 2.577781915664673, Last rpr Loss: 1.0040936470031738, Last lagvar Loss: 0.841616690158844\n",
      "Step 7150/10000- lr: [2.8767961696969693e-06] - Loss total: 2.5777573585510254, Last rpr Loss: 0.9963243007659912, Last lagvar Loss: 0.8493834733963013\n",
      "Step 7151/10000- lr: [2.8757860727272726e-06] - Loss total: 2.577730894088745, Last rpr Loss: 1.002882480621338, Last lagvar Loss: 0.8428194522857666\n",
      "Step 7152/10000- lr: [2.874775975757575e-06] - Loss total: 2.577704668045044, Last rpr Loss: 0.998228132724762, Last lagvar Loss: 0.8474690318107605\n",
      "Step 7153/10000- lr: [2.873765878787879e-06] - Loss total: 2.5776801109313965, Last rpr Loss: 1.0006252527236938, Last lagvar Loss: 0.8450688123703003\n",
      "Step 7154/10000- lr: [2.8727557818181816e-06] - Loss total: 2.5776586532592773, Last rpr Loss: 1.000504970550537, Last lagvar Loss: 0.8451889753341675\n",
      "Step 7155/10000- lr: [2.871745684848485e-06] - Loss total: 2.57763934135437, Last rpr Loss: 0.9985204935073853, Last lagvar Loss: 0.8471754789352417\n",
      "Step 7156/10000- lr: [2.8707355878787873e-06] - Loss total: 2.577620506286621, Last rpr Loss: 1.0021229982376099, Last lagvar Loss: 0.843575119972229\n",
      "Step 7157/10000- lr: [2.8697254909090906e-06] - Loss total: 2.5776004791259766, Last rpr Loss: 0.9974461793899536, Last lagvar Loss: 0.8482540845870972\n",
      "Step 7158/10000- lr: [2.868715393939393e-06] - Loss total: 2.5775794982910156, Last rpr Loss: 1.0025646686553955, Last lagvar Loss: 0.8431353569030762\n",
      "Step 7159/10000- lr: [2.867705296969697e-06] - Loss total: 2.577556610107422, Last rpr Loss: 0.997646689414978, Last lagvar Loss: 0.8480525016784668\n",
      "Step 7160/10000- lr: [2.8666951999999995e-06] - Loss total: 2.577533483505249, Last rpr Loss: 1.0018653869628906, Last lagvar Loss: 0.8438314199447632\n",
      "Step 7161/10000- lr: [2.865685103030303e-06] - Loss total: 2.577510118484497, Last rpr Loss: 0.9987891316413879, Last lagvar Loss: 0.8469058275222778\n",
      "Step 7162/10000- lr: [2.8646750060606052e-06] - Loss total: 2.5774874687194824, Last rpr Loss: 1.0005066394805908, Last lagvar Loss: 0.8451869487762451\n",
      "Step 7163/10000- lr: [2.8636649090909094e-06] - Loss total: 2.5774660110473633, Last rpr Loss: 1.0002026557922363, Last lagvar Loss: 0.8454907536506653\n",
      "Step 7164/10000- lr: [2.862654812121212e-06] - Loss total: 2.5774450302124023, Last rpr Loss: 0.9991808533668518, Last lagvar Loss: 0.8465132117271423\n",
      "Step 7165/10000- lr: [2.861644715151515e-06] - Loss total: 2.5774242877960205, Last rpr Loss: 1.001265048980713, Last lagvar Loss: 0.8444298505783081\n",
      "Step 7166/10000- lr: [2.8606346181818175e-06] - Loss total: 2.5774037837982178, Last rpr Loss: 0.9984347820281982, Last lagvar Loss: 0.8472609519958496\n",
      "Step 7167/10000- lr: [2.8596245212121208e-06] - Loss total: 2.5773825645446777, Last rpr Loss: 1.0016329288482666, Last lagvar Loss: 0.8440626859664917\n",
      "Step 7168/10000- lr: [2.8586144242424232e-06] - Loss total: 2.5773608684539795, Last rpr Loss: 0.9984606504440308, Last lagvar Loss: 0.8472349643707275\n",
      "Step 7169/10000- lr: [2.8576043272727273e-06] - Loss total: 2.577338695526123, Last rpr Loss: 1.0012770891189575, Last lagvar Loss: 0.8444175720214844\n",
      "Step 7170/10000- lr: [2.8565942303030298e-06] - Loss total: 2.577316999435425, Last rpr Loss: 0.9990813732147217, Last lagvar Loss: 0.8466126322746277\n",
      "Step 7171/10000- lr: [2.855584133333333e-06] - Loss total: 2.5772945880889893, Last rpr Loss: 1.0004839897155762, Last lagvar Loss: 0.8452091217041016\n",
      "Step 7172/10000- lr: [2.8545740363636355e-06] - Loss total: 2.57727313041687, Last rpr Loss: 0.9999338388442993, Last lagvar Loss: 0.8457592129707336\n",
      "Step 7173/10000- lr: [2.8535639393939396e-06] - Loss total: 2.577251672744751, Last rpr Loss: 0.9996622800827026, Last lagvar Loss: 0.8460308313369751\n",
      "Step 7174/10000- lr: [2.852553842424242e-06] - Loss total: 2.577230930328369, Last rpr Loss: 1.0006420612335205, Last lagvar Loss: 0.8450512886047363\n",
      "Step 7175/10000- lr: [2.8515437454545453e-06] - Loss total: 2.577209949493408, Last rpr Loss: 0.9991230368614197, Last lagvar Loss: 0.8465706706047058\n",
      "Step 7176/10000- lr: [2.8505336484848477e-06] - Loss total: 2.577188730239868, Last rpr Loss: 1.0009701251983643, Last lagvar Loss: 0.8447235822677612\n",
      "Step 7177/10000- lr: [2.849523551515151e-06] - Loss total: 2.577167510986328, Last rpr Loss: 0.9990106225013733, Last lagvar Loss: 0.8466832637786865\n",
      "Step 7178/10000- lr: [2.8485134545454534e-06] - Loss total: 2.577146053314209, Last rpr Loss: 1.0008845329284668, Last lagvar Loss: 0.8448090553283691\n",
      "Step 7179/10000- lr: [2.8475033575757576e-06] - Loss total: 2.5771241188049316, Last rpr Loss: 0.9992775917053223, Last lagvar Loss: 0.8464157581329346\n",
      "Step 7180/10000- lr: [2.84649326060606e-06] - Loss total: 2.5771026611328125, Last rpr Loss: 1.000495195388794, Last lagvar Loss: 0.8451976180076599\n",
      "Step 7181/10000- lr: [2.8454831636363633e-06] - Loss total: 2.5770809650421143, Last rpr Loss: 0.9997384548187256, Last lagvar Loss: 0.8459542393684387\n",
      "Step 7182/10000- lr: [2.8444730666666674e-06] - Loss total: 2.5770599842071533, Last rpr Loss: 1.0000005960464478, Last lagvar Loss: 0.8456920981407166\n",
      "Step 7183/10000- lr: [2.84346296969697e-06] - Loss total: 2.577038526535034, Last rpr Loss: 1.0002094507217407, Last lagvar Loss: 0.8454832434654236\n",
      "Step 7184/10000- lr: [2.842452872727273e-06] - Loss total: 2.577017068862915, Last rpr Loss: 0.9995893239974976, Last lagvar Loss: 0.8461034893989563\n",
      "Step 7185/10000- lr: [2.8414427757575755e-06] - Loss total: 2.576995849609375, Last rpr Loss: 1.0005199909210205, Last lagvar Loss: 0.8451727628707886\n",
      "Step 7186/10000- lr: [2.840432678787879e-06] - Loss total: 2.576974391937256, Last rpr Loss: 0.9993987679481506, Last lagvar Loss: 0.8462941646575928\n",
      "Step 7187/10000- lr: [2.8394225818181812e-06] - Loss total: 2.576953172683716, Last rpr Loss: 1.0006000995635986, Last lagvar Loss: 0.8450926542282104\n",
      "Step 7188/10000- lr: [2.8384124848484854e-06] - Loss total: 2.576932191848755, Last rpr Loss: 0.9994447231292725, Last lagvar Loss: 0.8462480306625366\n",
      "Step 7189/10000- lr: [2.837402387878788e-06] - Loss total: 2.5769104957580566, Last rpr Loss: 1.000455379486084, Last lagvar Loss: 0.8452372550964355\n",
      "Step 7190/10000- lr: [2.836392290909091e-06] - Loss total: 2.5768890380859375, Last rpr Loss: 0.9996634125709534, Last lagvar Loss: 0.8460290431976318\n",
      "Step 7191/10000- lr: [2.8353821939393935e-06] - Loss total: 2.5768675804138184, Last rpr Loss: 1.0001859664916992, Last lagvar Loss: 0.8455063104629517\n",
      "Step 7192/10000- lr: [2.8343720969696976e-06] - Loss total: 2.5768463611602783, Last rpr Loss: 0.9999406337738037, Last lagvar Loss: 0.8457517027854919\n",
      "Step 7193/10000- lr: [2.833362e-06] - Loss total: 2.5768253803253174, Last rpr Loss: 0.9999104142189026, Last lagvar Loss: 0.8457818627357483\n",
      "Step 7194/10000- lr: [2.8323519030303033e-06] - Loss total: 2.5768039226531982, Last rpr Loss: 1.0001804828643799, Last lagvar Loss: 0.8455117344856262\n",
      "Step 7195/10000- lr: [2.8313418060606058e-06] - Loss total: 2.576782464981079, Last rpr Loss: 0.9997203350067139, Last lagvar Loss: 0.8459718823432922\n",
      "Step 7196/10000- lr: [2.830331709090909e-06] - Loss total: 2.576761245727539, Last rpr Loss: 1.000319480895996, Last lagvar Loss: 0.8453728556632996\n",
      "Step 7197/10000- lr: [2.8293216121212115e-06] - Loss total: 2.576740264892578, Last rpr Loss: 0.9996519088745117, Last lagvar Loss: 0.8460403084754944\n",
      "Step 7198/10000- lr: [2.8283115151515156e-06] - Loss total: 2.57671856880188, Last rpr Loss: 1.000328540802002, Last lagvar Loss: 0.8453634977340698\n",
      "Step 7199/10000- lr: [2.827301418181818e-06] - Loss total: 2.576697587966919, Last rpr Loss: 0.9996992349624634, Last lagvar Loss: 0.845992922782898\n",
      "Step 7200/10000- lr: [2.8262913212121213e-06] - Loss total: 2.5766761302948, Last rpr Loss: 1.0002326965332031, Last lagvar Loss: 0.8454593420028687\n",
      "Step 7201/10000- lr: [2.8252812242424237e-06] - Loss total: 2.5766546726226807, Last rpr Loss: 0.9998230934143066, Last lagvar Loss: 0.8458689451217651\n",
      "Step 7202/10000- lr: [2.824271127272728e-06] - Loss total: 2.5766334533691406, Last rpr Loss: 1.0000877380371094, Last lagvar Loss: 0.8456043004989624\n",
      "Step 7203/10000- lr: [2.8232610303030303e-06] - Loss total: 2.5766122341156006, Last rpr Loss: 0.9999773502349854, Last lagvar Loss: 0.8457145690917969\n",
      "Step 7204/10000- lr: [2.8222509333333336e-06] - Loss total: 2.5765910148620605, Last rpr Loss: 0.9999374151229858, Last lagvar Loss: 0.8457544445991516\n",
      "Step 7205/10000- lr: [2.821240836363636e-06] - Loss total: 2.5765695571899414, Last rpr Loss: 1.0001075267791748, Last lagvar Loss: 0.8455843925476074\n",
      "Step 7206/10000- lr: [2.8202307393939393e-06] - Loss total: 2.5765483379364014, Last rpr Loss: 0.9998340606689453, Last lagvar Loss: 0.8458578586578369\n",
      "Step 7207/10000- lr: [2.8192206424242417e-06] - Loss total: 2.5765271186828613, Last rpr Loss: 1.0001822710037231, Last lagvar Loss: 0.8455095887184143\n",
      "Step 7208/10000- lr: [2.818210545454546e-06] - Loss total: 2.5765058994293213, Last rpr Loss: 0.9997957944869995, Last lagvar Loss: 0.8458960056304932\n",
      "Step 7209/10000- lr: [2.8172004484848483e-06] - Loss total: 2.576484441757202, Last rpr Loss: 1.0001869201660156, Last lagvar Loss: 0.8455048203468323\n",
      "Step 7210/10000- lr: [2.8161903515151515e-06] - Loss total: 2.576462984085083, Last rpr Loss: 0.9998201131820679, Last lagvar Loss: 0.8458715677261353\n",
      "Step 7211/10000- lr: [2.815180254545454e-06] - Loss total: 2.576442003250122, Last rpr Loss: 1.0001373291015625, Last lagvar Loss: 0.8455543518066406\n",
      "Step 7212/10000- lr: [2.814170157575758e-06] - Loss total: 2.576420783996582, Last rpr Loss: 0.9998892545700073, Last lagvar Loss: 0.8458024263381958\n",
      "Step 7213/10000- lr: [2.8131600606060605e-06] - Loss total: 2.576399326324463, Last rpr Loss: 1.0000555515289307, Last lagvar Loss: 0.8456361293792725\n",
      "Step 7214/10000- lr: [2.812149963636364e-06] - Loss total: 2.576378345489502, Last rpr Loss: 0.9999731779098511, Last lagvar Loss: 0.8457183837890625\n",
      "Step 7215/10000- lr: [2.8111398666666662e-06] - Loss total: 2.576356887817383, Last rpr Loss: 0.9999788999557495, Last lagvar Loss: 0.8457126617431641\n",
      "Step 7216/10000- lr: [2.8101297696969695e-06] - Loss total: 2.5763354301452637, Last rpr Loss: 1.00003981590271, Last lagvar Loss: 0.8456516265869141\n",
      "Step 7217/10000- lr: [2.809119672727272e-06] - Loss total: 2.5763142108917236, Last rpr Loss: 0.9999173879623413, Last lagvar Loss: 0.8457741141319275\n",
      "Step 7218/10000- lr: [2.808109575757576e-06] - Loss total: 2.5762929916381836, Last rpr Loss: 1.0000922679901123, Last lagvar Loss: 0.8455992937088013\n",
      "Step 7219/10000- lr: [2.8070994787878785e-06] - Loss total: 2.5762720108032227, Last rpr Loss: 0.9998849034309387, Last lagvar Loss: 0.8458065986633301\n",
      "Step 7220/10000- lr: [2.8060893818181818e-06] - Loss total: 2.5762505531311035, Last rpr Loss: 1.0001041889190674, Last lagvar Loss: 0.8455872535705566\n",
      "Step 7221/10000- lr: [2.805079284848484e-06] - Loss total: 2.5762290954589844, Last rpr Loss: 0.9998865127563477, Last lagvar Loss: 0.8458048105239868\n",
      "Step 7222/10000- lr: [2.8040691878787883e-06] - Loss total: 2.5762081146240234, Last rpr Loss: 1.0000910758972168, Last lagvar Loss: 0.8456002473831177\n",
      "Step 7223/10000- lr: [2.8030590909090908e-06] - Loss total: 2.5761871337890625, Last rpr Loss: 0.9999103546142578, Last lagvar Loss: 0.8457809686660767\n",
      "Step 7224/10000- lr: [2.802048993939394e-06] - Loss total: 2.5761654376983643, Last rpr Loss: 1.0000594854354858, Last lagvar Loss: 0.8456318378448486\n",
      "Step 7225/10000- lr: [2.8010388969696965e-06] - Loss total: 2.5761444568634033, Last rpr Loss: 0.999948263168335, Last lagvar Loss: 0.8457430601119995\n",
      "Step 7226/10000- lr: [2.8000287999999997e-06] - Loss total: 2.576122522354126, Last rpr Loss: 1.0000169277191162, Last lagvar Loss: 0.8456743359565735\n",
      "Step 7227/10000- lr: [2.799018703030302e-06] - Loss total: 2.576101541519165, Last rpr Loss: 0.9999929666519165, Last lagvar Loss: 0.845698356628418\n",
      "Step 7228/10000- lr: [2.7980086060606063e-06] - Loss total: 2.576080322265625, Last rpr Loss: 0.99997878074646, Last lagvar Loss: 0.845712423324585\n",
      "Step 7229/10000- lr: [2.7969985090909087e-06] - Loss total: 2.576058864593506, Last rpr Loss: 1.000028133392334, Last lagvar Loss: 0.8456630706787109\n",
      "Step 7230/10000- lr: [2.795988412121212e-06] - Loss total: 2.576037645339966, Last rpr Loss: 0.9999408721923828, Last lagvar Loss: 0.8457502126693726\n",
      "Step 7231/10000- lr: [2.7949783151515144e-06] - Loss total: 2.576016664505005, Last rpr Loss: 1.0000516176223755, Last lagvar Loss: 0.8456395864486694\n",
      "Step 7232/10000- lr: [2.7939682181818186e-06] - Loss total: 2.5759952068328857, Last rpr Loss: 0.9999284148216248, Last lagvar Loss: 0.8457627296447754\n",
      "Step 7233/10000- lr: [2.792958121212121e-06] - Loss total: 2.575974225997925, Last rpr Loss: 1.0000629425048828, Last lagvar Loss: 0.8456281423568726\n",
      "Step 7234/10000- lr: [2.7919480242424243e-06] - Loss total: 2.5759530067443848, Last rpr Loss: 0.9999308586120605, Last lagvar Loss: 0.8457602262496948\n",
      "Step 7235/10000- lr: [2.7909379272727267e-06] - Loss total: 2.5759310722351074, Last rpr Loss: 1.0000503063201904, Last lagvar Loss: 0.8456407785415649\n",
      "Step 7236/10000- lr: [2.78992783030303e-06] - Loss total: 2.5759098529815674, Last rpr Loss: 0.9999430179595947, Last lagvar Loss: 0.8457480072975159\n",
      "Step 7237/10000- lr: [2.7889177333333324e-06] - Loss total: 2.5758888721466064, Last rpr Loss: 1.0000375509262085, Last lagvar Loss: 0.8456534147262573\n",
      "Step 7238/10000- lr: [2.7879076363636365e-06] - Loss total: 2.5758676528930664, Last rpr Loss: 0.9999556541442871, Last lagvar Loss: 0.8457353711128235\n",
      "Step 7239/10000- lr: [2.786897539393939e-06] - Loss total: 2.5758464336395264, Last rpr Loss: 1.0000205039978027, Last lagvar Loss: 0.8456704020500183\n",
      "Step 7240/10000- lr: [2.7858874424242422e-06] - Loss total: 2.5758252143859863, Last rpr Loss: 0.9999803304672241, Last lagvar Loss: 0.8457105159759521\n",
      "Step 7241/10000- lr: [2.7848773454545447e-06] - Loss total: 2.575803756713867, Last rpr Loss: 0.9999967813491821, Last lagvar Loss: 0.8456940650939941\n",
      "Step 7242/10000- lr: [2.7838672484848488e-06] - Loss total: 2.575782299041748, Last rpr Loss: 0.9999986886978149, Last lagvar Loss: 0.8456921577453613\n",
      "Step 7243/10000- lr: [2.7828571515151512e-06] - Loss total: 2.575761318206787, Last rpr Loss: 0.9999812841415405, Last lagvar Loss: 0.8457095623016357\n",
      "Step 7244/10000- lr: [2.7818470545454545e-06] - Loss total: 2.575739860534668, Last rpr Loss: 1.0000100135803223, Last lagvar Loss: 0.845680832862854\n",
      "Step 7245/10000- lr: [2.780836957575757e-06] - Loss total: 2.575718641281128, Last rpr Loss: 0.9999740123748779, Last lagvar Loss: 0.8457168340682983\n",
      "Step 7246/10000- lr: [2.77982686060606e-06] - Loss total: 2.575697422027588, Last rpr Loss: 1.0000171661376953, Last lagvar Loss: 0.8456736207008362\n",
      "Step 7247/10000- lr: [2.7788167636363626e-06] - Loss total: 2.5756759643554688, Last rpr Loss: 0.9999654293060303, Last lagvar Loss: 0.8457253575325012\n",
      "Step 7248/10000- lr: [2.7778066666666668e-06] - Loss total: 2.5756547451019287, Last rpr Loss: 1.0000239610671997, Last lagvar Loss: 0.8456668853759766\n",
      "Step 7249/10000- lr: [2.776796569696969e-06] - Loss total: 2.5756332874298096, Last rpr Loss: 0.9999607801437378, Last lagvar Loss: 0.8457300662994385\n",
      "Step 7250/10000- lr: [2.7757864727272725e-06] - Loss total: 2.5756118297576904, Last rpr Loss: 1.0000295639038086, Last lagvar Loss: 0.8456611633300781\n",
      "Step 7251/10000- lr: [2.774776375757575e-06] - Loss total: 2.5755908489227295, Last rpr Loss: 0.9999591112136841, Last lagvar Loss: 0.8457316756248474\n",
      "Step 7252/10000- lr: [2.773766278787879e-06] - Loss total: 2.5755691528320312, Last rpr Loss: 1.0000243186950684, Last lagvar Loss: 0.8456664085388184\n",
      "Step 7253/10000- lr: [2.7727561818181814e-06] - Loss total: 2.575547933578491, Last rpr Loss: 0.9999659061431885, Last lagvar Loss: 0.8457249402999878\n",
      "Step 7254/10000- lr: [2.7717460848484847e-06] - Loss total: 2.575526475906372, Last rpr Loss: 1.0000144243240356, Last lagvar Loss: 0.8456761837005615\n",
      "Step 7255/10000- lr: [2.770735987878787e-06] - Loss total: 2.575505495071411, Last rpr Loss: 0.9999775886535645, Last lagvar Loss: 0.8457131385803223\n",
      "Step 7256/10000- lr: [2.7697258909090904e-06] - Loss total: 2.575483798980713, Last rpr Loss: 1.0000067949295044, Last lagvar Loss: 0.845683753490448\n",
      "Step 7257/10000- lr: [2.768715793939393e-06] - Loss total: 2.575462579727173, Last rpr Loss: 0.9999853372573853, Last lagvar Loss: 0.8457053303718567\n",
      "Step 7258/10000- lr: [2.767705696969697e-06] - Loss total: 2.5754411220550537, Last rpr Loss: 0.9999992847442627, Last lagvar Loss: 0.845691442489624\n",
      "Step 7259/10000- lr: [2.7666955999999994e-06] - Loss total: 2.5754199028015137, Last rpr Loss: 0.9999901056289673, Last lagvar Loss: 0.8457005023956299\n",
      "Step 7260/10000- lr: [2.7656855030303027e-06] - Loss total: 2.5753986835479736, Last rpr Loss: 0.9999927282333374, Last lagvar Loss: 0.8456978797912598\n",
      "Step 7261/10000- lr: [2.764675406060605e-06] - Loss total: 2.5753774642944336, Last rpr Loss: 0.9999929666519165, Last lagvar Loss: 0.8456976413726807\n",
      "Step 7262/10000- lr: [2.7636653090909092e-06] - Loss total: 2.5753560066223145, Last rpr Loss: 0.9999904632568359, Last lagvar Loss: 0.8457000255584717\n",
      "Step 7263/10000- lr: [2.7626552121212117e-06] - Loss total: 2.5753345489501953, Last rpr Loss: 1.0000007152557373, Last lagvar Loss: 0.8456897735595703\n",
      "Step 7264/10000- lr: [2.761645115151515e-06] - Loss total: 2.575312852859497, Last rpr Loss: 0.9999858140945435, Last lagvar Loss: 0.8457047939300537\n",
      "Step 7265/10000- lr: [2.7606350181818174e-06] - Loss total: 2.575291872024536, Last rpr Loss: 1.000004768371582, Last lagvar Loss: 0.8456859588623047\n",
      "Step 7266/10000- lr: [2.7596249212121207e-06] - Loss total: 2.575270414352417, Last rpr Loss: 0.9999809265136719, Last lagvar Loss: 0.8457096219062805\n",
      "Step 7267/10000- lr: [2.7586148242424248e-06] - Loss total: 2.575248956680298, Last rpr Loss: 1.000003457069397, Last lagvar Loss: 0.8456870317459106\n",
      "Step 7268/10000- lr: [2.757604727272727e-06] - Loss total: 2.575227737426758, Last rpr Loss: 0.9999821782112122, Last lagvar Loss: 0.8457083106040955\n",
      "Step 7269/10000- lr: [2.7565946303030305e-06] - Loss total: 2.5752062797546387, Last rpr Loss: 1.0000038146972656, Last lagvar Loss: 0.8456867933273315\n",
      "Step 7270/10000- lr: [2.755584533333333e-06] - Loss total: 2.5751850605010986, Last rpr Loss: 0.9999817609786987, Last lagvar Loss: 0.8457087278366089\n",
      "Step 7271/10000- lr: [2.754574436363637e-06] - Loss total: 2.5751633644104004, Last rpr Loss: 1.0000090599060059, Last lagvar Loss: 0.8456813097000122\n",
      "Step 7272/10000- lr: [2.7535643393939395e-06] - Loss total: 2.5751421451568604, Last rpr Loss: 0.9999761581420898, Last lagvar Loss: 0.8457143306732178\n",
      "Step 7273/10000- lr: [2.7525542424242427e-06] - Loss total: 2.575120449066162, Last rpr Loss: 1.000011682510376, Last lagvar Loss: 0.8456788659095764\n",
      "Step 7274/10000- lr: [2.751544145454545e-06] - Loss total: 2.575099229812622, Last rpr Loss: 0.9999743103981018, Last lagvar Loss: 0.845716118812561\n",
      "Step 7275/10000- lr: [2.7505340484848485e-06] - Loss total: 2.5750770568847656, Last rpr Loss: 1.0000135898590088, Last lagvar Loss: 0.8456768989562988\n",
      "Step 7276/10000- lr: [2.749523951515151e-06] - Loss total: 2.5750558376312256, Last rpr Loss: 0.9999688267707825, Last lagvar Loss: 0.8457216620445251\n",
      "Step 7277/10000- lr: [2.748513854545455e-06] - Loss total: 2.5750343799591064, Last rpr Loss: 1.0000207424163818, Last lagvar Loss: 0.8456696271896362\n",
      "Step 7278/10000- lr: [2.7475037575757574e-06] - Loss total: 2.5750129222869873, Last rpr Loss: 0.9999654293060303, Last lagvar Loss: 0.8457249402999878\n",
      "Step 7279/10000- lr: [2.7464936606060607e-06] - Loss total: 2.5749917030334473, Last rpr Loss: 1.0000197887420654, Last lagvar Loss: 0.8456705808639526\n",
      "Step 7280/10000- lr: [2.745483563636363e-06] - Loss total: 2.574970006942749, Last rpr Loss: 0.9999666810035706, Last lagvar Loss: 0.8457236886024475\n",
      "Step 7281/10000- lr: [2.7444734666666673e-06] - Loss total: 2.57494854927063, Last rpr Loss: 1.0000182390213013, Last lagvar Loss: 0.8456721305847168\n",
      "Step 7282/10000- lr: [2.7434633696969697e-06] - Loss total: 2.5749268531799316, Last rpr Loss: 0.9999715685844421, Last lagvar Loss: 0.8457187414169312\n",
      "Step 7283/10000- lr: [2.742453272727273e-06] - Loss total: 2.5749056339263916, Last rpr Loss: 1.0000123977661133, Last lagvar Loss: 0.8456780910491943\n",
      "Step 7284/10000- lr: [2.7414431757575754e-06] - Loss total: 2.5748841762542725, Last rpr Loss: 0.9999754428863525, Last lagvar Loss: 0.8457149267196655\n",
      "Step 7285/10000- lr: [2.7404330787878787e-06] - Loss total: 2.5748627185821533, Last rpr Loss: 1.0000075101852417, Last lagvar Loss: 0.8456828594207764\n",
      "Step 7286/10000- lr: [2.739422981818181e-06] - Loss total: 2.574841260910034, Last rpr Loss: 0.9999836683273315, Last lagvar Loss: 0.8457067608833313\n",
      "Step 7287/10000- lr: [2.7384128848484852e-06] - Loss total: 2.574819564819336, Last rpr Loss: 0.9999986886978149, Last lagvar Loss: 0.8456917405128479\n",
      "Step 7288/10000- lr: [2.7374027878787877e-06] - Loss total: 2.5747978687286377, Last rpr Loss: 0.9999889135360718, Last lagvar Loss: 0.8457015156745911\n",
      "Step 7289/10000- lr: [2.736392690909091e-06] - Loss total: 2.5747761726379395, Last rpr Loss: 0.999998152256012, Last lagvar Loss: 0.8456921577453613\n",
      "Step 7290/10000- lr: [2.7353825939393934e-06] - Loss total: 2.5747547149658203, Last rpr Loss: 0.9999868869781494, Last lagvar Loss: 0.8457034826278687\n",
      "Step 7291/10000- lr: [2.7343724969696975e-06] - Loss total: 2.574733257293701, Last rpr Loss: 0.9999983310699463, Last lagvar Loss: 0.8456921577453613\n",
      "Step 7292/10000- lr: [2.7333624e-06] - Loss total: 2.574712038040161, Last rpr Loss: 0.9999885559082031, Last lagvar Loss: 0.8457018136978149\n",
      "Step 7293/10000- lr: [2.732352303030303e-06] - Loss total: 2.574690341949463, Last rpr Loss: 1.0000019073486328, Last lagvar Loss: 0.8456884622573853\n",
      "Step 7294/10000- lr: [2.7313422060606056e-06] - Loss total: 2.5746686458587646, Last rpr Loss: 0.9999813437461853, Last lagvar Loss: 0.845708966255188\n",
      "Step 7295/10000- lr: [2.730332109090909e-06] - Loss total: 2.5746469497680664, Last rpr Loss: 1.000004768371582, Last lagvar Loss: 0.8456856608390808\n",
      "Step 7296/10000- lr: [2.7293220121212113e-06] - Loss total: 2.5746254920959473, Last rpr Loss: 0.9999808669090271, Last lagvar Loss: 0.8457095623016357\n",
      "Step 7297/10000- lr: [2.7283119151515155e-06] - Loss total: 2.574603796005249, Last rpr Loss: 1.0000046491622925, Last lagvar Loss: 0.8456857204437256\n",
      "Step 7298/10000- lr: [2.727301818181818e-06] - Loss total: 2.57458233833313, Last rpr Loss: 0.9999784231185913, Last lagvar Loss: 0.8457119464874268\n",
      "Step 7299/10000- lr: [2.726291721212121e-06] - Loss total: 2.5745604038238525, Last rpr Loss: 1.000012755393982, Last lagvar Loss: 0.8456775546073914\n",
      "Step 7300/10000- lr: [2.7252816242424236e-06] - Loss total: 2.5745389461517334, Last rpr Loss: 0.9999736547470093, Last lagvar Loss: 0.8457167744636536\n",
      "Step 7301/10000- lr: [2.7242715272727277e-06] - Loss total: 2.5745174884796143, Last rpr Loss: 1.0000112056732178, Last lagvar Loss: 0.8456792235374451\n",
      "Step 7302/10000- lr: [2.72326143030303e-06] - Loss total: 2.574495792388916, Last rpr Loss: 0.9999725818634033, Last lagvar Loss: 0.84571772813797\n",
      "Step 7303/10000- lr: [2.7222513333333334e-06] - Loss total: 2.5744736194610596, Last rpr Loss: 1.000011682510376, Last lagvar Loss: 0.8456786274909973\n",
      "Step 7304/10000- lr: [2.721241236363636e-06] - Loss total: 2.5744526386260986, Last rpr Loss: 0.9999751448631287, Last lagvar Loss: 0.8457151651382446\n",
      "Step 7305/10000- lr: [2.720231139393939e-06] - Loss total: 2.5744307041168213, Last rpr Loss: 1.00001060962677, Last lagvar Loss: 0.845679759979248\n",
      "Step 7306/10000- lr: [2.7192210424242416e-06] - Loss total: 2.574409008026123, Last rpr Loss: 0.999975323677063, Last lagvar Loss: 0.8457150459289551\n",
      "Step 7307/10000- lr: [2.7182109454545457e-06] - Loss total: 2.574387550354004, Last rpr Loss: 1.0000144243240356, Last lagvar Loss: 0.8456760048866272\n",
      "Step 7308/10000- lr: [2.717200848484848e-06] - Loss total: 2.5743658542633057, Last rpr Loss: 0.9999699592590332, Last lagvar Loss: 0.8457204699516296\n",
      "Step 7309/10000- lr: [2.7161907515151514e-06] - Loss total: 2.5743441581726074, Last rpr Loss: 1.0000202655792236, Last lagvar Loss: 0.8456701040267944\n",
      "Step 7310/10000- lr: [2.715180654545454e-06] - Loss total: 2.57432222366333, Last rpr Loss: 0.9999561309814453, Last lagvar Loss: 0.8457342386245728\n",
      "Step 7311/10000- lr: [2.714170557575758e-06] - Loss total: 2.574300527572632, Last rpr Loss: 1.00003182888031, Last lagvar Loss: 0.8456584215164185\n",
      "Step 7312/10000- lr: [2.7131604606060604e-06] - Loss total: 2.5742785930633545, Last rpr Loss: 0.9999518394470215, Last lagvar Loss: 0.8457384705543518\n",
      "Step 7313/10000- lr: [2.7121503636363637e-06] - Loss total: 2.5742568969726562, Last rpr Loss: 1.000041127204895, Last lagvar Loss: 0.845649242401123\n",
      "Step 7314/10000- lr: [2.711140266666666e-06] - Loss total: 2.574235200881958, Last rpr Loss: 0.9999432563781738, Last lagvar Loss: 0.845747172832489\n",
      "Step 7315/10000- lr: [2.7101301696969694e-06] - Loss total: 2.574213981628418, Last rpr Loss: 1.0000464916229248, Last lagvar Loss: 0.8456438779830933\n",
      "Step 7316/10000- lr: [2.709120072727272e-06] - Loss total: 2.5741920471191406, Last rpr Loss: 0.9999310374259949, Last lagvar Loss: 0.8457592725753784\n",
      "Step 7317/10000- lr: [2.708109975757576e-06] - Loss total: 2.5741703510284424, Last rpr Loss: 1.0000567436218262, Last lagvar Loss: 0.8456336259841919\n",
      "Step 7318/10000- lr: [2.7070998787878784e-06] - Loss total: 2.574148416519165, Last rpr Loss: 0.9999241828918457, Last lagvar Loss: 0.8457661271095276\n",
      "Step 7319/10000- lr: [2.7060897818181816e-06] - Loss total: 2.574126720428467, Last rpr Loss: 1.000072956085205, Last lagvar Loss: 0.845617413520813\n",
      "Step 7320/10000- lr: [2.705079684848484e-06] - Loss total: 2.5741052627563477, Last rpr Loss: 0.9999046325683594, Last lagvar Loss: 0.8457856774330139\n",
      "Step 7321/10000- lr: [2.704069587878788e-06] - Loss total: 2.5740833282470703, Last rpr Loss: 1.0000908374786377, Last lagvar Loss: 0.8455994129180908\n",
      "Step 7322/10000- lr: [2.7030594909090906e-06] - Loss total: 2.574061632156372, Last rpr Loss: 0.999880313873291, Last lagvar Loss: 0.8458099961280823\n",
      "Step 7323/10000- lr: [2.702049393939394e-06] - Loss total: 2.574040174484253, Last rpr Loss: 1.0001168251037598, Last lagvar Loss: 0.8455734252929688\n",
      "Step 7324/10000- lr: [2.7010392969696963e-06] - Loss total: 2.5740182399749756, Last rpr Loss: 0.9998538494110107, Last lagvar Loss: 0.8458364605903625\n",
      "Step 7325/10000- lr: [2.7000291999999996e-06] - Loss total: 2.5739963054656982, Last rpr Loss: 1.0001487731933594, Last lagvar Loss: 0.8455414772033691\n",
      "Step 7326/10000- lr: [2.699019103030302e-06] - Loss total: 2.573974609375, Last rpr Loss: 0.9998254776000977, Last lagvar Loss: 0.8458648920059204\n",
      "Step 7327/10000- lr: [2.698009006060606e-06] - Loss total: 2.5739529132843018, Last rpr Loss: 1.0001788139343262, Last lagvar Loss: 0.8455114364624023\n",
      "Step 7328/10000- lr: [2.6969989090909086e-06] - Loss total: 2.5739312171936035, Last rpr Loss: 0.9997809529304504, Last lagvar Loss: 0.8459093570709229\n",
      "Step 7329/10000- lr: [2.695988812121212e-06] - Loss total: 2.5739095211029053, Last rpr Loss: 1.0002269744873047, Last lagvar Loss: 0.8454633355140686\n",
      "Step 7330/10000- lr: [2.6949787151515143e-06] - Loss total: 2.573887825012207, Last rpr Loss: 0.9997342228889465, Last lagvar Loss: 0.8459560871124268\n",
      "Step 7331/10000- lr: [2.6939686181818184e-06] - Loss total: 2.573866128921509, Last rpr Loss: 1.0002845525741577, Last lagvar Loss: 0.8454057574272156\n",
      "Step 7332/10000- lr: [2.692958521212121e-06] - Loss total: 2.5738441944122314, Last rpr Loss: 0.9996671676635742, Last lagvar Loss: 0.8460230827331543\n",
      "Step 7333/10000- lr: [2.691948424242424e-06] - Loss total: 2.5738227367401123, Last rpr Loss: 1.0003619194030762, Last lagvar Loss: 0.8453283905982971\n",
      "Step 7334/10000- lr: [2.6909383272727266e-06] - Loss total: 2.573800802230835, Last rpr Loss: 0.9995723366737366, Last lagvar Loss: 0.8461179733276367\n",
      "Step 7335/10000- lr: [2.68992823030303e-06] - Loss total: 2.573779344558716, Last rpr Loss: 1.0004621744155884, Last lagvar Loss: 0.8452281951904297\n",
      "Step 7336/10000- lr: [2.6889181333333323e-06] - Loss total: 2.5737576484680176, Last rpr Loss: 0.9994622468948364, Last lagvar Loss: 0.8462282419204712\n",
      "Step 7337/10000- lr: [2.6879080363636364e-06] - Loss total: 2.5737359523773193, Last rpr Loss: 1.000598430633545, Last lagvar Loss: 0.8450920581817627\n",
      "Step 7338/10000- lr: [2.686897939393939e-06] - Loss total: 2.5737144947052, Last rpr Loss: 0.9993056058883667, Last lagvar Loss: 0.8463850617408752\n",
      "Step 7339/10000- lr: [2.685887842424242e-06] - Loss total: 2.573692798614502, Last rpr Loss: 1.000773310661316, Last lagvar Loss: 0.8449174165725708\n",
      "Step 7340/10000- lr: [2.6848777454545445e-06] - Loss total: 2.5736711025238037, Last rpr Loss: 0.9991075992584229, Last lagvar Loss: 0.8465833067893982\n",
      "Step 7341/10000- lr: [2.6838676484848486e-06] - Loss total: 2.5736496448516846, Last rpr Loss: 1.0010051727294922, Last lagvar Loss: 0.8446859121322632\n",
      "Step 7342/10000- lr: [2.682857551515151e-06] - Loss total: 2.5736286640167236, Last rpr Loss: 0.9988338947296143, Last lagvar Loss: 0.8468576669692993\n",
      "Step 7343/10000- lr: [2.6818474545454544e-06] - Loss total: 2.5736067295074463, Last rpr Loss: 1.00132155418396, Last lagvar Loss: 0.8443702459335327\n",
      "Step 7344/10000- lr: [2.6808373575757568e-06] - Loss total: 2.5735855102539062, Last rpr Loss: 0.9984645843505859, Last lagvar Loss: 0.8472280502319336\n",
      "Step 7345/10000- lr: [2.67982726060606e-06] - Loss total: 2.5735647678375244, Last rpr Loss: 1.0017564296722412, Last lagvar Loss: 0.8439368605613708\n",
      "Step 7346/10000- lr: [2.6788171636363625e-06] - Loss total: 2.5735442638397217, Last rpr Loss: 0.9979530572891235, Last lagvar Loss: 0.8477414846420288\n",
      "Step 7347/10000- lr: [2.6778070666666666e-06] - Loss total: 2.573523759841919, Last rpr Loss: 1.0023549795150757, Last lagvar Loss: 0.8433406949043274\n",
      "Step 7348/10000- lr: [2.676796969696969e-06] - Loss total: 2.5735042095184326, Last rpr Loss: 0.9972521066665649, Last lagvar Loss: 0.8484458923339844\n",
      "Step 7349/10000- lr: [2.6757868727272723e-06] - Loss total: 2.5734848976135254, Last rpr Loss: 1.0031800270080566, Last lagvar Loss: 0.8425202369689941\n",
      "Step 7350/10000- lr: [2.6747767757575748e-06] - Loss total: 2.5734667778015137, Last rpr Loss: 0.9962806701660156, Last lagvar Loss: 0.8494239449501038\n",
      "Step 7351/10000- lr: [2.673766678787879e-06] - Loss total: 2.5734496116638184, Last rpr Loss: 1.004323959350586, Last lagvar Loss: 0.8413853049278259\n",
      "Step 7352/10000- lr: [2.6727565818181813e-06] - Loss total: 2.573435068130493, Last rpr Loss: 0.9949374794960022, Last lagvar Loss: 0.8507795333862305\n",
      "Step 7353/10000- lr: [2.6717464848484846e-06] - Loss total: 2.573422431945801, Last rpr Loss: 1.0059027671813965, Last lagvar Loss: 0.8398229479789734\n",
      "Step 7354/10000- lr: [2.670736387878788e-06] - Loss total: 2.573413610458374, Last rpr Loss: 0.9930886030197144, Last lagvar Loss: 0.8526518940925598\n",
      "Step 7355/10000- lr: [2.6697262909090903e-06] - Loss total: 2.5734078884124756, Last rpr Loss: 1.008055329322815, Last lagvar Loss: 0.8377014398574829\n",
      "Step 7356/10000- lr: [2.6687161939393944e-06] - Loss total: 2.573411226272583, Last rpr Loss: 0.9905886650085449, Last lagvar Loss: 0.8551952838897705\n",
      "Step 7357/10000- lr: [2.667706096969697e-06] - Loss total: 2.5734171867370605, Last rpr Loss: 1.0109301805496216, Last lagvar Loss: 0.8348820209503174\n",
      "Step 7358/10000- lr: [2.666696e-06] - Loss total: 2.5734405517578125, Last rpr Loss: 0.9873182773590088, Last lagvar Loss: 0.8585430383682251\n",
      "Step 7359/10000- lr: [2.6656859030303026e-06] - Loss total: 2.573462963104248, Last rpr Loss: 1.0145859718322754, Last lagvar Loss: 0.83132004737854\n",
      "Step 7360/10000- lr: [2.6646758060606067e-06] - Loss total: 2.5735156536102295, Last rpr Loss: 0.9833368062973022, Last lagvar Loss: 0.8626497983932495\n",
      "Step 7361/10000- lr: [2.663665709090909e-06] - Loss total: 2.573549270629883, Last rpr Loss: 1.018742322921753, Last lagvar Loss: 0.8273007273674011\n",
      "Step 7362/10000- lr: [2.6626556121212124e-06] - Loss total: 2.573627471923828, Last rpr Loss: 0.9792259335517883, Last lagvar Loss: 0.8669251203536987\n",
      "Step 7363/10000- lr: [2.661645515151515e-06] - Loss total: 2.5736429691314697, Last rpr Loss: 1.0223854780197144, Last lagvar Loss: 0.8238013982772827\n",
      "Step 7364/10000- lr: [2.660635418181818e-06] - Loss total: 2.573701858520508, Last rpr Loss: 0.9765180349349976, Last lagvar Loss: 0.8697576522827148\n",
      "Step 7365/10000- lr: [2.6596253212121205e-06] - Loss total: 2.5736403465270996, Last rpr Loss: 1.0235016345977783, Last lagvar Loss: 0.822727620601654\n",
      "Step 7366/10000- lr: [2.6586152242424246e-06] - Loss total: 2.5736019611358643, Last rpr Loss: 0.9775922894477844, Last lagvar Loss: 0.8686228394508362\n",
      "Step 7367/10000- lr: [2.657605127272727e-06] - Loss total: 2.57344651222229, Last rpr Loss: 1.0198404788970947, Last lagvar Loss: 0.8262284398078918\n",
      "Step 7368/10000- lr: [2.6565950303030304e-06] - Loss total: 2.573310136795044, Last rpr Loss: 0.9840204119682312, Last lagvar Loss: 0.8619300127029419\n",
      "Step 7369/10000- lr: [2.6555849333333328e-06] - Loss total: 2.5731570720672607, Last rpr Loss: 1.0111746788024902, Last lagvar Loss: 0.8346338272094727\n",
      "Step 7370/10000- lr: [2.654574836363637e-06] - Loss total: 2.5730526447296143, Last rpr Loss: 0.9943199157714844, Last lagvar Loss: 0.851401686668396\n",
      "Step 7371/10000- lr: [2.6535647393939393e-06] - Loss total: 2.5730020999908447, Last rpr Loss: 1.0003368854522705, Last lagvar Loss: 0.8453528881072998\n",
      "Step 7372/10000- lr: [2.6525546424242426e-06] - Loss total: 2.5730011463165283, Last rpr Loss: 1.0046286582946777, Last lagvar Loss: 0.8410822749137878\n",
      "Step 7373/10000- lr: [2.651544545454545e-06] - Loss total: 2.5730297565460205, Last rpr Loss: 0.9913443326950073, Last lagvar Loss: 0.8544201850891113\n",
      "Step 7374/10000- lr: [2.6505344484848483e-06] - Loss total: 2.5730578899383545, Last rpr Loss: 1.0114171504974365, Last lagvar Loss: 0.8343989253044128\n",
      "Step 7375/10000- lr: [2.6495243515151508e-06] - Loss total: 2.5730748176574707, Last rpr Loss: 0.9870797395706177, Last lagvar Loss: 0.8587771654129028\n",
      "Step 7376/10000- lr: [2.648514254545455e-06] - Loss total: 2.5730481147766113, Last rpr Loss: 1.0128862857818604, Last lagvar Loss: 0.8329633474349976\n",
      "Step 7377/10000- lr: [2.6475041575757573e-06] - Loss total: 2.5730032920837402, Last rpr Loss: 0.9883939027786255, Last lagvar Loss: 0.8574321269989014\n",
      "Step 7378/10000- lr: [2.6464940606060606e-06] - Loss total: 2.572932481765747, Last rpr Loss: 1.009204626083374, Last lagvar Loss: 0.8365675210952759\n",
      "Step 7379/10000- lr: [2.645483963636363e-06] - Loss total: 2.5728678703308105, Last rpr Loss: 0.9939413070678711, Last lagvar Loss: 0.8517860174179077\n",
      "Step 7380/10000- lr: [2.644473866666667e-06] - Loss total: 2.5728180408477783, Last rpr Loss: 1.0025826692581177, Last lagvar Loss: 0.8431136608123779\n",
      "Step 7381/10000- lr: [2.6434637696969696e-06] - Loss total: 2.5727908611297607, Last rpr Loss: 1.0007747411727905, Last lagvar Loss: 0.8449152708053589\n",
      "Step 7382/10000- lr: [2.642453672727273e-06] - Loss total: 2.572782278060913, Last rpr Loss: 0.996220588684082, Last lagvar Loss: 0.849482536315918\n",
      "Step 7383/10000- lr: [2.6414435757575753e-06] - Loss total: 2.572781801223755, Last rpr Loss: 1.0059669017791748, Last lagvar Loss: 0.8397578001022339\n",
      "Step 7384/10000- lr: [2.6404334787878786e-06] - Loss total: 2.5727791786193848, Last rpr Loss: 0.9926156997680664, Last lagvar Loss: 0.8531285524368286\n",
      "Step 7385/10000- lr: [2.639423381818181e-06] - Loss total: 2.5727639198303223, Last rpr Loss: 1.0078285932540894, Last lagvar Loss: 0.8379217386245728\n",
      "Step 7386/10000- lr: [2.638413284848485e-06] - Loss total: 2.5727381706237793, Last rpr Loss: 0.9926214218139648, Last lagvar Loss: 0.8531236052513123\n",
      "Step 7387/10000- lr: [2.6374031878787875e-06] - Loss total: 2.5727009773254395, Last rpr Loss: 1.006232500076294, Last lagvar Loss: 0.839495062828064\n",
      "Step 7388/10000- lr: [2.636393090909091e-06] - Loss total: 2.572662353515625, Last rpr Loss: 0.9955297708511353, Last lagvar Loss: 0.8501796722412109\n",
      "Step 7389/10000- lr: [2.6353829939393932e-06] - Loss total: 2.572627305984497, Last rpr Loss: 1.0024267435073853, Last lagvar Loss: 0.8432678580284119\n",
      "Step 7390/10000- lr: [2.6343728969696974e-06] - Loss total: 2.572600841522217, Last rpr Loss: 0.9996591806411743, Last lagvar Loss: 0.8460296988487244\n",
      "Step 7391/10000- lr: [2.6333628e-06] - Loss total: 2.572582721710205, Last rpr Loss: 0.9983546733856201, Last lagvar Loss: 0.847337007522583\n",
      "Step 7392/10000- lr: [2.632352703030303e-06] - Loss total: 2.572568655014038, Last rpr Loss: 1.003166913986206, Last lagvar Loss: 0.8425321578979492\n",
      "Step 7393/10000- lr: [2.6313426060606055e-06] - Loss total: 2.5725557804107666, Last rpr Loss: 0.9957001209259033, Last lagvar Loss: 0.8500074148178101\n",
      "Step 7394/10000- lr: [2.6303325090909088e-06] - Loss total: 2.5725386142730713, Last rpr Loss: 1.0047969818115234, Last lagvar Loss: 0.8409147262573242\n",
      "Step 7395/10000- lr: [2.6293224121212112e-06] - Loss total: 2.5725178718566895, Last rpr Loss: 0.9952437281608582, Last lagvar Loss: 0.8504676818847656\n",
      "Step 7396/10000- lr: [2.6283123151515153e-06] - Loss total: 2.5724918842315674, Last rpr Loss: 1.0042279958724976, Last lagvar Loss: 0.8414780497550964\n",
      "Step 7397/10000- lr: [2.6273022181818178e-06] - Loss total: 2.5724644660949707, Last rpr Loss: 0.9967392683029175, Last lagvar Loss: 0.8489599227905273\n",
      "Step 7398/10000- lr: [2.626292121212121e-06] - Loss total: 2.5724377632141113, Last rpr Loss: 1.0020651817321777, Last lagvar Loss: 0.8436274528503418\n",
      "Step 7399/10000- lr: [2.6252820242424235e-06] - Loss total: 2.572413444519043, Last rpr Loss: 0.9992336630821228, Last lagvar Loss: 0.846455454826355\n",
      "Step 7400/10000- lr: [2.6242719272727276e-06] - Loss total: 2.572392463684082, Last rpr Loss: 0.9994809627532959, Last lagvar Loss: 0.8462077379226685\n",
      "Step 7401/10000- lr: [2.62326183030303e-06] - Loss total: 2.572373628616333, Last rpr Loss: 1.001562476158142, Last lagvar Loss: 0.8441282510757446\n",
      "Step 7402/10000- lr: [2.6222517333333333e-06] - Loss total: 2.5723555088043213, Last rpr Loss: 0.9976072311401367, Last lagvar Loss: 0.8480868339538574\n",
      "Step 7403/10000- lr: [2.6212416363636357e-06] - Loss total: 2.5723371505737305, Last rpr Loss: 1.0028560161590576, Last lagvar Loss: 0.8428400754928589\n",
      "Step 7404/10000- lr: [2.620231539393939e-06] - Loss total: 2.572317123413086, Last rpr Loss: 0.9970171451568604, Last lagvar Loss: 0.8486800789833069\n",
      "Step 7405/10000- lr: [2.6192214424242414e-06] - Loss total: 2.5722951889038086, Last rpr Loss: 1.0028047561645508, Last lagvar Loss: 0.8428910374641418\n",
      "Step 7406/10000- lr: [2.6182113454545456e-06] - Loss total: 2.572272539138794, Last rpr Loss: 0.9976645708084106, Last lagvar Loss: 0.8480291962623596\n",
      "Step 7407/10000- lr: [2.617201248484848e-06] - Loss total: 2.572249412536621, Last rpr Loss: 1.001684546470642, Last lagvar Loss: 0.8440062999725342\n",
      "Step 7408/10000- lr: [2.6161911515151513e-06] - Loss total: 2.5722267627716064, Last rpr Loss: 0.9990442395210266, Last lagvar Loss: 0.8466448187828064\n",
      "Step 7409/10000- lr: [2.6151810545454537e-06] - Loss total: 2.572204828262329, Last rpr Loss: 1.000164270401001, Last lagvar Loss: 0.8455237150192261\n",
      "Step 7410/10000- lr: [2.614170957575758e-06] - Loss total: 2.5721845626831055, Last rpr Loss: 1.000495433807373, Last lagvar Loss: 0.8451927304267883\n",
      "Step 7411/10000- lr: [2.6131608606060603e-06] - Loss total: 2.572165012359619, Last rpr Loss: 0.9988939762115479, Last lagvar Loss: 0.8467953205108643\n",
      "Step 7412/10000- lr: [2.6121507636363635e-06] - Loss total: 2.5721452236175537, Last rpr Loss: 1.0015019178390503, Last lagvar Loss: 0.8441882729530334\n",
      "Step 7413/10000- lr: [2.611140666666666e-06] - Loss total: 2.5721256732940674, Last rpr Loss: 0.9982607960700989, Last lagvar Loss: 0.8474302291870117\n",
      "Step 7414/10000- lr: [2.6101305696969692e-06] - Loss total: 2.5721046924591064, Last rpr Loss: 1.001781702041626, Last lagvar Loss: 0.8439092040061951\n",
      "Step 7415/10000- lr: [2.6091204727272725e-06] - Loss total: 2.5720837116241455, Last rpr Loss: 0.9983543157577515, Last lagvar Loss: 0.8473363518714905\n",
      "Step 7416/10000- lr: [2.608110375757576e-06] - Loss total: 2.5720627307891846, Last rpr Loss: 1.0013773441314697, Last lagvar Loss: 0.8443120718002319\n",
      "Step 7417/10000- lr: [2.6071002787878782e-06] - Loss total: 2.5720407962799072, Last rpr Loss: 0.9989913105964661, Last lagvar Loss: 0.8466973900794983\n",
      "Step 7418/10000- lr: [2.6060901818181815e-06] - Loss total: 2.5720198154449463, Last rpr Loss: 1.0005731582641602, Last lagvar Loss: 0.8451145887374878\n",
      "Step 7419/10000- lr: [2.605080084848484e-06] - Loss total: 2.5719990730285645, Last rpr Loss: 0.9998563528060913, Last lagvar Loss: 0.8458312153816223\n",
      "Step 7420/10000- lr: [2.604069987878788e-06] - Loss total: 2.5719785690307617, Last rpr Loss: 0.9997155070304871, Last lagvar Loss: 0.8459720015525818\n",
      "Step 7421/10000- lr: [2.6030598909090905e-06] - Loss total: 2.571958303451538, Last rpr Loss: 1.0006119012832642, Last lagvar Loss: 0.8450759053230286\n",
      "Step 7422/10000- lr: [2.6020497939393938e-06] - Loss total: 2.5719382762908936, Last rpr Loss: 0.9991147518157959, Last lagvar Loss: 0.846573531627655\n",
      "Step 7423/10000- lr: [2.601039696969696e-06] - Loss total: 2.571917772293091, Last rpr Loss: 1.0010271072387695, Last lagvar Loss: 0.844661295413971\n",
      "Step 7424/10000- lr: [2.6000295999999995e-06] - Loss total: 2.571897506713867, Last rpr Loss: 0.9989173412322998, Last lagvar Loss: 0.846771240234375\n",
      "Step 7425/10000- lr: [2.5990195030303027e-06] - Loss total: 2.5718770027160645, Last rpr Loss: 1.0010194778442383, Last lagvar Loss: 0.8446688652038574\n",
      "Step 7426/10000- lr: [2.598009406060606e-06] - Loss total: 2.5718562602996826, Last rpr Loss: 0.9991119503974915, Last lagvar Loss: 0.8465760946273804\n",
      "Step 7427/10000- lr: [2.5969993090909085e-06] - Loss total: 2.571835517883301, Last rpr Loss: 1.0006730556488037, Last lagvar Loss: 0.8450144529342651\n",
      "Step 7428/10000- lr: [2.5959892121212117e-06] - Loss total: 2.571814775466919, Last rpr Loss: 0.9995570778846741, Last lagvar Loss: 0.8461301922798157\n",
      "Step 7429/10000- lr: [2.594979115151514e-06] - Loss total: 2.571794271469116, Last rpr Loss: 1.0001733303070068, Last lagvar Loss: 0.8455137610435486\n",
      "Step 7430/10000- lr: [2.5939690181818183e-06] - Loss total: 2.5717740058898926, Last rpr Loss: 1.0000606775283813, Last lagvar Loss: 0.8456263542175293\n",
      "Step 7431/10000- lr: [2.5929589212121207e-06] - Loss total: 2.571753740310669, Last rpr Loss: 0.9997121095657349, Last lagvar Loss: 0.8459749221801758\n",
      "Step 7432/10000- lr: [2.591948824242424e-06] - Loss total: 2.5717334747314453, Last rpr Loss: 1.0004448890686035, Last lagvar Loss: 0.8452422618865967\n",
      "Step 7433/10000- lr: [2.5909387272727264e-06] - Loss total: 2.5717132091522217, Last rpr Loss: 0.9994336366653442, Last lagvar Loss: 0.8462535738945007\n",
      "Step 7434/10000- lr: [2.5899286303030297e-06] - Loss total: 2.571692943572998, Last rpr Loss: 1.0006099939346313, Last lagvar Loss: 0.8450771570205688\n",
      "Step 7435/10000- lr: [2.588918533333333e-06] - Loss total: 2.5716726779937744, Last rpr Loss: 0.9993774890899658, Last lagvar Loss: 0.8463097810745239\n",
      "Step 7436/10000- lr: [2.5879084363636363e-06] - Loss total: 2.57165265083313, Last rpr Loss: 1.0005561113357544, Last lagvar Loss: 0.8451308608055115\n",
      "Step 7437/10000- lr: [2.5868983393939387e-06] - Loss total: 2.571631908416748, Last rpr Loss: 0.9995193481445312, Last lagvar Loss: 0.8461675643920898\n",
      "Step 7438/10000- lr: [2.585888242424242e-06] - Loss total: 2.5716116428375244, Last rpr Loss: 1.0003526210784912, Last lagvar Loss: 0.8453340530395508\n",
      "Step 7439/10000- lr: [2.584878145454546e-06] - Loss total: 2.57159161567688, Last rpr Loss: 0.9997699856758118, Last lagvar Loss: 0.8459166288375854\n",
      "Step 7440/10000- lr: [2.5838680484848485e-06] - Loss total: 2.571571111679077, Last rpr Loss: 1.0000865459442139, Last lagvar Loss: 0.8455998301506042\n",
      "Step 7441/10000- lr: [2.582857951515152e-06] - Loss total: 2.5715510845184326, Last rpr Loss: 1.0000360012054443, Last lagvar Loss: 0.8456504344940186\n",
      "Step 7442/10000- lr: [2.5818478545454542e-06] - Loss total: 2.57153058052063, Last rpr Loss: 0.9998424053192139, Last lagvar Loss: 0.845844030380249\n",
      "Step 7443/10000- lr: [2.5808377575757575e-06] - Loss total: 2.5715103149414062, Last rpr Loss: 1.000238299369812, Last lagvar Loss: 0.8454481363296509\n",
      "Step 7444/10000- lr: [2.57982766060606e-06] - Loss total: 2.571490526199341, Last rpr Loss: 0.9996853470802307, Last lagvar Loss: 0.8460010290145874\n",
      "Step 7445/10000- lr: [2.578817563636364e-06] - Loss total: 2.571470260620117, Last rpr Loss: 1.0003349781036377, Last lagvar Loss: 0.8453513383865356\n",
      "Step 7446/10000- lr: [2.5778074666666665e-06] - Loss total: 2.5714502334594727, Last rpr Loss: 0.9996411204338074, Last lagvar Loss: 0.8460452556610107\n",
      "Step 7447/10000- lr: [2.5767973696969698e-06] - Loss total: 2.57142972946167, Last rpr Loss: 1.000328779220581, Last lagvar Loss: 0.8453575372695923\n",
      "Step 7448/10000- lr: [2.575787272727272e-06] - Loss total: 2.5714097023010254, Last rpr Loss: 0.9996997714042664, Last lagvar Loss: 0.8459864258766174\n",
      "Step 7449/10000- lr: [2.5747771757575763e-06] - Loss total: 2.5713894367218018, Last rpr Loss: 1.0002309083938599, Last lagvar Loss: 0.8454551100730896\n",
      "Step 7450/10000- lr: [2.5737670787878787e-06] - Loss total: 2.5713694095611572, Last rpr Loss: 0.9998264908790588, Last lagvar Loss: 0.8458596467971802\n",
      "Step 7451/10000- lr: [2.572756981818182e-06] - Loss total: 2.5713493824005127, Last rpr Loss: 1.0000908374786377, Last lagvar Loss: 0.8455950021743774\n",
      "Step 7452/10000- lr: [2.5717468848484845e-06] - Loss total: 2.571329355239868, Last rpr Loss: 0.9999794960021973, Last lagvar Loss: 0.8457064628601074\n",
      "Step 7453/10000- lr: [2.5707367878787877e-06] - Loss total: 2.5713093280792236, Last rpr Loss: 0.9999398589134216, Last lagvar Loss: 0.8457460403442383\n",
      "Step 7454/10000- lr: [2.56972669090909e-06] - Loss total: 2.571289300918579, Last rpr Loss: 1.000108003616333, Last lagvar Loss: 0.8455778956413269\n",
      "Step 7455/10000- lr: [2.5687165939393943e-06] - Loss total: 2.5712692737579346, Last rpr Loss: 0.9998328685760498, Last lagvar Loss: 0.8458528518676758\n",
      "Step 7456/10000- lr: [2.5677064969696967e-06] - Loss total: 2.571249008178711, Last rpr Loss: 1.0001811981201172, Last lagvar Loss: 0.8455045223236084\n",
      "Step 7457/10000- lr: [2.5666964e-06] - Loss total: 2.5712292194366455, Last rpr Loss: 0.9997916221618652, Last lagvar Loss: 0.8458940982818604\n",
      "Step 7458/10000- lr: [2.5656863030303024e-06] - Loss total: 2.571209192276001, Last rpr Loss: 1.0001943111419678, Last lagvar Loss: 0.8454912900924683\n",
      "Step 7459/10000- lr: [2.5646762060606065e-06] - Loss total: 2.5711891651153564, Last rpr Loss: 0.9998146295547485, Last lagvar Loss: 0.8458709120750427\n",
      "Step 7460/10000- lr: [2.563666109090909e-06] - Loss total: 2.571169137954712, Last rpr Loss: 1.0001473426818848, Last lagvar Loss: 0.8455382585525513\n",
      "Step 7461/10000- lr: [2.5626560121212123e-06] - Loss total: 2.5711491107940674, Last rpr Loss: 0.9998759031295776, Last lagvar Loss: 0.8458095788955688\n",
      "Step 7462/10000- lr: [2.5616459151515147e-06] - Loss total: 2.571129322052002, Last rpr Loss: 1.0000755786895752, Last lagvar Loss: 0.8456099033355713\n",
      "Step 7463/10000- lr: [2.560635818181818e-06] - Loss total: 2.5711090564727783, Last rpr Loss: 0.9999487996101379, Last lagvar Loss: 0.8457365036010742\n",
      "Step 7464/10000- lr: [2.5596257212121204e-06] - Loss total: 2.571089029312134, Last rpr Loss: 1.000006914138794, Last lagvar Loss: 0.845678448677063\n",
      "Step 7465/10000- lr: [2.5586156242424245e-06] - Loss total: 2.5710690021514893, Last rpr Loss: 1.0000165700912476, Last lagvar Loss: 0.8456686735153198\n",
      "Step 7466/10000- lr: [2.557605527272727e-06] - Loss total: 2.571049213409424, Last rpr Loss: 0.9999425411224365, Last lagvar Loss: 0.8457427024841309\n",
      "Step 7467/10000- lr: [2.5565954303030302e-06] - Loss total: 2.5710291862487793, Last rpr Loss: 1.0000730752944946, Last lagvar Loss: 0.845612108707428\n",
      "Step 7468/10000- lr: [2.5555853333333327e-06] - Loss total: 2.571009635925293, Last rpr Loss: 0.999893069267273, Last lagvar Loss: 0.8457920551300049\n",
      "Step 7469/10000- lr: [2.5545752363636368e-06] - Loss total: 2.5709893703460693, Last rpr Loss: 1.0001075267791748, Last lagvar Loss: 0.845577597618103\n",
      "Step 7470/10000- lr: [2.553565139393939e-06] - Loss total: 2.570969820022583, Last rpr Loss: 0.9998744130134583, Last lagvar Loss: 0.8458107113838196\n",
      "Step 7471/10000- lr: [2.5525550424242425e-06] - Loss total: 2.5709495544433594, Last rpr Loss: 1.0001147985458374, Last lagvar Loss: 0.8455702066421509\n",
      "Step 7472/10000- lr: [2.551544945454545e-06] - Loss total: 2.570929765701294, Last rpr Loss: 0.9998831152915955, Last lagvar Loss: 0.845801830291748\n",
      "Step 7473/10000- lr: [2.550534848484848e-06] - Loss total: 2.5709102153778076, Last rpr Loss: 1.0000954866409302, Last lagvar Loss: 0.8455895185470581\n",
      "Step 7474/10000- lr: [2.5495247515151515e-06] - Loss total: 2.570890426635742, Last rpr Loss: 0.9999075531959534, Last lagvar Loss: 0.8457773327827454\n",
      "Step 7475/10000- lr: [2.5485146545454547e-06] - Loss total: 2.5708703994750977, Last rpr Loss: 1.0000602006912231, Last lagvar Loss: 0.845624566078186\n",
      "Step 7476/10000- lr: [2.547504557575757e-06] - Loss total: 2.5708506107330322, Last rpr Loss: 0.9999533891677856, Last lagvar Loss: 0.8457314968109131\n",
      "Step 7477/10000- lr: [2.5464944606060605e-06] - Loss total: 2.570830821990967, Last rpr Loss: 1.0000145435333252, Last lagvar Loss: 0.845670223236084\n",
      "Step 7478/10000- lr: [2.545484363636363e-06] - Loss total: 2.5708112716674805, Last rpr Loss: 0.9999932050704956, Last lagvar Loss: 0.8456915616989136\n",
      "Step 7479/10000- lr: [2.544474266666667e-06] - Loss total: 2.570791006088257, Last rpr Loss: 0.9999783039093018, Last lagvar Loss: 0.8457063436508179\n",
      "Step 7480/10000- lr: [2.5434641696969694e-06] - Loss total: 2.5707714557647705, Last rpr Loss: 1.0000255107879639, Last lagvar Loss: 0.8456592559814453\n",
      "Step 7481/10000- lr: [2.5424540727272727e-06] - Loss total: 2.570751428604126, Last rpr Loss: 0.9999556541442871, Last lagvar Loss: 0.845728874206543\n",
      "Step 7482/10000- lr: [2.541443975757575e-06] - Loss total: 2.5707316398620605, Last rpr Loss: 1.0000414848327637, Last lagvar Loss: 0.8456431031227112\n",
      "Step 7483/10000- lr: [2.5404338787878784e-06] - Loss total: 2.5707123279571533, Last rpr Loss: 0.9999420642852783, Last lagvar Loss: 0.8457424640655518\n",
      "Step 7484/10000- lr: [2.5394237818181817e-06] - Loss total: 2.570692539215088, Last rpr Loss: 1.000045895576477, Last lagvar Loss: 0.8456385731697083\n",
      "Step 7485/10000- lr: [2.538413684848485e-06] - Loss total: 2.5706727504730225, Last rpr Loss: 0.9999430179595947, Last lagvar Loss: 0.8457413911819458\n",
      "Step 7486/10000- lr: [2.5374035878787874e-06] - Loss total: 2.570652723312378, Last rpr Loss: 1.000044345855713, Last lagvar Loss: 0.8456401228904724\n",
      "Step 7487/10000- lr: [2.5363934909090907e-06] - Loss total: 2.5706329345703125, Last rpr Loss: 0.9999517202377319, Last lagvar Loss: 0.8457326889038086\n",
      "Step 7488/10000- lr: [2.535383393939393e-06] - Loss total: 2.570613145828247, Last rpr Loss: 1.000035047531128, Last lagvar Loss: 0.845649242401123\n",
      "Step 7489/10000- lr: [2.5343732969696972e-06] - Loss total: 2.57059383392334, Last rpr Loss: 0.9999598860740662, Last lagvar Loss: 0.84572434425354\n",
      "Step 7490/10000- lr: [2.5333631999999997e-06] - Loss total: 2.5705740451812744, Last rpr Loss: 1.0000169277191162, Last lagvar Loss: 0.8456672430038452\n",
      "Step 7491/10000- lr: [2.532353103030303e-06] - Loss total: 2.570554256439209, Last rpr Loss: 0.9999843835830688, Last lagvar Loss: 0.8456997871398926\n",
      "Step 7492/10000- lr: [2.5313430060606054e-06] - Loss total: 2.5705347061157227, Last rpr Loss: 0.9999974966049194, Last lagvar Loss: 0.845686674118042\n",
      "Step 7493/10000- lr: [2.5303329090909086e-06] - Loss total: 2.5705149173736572, Last rpr Loss: 0.9999993443489075, Last lagvar Loss: 0.8456847667694092\n",
      "Step 7494/10000- lr: [2.529322812121212e-06] - Loss total: 2.570495128631592, Last rpr Loss: 0.9999812841415405, Last lagvar Loss: 0.8457026481628418\n",
      "Step 7495/10000- lr: [2.528312715151515e-06] - Loss total: 2.5704758167266846, Last rpr Loss: 1.0000126361846924, Last lagvar Loss: 0.8456714153289795\n",
      "Step 7496/10000- lr: [2.5273026181818176e-06] - Loss total: 2.5704562664031982, Last rpr Loss: 0.9999759793281555, Last lagvar Loss: 0.8457080125808716\n",
      "Step 7497/10000- lr: [2.526292521212121e-06] - Loss total: 2.570436477661133, Last rpr Loss: 1.0000128746032715, Last lagvar Loss: 0.8456711769104004\n",
      "Step 7498/10000- lr: [2.5252824242424233e-06] - Loss total: 2.5704166889190674, Last rpr Loss: 0.9999817609786987, Last lagvar Loss: 0.8457021117210388\n",
      "Step 7499/10000- lr: [2.5242723272727275e-06] - Loss total: 2.570397138595581, Last rpr Loss: 1.0000030994415283, Last lagvar Loss: 0.8456807136535645\n",
      "Step 7500/10000- lr: [2.52326223030303e-06] - Loss total: 2.570377826690674, Last rpr Loss: 0.9999875426292419, Last lagvar Loss: 0.845696210861206\n",
      "Step 7501/10000- lr: [2.522252133333333e-06] - Loss total: 2.5703580379486084, Last rpr Loss: 0.9999980926513672, Last lagvar Loss: 0.8456857204437256\n",
      "Step 7502/10000- lr: [2.5212420363636356e-06] - Loss total: 2.570338487625122, Last rpr Loss: 0.999997615814209, Last lagvar Loss: 0.8456861972808838\n",
      "Step 7503/10000- lr: [2.520231939393939e-06] - Loss total: 2.5703186988830566, Last rpr Loss: 0.999987781047821, Last lagvar Loss: 0.845695972442627\n",
      "Step 7504/10000- lr: [2.519221842424242e-06] - Loss total: 2.5702991485595703, Last rpr Loss: 1.000002384185791, Last lagvar Loss: 0.8456812500953674\n",
      "Step 7505/10000- lr: [2.5182117454545454e-06] - Loss total: 2.570279836654663, Last rpr Loss: 0.9999876022338867, Last lagvar Loss: 0.8456960320472717\n",
      "Step 7506/10000- lr: [2.517201648484848e-06] - Loss total: 2.5702600479125977, Last rpr Loss: 1.000002145767212, Last lagvar Loss: 0.8456814289093018\n",
      "Step 7507/10000- lr: [2.516191551515151e-06] - Loss total: 2.5702404975891113, Last rpr Loss: 0.9999901056289673, Last lagvar Loss: 0.8456934094429016\n",
      "Step 7508/10000- lr: [2.5151814545454536e-06] - Loss total: 2.570220708847046, Last rpr Loss: 0.9999933242797852, Last lagvar Loss: 0.8456901907920837\n",
      "Step 7509/10000- lr: [2.5141713575757577e-06] - Loss total: 2.5702011585235596, Last rpr Loss: 0.9999990463256836, Last lagvar Loss: 0.8456843495368958\n",
      "Step 7510/10000- lr: [2.51316126060606e-06] - Loss total: 2.5701818466186523, Last rpr Loss: 0.9999876022338867, Last lagvar Loss: 0.8456957340240479\n",
      "Step 7511/10000- lr: [2.5121511636363634e-06] - Loss total: 2.570162296295166, Last rpr Loss: 1.000006079673767, Last lagvar Loss: 0.8456772565841675\n",
      "Step 7512/10000- lr: [2.511141066666666e-06] - Loss total: 2.5701427459716797, Last rpr Loss: 0.9999843239784241, Last lagvar Loss: 0.8456989526748657\n",
      "Step 7513/10000- lr: [2.510130969696969e-06] - Loss total: 2.5701234340667725, Last rpr Loss: 1.0000081062316895, Last lagvar Loss: 0.8456752300262451\n",
      "Step 7514/10000- lr: [2.5091208727272724e-06] - Loss total: 2.570103883743286, Last rpr Loss: 0.9999780654907227, Last lagvar Loss: 0.8457051515579224\n",
      "Step 7515/10000- lr: [2.5081107757575757e-06] - Loss total: 2.570084571838379, Last rpr Loss: 1.0000126361846924, Last lagvar Loss: 0.8456705808639526\n",
      "Step 7516/10000- lr: [2.507100678787878e-06] - Loss total: 2.5700650215148926, Last rpr Loss: 0.9999722242355347, Last lagvar Loss: 0.8457109928131104\n",
      "Step 7517/10000- lr: [2.5060905818181814e-06] - Loss total: 2.5700454711914062, Last rpr Loss: 1.0000205039978027, Last lagvar Loss: 0.8456625938415527\n",
      "Step 7518/10000- lr: [2.505080484848484e-06] - Loss total: 2.57002592086792, Last rpr Loss: 0.999967098236084, Last lagvar Loss: 0.8457159399986267\n",
      "Step 7519/10000- lr: [2.504070387878788e-06] - Loss total: 2.5700066089630127, Last rpr Loss: 1.0000224113464355, Last lagvar Loss: 0.8456606864929199\n",
      "Step 7520/10000- lr: [2.5030602909090904e-06] - Loss total: 2.5699870586395264, Last rpr Loss: 0.9999704360961914, Last lagvar Loss: 0.8457125425338745\n",
      "Step 7521/10000- lr: [2.5020501939393936e-06] - Loss total: 2.569967746734619, Last rpr Loss: 1.0000145435333252, Last lagvar Loss: 0.845668375492096\n",
      "Step 7522/10000- lr: [2.501040096969696e-06] - Loss total: 2.569948434829712, Last rpr Loss: 0.9999784231185913, Last lagvar Loss: 0.8457045555114746\n",
      "Step 7523/10000- lr: [2.50003e-06] - Loss total: 2.5699291229248047, Last rpr Loss: 1.00001060962677, Last lagvar Loss: 0.8456723093986511\n",
      "Step 7524/10000- lr: [2.4990199030303035e-06] - Loss total: 2.5699093341827393, Last rpr Loss: 0.9999812245368958, Last lagvar Loss: 0.8457016944885254\n",
      "Step 7525/10000- lr: [2.498009806060606e-06] - Loss total: 2.569890022277832, Last rpr Loss: 1.000006914138794, Last lagvar Loss: 0.8456758856773376\n",
      "Step 7526/10000- lr: [2.496999709090909e-06] - Loss total: 2.569870710372925, Last rpr Loss: 0.9999861717224121, Last lagvar Loss: 0.8456966280937195\n",
      "Step 7527/10000- lr: [2.4959896121212116e-06] - Loss total: 2.5698511600494385, Last rpr Loss: 0.9999994039535522, Last lagvar Loss: 0.8456833362579346\n",
      "Step 7528/10000- lr: [2.4949795151515157e-06] - Loss total: 2.5698320865631104, Last rpr Loss: 0.9999889135360718, Last lagvar Loss: 0.845693826675415\n",
      "Step 7529/10000- lr: [2.493969418181818e-06] - Loss total: 2.569812297821045, Last rpr Loss: 1.000000238418579, Last lagvar Loss: 0.8456825017929077\n",
      "Step 7530/10000- lr: [2.4929593212121214e-06] - Loss total: 2.569793224334717, Last rpr Loss: 0.9999910593032837, Last lagvar Loss: 0.8456915616989136\n",
      "Step 7531/10000- lr: [2.491949224242424e-06] - Loss total: 2.5697739124298096, Last rpr Loss: 0.9999988079071045, Last lagvar Loss: 0.8456839323043823\n",
      "Step 7532/10000- lr: [2.490939127272727e-06] - Loss total: 2.5697543621063232, Last rpr Loss: 0.9999929666519165, Last lagvar Loss: 0.8456895351409912\n",
      "Step 7533/10000- lr: [2.4899290303030304e-06] - Loss total: 2.569735050201416, Last rpr Loss: 0.9999968409538269, Last lagvar Loss: 0.845685601234436\n",
      "Step 7534/10000- lr: [2.4889189333333337e-06] - Loss total: 2.5697154998779297, Last rpr Loss: 0.9999935626983643, Last lagvar Loss: 0.8456889390945435\n",
      "Step 7535/10000- lr: [2.487908836363636e-06] - Loss total: 2.5696961879730225, Last rpr Loss: 0.9999939203262329, Last lagvar Loss: 0.8456884622573853\n",
      "Step 7536/10000- lr: [2.4868987393939394e-06] - Loss total: 2.5696768760681152, Last rpr Loss: 0.9999971389770508, Last lagvar Loss: 0.8456853628158569\n",
      "Step 7537/10000- lr: [2.485888642424242e-06] - Loss total: 2.569657564163208, Last rpr Loss: 0.9999886751174927, Last lagvar Loss: 0.8456937074661255\n",
      "Step 7538/10000- lr: [2.484878545454546e-06] - Loss total: 2.56963849067688, Last rpr Loss: 1.000002384185791, Last lagvar Loss: 0.8456798195838928\n",
      "Step 7539/10000- lr: [2.4838684484848484e-06] - Loss total: 2.5696189403533936, Last rpr Loss: 0.9999899864196777, Last lagvar Loss: 0.8456923365592957\n",
      "Step 7540/10000- lr: [2.4828583515151517e-06] - Loss total: 2.5696001052856445, Last rpr Loss: 0.9999963045120239, Last lagvar Loss: 0.8456859588623047\n",
      "Step 7541/10000- lr: [2.481848254545454e-06] - Loss total: 2.569580554962158, Last rpr Loss: 0.9999966025352478, Last lagvar Loss: 0.8456856608390808\n",
      "Step 7542/10000- lr: [2.4808381575757574e-06] - Loss total: 2.569561719894409, Last rpr Loss: 0.9999918341636658, Last lagvar Loss: 0.8456903696060181\n",
      "Step 7543/10000- lr: [2.4798280606060606e-06] - Loss total: 2.5695419311523438, Last rpr Loss: 0.9999995827674866, Last lagvar Loss: 0.8456825017929077\n",
      "Step 7544/10000- lr: [2.478817963636364e-06] - Loss total: 2.5695226192474365, Last rpr Loss: 0.9999919533729553, Last lagvar Loss: 0.8456901907920837\n",
      "Step 7545/10000- lr: [2.4778078666666664e-06] - Loss total: 2.5695033073425293, Last rpr Loss: 0.9999929666519165, Last lagvar Loss: 0.8456891775131226\n",
      "Step 7546/10000- lr: [2.4767977696969696e-06] - Loss total: 2.569483995437622, Last rpr Loss: 0.9999969005584717, Last lagvar Loss: 0.8456851243972778\n",
      "Step 7547/10000- lr: [2.475787672727272e-06] - Loss total: 2.569464921951294, Last rpr Loss: 0.9999909996986389, Last lagvar Loss: 0.8456910848617554\n",
      "Step 7548/10000- lr: [2.474777575757576e-06] - Loss total: 2.569445848464966, Last rpr Loss: 1.0000035762786865, Last lagvar Loss: 0.845678448677063\n",
      "Step 7549/10000- lr: [2.4737674787878786e-06] - Loss total: 2.5694267749786377, Last rpr Loss: 0.9999868869781494, Last lagvar Loss: 0.8456951379776001\n",
      "Step 7550/10000- lr: [2.472757381818182e-06] - Loss total: 2.5694074630737305, Last rpr Loss: 1.0000040531158447, Last lagvar Loss: 0.8456778526306152\n",
      "Step 7551/10000- lr: [2.4717472848484843e-06] - Loss total: 2.5693883895874023, Last rpr Loss: 0.9999845027923584, Last lagvar Loss: 0.8456974029541016\n",
      "Step 7552/10000- lr: [2.4707371878787876e-06] - Loss total: 2.569368839263916, Last rpr Loss: 1.0000026226043701, Last lagvar Loss: 0.8456792235374451\n",
      "Step 7553/10000- lr: [2.469727090909091e-06] - Loss total: 2.569349765777588, Last rpr Loss: 0.9999865293502808, Last lagvar Loss: 0.8456953763961792\n",
      "Step 7554/10000- lr: [2.468716993939394e-06] - Loss total: 2.5693304538726807, Last rpr Loss: 1.0000038146972656, Last lagvar Loss: 0.8456780314445496\n",
      "Step 7555/10000- lr: [2.4677068969696966e-06] - Loss total: 2.5693113803863525, Last rpr Loss: 0.999988317489624, Last lagvar Loss: 0.8456934094429016\n",
      "Step 7556/10000- lr: [2.4666968e-06] - Loss total: 2.569291830062866, Last rpr Loss: 1.000002145767212, Last lagvar Loss: 0.845679521560669\n",
      "Step 7557/10000- lr: [2.4656867030303023e-06] - Loss total: 2.569272756576538, Last rpr Loss: 0.9999868273735046, Last lagvar Loss: 0.8456948399543762\n",
      "Step 7558/10000- lr: [2.4646766060606064e-06] - Loss total: 2.569253921508789, Last rpr Loss: 1.0000008344650269, Last lagvar Loss: 0.8456807732582092\n",
      "Step 7559/10000- lr: [2.463666509090909e-06] - Loss total: 2.569234609603882, Last rpr Loss: 0.9999899864196777, Last lagvar Loss: 0.8456916809082031\n",
      "Step 7560/10000- lr: [2.462656412121212e-06] - Loss total: 2.5692155361175537, Last rpr Loss: 0.9999998211860657, Last lagvar Loss: 0.8456817269325256\n",
      "Step 7561/10000- lr: [2.4616463151515146e-06] - Loss total: 2.5691959857940674, Last rpr Loss: 0.9999901056289673, Last lagvar Loss: 0.845691442489624\n",
      "Step 7562/10000- lr: [2.460636218181818e-06] - Loss total: 2.5691769123077393, Last rpr Loss: 0.9999997019767761, Last lagvar Loss: 0.8456817865371704\n",
      "Step 7563/10000- lr: [2.459626121212121e-06] - Loss total: 2.569157838821411, Last rpr Loss: 0.9999911189079285, Last lagvar Loss: 0.8456903100013733\n",
      "Step 7564/10000- lr: [2.4586160242424244e-06] - Loss total: 2.569138765335083, Last rpr Loss: 0.9999998211860657, Last lagvar Loss: 0.8456816673278809\n",
      "Step 7565/10000- lr: [2.457605927272727e-06] - Loss total: 2.569119691848755, Last rpr Loss: 0.9999921321868896, Last lagvar Loss: 0.8456892967224121\n",
      "Step 7566/10000- lr: [2.45659583030303e-06] - Loss total: 2.5691006183624268, Last rpr Loss: 0.9999967217445374, Last lagvar Loss: 0.8456847071647644\n",
      "Step 7567/10000- lr: [2.4555857333333325e-06] - Loss total: 2.5690817832946777, Last rpr Loss: 0.9999923706054688, Last lagvar Loss: 0.8456889986991882\n",
      "Step 7568/10000- lr: [2.4545756363636366e-06] - Loss total: 2.5690624713897705, Last rpr Loss: 0.9999921321868896, Last lagvar Loss: 0.8456891775131226\n",
      "Step 7569/10000- lr: [2.453565539393939e-06] - Loss total: 2.5690433979034424, Last rpr Loss: 0.9999985098838806, Last lagvar Loss: 0.8456827402114868\n",
      "Step 7570/10000- lr: [2.4525554424242424e-06] - Loss total: 2.5690243244171143, Last rpr Loss: 0.9999953508377075, Last lagvar Loss: 0.8456858396530151\n",
      "Step 7571/10000- lr: [2.4515453454545448e-06] - Loss total: 2.569005250930786, Last rpr Loss: 0.9999968409538269, Last lagvar Loss: 0.8456844091415405\n",
      "Step 7572/10000- lr: [2.450535248484848e-06] - Loss total: 2.568986177444458, Last rpr Loss: 0.999992847442627, Last lagvar Loss: 0.8456883430480957\n",
      "Step 7573/10000- lr: [2.4495251515151513e-06] - Loss total: 2.56896710395813, Last rpr Loss: 0.9999986886978149, Last lagvar Loss: 0.8456823825836182\n",
      "Step 7574/10000- lr: [2.4485150545454546e-06] - Loss total: 2.5689480304718018, Last rpr Loss: 0.999987781047821, Last lagvar Loss: 0.8456933498382568\n",
      "Step 7575/10000- lr: [2.447504957575757e-06] - Loss total: 2.5689289569854736, Last rpr Loss: 0.9999992251396179, Last lagvar Loss: 0.8456817865371704\n",
      "Step 7576/10000- lr: [2.4464948606060603e-06] - Loss total: 2.5689098834991455, Last rpr Loss: 0.9999912977218628, Last lagvar Loss: 0.8456897735595703\n",
      "Step 7577/10000- lr: [2.4454847636363627e-06] - Loss total: 2.5688908100128174, Last rpr Loss: 0.9999976754188538, Last lagvar Loss: 0.8456834554672241\n",
      "Step 7578/10000- lr: [2.444474666666667e-06] - Loss total: 2.5688719749450684, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.8456845283508301\n",
      "Step 7579/10000- lr: [2.4434645696969693e-06] - Loss total: 2.5688531398773193, Last rpr Loss: 0.9999933838844299, Last lagvar Loss: 0.8456876277923584\n",
      "Step 7580/10000- lr: [2.4424544727272726e-06] - Loss total: 2.568834066390991, Last rpr Loss: 0.9999992847442627, Last lagvar Loss: 0.8456816077232361\n",
      "Step 7581/10000- lr: [2.441444375757575e-06] - Loss total: 2.568814516067505, Last rpr Loss: 0.99998939037323, Last lagvar Loss: 0.845691442489624\n",
      "Step 7582/10000- lr: [2.440434278787879e-06] - Loss total: 2.568795680999756, Last rpr Loss: 0.9999991059303284, Last lagvar Loss: 0.8456817269325256\n",
      "Step 7583/10000- lr: [2.4394241818181816e-06] - Loss total: 2.568776845932007, Last rpr Loss: 0.9999874830245972, Last lagvar Loss: 0.8456933498382568\n",
      "Step 7584/10000- lr: [2.438414084848485e-06] - Loss total: 2.568758010864258, Last rpr Loss: 1.0000028610229492, Last lagvar Loss: 0.8456779718399048\n",
      "Step 7585/10000- lr: [2.4374039878787873e-06] - Loss total: 2.5687386989593506, Last rpr Loss: 0.9999871253967285, Last lagvar Loss: 0.8456937074661255\n",
      "Step 7586/10000- lr: [2.4363938909090905e-06] - Loss total: 2.5687198638916016, Last rpr Loss: 1.0000059604644775, Last lagvar Loss: 0.8456746935844421\n",
      "Step 7587/10000- lr: [2.435383793939393e-06] - Loss total: 2.5687007904052734, Last rpr Loss: 0.999988317489624, Last lagvar Loss: 0.8456923961639404\n",
      "Step 7588/10000- lr: [2.434373696969697e-06] - Loss total: 2.5686819553375244, Last rpr Loss: 1.0000011920928955, Last lagvar Loss: 0.845679521560669\n",
      "Step 7589/10000- lr: [2.4333635999999995e-06] - Loss total: 2.5686631202697754, Last rpr Loss: 0.9999874830245972, Last lagvar Loss: 0.845693051815033\n",
      "Step 7590/10000- lr: [2.432353503030303e-06] - Loss total: 2.5686440467834473, Last rpr Loss: 0.9999975562095642, Last lagvar Loss: 0.8456830382347107\n",
      "Step 7591/10000- lr: [2.4313434060606052e-06] - Loss total: 2.568624973297119, Last rpr Loss: 0.9999949336051941, Last lagvar Loss: 0.845685601234436\n",
      "Step 7592/10000- lr: [2.4303333090909094e-06] - Loss total: 2.56860613822937, Last rpr Loss: 0.9999942183494568, Last lagvar Loss: 0.8456863164901733\n",
      "Step 7593/10000- lr: [2.429323212121212e-06] - Loss total: 2.568587064743042, Last rpr Loss: 0.9999954700469971, Last lagvar Loss: 0.8456850051879883\n",
      "Step 7594/10000- lr: [2.428313115151515e-06] - Loss total: 2.568568468093872, Last rpr Loss: 0.9999960064888, Last lagvar Loss: 0.8456844091415405\n",
      "Step 7595/10000- lr: [2.4273030181818175e-06] - Loss total: 2.568549394607544, Last rpr Loss: 0.999993622303009, Last lagvar Loss: 0.8456869125366211\n",
      "Step 7596/10000- lr: [2.4262929212121208e-06] - Loss total: 2.568530559539795, Last rpr Loss: 0.9999967813491821, Last lagvar Loss: 0.8456836342811584\n",
      "Step 7597/10000- lr: [2.425282824242423e-06] - Loss total: 2.568511724472046, Last rpr Loss: 0.9999951720237732, Last lagvar Loss: 0.8456851840019226\n",
      "Step 7598/10000- lr: [2.4242727272727273e-06] - Loss total: 2.5684926509857178, Last rpr Loss: 0.999992847442627, Last lagvar Loss: 0.8456874489784241\n",
      "Step 7599/10000- lr: [2.4232626303030298e-06] - Loss total: 2.568474054336548, Last rpr Loss: 0.9999986886978149, Last lagvar Loss: 0.8456816673278809\n",
      "Step 7600/10000- lr: [2.422252533333333e-06] - Loss total: 2.5684549808502197, Last rpr Loss: 0.9999867677688599, Last lagvar Loss: 0.8456934690475464\n",
      "Step 7601/10000- lr: [2.4212424363636355e-06] - Loss total: 2.5684359073638916, Last rpr Loss: 1.0000097751617432, Last lagvar Loss: 0.8456703424453735\n",
      "Step 7602/10000- lr: [2.4202323393939396e-06] - Loss total: 2.5684173107147217, Last rpr Loss: 0.999976396560669, Last lagvar Loss: 0.8457038402557373\n",
      "Step 7603/10000- lr: [2.419222242424242e-06] - Loss total: 2.5683987140655518, Last rpr Loss: 1.000016212463379, Last lagvar Loss: 0.8456639647483826\n",
      "Step 7604/10000- lr: [2.4182121454545453e-06] - Loss total: 2.5683796405792236, Last rpr Loss: 0.9999709129333496, Last lagvar Loss: 0.8457092642784119\n",
      "Step 7605/10000- lr: [2.4172020484848477e-06] - Loss total: 2.5683605670928955, Last rpr Loss: 1.0000197887420654, Last lagvar Loss: 0.8456603288650513\n",
      "Step 7606/10000- lr: [2.416191951515151e-06] - Loss total: 2.5683417320251465, Last rpr Loss: 0.9999677538871765, Last lagvar Loss: 0.8457123637199402\n",
      "Step 7607/10000- lr: [2.4151818545454534e-06] - Loss total: 2.5683228969573975, Last rpr Loss: 1.0000287294387817, Last lagvar Loss: 0.8456512689590454\n",
      "Step 7608/10000- lr: [2.4141717575757576e-06] - Loss total: 2.5683043003082275, Last rpr Loss: 0.9999583959579468, Last lagvar Loss: 0.8457217216491699\n",
      "Step 7609/10000- lr: [2.413161660606061e-06] - Loss total: 2.5682854652404785, Last rpr Loss: 1.0000333786010742, Last lagvar Loss: 0.8456466794013977\n",
      "Step 7610/10000- lr: [2.4121515636363633e-06] - Loss total: 2.5682661533355713, Last rpr Loss: 0.9999493360519409, Last lagvar Loss: 0.8457306623458862\n",
      "Step 7611/10000- lr: [2.4111414666666665e-06] - Loss total: 2.5682473182678223, Last rpr Loss: 1.0000499486923218, Last lagvar Loss: 0.8456300497055054\n",
      "Step 7612/10000- lr: [2.41013136969697e-06] - Loss total: 2.5682287216186523, Last rpr Loss: 0.9999337792396545, Last lagvar Loss: 0.8457461595535278\n",
      "Step 7613/10000- lr: [2.409121272727273e-06] - Loss total: 2.5682098865509033, Last rpr Loss: 1.0000665187835693, Last lagvar Loss: 0.8456132411956787\n",
      "Step 7614/10000- lr: [2.4081111757575755e-06] - Loss total: 2.5681910514831543, Last rpr Loss: 0.9999128580093384, Last lagvar Loss: 0.8457669615745544\n",
      "Step 7615/10000- lr: [2.407101078787879e-06] - Loss total: 2.5681724548339844, Last rpr Loss: 1.0000848770141602, Last lagvar Loss: 0.8455950021743774\n",
      "Step 7616/10000- lr: [2.4060909818181812e-06] - Loss total: 2.5681538581848145, Last rpr Loss: 0.9998910427093506, Last lagvar Loss: 0.8457887172698975\n",
      "Step 7617/10000- lr: [2.4050808848484854e-06] - Loss total: 2.5681345462799072, Last rpr Loss: 1.0001134872436523, Last lagvar Loss: 0.8455663323402405\n",
      "Step 7618/10000- lr: [2.404070787878788e-06] - Loss total: 2.5681161880493164, Last rpr Loss: 0.9998658299446106, Last lagvar Loss: 0.8458139896392822\n",
      "Step 7619/10000- lr: [2.403060690909091e-06] - Loss total: 2.5680973529815674, Last rpr Loss: 1.0001420974731445, Last lagvar Loss: 0.845537543296814\n",
      "Step 7620/10000- lr: [2.4020505939393935e-06] - Loss total: 2.5680787563323975, Last rpr Loss: 0.9998288154602051, Last lagvar Loss: 0.845850944519043\n",
      "Step 7621/10000- lr: [2.4010404969696968e-06] - Loss total: 2.5680596828460693, Last rpr Loss: 1.000185489654541, Last lagvar Loss: 0.8454940319061279\n",
      "Step 7622/10000- lr: [2.4000304e-06] - Loss total: 2.5680410861968994, Last rpr Loss: 0.9997721910476685, Last lagvar Loss: 0.84590744972229\n",
      "Step 7623/10000- lr: [2.3990203030303033e-06] - Loss total: 2.5680222511291504, Last rpr Loss: 1.000253677368164, Last lagvar Loss: 0.8454259037971497\n",
      "Step 7624/10000- lr: [2.3980102060606058e-06] - Loss total: 2.5680036544799805, Last rpr Loss: 0.9996945261955261, Last lagvar Loss: 0.8459851145744324\n",
      "Step 7625/10000- lr: [2.397000109090909e-06] - Loss total: 2.5679848194122314, Last rpr Loss: 1.0003433227539062, Last lagvar Loss: 0.8453362584114075\n",
      "Step 7626/10000- lr: [2.3959900121212115e-06] - Loss total: 2.5679662227630615, Last rpr Loss: 0.999589741230011, Last lagvar Loss: 0.8460900783538818\n",
      "Step 7627/10000- lr: [2.3949799151515156e-06] - Loss total: 2.5679476261138916, Last rpr Loss: 1.0004701614379883, Last lagvar Loss: 0.8452094197273254\n",
      "Step 7628/10000- lr: [2.393969818181818e-06] - Loss total: 2.567929267883301, Last rpr Loss: 0.9994423985481262, Last lagvar Loss: 0.8462374210357666\n",
      "Step 7629/10000- lr: [2.3929597212121213e-06] - Loss total: 2.5679104328155518, Last rpr Loss: 1.000641107559204, Last lagvar Loss: 0.845038652420044\n",
      "Step 7630/10000- lr: [2.3919496242424237e-06] - Loss total: 2.567891836166382, Last rpr Loss: 0.9992373585700989, Last lagvar Loss: 0.8464426398277283\n",
      "Step 7631/10000- lr: [2.390939527272727e-06] - Loss total: 2.567873477935791, Last rpr Loss: 1.0008764266967773, Last lagvar Loss: 0.8448035717010498\n",
      "Step 7632/10000- lr: [2.3899294303030303e-06] - Loss total: 2.5678551197052, Last rpr Loss: 0.9989697933197021, Last lagvar Loss: 0.8467108011245728\n",
      "Step 7633/10000- lr: [2.3889193333333336e-06] - Loss total: 2.5678365230560303, Last rpr Loss: 1.0011926889419556, Last lagvar Loss: 0.8444879651069641\n",
      "Step 7634/10000- lr: [2.387909236363636e-06] - Loss total: 2.5678186416625977, Last rpr Loss: 0.9985964894294739, Last lagvar Loss: 0.8470849990844727\n",
      "Step 7635/10000- lr: [2.3868991393939393e-06] - Loss total: 2.567800998687744, Last rpr Loss: 1.0016340017318726, Last lagvar Loss: 0.8440477848052979\n",
      "Step 7636/10000- lr: [2.3858890424242417e-06] - Loss total: 2.5677828788757324, Last rpr Loss: 0.9980735778808594, Last lagvar Loss: 0.8476098775863647\n",
      "Step 7637/10000- lr: [2.384878945454546e-06] - Loss total: 2.567765474319458, Last rpr Loss: 1.0022451877593994, Last lagvar Loss: 0.843438982963562\n",
      "Step 7638/10000- lr: [2.3838688484848483e-06] - Loss total: 2.5677490234375, Last rpr Loss: 0.9973520040512085, Last lagvar Loss: 0.8483349680900574\n",
      "Step 7639/10000- lr: [2.3828587515151515e-06] - Loss total: 2.5677330493927, Last rpr Loss: 1.003103494644165, Last lagvar Loss: 0.8425853848457336\n",
      "Step 7640/10000- lr: [2.381848654545454e-06] - Loss total: 2.567718029022217, Last rpr Loss: 0.9963431358337402, Last lagvar Loss: 0.8493507504463196\n",
      "Step 7641/10000- lr: [2.380838557575758e-06] - Loss total: 2.567704439163208, Last rpr Loss: 1.0042915344238281, Last lagvar Loss: 0.8414064645767212\n",
      "Step 7642/10000- lr: [2.3798284606060605e-06] - Loss total: 2.5676934719085693, Last rpr Loss: 0.9949352741241455, Last lagvar Loss: 0.8507719039916992\n",
      "Step 7643/10000- lr: [2.378818363636364e-06] - Loss total: 2.5676841735839844, Last rpr Loss: 1.0059466361999512, Last lagvar Loss: 0.8397690653800964\n",
      "Step 7644/10000- lr: [2.3778082666666662e-06] - Loss total: 2.5676801204681396, Last rpr Loss: 0.992996335029602, Last lagvar Loss: 0.8527362942695618\n",
      "Step 7645/10000- lr: [2.3767981696969695e-06] - Loss total: 2.567678689956665, Last rpr Loss: 1.0082147121429443, Last lagvar Loss: 0.8375340104103088\n",
      "Step 7646/10000- lr: [2.375788072727272e-06] - Loss total: 2.5676872730255127, Last rpr Loss: 0.990376353263855, Last lagvar Loss: 0.8554036617279053\n",
      "Step 7647/10000- lr: [2.374777975757576e-06] - Loss total: 2.5676987171173096, Last rpr Loss: 1.011205792427063, Last lagvar Loss: 0.8346027135848999\n",
      "Step 7648/10000- lr: [2.3737678787878785e-06] - Loss total: 2.5677285194396973, Last rpr Loss: 0.9870024919509888, Last lagvar Loss: 0.8588607311248779\n",
      "Step 7649/10000- lr: [2.3727577818181818e-06] - Loss total: 2.5677542686462402, Last rpr Loss: 1.0148998498916626, Last lagvar Loss: 0.8310064077377319\n",
      "Step 7650/10000- lr: [2.371747684848484e-06] - Loss total: 2.567810535430908, Last rpr Loss: 0.9830945730209351, Last lagvar Loss: 0.8628954887390137\n",
      "Step 7651/10000- lr: [2.3707375878787883e-06] - Loss total: 2.567840576171875, Last rpr Loss: 1.0187792778015137, Last lagvar Loss: 0.827256441116333\n",
      "Step 7652/10000- lr: [2.3697274909090907e-06] - Loss total: 2.5679070949554443, Last rpr Loss: 0.979561448097229, Last lagvar Loss: 0.8665699362754822\n",
      "Step 7653/10000- lr: [2.368717393939394e-06] - Loss total: 2.567899703979492, Last rpr Loss: 1.0214440822601318, Last lagvar Loss: 0.8246922492980957\n",
      "Step 7654/10000- lr: [2.3677072969696956e-06] - Loss total: 2.5679163932800293, Last rpr Loss: 0.978322446346283, Last lagvar Loss: 0.8678584098815918\n",
      "Step 7655/10000- lr: [2.3666972000000006e-06] - Loss total: 2.5678231716156006, Last rpr Loss: 1.0206362009048462, Last lagvar Loss: 0.8254579305648804\n",
      "Step 7656/10000- lr: [2.365687103030302e-06] - Loss total: 2.5677380561828613, Last rpr Loss: 0.981645405292511, Last lagvar Loss: 0.8643844127655029\n",
      "Step 7657/10000- lr: [2.3646770060606054e-06] - Loss total: 2.5675899982452393, Last rpr Loss: 1.0147887468338013, Last lagvar Loss: 0.8310984373092651\n",
      "Step 7658/10000- lr: [2.3636669090909087e-06] - Loss total: 2.567469358444214, Last rpr Loss: 0.989830493927002, Last lagvar Loss: 0.855952262878418\n",
      "Step 7659/10000- lr: [2.362656812121212e-06] - Loss total: 2.5673773288726807, Last rpr Loss: 1.0051510334014893, Last lagvar Loss: 0.840551495552063\n",
      "Step 7660/10000- lr: [2.3616467151515153e-06] - Loss total: 2.5673365592956543, Last rpr Loss: 1.0000354051589966, Last lagvar Loss: 0.8456436395645142\n",
      "Step 7661/10000- lr: [2.3606366181818185e-06] - Loss total: 2.5673396587371826, Last rpr Loss: 0.9953769445419312, Last lagvar Loss: 0.8503247499465942\n",
      "Step 7662/10000- lr: [2.35962652121212e-06] - Loss total: 2.5673656463623047, Last rpr Loss: 1.0083496570587158, Last lagvar Loss: 0.8373974561691284\n",
      "Step 7663/10000- lr: [2.3586164242424234e-06] - Loss total: 2.5673954486846924, Last rpr Loss: 0.9890478849411011, Last lagvar Loss: 0.8567519187927246\n",
      "Step 7664/10000- lr: [2.3576063272727267e-06] - Loss total: 2.567397356033325, Last rpr Loss: 1.012092113494873, Last lagvar Loss: 0.8337262272834778\n",
      "Step 7665/10000- lr: [2.35659623030303e-06] - Loss total: 2.5673797130584717, Last rpr Loss: 0.9880573749542236, Last lagvar Loss: 0.8577644228935242\n",
      "Step 7666/10000- lr: [2.3555861333333332e-06] - Loss total: 2.567326545715332, Last rpr Loss: 1.0104390382766724, Last lagvar Loss: 0.8353427052497864\n",
      "Step 7667/10000- lr: [2.3545760363636365e-06] - Loss total: 2.567268133163452, Last rpr Loss: 0.9920939207077026, Last lagvar Loss: 0.8536478281021118\n",
      "Step 7668/10000- lr: [2.353565939393938e-06] - Loss total: 2.5672123432159424, Last rpr Loss: 1.004734992980957, Last lagvar Loss: 0.8409647941589355\n",
      "Step 7669/10000- lr: [2.352555842424243e-06] - Loss total: 2.5671751499176025, Last rpr Loss: 0.9986764192581177, Last lagvar Loss: 0.8470039963722229\n",
      "Step 7670/10000- lr: [2.3515457454545446e-06] - Loss total: 2.5671584606170654, Last rpr Loss: 0.9980690479278564, Last lagvar Loss: 0.8476129174232483\n",
      "Step 7671/10000- lr: [2.350535648484848e-06] - Loss total: 2.5671558380126953, Last rpr Loss: 1.0045353174209595, Last lagvar Loss: 0.8411625027656555\n",
      "Step 7672/10000- lr: [2.349525551515151e-06] - Loss total: 2.567157506942749, Last rpr Loss: 0.9935450553894043, Last lagvar Loss: 0.8521744608879089\n",
      "Step 7673/10000- lr: [2.3485154545454545e-06] - Loss total: 2.567150831222534, Last rpr Loss: 1.0073418617248535, Last lagvar Loss: 0.8383884429931641\n",
      "Step 7674/10000- lr: [2.347505357575756e-06] - Loss total: 2.567134141921997, Last rpr Loss: 0.9927002787590027, Last lagvar Loss: 0.8530323505401611\n",
      "Step 7675/10000- lr: [2.346495260606061e-06] - Loss total: 2.5671041011810303, Last rpr Loss: 1.0064425468444824, Last lagvar Loss: 0.8392763137817383\n",
      "Step 7676/10000- lr: [2.3454851636363626e-06] - Loss total: 2.567070484161377, Last rpr Loss: 0.9951611161231995, Last lagvar Loss: 0.8505419492721558\n",
      "Step 7677/10000- lr: [2.344475066666666e-06] - Loss total: 2.56703782081604, Last rpr Loss: 1.0028932094573975, Last lagvar Loss: 0.842793345451355\n",
      "Step 7678/10000- lr: [2.343464969696969e-06] - Loss total: 2.567011833190918, Last rpr Loss: 0.9992165565490723, Last lagvar Loss: 0.8464623689651489\n",
      "Step 7679/10000- lr: [2.3424548727272724e-06] - Loss total: 2.5669944286346436, Last rpr Loss: 0.9987683296203613, Last lagvar Loss: 0.8469113111495972\n",
      "Step 7680/10000- lr: [2.3414447757575757e-06] - Loss total: 2.5669829845428467, Last rpr Loss: 1.0028076171875, Last lagvar Loss: 0.842877984046936\n",
      "Step 7681/10000- lr: [2.340434678787879e-06] - Loss total: 2.566972494125366, Last rpr Loss: 0.9959923624992371, Last lagvar Loss: 0.8497021794319153\n",
      "Step 7682/10000- lr: [2.3394245818181806e-06] - Loss total: 2.5669591426849365, Last rpr Loss: 1.0045208930969238, Last lagvar Loss: 0.8411775231361389\n",
      "Step 7683/10000- lr: [2.338414484848484e-06] - Loss total: 2.566941261291504, Last rpr Loss: 0.9954917430877686, Last lagvar Loss: 0.8502076864242554\n",
      "Step 7684/10000- lr: [2.337404387878787e-06] - Loss total: 2.5669186115264893, Last rpr Loss: 1.0039762258529663, Last lagvar Loss: 0.8417172431945801\n",
      "Step 7685/10000- lr: [2.3363942909090904e-06] - Loss total: 2.566894054412842, Last rpr Loss: 0.9970089197158813, Last lagvar Loss: 0.848678469657898\n",
      "Step 7686/10000- lr: [2.3353841939393937e-06] - Loss total: 2.56687068939209, Last rpr Loss: 1.0018073320388794, Last lagvar Loss: 0.8438735008239746\n",
      "Step 7687/10000- lr: [2.334374096969697e-06] - Loss total: 2.566849946975708, Last rpr Loss: 0.9994986653327942, Last lagvar Loss: 0.8461793661117554\n",
      "Step 7688/10000- lr: [2.3333639999999986e-06] - Loss total: 2.5668320655822754, Last rpr Loss: 0.9992499947547913, Last lagvar Loss: 0.8464284539222717\n",
      "Step 7689/10000- lr: [2.3323539030303035e-06] - Loss total: 2.566817045211792, Last rpr Loss: 1.0017457008361816, Last lagvar Loss: 0.8439350128173828\n",
      "Step 7690/10000- lr: [2.331343806060605e-06] - Loss total: 2.5668017864227295, Last rpr Loss: 0.9974924325942993, Last lagvar Loss: 0.8481919765472412\n",
      "Step 7691/10000- lr: [2.3303337090909084e-06] - Loss total: 2.5667853355407715, Last rpr Loss: 1.002853274345398, Last lagvar Loss: 0.8428322076797485\n",
      "Step 7692/10000- lr: [2.3293236121212117e-06] - Loss total: 2.566767930984497, Last rpr Loss: 0.9971356391906738, Last lagvar Loss: 0.8485504984855652\n",
      "Step 7693/10000- lr: [2.328313515151515e-06] - Loss total: 2.5667479038238525, Last rpr Loss: 1.0025500059127808, Last lagvar Loss: 0.8431336283683777\n",
      "Step 7694/10000- lr: [2.3273034181818182e-06] - Loss total: 2.566727638244629, Last rpr Loss: 0.9980608224868774, Last lagvar Loss: 0.8476204872131348\n",
      "Step 7695/10000- lr: [2.3262933212121215e-06] - Loss total: 2.5667073726654053, Last rpr Loss: 1.00118887424469, Last lagvar Loss: 0.8444898128509521\n",
      "Step 7696/10000- lr: [2.3252832242424248e-06] - Loss total: 2.5666885375976562, Last rpr Loss: 0.9996333718299866, Last lagvar Loss: 0.8460443019866943\n",
      "Step 7697/10000- lr: [2.3242731272727264e-06] - Loss total: 2.5666706562042236, Last rpr Loss: 0.9995542764663696, Last lagvar Loss: 0.8461233973503113\n",
      "Step 7698/10000- lr: [2.3232630303030313e-06] - Loss total: 2.5666534900665283, Last rpr Loss: 1.0010740756988525, Last lagvar Loss: 0.8446043133735657\n",
      "Step 7699/10000- lr: [2.322252933333333e-06] - Loss total: 2.5666370391845703, Last rpr Loss: 0.9984188675880432, Last lagvar Loss: 0.8472611904144287\n",
      "Step 7700/10000- lr: [2.321242836363636e-06] - Loss total: 2.566619873046875, Last rpr Loss: 1.0018038749694824, Last lagvar Loss: 0.8438764810562134\n",
      "Step 7701/10000- lr: [2.3202327393939395e-06] - Loss total: 2.5666019916534424, Last rpr Loss: 0.9981664419174194, Last lagvar Loss: 0.8475143909454346\n",
      "Step 7702/10000- lr: [2.3192226424242427e-06] - Loss total: 2.5665836334228516, Last rpr Loss: 1.001641035079956, Last lagvar Loss: 0.8440386652946472\n",
      "Step 7703/10000- lr: [2.3182125454545443e-06] - Loss total: 2.5665647983551025, Last rpr Loss: 0.998724102973938, Last lagvar Loss: 0.8469549417495728\n",
      "Step 7704/10000- lr: [2.3172024484848493e-06] - Loss total: 2.5665462017059326, Last rpr Loss: 1.000813364982605, Last lagvar Loss: 0.8448644280433655\n",
      "Step 7705/10000- lr: [2.316192351515151e-06] - Loss total: 2.5665276050567627, Last rpr Loss: 0.9997022747993469, Last lagvar Loss: 0.8459750413894653\n",
      "Step 7706/10000- lr: [2.315182254545454e-06] - Loss total: 2.566509485244751, Last rpr Loss: 0.9998012781143188, Last lagvar Loss: 0.8458759784698486\n",
      "Step 7707/10000- lr: [2.3141721575757574e-06] - Loss total: 2.5664923191070557, Last rpr Loss: 1.000605583190918, Last lagvar Loss: 0.8450719118118286\n",
      "Step 7708/10000- lr: [2.3131620606060607e-06] - Loss total: 2.5664751529693604, Last rpr Loss: 0.9990757703781128, Last lagvar Loss: 0.8466023206710815\n",
      "Step 7709/10000- lr: [2.312151963636364e-06] - Loss total: 2.566457509994507, Last rpr Loss: 1.0010859966278076, Last lagvar Loss: 0.8445920944213867\n",
      "Step 7710/10000- lr: [2.3111418666666673e-06] - Loss total: 2.5664398670196533, Last rpr Loss: 0.9988671541213989, Last lagvar Loss: 0.8468114137649536\n",
      "Step 7711/10000- lr: [2.310131769696969e-06] - Loss total: 2.5664219856262207, Last rpr Loss: 1.0010294914245605, Last lagvar Loss: 0.8446484804153442\n",
      "Step 7712/10000- lr: [2.309121672727272e-06] - Loss total: 2.56640362739563, Last rpr Loss: 0.9991527795791626, Last lagvar Loss: 0.8465250730514526\n",
      "Step 7713/10000- lr: [2.3081115757575754e-06] - Loss total: 2.566385269165039, Last rpr Loss: 1.0005733966827393, Last lagvar Loss: 0.8451038002967834\n",
      "Step 7714/10000- lr: [2.3071014787878787e-06] - Loss total: 2.5663673877716064, Last rpr Loss: 0.9997110962867737, Last lagvar Loss: 0.8459661602973938\n",
      "Step 7715/10000- lr: [2.306091381818182e-06] - Loss total: 2.566349744796753, Last rpr Loss: 0.9999874830245972, Last lagvar Loss: 0.8456895351409912\n",
      "Step 7716/10000- lr: [2.3050812848484852e-06] - Loss total: 2.5663318634033203, Last rpr Loss: 1.0002696514129639, Last lagvar Loss: 0.8454073667526245\n",
      "Step 7717/10000- lr: [2.304071187878787e-06] - Loss total: 2.5663139820098877, Last rpr Loss: 0.9995198249816895, Last lagvar Loss: 0.846157431602478\n",
      "Step 7718/10000- lr: [2.3030610909090918e-06] - Loss total: 2.5662968158721924, Last rpr Loss: 1.000604271888733, Last lagvar Loss: 0.8450729846954346\n",
      "Step 7719/10000- lr: [2.3020509939393934e-06] - Loss total: 2.5662789344787598, Last rpr Loss: 0.9993258714675903, Last lagvar Loss: 0.8463516235351562\n",
      "Step 7720/10000- lr: [2.3010408969696966e-06] - Loss total: 2.566261053085327, Last rpr Loss: 1.0006513595581055, Last lagvar Loss: 0.8450259566307068\n",
      "Step 7721/10000- lr: [2.3000308e-06] - Loss total: 2.5662434101104736, Last rpr Loss: 0.9994187355041504, Last lagvar Loss: 0.8462584614753723\n",
      "Step 7722/10000- lr: [2.299020703030303e-06] - Loss total: 2.566225290298462, Last rpr Loss: 1.000439167022705, Last lagvar Loss: 0.8452377319335938\n",
      "Step 7723/10000- lr: [2.2980106060606048e-06] - Loss total: 2.5662076473236084, Last rpr Loss: 0.9997155666351318, Last lagvar Loss: 0.845961332321167\n",
      "Step 7724/10000- lr: [2.2970005090909098e-06] - Loss total: 2.566190004348755, Last rpr Loss: 1.0000979900360107, Last lagvar Loss: 0.845578670501709\n",
      "Step 7725/10000- lr: [2.2959904121212113e-06] - Loss total: 2.5661721229553223, Last rpr Loss: 1.000058889389038, Last lagvar Loss: 0.845617949962616\n",
      "Step 7726/10000- lr: [2.2949803151515146e-06] - Loss total: 2.5661544799804688, Last rpr Loss: 0.9997830986976624, Last lagvar Loss: 0.8458937406539917\n",
      "Step 7727/10000- lr: [2.293970218181818e-06] - Loss total: 2.566136598587036, Last rpr Loss: 1.0003225803375244, Last lagvar Loss: 0.8453543186187744\n",
      "Step 7728/10000- lr: [2.292960121212121e-06] - Loss total: 2.5661191940307617, Last rpr Loss: 0.9995990991592407, Last lagvar Loss: 0.8460777997970581\n",
      "Step 7729/10000- lr: [2.2919500242424244e-06] - Loss total: 2.566101551055908, Last rpr Loss: 1.0004169940948486, Last lagvar Loss: 0.8452599048614502\n",
      "Step 7730/10000- lr: [2.2909399272727277e-06] - Loss total: 2.5660834312438965, Last rpr Loss: 0.9995987415313721, Last lagvar Loss: 0.846078097820282\n",
      "Step 7731/10000- lr: [2.2899298303030293e-06] - Loss total: 2.566066026687622, Last rpr Loss: 1.0003361701965332, Last lagvar Loss: 0.8453406095504761\n",
      "Step 7732/10000- lr: [2.2889197333333326e-06] - Loss total: 2.5660479068756104, Last rpr Loss: 0.999742865562439, Last lagvar Loss: 0.8459338545799255\n",
      "Step 7733/10000- lr: [2.287909636363636e-06] - Loss total: 2.566030263900757, Last rpr Loss: 1.0001425743103027, Last lagvar Loss: 0.8455339670181274\n",
      "Step 7734/10000- lr: [2.286899539393939e-06] - Loss total: 2.5660126209259033, Last rpr Loss: 0.9999561309814453, Last lagvar Loss: 0.8457204103469849\n",
      "Step 7735/10000- lr: [2.2858894424242424e-06] - Loss total: 2.56599497795105, Last rpr Loss: 0.9999256134033203, Last lagvar Loss: 0.8457509279251099\n",
      "Step 7736/10000- lr: [2.2848793454545457e-06] - Loss total: 2.565977096557617, Last rpr Loss: 1.0001477003097534, Last lagvar Loss: 0.845528781414032\n",
      "Step 7737/10000- lr: [2.2838692484848473e-06] - Loss total: 2.5659596920013428, Last rpr Loss: 0.9997824430465698, Last lagvar Loss: 0.8458942174911499\n",
      "Step 7738/10000- lr: [2.2828591515151522e-06] - Loss total: 2.5659420490264893, Last rpr Loss: 1.0002473592758179, Last lagvar Loss: 0.8454291820526123\n",
      "Step 7739/10000- lr: [2.281849054545454e-06] - Loss total: 2.5659244060516357, Last rpr Loss: 0.9997408986091614, Last lagvar Loss: 0.8459356427192688\n",
      "Step 7740/10000- lr: [2.280838957575757e-06] - Loss total: 2.565906524658203, Last rpr Loss: 1.0002321004867554, Last lagvar Loss: 0.8454442620277405\n",
      "Step 7741/10000- lr: [2.2798288606060604e-06] - Loss total: 2.5658888816833496, Last rpr Loss: 0.9998000264167786, Last lagvar Loss: 0.8458763957023621\n",
      "Step 7742/10000- lr: [2.2788187636363637e-06] - Loss total: 2.565871477127075, Last rpr Loss: 1.0001353025436401, Last lagvar Loss: 0.8455411195755005\n",
      "Step 7743/10000- lr: [2.2778086666666652e-06] - Loss total: 2.5658535957336426, Last rpr Loss: 0.9999127984046936, Last lagvar Loss: 0.8457635641098022\n",
      "Step 7744/10000- lr: [2.27679856969697e-06] - Loss total: 2.565835952758789, Last rpr Loss: 1.0000123977661133, Last lagvar Loss: 0.8456639051437378\n",
      "Step 7745/10000- lr: [2.275788472727272e-06] - Loss total: 2.5658185482025146, Last rpr Loss: 1.0000338554382324, Last lagvar Loss: 0.8456423282623291\n",
      "Step 7746/10000- lr: [2.274778375757575e-06] - Loss total: 2.565800905227661, Last rpr Loss: 0.9999117851257324, Last lagvar Loss: 0.8457645177841187\n",
      "Step 7747/10000- lr: [2.2737682787878783e-06] - Loss total: 2.5657832622528076, Last rpr Loss: 1.0001167058944702, Last lagvar Loss: 0.8455594778060913\n",
      "Step 7748/10000- lr: [2.2727581818181816e-06] - Loss total: 2.565765619277954, Last rpr Loss: 0.9998552799224854, Last lagvar Loss: 0.8458210229873657\n",
      "Step 7749/10000- lr: [2.271748084848485e-06] - Loss total: 2.5657479763031006, Last rpr Loss: 1.0001401901245117, Last lagvar Loss: 0.8455359935760498\n",
      "Step 7750/10000- lr: [2.270737987878788e-06] - Loss total: 2.565730333328247, Last rpr Loss: 0.9998570680618286, Last lagvar Loss: 0.8458191156387329\n",
      "Step 7751/10000- lr: [2.2697278909090898e-06] - Loss total: 2.5657131671905518, Last rpr Loss: 1.0001120567321777, Last lagvar Loss: 0.845564067363739\n",
      "Step 7752/10000- lr: [2.268717793939393e-06] - Loss total: 2.5656955242156982, Last rpr Loss: 0.9999059438705444, Last lagvar Loss: 0.8457701206207275\n",
      "Step 7753/10000- lr: [2.2677076969696963e-06] - Loss total: 2.5656776428222656, Last rpr Loss: 1.000056266784668, Last lagvar Loss: 0.845619797706604\n",
      "Step 7754/10000- lr: [2.2666975999999996e-06] - Loss total: 2.565659761428833, Last rpr Loss: 0.9999681711196899, Last lagvar Loss: 0.8457079529762268\n",
      "Step 7755/10000- lr: [2.265687503030303e-06] - Loss total: 2.5656425952911377, Last rpr Loss: 0.9999884366989136, Last lagvar Loss: 0.8456876277923584\n",
      "Step 7756/10000- lr: [2.264677406060606e-06] - Loss total: 2.565624952316284, Last rpr Loss: 1.0000349283218384, Last lagvar Loss: 0.8456410765647888\n",
      "Step 7757/10000- lr: [2.2636673090909077e-06] - Loss total: 2.5656075477600098, Last rpr Loss: 0.9999275207519531, Last lagvar Loss: 0.8457484245300293\n",
      "Step 7758/10000- lr: [2.2626572121212127e-06] - Loss total: 2.5655899047851562, Last rpr Loss: 1.000079870223999, Last lagvar Loss: 0.8455959558486938\n",
      "Step 7759/10000- lr: [2.2616471151515143e-06] - Loss total: 2.5655722618103027, Last rpr Loss: 0.9999035596847534, Last lagvar Loss: 0.8457724452018738\n",
      "Step 7760/10000- lr: [2.2606370181818176e-06] - Loss total: 2.5655548572540283, Last rpr Loss: 1.0000858306884766, Last lagvar Loss: 0.8455901145935059\n",
      "Step 7761/10000- lr: [2.259626921212121e-06] - Loss total: 2.565537214279175, Last rpr Loss: 0.9999146461486816, Last lagvar Loss: 0.8457612991333008\n",
      "Step 7762/10000- lr: [2.258616824242424e-06] - Loss total: 2.5655195713043213, Last rpr Loss: 1.0000600814819336, Last lagvar Loss: 0.8456158638000488\n",
      "Step 7763/10000- lr: [2.2576067272727274e-06] - Loss total: 2.565502166748047, Last rpr Loss: 0.9999523758888245, Last lagvar Loss: 0.8457235097885132\n",
      "Step 7764/10000- lr: [2.2565966303030307e-06] - Loss total: 2.5654842853546143, Last rpr Loss: 1.0000171661376953, Last lagvar Loss: 0.8456586599349976\n",
      "Step 7765/10000- lr: [2.2555865333333323e-06] - Loss total: 2.5654666423797607, Last rpr Loss: 0.9999927282333374, Last lagvar Loss: 0.8456830978393555\n",
      "Step 7766/10000- lr: [2.2545764363636355e-06] - Loss total: 2.5654497146606445, Last rpr Loss: 0.9999794960021973, Last lagvar Loss: 0.8456962704658508\n",
      "Step 7767/10000- lr: [2.253566339393939e-06] - Loss total: 2.565431833267212, Last rpr Loss: 1.000025749206543, Last lagvar Loss: 0.8456500172615051\n",
      "Step 7768/10000- lr: [2.252556242424242e-06] - Loss total: 2.5654141902923584, Last rpr Loss: 0.9999549388885498, Last lagvar Loss: 0.8457208275794983\n",
      "Step 7769/10000- lr: [2.2515461454545454e-06] - Loss total: 2.565396785736084, Last rpr Loss: 1.0000447034835815, Last lagvar Loss: 0.8456310033798218\n",
      "Step 7770/10000- lr: [2.2505360484848486e-06] - Loss total: 2.5653793811798096, Last rpr Loss: 0.9999447464942932, Last lagvar Loss: 0.8457310199737549\n",
      "Step 7771/10000- lr: [2.2495259515151502e-06] - Loss total: 2.565361976623535, Last rpr Loss: 1.00003981590271, Last lagvar Loss: 0.8456357717514038\n",
      "Step 7772/10000- lr: [2.2485158545454535e-06] - Loss total: 2.5653445720672607, Last rpr Loss: 0.999955415725708, Last lagvar Loss: 0.8457202911376953\n",
      "Step 7773/10000- lr: [2.2475057575757568e-06] - Loss total: 2.5653269290924072, Last rpr Loss: 1.0000267028808594, Last lagvar Loss: 0.8456489443778992\n",
      "Step 7774/10000- lr: [2.24649566060606e-06] - Loss total: 2.5653092861175537, Last rpr Loss: 0.9999767541885376, Last lagvar Loss: 0.8456988334655762\n",
      "Step 7775/10000- lr: [2.2454855636363633e-06] - Loss total: 2.5652918815612793, Last rpr Loss: 1.0000083446502686, Last lagvar Loss: 0.8456672430038452\n",
      "Step 7776/10000- lr: [2.2444754666666666e-06] - Loss total: 2.565274715423584, Last rpr Loss: 0.9999913573265076, Last lagvar Loss: 0.8456841707229614\n",
      "Step 7777/10000- lr: [2.243465369696968e-06] - Loss total: 2.5652568340301514, Last rpr Loss: 0.9999885559082031, Last lagvar Loss: 0.8456870317459106\n",
      "Step 7778/10000- lr: [2.242455272727273e-06] - Loss total: 2.565239429473877, Last rpr Loss: 1.0000064373016357, Last lagvar Loss: 0.8456690907478333\n",
      "Step 7779/10000- lr: [2.2414451757575747e-06] - Loss total: 2.5652222633361816, Last rpr Loss: 0.9999783039093018, Last lagvar Loss: 0.8456972241401672\n",
      "Step 7780/10000- lr: [2.240435078787878e-06] - Loss total: 2.565204620361328, Last rpr Loss: 1.000016689300537, Last lagvar Loss: 0.8456587791442871\n",
      "Step 7781/10000- lr: [2.2394249818181813e-06] - Loss total: 2.5651872158050537, Last rpr Loss: 0.9999744892120361, Last lagvar Loss: 0.8457009792327881\n",
      "Step 7782/10000- lr: [2.2384148848484846e-06] - Loss total: 2.5651695728302, Last rpr Loss: 1.0000159740447998, Last lagvar Loss: 0.8456593751907349\n",
      "Step 7783/10000- lr: [2.237404787878788e-06] - Loss total: 2.565152406692505, Last rpr Loss: 0.9999761581420898, Last lagvar Loss: 0.8456991910934448\n",
      "Step 7784/10000- lr: [2.236394690909091e-06] - Loss total: 2.5651352405548096, Last rpr Loss: 1.0000139474868774, Last lagvar Loss: 0.845661461353302\n",
      "Step 7785/10000- lr: [2.2353845939393944e-06] - Loss total: 2.565117597579956, Last rpr Loss: 0.9999802112579346, Last lagvar Loss: 0.8456951379776001\n",
      "Step 7786/10000- lr: [2.234374496969696e-06] - Loss total: 2.5651001930236816, Last rpr Loss: 1.000003695487976, Last lagvar Loss: 0.8456716537475586\n",
      "Step 7787/10000- lr: [2.233364400000001e-06] - Loss total: 2.5650827884674072, Last rpr Loss: 0.9999938011169434, Last lagvar Loss: 0.8456815481185913\n",
      "Step 7788/10000- lr: [2.2323543030303025e-06] - Loss total: 2.565065383911133, Last rpr Loss: 0.9999933838844299, Last lagvar Loss: 0.84568190574646\n",
      "Step 7789/10000- lr: [2.231344206060606e-06] - Loss total: 2.5650477409362793, Last rpr Loss: 0.9999983310699463, Last lagvar Loss: 0.8456770181655884\n",
      "Step 7790/10000- lr: [2.230334109090909e-06] - Loss total: 2.565030574798584, Last rpr Loss: 0.9999871253967285, Last lagvar Loss: 0.8456881046295166\n",
      "Step 7791/10000- lr: [2.2293240121212124e-06] - Loss total: 2.5650131702423096, Last rpr Loss: 1.0000076293945312, Last lagvar Loss: 0.8456674814224243\n",
      "Step 7792/10000- lr: [2.228313915151514e-06] - Loss total: 2.564995527267456, Last rpr Loss: 0.9999847412109375, Last lagvar Loss: 0.8456905484199524\n",
      "Step 7793/10000- lr: [2.227303818181819e-06] - Loss total: 2.5649783611297607, Last rpr Loss: 1.0000065565109253, Last lagvar Loss: 0.8456685543060303\n",
      "Step 7794/10000- lr: [2.2262937212121205e-06] - Loss total: 2.5649609565734863, Last rpr Loss: 0.9999866485595703, Last lagvar Loss: 0.8456884622573853\n",
      "Step 7795/10000- lr: [2.225283624242424e-06] - Loss total: 2.564943552017212, Last rpr Loss: 1.0000001192092896, Last lagvar Loss: 0.845674991607666\n",
      "Step 7796/10000- lr: [2.224273527272727e-06] - Loss total: 2.5649261474609375, Last rpr Loss: 0.9999915957450867, Last lagvar Loss: 0.8456835150718689\n",
      "Step 7797/10000- lr: [2.2232634303030303e-06] - Loss total: 2.564908981323242, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8456800580024719\n",
      "Step 7798/10000- lr: [2.2222533333333336e-06] - Loss total: 2.5648915767669678, Last rpr Loss: 0.9999998807907104, Last lagvar Loss: 0.8456751108169556\n",
      "Step 7799/10000- lr: [2.221243236363637e-06] - Loss total: 2.5648741722106934, Last rpr Loss: 0.9999880790710449, Last lagvar Loss: 0.8456868529319763\n",
      "Step 7800/10000- lr: [2.2202331393939385e-06] - Loss total: 2.564856767654419, Last rpr Loss: 1.0000039339065552, Last lagvar Loss: 0.8456710577011108\n",
      "Step 7801/10000- lr: [2.2192230424242418e-06] - Loss total: 2.5648393630981445, Last rpr Loss: 0.9999860525131226, Last lagvar Loss: 0.8456888794898987\n",
      "Step 7802/10000- lr: [2.218212945454545e-06] - Loss total: 2.56482195854187, Last rpr Loss: 1.0000079870224, Last lagvar Loss: 0.8456670045852661\n",
      "Step 7803/10000- lr: [2.2172028484848483e-06] - Loss total: 2.5648045539855957, Last rpr Loss: 0.9999822378158569, Last lagvar Loss: 0.8456927537918091\n",
      "Step 7804/10000- lr: [2.2161927515151516e-06] - Loss total: 2.5647871494293213, Last rpr Loss: 1.0000096559524536, Last lagvar Loss: 0.8456652164459229\n",
      "Step 7805/10000- lr: [2.215182654545455e-06] - Loss total: 2.564769983291626, Last rpr Loss: 0.9999798536300659, Last lagvar Loss: 0.8456951379776001\n",
      "Step 7806/10000- lr: [2.2141725575757564e-06] - Loss total: 2.5647525787353516, Last rpr Loss: 1.0000100135803223, Last lagvar Loss: 0.8456648588180542\n",
      "Step 7807/10000- lr: [2.2131624606060614e-06] - Loss total: 2.5647354125976562, Last rpr Loss: 0.9999807476997375, Last lagvar Loss: 0.8456941843032837\n",
      "Step 7808/10000- lr: [2.212152363636363e-06] - Loss total: 2.5647177696228027, Last rpr Loss: 1.0000087022781372, Last lagvar Loss: 0.8456661701202393\n",
      "Step 7809/10000- lr: [2.2111422666666663e-06] - Loss total: 2.5647006034851074, Last rpr Loss: 0.9999829530715942, Last lagvar Loss: 0.8456919193267822\n",
      "Step 7810/10000- lr: [2.2101321696969696e-06] - Loss total: 2.564683437347412, Last rpr Loss: 1.0000040531158447, Last lagvar Loss: 0.8456707000732422\n",
      "Step 7811/10000- lr: [2.209122072727273e-06] - Loss total: 2.5646660327911377, Last rpr Loss: 0.9999896287918091, Last lagvar Loss: 0.8456850647926331\n",
      "Step 7812/10000- lr: [2.2081119757575744e-06] - Loss total: 2.5646488666534424, Last rpr Loss: 1.0000015497207642, Last lagvar Loss: 0.8456732034683228\n",
      "Step 7813/10000- lr: [2.2071018787878794e-06] - Loss total: 2.564631700515747, Last rpr Loss: 0.999994695186615, Last lagvar Loss: 0.8456800580024719\n",
      "Step 7814/10000- lr: [2.206091781818181e-06] - Loss total: 2.5646142959594727, Last rpr Loss: 0.9999914169311523, Last lagvar Loss: 0.8456832766532898\n",
      "Step 7815/10000- lr: [2.2050816848484842e-06] - Loss total: 2.5645973682403564, Last rpr Loss: 1.0000004768371582, Last lagvar Loss: 0.8456743359565735\n",
      "Step 7816/10000- lr: [2.2040715878787875e-06] - Loss total: 2.564579486846924, Last rpr Loss: 0.9999909996986389, Last lagvar Loss: 0.8456836342811584\n",
      "Step 7817/10000- lr: [2.203061490909091e-06] - Loss total: 2.5645625591278076, Last rpr Loss: 1.000001311302185, Last lagvar Loss: 0.8456733226776123\n",
      "Step 7818/10000- lr: [2.202051393939394e-06] - Loss total: 2.564545154571533, Last rpr Loss: 0.9999845027923584, Last lagvar Loss: 0.845690131187439\n",
      "Step 7819/10000- lr: [2.2010412969696974e-06] - Loss total: 2.564527988433838, Last rpr Loss: 1.0000033378601074, Last lagvar Loss: 0.8456711769104004\n",
      "Step 7820/10000- lr: [2.200031199999999e-06] - Loss total: 2.5645108222961426, Last rpr Loss: 0.9999872446060181, Last lagvar Loss: 0.8456872701644897\n",
      "Step 7821/10000- lr: [2.1990211030303022e-06] - Loss total: 2.5644936561584473, Last rpr Loss: 1.0000079870224, Last lagvar Loss: 0.8456665873527527\n",
      "Step 7822/10000- lr: [2.1980110060606055e-06] - Loss total: 2.564476490020752, Last rpr Loss: 0.9999864101409912, Last lagvar Loss: 0.8456881046295166\n",
      "Step 7823/10000- lr: [2.1970009090909088e-06] - Loss total: 2.5644593238830566, Last rpr Loss: 1.000002384185791, Last lagvar Loss: 0.8456721305847168\n",
      "Step 7824/10000- lr: [2.195990812121212e-06] - Loss total: 2.5644419193267822, Last rpr Loss: 0.9999881386756897, Last lagvar Loss: 0.8456863164901733\n",
      "Step 7825/10000- lr: [2.1949807151515153e-06] - Loss total: 2.564424753189087, Last rpr Loss: 0.9999977350234985, Last lagvar Loss: 0.8456766605377197\n",
      "Step 7826/10000- lr: [2.193970618181817e-06] - Loss total: 2.5644071102142334, Last rpr Loss: 0.9999952912330627, Last lagvar Loss: 0.8456791639328003\n",
      "Step 7827/10000- lr: [2.192960521212122e-06] - Loss total: 2.564389944076538, Last rpr Loss: 0.9999949336051941, Last lagvar Loss: 0.8456794619560242\n",
      "Step 7828/10000- lr: [2.1919504242424235e-06] - Loss total: 2.564373016357422, Last rpr Loss: 1.0000009536743164, Last lagvar Loss: 0.8456735014915466\n",
      "Step 7829/10000- lr: [2.1909403272727267e-06] - Loss total: 2.5643558502197266, Last rpr Loss: 0.9999876022338867, Last lagvar Loss: 0.8456867933273315\n",
      "Step 7830/10000- lr: [2.18993023030303e-06] - Loss total: 2.5643386840820312, Last rpr Loss: 1.0000040531158447, Last lagvar Loss: 0.8456703424453735\n",
      "Step 7831/10000- lr: [2.1889201333333333e-06] - Loss total: 2.564321517944336, Last rpr Loss: 0.9999820590019226, Last lagvar Loss: 0.8456923365592957\n",
      "Step 7832/10000- lr: [2.1879100363636366e-06] - Loss total: 2.5643038749694824, Last rpr Loss: 1.0000075101852417, Last lagvar Loss: 0.845666766166687\n",
      "Step 7833/10000- lr: [2.18689993939394e-06] - Loss total: 2.564286947250366, Last rpr Loss: 0.9999843239784241, Last lagvar Loss: 0.8456898927688599\n",
      "Step 7834/10000- lr: [2.1858898424242414e-06] - Loss total: 2.56427001953125, Last rpr Loss: 1.0000091791152954, Last lagvar Loss: 0.8456650376319885\n",
      "Step 7835/10000- lr: [2.1848797454545447e-06] - Loss total: 2.5642528533935547, Last rpr Loss: 0.9999845027923584, Last lagvar Loss: 0.8456897139549255\n",
      "Step 7836/10000- lr: [2.183869648484848e-06] - Loss total: 2.5642356872558594, Last rpr Loss: 1.0000064373016357, Last lagvar Loss: 0.8456677198410034\n",
      "Step 7837/10000- lr: [2.1828595515151513e-06] - Loss total: 2.564218521118164, Last rpr Loss: 0.9999849200248718, Last lagvar Loss: 0.8456892967224121\n",
      "Step 7838/10000- lr: [2.1818494545454545e-06] - Loss total: 2.5642013549804688, Last rpr Loss: 0.9999973773956299, Last lagvar Loss: 0.8456767797470093\n",
      "Step 7839/10000- lr: [2.180839357575758e-06] - Loss total: 2.5641844272613525, Last rpr Loss: 0.9999968409538269, Last lagvar Loss: 0.845677375793457\n",
      "Step 7840/10000- lr: [2.1798292606060594e-06] - Loss total: 2.564167022705078, Last rpr Loss: 0.9999891519546509, Last lagvar Loss: 0.8456848859786987\n",
      "Step 7841/10000- lr: [2.1788191636363627e-06] - Loss total: 2.5641496181488037, Last rpr Loss: 1.000006079673767, Last lagvar Loss: 0.8456679582595825\n",
      "Step 7842/10000- lr: [2.177809066666666e-06] - Loss total: 2.5641326904296875, Last rpr Loss: 0.9999879002571106, Last lagvar Loss: 0.8456861972808838\n",
      "Step 7843/10000- lr: [2.1767989696969692e-06] - Loss total: 2.564115285873413, Last rpr Loss: 1.0000022649765015, Last lagvar Loss: 0.8456718325614929\n",
      "Step 7844/10000- lr: [2.1757888727272725e-06] - Loss total: 2.564098358154297, Last rpr Loss: 0.9999858736991882, Last lagvar Loss: 0.8456881642341614\n",
      "Step 7845/10000- lr: [2.1747787757575758e-06] - Loss total: 2.5640811920166016, Last rpr Loss: 1.0000003576278687, Last lagvar Loss: 0.845673680305481\n",
      "Step 7846/10000- lr: [2.1737686787878774e-06] - Loss total: 2.5640640258789062, Last rpr Loss: 0.9999960660934448, Last lagvar Loss: 0.84567791223526\n",
      "Step 7847/10000- lr: [2.1727585818181823e-06] - Loss total: 2.56404709815979, Last rpr Loss: 0.9999933242797852, Last lagvar Loss: 0.8456805944442749\n",
      "Step 7848/10000- lr: [2.171748484848484e-06] - Loss total: 2.5640299320220947, Last rpr Loss: 1.0000019073486328, Last lagvar Loss: 0.8456721305847168\n",
      "Step 7849/10000- lr: [2.170738387878787e-06] - Loss total: 2.5640127658843994, Last rpr Loss: 0.9999837875366211, Last lagvar Loss: 0.8456901907920837\n",
      "Step 7850/10000- lr: [2.1697282909090905e-06] - Loss total: 2.563995599746704, Last rpr Loss: 1.000006079673767, Last lagvar Loss: 0.8456677198410034\n",
      "Step 7851/10000- lr: [2.1687181939393938e-06] - Loss total: 2.563978672027588, Last rpr Loss: 0.9999836683273315, Last lagvar Loss: 0.8456902503967285\n",
      "Step 7852/10000- lr: [2.167708096969697e-06] - Loss total: 2.5639612674713135, Last rpr Loss: 1.0000076293945312, Last lagvar Loss: 0.8456661701202393\n",
      "Step 7853/10000- lr: [2.1666980000000003e-06] - Loss total: 2.5639443397521973, Last rpr Loss: 0.9999834895133972, Last lagvar Loss: 0.8456903696060181\n",
      "Step 7854/10000- lr: [2.165687903030302e-06] - Loss total: 2.563927412033081, Last rpr Loss: 1.0000090599060059, Last lagvar Loss: 0.8456648588180542\n",
      "Step 7855/10000- lr: [2.164677806060605e-06] - Loss total: 2.563910484313965, Last rpr Loss: 0.9999818801879883, Last lagvar Loss: 0.8456919193267822\n",
      "Step 7856/10000- lr: [2.1636677090909084e-06] - Loss total: 2.5638933181762695, Last rpr Loss: 1.0000066757202148, Last lagvar Loss: 0.8456670641899109\n",
      "Step 7857/10000- lr: [2.1626576121212117e-06] - Loss total: 2.563875913619995, Last rpr Loss: 0.9999837875366211, Last lagvar Loss: 0.8456898927688599\n",
      "Step 7858/10000- lr: [2.161647515151515e-06] - Loss total: 2.563858985900879, Last rpr Loss: 1.0000040531158447, Last lagvar Loss: 0.8456697463989258\n",
      "Step 7859/10000- lr: [2.1606374181818183e-06] - Loss total: 2.5638420581817627, Last rpr Loss: 0.9999876022338867, Last lagvar Loss: 0.8456860780715942\n",
      "Step 7860/10000- lr: [2.15962732121212e-06] - Loss total: 2.5638248920440674, Last rpr Loss: 1.0000015497207642, Last lagvar Loss: 0.8456722497940063\n",
      "Step 7861/10000- lr: [2.158617224242423e-06] - Loss total: 2.563807964324951, Last rpr Loss: 0.9999943375587463, Last lagvar Loss: 0.8456792831420898\n",
      "Step 7862/10000- lr: [2.1576071272727264e-06] - Loss total: 2.563791036605835, Last rpr Loss: 0.9999934434890747, Last lagvar Loss: 0.8456801176071167\n",
      "Step 7863/10000- lr: [2.1565970303030297e-06] - Loss total: 2.5637741088867188, Last rpr Loss: 1.0000016689300537, Last lagvar Loss: 0.8456718921661377\n",
      "Step 7864/10000- lr: [2.155586933333333e-06] - Loss total: 2.5637571811676025, Last rpr Loss: 0.9999852180480957, Last lagvar Loss: 0.8456883430480957\n",
      "Step 7865/10000- lr: [2.1545768363636362e-06] - Loss total: 2.563739538192749, Last rpr Loss: 1.0000054836273193, Last lagvar Loss: 0.8456680774688721\n",
      "Step 7866/10000- lr: [2.1535667393939395e-06] - Loss total: 2.563722848892212, Last rpr Loss: 0.9999821782112122, Last lagvar Loss: 0.8456913828849792\n",
      "Step 7867/10000- lr: [2.152556642424243e-06] - Loss total: 2.5637056827545166, Last rpr Loss: 1.0000107288360596, Last lagvar Loss: 0.8456628322601318\n",
      "Step 7868/10000- lr: [2.151546545454546e-06] - Loss total: 2.5636887550354004, Last rpr Loss: 0.9999760985374451, Last lagvar Loss: 0.8456973433494568\n",
      "Step 7869/10000- lr: [2.1505364484848477e-06] - Loss total: 2.5636720657348633, Last rpr Loss: 1.0000171661376953, Last lagvar Loss: 0.8456562757492065\n",
      "Step 7870/10000- lr: [2.149526351515151e-06] - Loss total: 2.563654899597168, Last rpr Loss: 0.9999746084213257, Last lagvar Loss: 0.8456988334655762\n",
      "Step 7871/10000- lr: [2.1485162545454542e-06] - Loss total: 2.5636379718780518, Last rpr Loss: 1.0000145435333252, Last lagvar Loss: 0.8456588387489319\n",
      "Step 7872/10000- lr: [2.1475061575757575e-06] - Loss total: 2.5636210441589355, Last rpr Loss: 0.9999768137931824, Last lagvar Loss: 0.8456965684890747\n",
      "Step 7873/10000- lr: [2.1464960606060608e-06] - Loss total: 2.5636038780212402, Last rpr Loss: 1.0000150203704834, Last lagvar Loss: 0.8456583023071289\n",
      "Step 7874/10000- lr: [2.145485963636364e-06] - Loss total: 2.563586950302124, Last rpr Loss: 0.9999762773513794, Last lagvar Loss: 0.8456970453262329\n",
      "Step 7875/10000- lr: [2.1444758666666656e-06] - Loss total: 2.5635697841644287, Last rpr Loss: 1.000009536743164, Last lagvar Loss: 0.8456637263298035\n",
      "Step 7876/10000- lr: [2.1434657696969706e-06] - Loss total: 2.5635530948638916, Last rpr Loss: 0.999983549118042, Last lagvar Loss: 0.8456897735595703\n",
      "Step 7877/10000- lr: [2.142455672727272e-06] - Loss total: 2.5635361671447754, Last rpr Loss: 1.0000050067901611, Last lagvar Loss: 0.8456683158874512\n",
      "Step 7878/10000- lr: [2.1414455757575755e-06] - Loss total: 2.563519239425659, Last rpr Loss: 0.9999880790710449, Last lagvar Loss: 0.8456851840019226\n",
      "Step 7879/10000- lr: [2.1404354787878787e-06] - Loss total: 2.563502311706543, Last rpr Loss: 0.9999988675117493, Last lagvar Loss: 0.8456743359565735\n",
      "Step 7880/10000- lr: [2.139425381818182e-06] - Loss total: 2.5634853839874268, Last rpr Loss: 0.9999957084655762, Last lagvar Loss: 0.8456775546073914\n",
      "Step 7881/10000- lr: [2.1384152848484853e-06] - Loss total: 2.5634684562683105, Last rpr Loss: 0.9999911785125732, Last lagvar Loss: 0.8456820249557495\n",
      "Step 7882/10000- lr: [2.1374051878787886e-06] - Loss total: 2.563451051712036, Last rpr Loss: 1.000001311302185, Last lagvar Loss: 0.8456718921661377\n",
      "Step 7883/10000- lr: [2.13639509090909e-06] - Loss total: 2.56343412399292, Last rpr Loss: 0.9999850988388062, Last lagvar Loss: 0.8456881046295166\n",
      "Step 7884/10000- lr: [2.1353849939393934e-06] - Loss total: 2.563417434692383, Last rpr Loss: 1.000010371208191, Last lagvar Loss: 0.8456626534461975\n",
      "Step 7885/10000- lr: [2.1343748969696967e-06] - Loss total: 2.5634005069732666, Last rpr Loss: 0.9999769926071167, Last lagvar Loss: 0.8456960916519165\n",
      "Step 7886/10000- lr: [2.1333648e-06] - Loss total: 2.5633835792541504, Last rpr Loss: 1.0000147819519043, Last lagvar Loss: 0.8456583023071289\n",
      "Step 7887/10000- lr: [2.1323547030303033e-06] - Loss total: 2.563366651535034, Last rpr Loss: 0.9999743700027466, Last lagvar Loss: 0.8456987142562866\n",
      "Step 7888/10000- lr: [2.1313446060606065e-06] - Loss total: 2.563349962234497, Last rpr Loss: 1.0000200271606445, Last lagvar Loss: 0.8456529974937439\n",
      "Step 7889/10000- lr: [2.130334509090908e-06] - Loss total: 2.563333034515381, Last rpr Loss: 0.9999684691429138, Last lagvar Loss: 0.8457046151161194\n",
      "Step 7890/10000- lr: [2.1293244121212114e-06] - Loss total: 2.5633161067962646, Last rpr Loss: 1.0000181198120117, Last lagvar Loss: 0.8456548452377319\n",
      "Step 7891/10000- lr: [2.1283143151515147e-06] - Loss total: 2.5632991790771484, Last rpr Loss: 0.9999737739562988, Last lagvar Loss: 0.8456991910934448\n",
      "Step 7892/10000- lr: [2.127304218181818e-06] - Loss total: 2.563282012939453, Last rpr Loss: 1.0000128746032715, Last lagvar Loss: 0.8456600904464722\n",
      "Step 7893/10000- lr: [2.1262941212121212e-06] - Loss total: 2.563265323638916, Last rpr Loss: 0.9999829530715942, Last lagvar Loss: 0.8456900715827942\n",
      "Step 7894/10000- lr: [2.1252840242424245e-06] - Loss total: 2.5632483959198, Last rpr Loss: 1.0000042915344238, Last lagvar Loss: 0.845668613910675\n",
      "Step 7895/10000- lr: [2.124273927272726e-06] - Loss total: 2.5632317066192627, Last rpr Loss: 0.9999923706054688, Last lagvar Loss: 0.8456804752349854\n",
      "Step 7896/10000- lr: [2.123263830303031e-06] - Loss total: 2.5632147789001465, Last rpr Loss: 0.9999955892562866, Last lagvar Loss: 0.8456772565841675\n",
      "Step 7897/10000- lr: [2.1222537333333326e-06] - Loss total: 2.5631978511810303, Last rpr Loss: 0.9999971985816956, Last lagvar Loss: 0.8456756472587585\n",
      "Step 7898/10000- lr: [2.121243636363636e-06] - Loss total: 2.563181161880493, Last rpr Loss: 0.9999879598617554, Last lagvar Loss: 0.845684826374054\n",
      "Step 7899/10000- lr: [2.120233539393939e-06] - Loss total: 2.563164234161377, Last rpr Loss: 1.0000016689300537, Last lagvar Loss: 0.8456711173057556\n",
      "Step 7900/10000- lr: [2.1192234424242425e-06] - Loss total: 2.56314754486084, Last rpr Loss: 0.9999839067459106, Last lagvar Loss: 0.8456888198852539\n",
      "Step 7901/10000- lr: [2.1182133454545457e-06] - Loss total: 2.5631306171417236, Last rpr Loss: 1.0000088214874268, Last lagvar Loss: 0.845663845539093\n",
      "Step 7902/10000- lr: [2.117203248484849e-06] - Loss total: 2.5631139278411865, Last rpr Loss: 0.9999858736991882, Last lagvar Loss: 0.8456868529319763\n",
      "Step 7903/10000- lr: [2.1161931515151506e-06] - Loss total: 2.5630970001220703, Last rpr Loss: 1.0000079870224, Last lagvar Loss: 0.8456647396087646\n",
      "Step 7904/10000- lr: [2.115183054545454e-06] - Loss total: 2.563080310821533, Last rpr Loss: 0.9999809265136719, Last lagvar Loss: 0.8456917405128479\n",
      "Step 7905/10000- lr: [2.114172957575757e-06] - Loss total: 2.563063383102417, Last rpr Loss: 1.000003457069397, Last lagvar Loss: 0.8456692099571228\n",
      "Step 7906/10000- lr: [2.1131628606060604e-06] - Loss total: 2.56304669380188, Last rpr Loss: 0.9999876618385315, Last lagvar Loss: 0.8456850051879883\n",
      "Step 7907/10000- lr: [2.1121527636363637e-06] - Loss total: 2.5630295276641846, Last rpr Loss: 1.0000016689300537, Last lagvar Loss: 0.8456709384918213\n",
      "Step 7908/10000- lr: [2.111142666666667e-06] - Loss total: 2.5630125999450684, Last rpr Loss: 0.9999877214431763, Last lagvar Loss: 0.8456848859786987\n",
      "Step 7909/10000- lr: [2.1101325696969686e-06] - Loss total: 2.5629961490631104, Last rpr Loss: 1.0000042915344238, Last lagvar Loss: 0.8456683158874512\n",
      "Step 7910/10000- lr: [2.109122472727272e-06] - Loss total: 2.5629794597625732, Last rpr Loss: 0.9999929666519165, Last lagvar Loss: 0.8456796407699585\n",
      "Step 7911/10000- lr: [2.108112375757575e-06] - Loss total: 2.562962770462036, Last rpr Loss: 0.9999955892562866, Last lagvar Loss: 0.8456768989562988\n",
      "Step 7912/10000- lr: [2.1071022787878784e-06] - Loss total: 2.56294584274292, Last rpr Loss: 0.9999901056289673, Last lagvar Loss: 0.8456824421882629\n",
      "Step 7913/10000- lr: [2.1060921818181817e-06] - Loss total: 2.562929153442383, Last rpr Loss: 1.0000014305114746, Last lagvar Loss: 0.8456710577011108\n",
      "Step 7914/10000- lr: [2.105082084848485e-06] - Loss total: 2.562912702560425, Last rpr Loss: 0.9999867677688599, Last lagvar Loss: 0.8456856608390808\n",
      "Step 7915/10000- lr: [2.1040719878787865e-06] - Loss total: 2.5628960132598877, Last rpr Loss: 1.000001072883606, Last lagvar Loss: 0.8456714153289795\n",
      "Step 7916/10000- lr: [2.1030618909090915e-06] - Loss total: 2.5628788471221924, Last rpr Loss: 0.9999899864196777, Last lagvar Loss: 0.8456823825836182\n",
      "Step 7917/10000- lr: [2.102051793939393e-06] - Loss total: 2.562861919403076, Last rpr Loss: 1.0000014305114746, Last lagvar Loss: 0.8456710577011108\n",
      "Step 7918/10000- lr: [2.1010416969696964e-06] - Loss total: 2.562845468521118, Last rpr Loss: 0.9999931454658508, Last lagvar Loss: 0.8456792235374451\n",
      "Step 7919/10000- lr: [2.1000315999999997e-06] - Loss total: 2.562828779220581, Last rpr Loss: 0.9999954104423523, Last lagvar Loss: 0.8456768989562988\n",
      "Step 7920/10000- lr: [2.099021503030303e-06] - Loss total: 2.562812089920044, Last rpr Loss: 0.9999978542327881, Last lagvar Loss: 0.8456743955612183\n",
      "Step 7921/10000- lr: [2.098011406060606e-06] - Loss total: 2.5627951622009277, Last rpr Loss: 0.9999854564666748, Last lagvar Loss: 0.8456867933273315\n",
      "Step 7922/10000- lr: [2.0970013090909095e-06] - Loss total: 2.5627784729003906, Last rpr Loss: 1.0000027418136597, Last lagvar Loss: 0.8456695675849915\n",
      "Step 7923/10000- lr: [2.095991212121211e-06] - Loss total: 2.5627620220184326, Last rpr Loss: 0.9999854564666748, Last lagvar Loss: 0.8456867933273315\n",
      "Step 7924/10000- lr: [2.0949811151515143e-06] - Loss total: 2.5627450942993164, Last rpr Loss: 1.000009298324585, Last lagvar Loss: 0.8456630110740662\n",
      "Step 7925/10000- lr: [2.0939710181818176e-06] - Loss total: 2.5627281665802, Last rpr Loss: 0.9999853372573853, Last lagvar Loss: 0.8456869721412659\n",
      "Step 7926/10000- lr: [2.092960921212121e-06] - Loss total: 2.562711238861084, Last rpr Loss: 1.0000050067901611, Last lagvar Loss: 0.84566730260849\n",
      "Step 7927/10000- lr: [2.091950824242424e-06] - Loss total: 2.562694787979126, Last rpr Loss: 0.9999812841415405, Last lagvar Loss: 0.8456908464431763\n",
      "Step 7928/10000- lr: [2.0909407272727275e-06] - Loss total: 2.562678337097168, Last rpr Loss: 1.0000100135803223, Last lagvar Loss: 0.8456622362136841\n",
      "Step 7929/10000- lr: [2.089930630303029e-06] - Loss total: 2.562661647796631, Last rpr Loss: 0.999976396560669, Last lagvar Loss: 0.8456957936286926\n",
      "Step 7930/10000- lr: [2.088920533333334e-06] - Loss total: 2.5626449584960938, Last rpr Loss: 1.0000150203704834, Last lagvar Loss: 0.8456571102142334\n",
      "Step 7931/10000- lr: [2.0879104363636356e-06] - Loss total: 2.5626285076141357, Last rpr Loss: 0.9999737739562988, Last lagvar Loss: 0.8456984162330627\n",
      "Step 7932/10000- lr: [2.086900339393939e-06] - Loss total: 2.5626115798950195, Last rpr Loss: 1.000019907951355, Last lagvar Loss: 0.8456522226333618\n",
      "Step 7933/10000- lr: [2.085890242424242e-06] - Loss total: 2.5625946521759033, Last rpr Loss: 0.9999667406082153, Last lagvar Loss: 0.8457052707672119\n",
      "Step 7934/10000- lr: [2.0848801454545454e-06] - Loss total: 2.562577724456787, Last rpr Loss: 1.0000277757644653, Last lagvar Loss: 0.8456442952156067\n",
      "Step 7935/10000- lr: [2.083870048484847e-06] - Loss total: 2.562561273574829, Last rpr Loss: 0.9999644160270691, Last lagvar Loss: 0.8457075357437134\n",
      "Step 7936/10000- lr: [2.082859951515152e-06] - Loss total: 2.562544822692871, Last rpr Loss: 1.0000219345092773, Last lagvar Loss: 0.8456499576568604\n",
      "Step 7937/10000- lr: [2.0818498545454536e-06] - Loss total: 2.562528133392334, Last rpr Loss: 0.9999682307243347, Last lagvar Loss: 0.845703661441803\n",
      "Step 7938/10000- lr: [2.080839757575757e-06] - Loss total: 2.562511444091797, Last rpr Loss: 1.0000174045562744, Last lagvar Loss: 0.8456547260284424\n",
      "Step 7939/10000- lr: [2.07982966060606e-06] - Loss total: 2.562494993209839, Last rpr Loss: 0.9999769926071167, Last lagvar Loss: 0.845694899559021\n",
      "Step 7940/10000- lr: [2.0788195636363634e-06] - Loss total: 2.5624783039093018, Last rpr Loss: 1.0000102519989014, Last lagvar Loss: 0.8456616997718811\n",
      "Step 7941/10000- lr: [2.0778094666666667e-06] - Loss total: 2.5624618530273438, Last rpr Loss: 0.9999843835830688, Last lagvar Loss: 0.8456875085830688\n",
      "Step 7942/10000- lr: [2.07679936969697e-06] - Loss total: 2.5624451637268066, Last rpr Loss: 1.000002384185791, Last lagvar Loss: 0.8456695079803467\n",
      "Step 7943/10000- lr: [2.0757892727272715e-06] - Loss total: 2.5624284744262695, Last rpr Loss: 0.9999924898147583, Last lagvar Loss: 0.8456794023513794\n",
      "Step 7944/10000- lr: [2.074779175757575e-06] - Loss total: 2.5624117851257324, Last rpr Loss: 0.9999929666519165, Last lagvar Loss: 0.8456788063049316\n",
      "Step 7945/10000- lr: [2.073769078787878e-06] - Loss total: 2.5623953342437744, Last rpr Loss: 0.9999968409538269, Last lagvar Loss: 0.8456748723983765\n",
      "Step 7946/10000- lr: [2.0727589818181814e-06] - Loss total: 2.5623788833618164, Last rpr Loss: 0.9999902248382568, Last lagvar Loss: 0.8456815481185913\n",
      "Step 7947/10000- lr: [2.0717488848484846e-06] - Loss total: 2.5623621940612793, Last rpr Loss: 1.000001072883606, Last lagvar Loss: 0.8456705808639526\n",
      "Step 7948/10000- lr: [2.070738787878788e-06] - Loss total: 2.562345504760742, Last rpr Loss: 0.9999876022338867, Last lagvar Loss: 0.8456841111183167\n",
      "Step 7949/10000- lr: [2.0697286909090895e-06] - Loss total: 2.562329053878784, Last rpr Loss: 1.0000065565109253, Last lagvar Loss: 0.8456652164459229\n",
      "Step 7950/10000- lr: [2.0687185939393945e-06] - Loss total: 2.562312364578247, Last rpr Loss: 0.9999840259552002, Last lagvar Loss: 0.8456876277923584\n",
      "Step 7951/10000- lr: [2.0677084969696977e-06] - Loss total: 2.562295913696289, Last rpr Loss: 1.0000075101852417, Last lagvar Loss: 0.8456641435623169\n",
      "Step 7952/10000- lr: [2.0666983999999993e-06] - Loss total: 2.562279224395752, Last rpr Loss: 0.999980092048645, Last lagvar Loss: 0.8456915616989136\n",
      "Step 7953/10000- lr: [2.0656883030303026e-06] - Loss total: 2.562262773513794, Last rpr Loss: 1.0000072717666626, Last lagvar Loss: 0.845664381980896\n",
      "Step 7954/10000- lr: [2.064678206060606e-06] - Loss total: 2.562246084213257, Last rpr Loss: 0.9999831318855286, Last lagvar Loss: 0.8456884622573853\n",
      "Step 7955/10000- lr: [2.063668109090909e-06] - Loss total: 2.562229633331299, Last rpr Loss: 1.0000042915344238, Last lagvar Loss: 0.8456672430038452\n",
      "Step 7956/10000- lr: [2.0626580121212124e-06] - Loss total: 2.562213182449341, Last rpr Loss: 0.9999861717224121, Last lagvar Loss: 0.8456854224205017\n",
      "Step 7957/10000- lr: [2.0616479151515157e-06] - Loss total: 2.5621964931488037, Last rpr Loss: 1.0000054836273193, Last lagvar Loss: 0.8456660509109497\n",
      "Step 7958/10000- lr: [2.0606378181818173e-06] - Loss total: 2.562180280685425, Last rpr Loss: 0.9999903440475464, Last lagvar Loss: 0.8456811308860779\n",
      "Step 7959/10000- lr: [2.0596277212121206e-06] - Loss total: 2.5621635913848877, Last rpr Loss: 0.9999979734420776, Last lagvar Loss: 0.8456735610961914\n",
      "Step 7960/10000- lr: [2.058617624242424e-06] - Loss total: 2.5621471405029297, Last rpr Loss: 0.9999938607215881, Last lagvar Loss: 0.8456776142120361\n",
      "Step 7961/10000- lr: [2.057607527272727e-06] - Loss total: 2.5621306896209717, Last rpr Loss: 0.9999887943267822, Last lagvar Loss: 0.8456826210021973\n",
      "Step 7962/10000- lr: [2.0565974303030304e-06] - Loss total: 2.5621137619018555, Last rpr Loss: 1.0000016689300537, Last lagvar Loss: 0.8456696271896362\n",
      "Step 7963/10000- lr: [2.0555873333333337e-06] - Loss total: 2.5620975494384766, Last rpr Loss: 0.9999847412109375, Last lagvar Loss: 0.8456866145133972\n",
      "Step 7964/10000- lr: [2.0545772363636353e-06] - Loss total: 2.5620810985565186, Last rpr Loss: 1.0000114440917969, Last lagvar Loss: 0.8456599712371826\n",
      "Step 7965/10000- lr: [2.0535671393939402e-06] - Loss total: 2.5620644092559814, Last rpr Loss: 0.9999792575836182, Last lagvar Loss: 0.8456920981407166\n",
      "Step 7966/10000- lr: [2.052557042424242e-06] - Loss total: 2.5620479583740234, Last rpr Loss: 1.0000134706497192, Last lagvar Loss: 0.8456578850746155\n",
      "Step 7967/10000- lr: [2.051546945454545e-06] - Loss total: 2.5620312690734863, Last rpr Loss: 0.9999712109565735, Last lagvar Loss: 0.8457000255584717\n",
      "Step 7968/10000- lr: [2.0505368484848484e-06] - Loss total: 2.5620150566101074, Last rpr Loss: 1.0000144243240356, Last lagvar Loss: 0.8456567525863647\n",
      "Step 7969/10000- lr: [2.0495267515151517e-06] - Loss total: 2.5619986057281494, Last rpr Loss: 0.9999781847000122, Last lagvar Loss: 0.8456931114196777\n",
      "Step 7970/10000- lr: [2.048516654545455e-06] - Loss total: 2.561981678009033, Last rpr Loss: 1.0000135898590088, Last lagvar Loss: 0.8456576466560364\n",
      "Step 7971/10000- lr: [2.047506557575758e-06] - Loss total: 2.561965227127075, Last rpr Loss: 0.9999804496765137, Last lagvar Loss: 0.8456907868385315\n",
      "Step 7972/10000- lr: [2.0464964606060598e-06] - Loss total: 2.561948776245117, Last rpr Loss: 1.0000053644180298, Last lagvar Loss: 0.8456658720970154\n",
      "Step 7973/10000- lr: [2.045486363636363e-06] - Loss total: 2.561932325363159, Last rpr Loss: 0.9999844431877136, Last lagvar Loss: 0.8456867337226868\n",
      "Step 7974/10000- lr: [2.0444762666666663e-06] - Loss total: 2.561915874481201, Last rpr Loss: 1.000002384185791, Last lagvar Loss: 0.8456687927246094\n",
      "Step 7975/10000- lr: [2.0434661696969696e-06] - Loss total: 2.561899423599243, Last rpr Loss: 0.9999940395355225, Last lagvar Loss: 0.8456770777702332\n",
      "Step 7976/10000- lr: [2.042456072727273e-06] - Loss total: 2.5618832111358643, Last rpr Loss: 0.9999924302101135, Last lagvar Loss: 0.8456786870956421\n",
      "Step 7977/10000- lr: [2.041445975757576e-06] - Loss total: 2.5618669986724854, Last rpr Loss: 1.0000011920928955, Last lagvar Loss: 0.8456699252128601\n",
      "Step 7978/10000- lr: [2.0404358787878778e-06] - Loss total: 2.5618503093719482, Last rpr Loss: 0.9999873638153076, Last lagvar Loss: 0.8456836938858032\n",
      "Step 7979/10000- lr: [2.039425781818181e-06] - Loss total: 2.561833620071411, Last rpr Loss: 1.0000005960464478, Last lagvar Loss: 0.8456704616546631\n",
      "Step 7980/10000- lr: [2.0384156848484843e-06] - Loss total: 2.561817169189453, Last rpr Loss: 0.9999858140945435, Last lagvar Loss: 0.8456851243972778\n",
      "Step 7981/10000- lr: [2.0374055878787876e-06] - Loss total: 2.561800718307495, Last rpr Loss: 1.0000078678131104, Last lagvar Loss: 0.8456631898880005\n",
      "Step 7982/10000- lr: [2.036395490909091e-06] - Loss total: 2.561784267425537, Last rpr Loss: 0.9999839067459106, Last lagvar Loss: 0.8456870317459106\n",
      "Step 7983/10000- lr: [2.035385393939394e-06] - Loss total: 2.561768054962158, Last rpr Loss: 1.000002384185791, Last lagvar Loss: 0.8456684947013855\n",
      "Step 7984/10000- lr: [2.0343752969696957e-06] - Loss total: 2.5617516040802, Last rpr Loss: 0.9999857544898987, Last lagvar Loss: 0.8456851840019226\n",
      "Step 7985/10000- lr: [2.0333652000000007e-06] - Loss total: 2.561735153198242, Last rpr Loss: 1.000006914138794, Last lagvar Loss: 0.8456639051437378\n",
      "Step 7986/10000- lr: [2.0323551030303023e-06] - Loss total: 2.5617189407348633, Last rpr Loss: 0.9999858736991882, Last lagvar Loss: 0.8456850051879883\n",
      "Step 7987/10000- lr: [2.0313450060606056e-06] - Loss total: 2.5617024898529053, Last rpr Loss: 1.0000064373016357, Last lagvar Loss: 0.845664381980896\n",
      "Step 7988/10000- lr: [2.030334909090909e-06] - Loss total: 2.5616862773895264, Last rpr Loss: 0.999980092048645, Last lagvar Loss: 0.8456906676292419\n",
      "Step 7989/10000- lr: [2.029324812121212e-06] - Loss total: 2.5616695880889893, Last rpr Loss: 1.0000065565109253, Last lagvar Loss: 0.8456642627716064\n",
      "Step 7990/10000- lr: [2.0283147151515154e-06] - Loss total: 2.5616531372070312, Last rpr Loss: 0.9999828338623047, Last lagvar Loss: 0.8456879258155823\n",
      "Step 7991/10000- lr: [2.0273046181818187e-06] - Loss total: 2.5616369247436523, Last rpr Loss: 1.0000054836273193, Last lagvar Loss: 0.8456652760505676\n",
      "Step 7992/10000- lr: [2.0262945212121202e-06] - Loss total: 2.5616204738616943, Last rpr Loss: 0.9999918937683105, Last lagvar Loss: 0.8456787467002869\n",
      "Step 7993/10000- lr: [2.0252844242424235e-06] - Loss total: 2.5616042613983154, Last rpr Loss: 0.9999982118606567, Last lagvar Loss: 0.8456724286079407\n",
      "Step 7994/10000- lr: [2.024274327272727e-06] - Loss total: 2.5615878105163574, Last rpr Loss: 0.9999933242797852, Last lagvar Loss: 0.8456773161888123\n",
      "Step 7995/10000- lr: [2.02326423030303e-06] - Loss total: 2.5615713596343994, Last rpr Loss: 0.9999939203262329, Last lagvar Loss: 0.8456767797470093\n",
      "Step 7996/10000- lr: [2.0222541333333334e-06] - Loss total: 2.5615551471710205, Last rpr Loss: 0.9999934434890747, Last lagvar Loss: 0.8456770777702332\n",
      "Step 7997/10000- lr: [2.0212440363636366e-06] - Loss total: 2.5615386962890625, Last rpr Loss: 0.9999953508377075, Last lagvar Loss: 0.8456753492355347\n",
      "Step 7998/10000- lr: [2.0202339393939382e-06] - Loss total: 2.5615224838256836, Last rpr Loss: 0.9999940395355225, Last lagvar Loss: 0.845676600933075\n",
      "Step 7999/10000- lr: [2.019223842424243e-06] - Loss total: 2.5615057945251465, Last rpr Loss: 0.9999963641166687, Last lagvar Loss: 0.8456742167472839\n",
      "Step 8000/10000- lr: [2.0182137454545448e-06] - Loss total: 2.5614895820617676, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8456757068634033\n",
      "Step 8001/10000- lr: [2.017203648484848e-06] - Loss total: 2.5614731311798096, Last rpr Loss: 0.9999939799308777, Last lagvar Loss: 0.8456765413284302\n",
      "Step 8002/10000- lr: [2.0161935515151513e-06] - Loss total: 2.5614569187164307, Last rpr Loss: 0.9999977350234985, Last lagvar Loss: 0.8456728458404541\n",
      "Step 8003/10000- lr: [2.0151834545454546e-06] - Loss total: 2.5614407062530518, Last rpr Loss: 0.9999922513961792, Last lagvar Loss: 0.8456782102584839\n",
      "Step 8004/10000- lr: [2.014173357575756e-06] - Loss total: 2.561424493789673, Last rpr Loss: 1.0000026226043701, Last lagvar Loss: 0.845667839050293\n",
      "Step 8005/10000- lr: [2.013163260606061e-06] - Loss total: 2.561408042907715, Last rpr Loss: 0.999987006187439, Last lagvar Loss: 0.8456834554672241\n",
      "Step 8006/10000- lr: [2.0121531636363627e-06] - Loss total: 2.561391830444336, Last rpr Loss: 1.0000026226043701, Last lagvar Loss: 0.845667839050293\n",
      "Step 8007/10000- lr: [2.011143066666666e-06] - Loss total: 2.561375379562378, Last rpr Loss: 0.9999837279319763, Last lagvar Loss: 0.845686674118042\n",
      "Step 8008/10000- lr: [2.0101329696969693e-06] - Loss total: 2.56135892868042, Last rpr Loss: 1.0000054836273193, Last lagvar Loss: 0.8456648588180542\n",
      "Step 8009/10000- lr: [2.0091228727272726e-06] - Loss total: 2.561342716217041, Last rpr Loss: 0.9999885559082031, Last lagvar Loss: 0.8456817865371704\n",
      "Step 8010/10000- lr: [2.008112775757576e-06] - Loss total: 2.561326265335083, Last rpr Loss: 1.0000014305114746, Last lagvar Loss: 0.8456689119338989\n",
      "Step 8011/10000- lr: [2.007102678787879e-06] - Loss total: 2.561309814453125, Last rpr Loss: 0.9999879598617554, Last lagvar Loss: 0.8456823825836182\n",
      "Step 8012/10000- lr: [2.0060925818181807e-06] - Loss total: 2.561293840408325, Last rpr Loss: 0.9999978542327881, Last lagvar Loss: 0.8456724286079407\n",
      "Step 8013/10000- lr: [2.005082484848484e-06] - Loss total: 2.561277389526367, Last rpr Loss: 0.9999973177909851, Last lagvar Loss: 0.8456729650497437\n",
      "Step 8014/10000- lr: [2.0040723878787873e-06] - Loss total: 2.5612611770629883, Last rpr Loss: 0.9999927282333374, Last lagvar Loss: 0.8456776142120361\n",
      "Step 8015/10000- lr: [2.0030622909090905e-06] - Loss total: 2.5612447261810303, Last rpr Loss: 1.0000016689300537, Last lagvar Loss: 0.845668613910675\n",
      "Step 8016/10000- lr: [2.002052193939394e-06] - Loss total: 2.5612285137176514, Last rpr Loss: 0.9999860525131226, Last lagvar Loss: 0.8456841707229614\n",
      "Step 8017/10000- lr: [2.001042096969697e-06] - Loss total: 2.5612118244171143, Last rpr Loss: 1.0000061988830566, Last lagvar Loss: 0.8456639647483826\n",
      "Step 8018/10000- lr: [2.0000319999999987e-06] - Loss total: 2.5611956119537354, Last rpr Loss: 0.9999833106994629, Last lagvar Loss: 0.8456868529319763\n",
      "Step 8019/10000- lr: [1.9990219030303036e-06] - Loss total: 2.5611793994903564, Last rpr Loss: 1.000007152557373, Last lagvar Loss: 0.8456630110740662\n",
      "Step 8020/10000- lr: [1.9980118060606052e-06] - Loss total: 2.5611627101898193, Last rpr Loss: 0.9999790191650391, Last lagvar Loss: 0.8456911444664001\n",
      "Step 8021/10000- lr: [1.9970017090909085e-06] - Loss total: 2.5611467361450195, Last rpr Loss: 1.0000128746032715, Last lagvar Loss: 0.8456573486328125\n",
      "Step 8022/10000- lr: [1.9959916121212118e-06] - Loss total: 2.5611305236816406, Last rpr Loss: 0.9999801516532898, Last lagvar Loss: 0.8456900119781494\n",
      "Step 8023/10000- lr: [1.994981515151515e-06] - Loss total: 2.5611140727996826, Last rpr Loss: 1.0000150203704834, Last lagvar Loss: 0.845655083656311\n",
      "Step 8024/10000- lr: [1.9939714181818166e-06] - Loss total: 2.5610978603363037, Last rpr Loss: 0.9999740123748779, Last lagvar Loss: 0.8456961512565613\n",
      "Step 8025/10000- lr: [1.9929613212121216e-06] - Loss total: 2.561081647872925, Last rpr Loss: 1.0000183582305908, Last lagvar Loss: 0.8456516861915588\n",
      "Step 8026/10000- lr: [1.991951224242423e-06] - Loss total: 2.561065196990967, Last rpr Loss: 0.9999706745147705, Last lagvar Loss: 0.8456993103027344\n",
      "Step 8027/10000- lr: [1.9909411272727265e-06] - Loss total: 2.561048984527588, Last rpr Loss: 1.0000213384628296, Last lagvar Loss: 0.8456486463546753\n",
      "Step 8028/10000- lr: [1.9899310303030298e-06] - Loss total: 2.561032772064209, Last rpr Loss: 0.9999668598175049, Last lagvar Loss: 0.8457031846046448\n",
      "Step 8029/10000- lr: [1.988920933333333e-06] - Loss total: 2.5610158443450928, Last rpr Loss: 1.0000280141830444, Last lagvar Loss: 0.8456419706344604\n",
      "Step 8030/10000- lr: [1.9879108363636363e-06] - Loss total: 2.560999631881714, Last rpr Loss: 0.999961256980896, Last lagvar Loss: 0.8457087278366089\n",
      "Step 8031/10000- lr: [1.9869007393939396e-06] - Loss total: 2.560983180999756, Last rpr Loss: 1.0000295639038086, Last lagvar Loss: 0.8456404805183411\n",
      "Step 8032/10000- lr: [1.985890642424241e-06] - Loss total: 2.560967206954956, Last rpr Loss: 0.9999645948410034, Last lagvar Loss: 0.8457053899765015\n",
      "Step 8033/10000- lr: [1.9848805454545444e-06] - Loss total: 2.560950756072998, Last rpr Loss: 1.0000272989273071, Last lagvar Loss: 0.8456427454948425\n",
      "Step 8034/10000- lr: [1.9838704484848477e-06] - Loss total: 2.560934543609619, Last rpr Loss: 0.999967098236084, Last lagvar Loss: 0.8457028865814209\n",
      "Step 8035/10000- lr: [1.982860351515151e-06] - Loss total: 2.560918092727661, Last rpr Loss: 1.0000227689743042, Last lagvar Loss: 0.8456472158432007\n",
      "Step 8036/10000- lr: [1.9818502545454543e-06] - Loss total: 2.5609018802642822, Last rpr Loss: 0.9999741315841675, Last lagvar Loss: 0.8456957936286926\n",
      "Step 8037/10000- lr: [1.9808401575757576e-06] - Loss total: 2.5608856678009033, Last rpr Loss: 1.0000123977661133, Last lagvar Loss: 0.8456575870513916\n",
      "Step 8038/10000- lr: [1.979830060606061e-06] - Loss total: 2.560868978500366, Last rpr Loss: 0.9999844431877136, Last lagvar Loss: 0.8456855416297913\n",
      "Step 8039/10000- lr: [1.978819963636364e-06] - Loss total: 2.5608527660369873, Last rpr Loss: 1.0000061988830566, Last lagvar Loss: 0.8456637859344482\n",
      "Step 8040/10000- lr: [1.9778098666666674e-06] - Loss total: 2.5608363151550293, Last rpr Loss: 0.9999930262565613, Last lagvar Loss: 0.8456770181655884\n",
      "Step 8041/10000- lr: [1.976799769696969e-06] - Loss total: 2.5608198642730713, Last rpr Loss: 0.9999998807907104, Last lagvar Loss: 0.8456701636314392\n",
      "Step 8042/10000- lr: [1.9757896727272722e-06] - Loss total: 2.5608034133911133, Last rpr Loss: 0.9999902248382568, Last lagvar Loss: 0.8456798195838928\n",
      "Step 8043/10000- lr: [1.9747795757575755e-06] - Loss total: 2.560786724090576, Last rpr Loss: 1.0000003576278687, Last lagvar Loss: 0.845669686794281\n",
      "Step 8044/10000- lr: [1.973769478787879e-06] - Loss total: 2.5607705116271973, Last rpr Loss: 0.999996542930603, Last lagvar Loss: 0.8456735014915466\n",
      "Step 8045/10000- lr: [1.972759381818182e-06] - Loss total: 2.5607540607452393, Last rpr Loss: 1.0000016689300537, Last lagvar Loss: 0.8456684350967407\n",
      "Step 8046/10000- lr: [1.9717492848484854e-06] - Loss total: 2.560737371444702, Last rpr Loss: 0.9999991655349731, Last lagvar Loss: 0.8456709980964661\n",
      "Step 8047/10000- lr: [1.970739187878787e-06] - Loss total: 2.560720920562744, Last rpr Loss: 0.9999949932098389, Last lagvar Loss: 0.8456752300262451\n",
      "Step 8048/10000- lr: [1.969729090909092e-06] - Loss total: 2.560704469680786, Last rpr Loss: 1.000002145767212, Last lagvar Loss: 0.8456681370735168\n",
      "Step 8049/10000- lr: [1.9687189939393935e-06] - Loss total: 2.56068754196167, Last rpr Loss: 0.999984622001648, Last lagvar Loss: 0.8456856608390808\n",
      "Step 8050/10000- lr: [1.9677088969696968e-06] - Loss total: 2.560670852661133, Last rpr Loss: 1.0000180006027222, Last lagvar Loss: 0.8456523418426514\n",
      "Step 8051/10000- lr: [1.9666988e-06] - Loss total: 2.5606541633605957, Last rpr Loss: 0.9999806880950928, Last lagvar Loss: 0.8456897735595703\n",
      "Step 8052/10000- lr: [1.9656887030303033e-06] - Loss total: 2.5606374740600586, Last rpr Loss: 1.0000245571136475, Last lagvar Loss: 0.8456461429595947\n",
      "Step 8053/10000- lr: [1.964678606060605e-06] - Loss total: 2.5606203079223633, Last rpr Loss: 0.999973714351654, Last lagvar Loss: 0.8456969857215881\n",
      "Step 8054/10000- lr: [1.96366850909091e-06] - Loss total: 2.560603141784668, Last rpr Loss: 1.0000323057174683, Last lagvar Loss: 0.8456385135650635\n",
      "Step 8055/10000- lr: [1.9626584121212115e-06] - Loss total: 2.5605857372283936, Last rpr Loss: 0.9999691843986511, Last lagvar Loss: 0.8457019329071045\n",
      "Step 8056/10000- lr: [1.9616483151515147e-06] - Loss total: 2.560568332672119, Last rpr Loss: 1.0000321865081787, Last lagvar Loss: 0.8456388711929321\n",
      "Step 8057/10000- lr: [1.960638218181818e-06] - Loss total: 2.5605504512786865, Last rpr Loss: 0.9999696016311646, Last lagvar Loss: 0.8457018733024597\n",
      "Step 8058/10000- lr: [1.9596281212121213e-06] - Loss total: 2.560532569885254, Last rpr Loss: 1.0000368356704712, Last lagvar Loss: 0.8456347584724426\n",
      "Step 8059/10000- lr: [1.9586180242424246e-06] - Loss total: 2.560514211654663, Last rpr Loss: 0.999968409538269, Last lagvar Loss: 0.8457033038139343\n",
      "Step 8060/10000- lr: [1.957607927272728e-06] - Loss total: 2.5604963302612305, Last rpr Loss: 1.0000404119491577, Last lagvar Loss: 0.8456315994262695\n",
      "Step 8061/10000- lr: [1.9565978303030294e-06] - Loss total: 2.5604772567749023, Last rpr Loss: 0.9999706745147705, Last lagvar Loss: 0.8457013964653015\n",
      "Step 8062/10000- lr: [1.9555877333333327e-06] - Loss total: 2.560458183288574, Last rpr Loss: 1.0000464916229248, Last lagvar Loss: 0.8456255197525024\n",
      "Step 8063/10000- lr: [1.954577636363636e-06] - Loss total: 2.560438394546509, Last rpr Loss: 0.9999600648880005, Last lagvar Loss: 0.8457114696502686\n",
      "Step 8064/10000- lr: [1.9535675393939393e-06] - Loss total: 2.560417413711548, Last rpr Loss: 1.000057339668274, Last lagvar Loss: 0.8456128835678101\n",
      "Step 8065/10000- lr: [1.9525574424242425e-06] - Loss total: 2.560396194458008, Last rpr Loss: 0.9999545812606812, Last lagvar Loss: 0.8457127213478088\n",
      "Step 8066/10000- lr: [1.951547345454546e-06] - Loss total: 2.5603723526000977, Last rpr Loss: 1.0000696182250977, Last lagvar Loss: 0.8455909490585327\n",
      "Step 8067/10000- lr: [1.9505372484848474e-06] - Loss total: 2.5603456497192383, Last rpr Loss: 0.9999451637268066, Last lagvar Loss: 0.8456991910934448\n",
      "Step 8068/10000- lr: [1.9495271515151524e-06] - Loss total: 2.560314655303955, Last rpr Loss: 1.000075340270996, Last lagvar Loss: 0.8455286622047424\n",
      "Step 8069/10000- lr: [1.948517054545454e-06] - Loss total: 2.5602753162384033, Last rpr Loss: 0.9999165534973145, Last lagvar Loss: 0.8455924987792969\n",
      "Step 8070/10000- lr: [1.9475069575757572e-06] - Loss total: 2.560230255126953, Last rpr Loss: 1.0000691413879395, Last lagvar Loss: 0.8452906012535095\n",
      "Step 8071/10000- lr: [1.9464968606060605e-06] - Loss total: 2.5601906776428223, Last rpr Loss: 0.9999992847442627, Last lagvar Loss: 0.8452467918395996\n",
      "Step 8072/10000- lr: [1.9454867636363638e-06] - Loss total: 2.5601539611816406, Last rpr Loss: 1.0002365112304688, Last lagvar Loss: 0.8449389934539795\n",
      "Step 8073/10000- lr: [1.9444766666666654e-06] - Loss total: 2.5601096153259277, Last rpr Loss: 1.000180959701538, Last lagvar Loss: 0.8449358940124512\n",
      "Step 8074/10000- lr: [1.9434665696969703e-06] - Loss total: 2.560048818588257, Last rpr Loss: 1.000331997871399, Last lagvar Loss: 0.8447278738021851\n",
      "Step 8075/10000- lr: [1.942456472727272e-06] - Loss total: 2.559971570968628, Last rpr Loss: 1.0001192092895508, Last lagvar Loss: 0.8448878526687622\n",
      "Step 8076/10000- lr: [1.941446375757575e-06] - Loss total: 2.5598998069763184, Last rpr Loss: 1.000223159790039, Last lagvar Loss: 0.8447463512420654\n",
      "Step 8077/10000- lr: [1.9404362787878785e-06] - Loss total: 2.559851884841919, Last rpr Loss: 0.9999673366546631, Last lagvar Loss: 0.8449944853782654\n",
      "Step 8078/10000- lr: [1.9394261818181817e-06] - Loss total: 2.559819459915161, Last rpr Loss: 0.9999778270721436, Last lagvar Loss: 0.8450136184692383\n",
      "Step 8079/10000- lr: [1.938416084848485e-06] - Loss total: 2.559796094894409, Last rpr Loss: 0.999564528465271, Last lagvar Loss: 0.8454816341400146\n",
      "Step 8080/10000- lr: [1.9374059878787883e-06] - Loss total: 2.5597760677337646, Last rpr Loss: 0.9995198249816895, Last lagvar Loss: 0.845584511756897\n",
      "Step 8081/10000- lr: [1.93639589090909e-06] - Loss total: 2.5597569942474365, Last rpr Loss: 0.9993926882743835, Last lagvar Loss: 0.8457533121109009\n",
      "Step 8082/10000- lr: [1.935385793939393e-06] - Loss total: 2.5597355365753174, Last rpr Loss: 0.9999499320983887, Last lagvar Loss: 0.8452081680297852\n",
      "Step 8083/10000- lr: [1.9343756969696964e-06] - Loss total: 2.559711217880249, Last rpr Loss: 0.9999731779098511, Last lagvar Loss: 0.8451697826385498\n",
      "Step 8084/10000- lr: [1.9333655999999997e-06] - Loss total: 2.559685230255127, Last rpr Loss: 1.000075101852417, Last lagvar Loss: 0.8450362682342529\n",
      "Step 8085/10000- lr: [1.932355503030303e-06] - Loss total: 2.559659242630005, Last rpr Loss: 0.9997214078903198, Last lagvar Loss: 0.845350444316864\n",
      "Step 8086/10000- lr: [1.9313454060606063e-06] - Loss total: 2.55963397026062, Last rpr Loss: 0.9999884366989136, Last lagvar Loss: 0.8450436592102051\n",
      "Step 8087/10000- lr: [1.930335309090908e-06] - Loss total: 2.55961012840271, Last rpr Loss: 1.0000008344650269, Last lagvar Loss: 0.8449968695640564\n",
      "Step 8088/10000- lr: [1.929325212121213e-06] - Loss total: 2.5595879554748535, Last rpr Loss: 1.0003036260604858, Last lagvar Loss: 0.8446682095527649\n",
      "Step 8089/10000- lr: [1.9283151151515144e-06] - Loss total: 2.5595664978027344, Last rpr Loss: 1.0000050067901611, Last lagvar Loss: 0.844948410987854\n",
      "Step 8090/10000- lr: [1.9273050181818177e-06] - Loss total: 2.559544801712036, Last rpr Loss: 1.0000180006027222, Last lagvar Loss: 0.844922661781311\n",
      "Step 8091/10000- lr: [1.926294921212121e-06] - Loss total: 2.559523820877075, Last rpr Loss: 0.9997309446334839, Last lagvar Loss: 0.8452012538909912\n",
      "Step 8092/10000- lr: [1.9252848242424242e-06] - Loss total: 2.559502363204956, Last rpr Loss: 0.9999072551727295, Last lagvar Loss: 0.8450197577476501\n",
      "Step 8093/10000- lr: [1.924274727272726e-06] - Loss total: 2.559481382369995, Last rpr Loss: 0.9997606873512268, Last lagvar Loss: 0.8451634645462036\n",
      "Step 8094/10000- lr: [1.923264630303031e-06] - Loss total: 2.5594608783721924, Last rpr Loss: 1.000096321105957, Last lagvar Loss: 0.8448264598846436\n",
      "Step 8095/10000- lr: [1.9222545333333324e-06] - Loss total: 2.5594406127929688, Last rpr Loss: 1.0001027584075928, Last lagvar Loss: 0.8448196649551392\n",
      "Step 8096/10000- lr: [1.9212444363636357e-06] - Loss total: 2.5594208240509033, Last rpr Loss: 1.0004266500473022, Last lagvar Loss: 0.8444952964782715\n",
      "Step 8097/10000- lr: [1.920234339393939e-06] - Loss total: 2.559401750564575, Last rpr Loss: 1.0002446174621582, Last lagvar Loss: 0.844675600528717\n",
      "Step 8098/10000- lr: [1.919224242424242e-06] - Loss total: 2.559382677078247, Last rpr Loss: 1.000227928161621, Last lagvar Loss: 0.8446893692016602\n",
      "Step 8099/10000- lr: [1.9182141454545455e-06] - Loss total: 2.559363603591919, Last rpr Loss: 0.9997807741165161, Last lagvar Loss: 0.8451328277587891\n",
      "Step 8100/10000- lr: [1.9172040484848488e-06] - Loss total: 2.559344530105591, Last rpr Loss: 0.999739944934845, Last lagvar Loss: 0.8451696634292603\n",
      "Step 8101/10000- lr: [1.9161939515151503e-06] - Loss total: 2.559325695037842, Last rpr Loss: 0.9996249675750732, Last lagvar Loss: 0.8452803492546082\n",
      "Step 8102/10000- lr: [1.9151838545454536e-06] - Loss total: 2.55930757522583, Last rpr Loss: 0.9999425411224365, Last lagvar Loss: 0.8449584245681763\n",
      "Step 8103/10000- lr: [1.914173757575757e-06] - Loss total: 2.55928897857666, Last rpr Loss: 1.0000169277191162, Last lagvar Loss: 0.8448799848556519\n",
      "Step 8104/10000- lr: [1.91316366060606e-06] - Loss total: 2.5592706203460693, Last rpr Loss: 1.0001288652420044, Last lagvar Loss: 0.8447641730308533\n",
      "Step 8105/10000- lr: [1.9121535636363635e-06] - Loss total: 2.5592522621154785, Last rpr Loss: 0.9998955130577087, Last lagvar Loss: 0.844994306564331\n",
      "Step 8106/10000- lr: [1.9111434666666667e-06] - Loss total: 2.559234619140625, Last rpr Loss: 0.9998860359191895, Last lagvar Loss: 0.845001220703125\n",
      "Step 8107/10000- lr: [1.9101333696969683e-06] - Loss total: 2.5592164993286133, Last rpr Loss: 0.9998668432235718, Last lagvar Loss: 0.8450182676315308\n",
      "Step 8108/10000- lr: [1.9091232727272733e-06] - Loss total: 2.559199094772339, Last rpr Loss: 1.0000975131988525, Last lagvar Loss: 0.8447856903076172\n",
      "Step 8109/10000- lr: [1.908113175757575e-06] - Loss total: 2.5591814517974854, Last rpr Loss: 1.000133752822876, Last lagvar Loss: 0.8447480201721191\n",
      "Step 8110/10000- lr: [1.9071030787878781e-06] - Loss total: 2.5591635704040527, Last rpr Loss: 1.0002177953720093, Last lagvar Loss: 0.8446627855300903\n",
      "Step 8111/10000- lr: [1.9060929818181814e-06] - Loss total: 2.5591464042663574, Last rpr Loss: 1.0000178813934326, Last lagvar Loss: 0.8448617458343506\n",
      "Step 8112/10000- lr: [1.9050828848484847e-06] - Loss total: 2.559128999710083, Last rpr Loss: 0.9999517202377319, Last lagvar Loss: 0.8449270129203796\n",
      "Step 8113/10000- lr: [1.9040727878787863e-06] - Loss total: 2.5591118335723877, Last rpr Loss: 0.9998315572738647, Last lagvar Loss: 0.8450462818145752\n",
      "Step 8114/10000- lr: [1.9030626909090913e-06] - Loss total: 2.5590944290161133, Last rpr Loss: 0.9999867081642151, Last lagvar Loss: 0.8448901176452637\n",
      "Step 8115/10000- lr: [1.9020525939393928e-06] - Loss total: 2.559077501296997, Last rpr Loss: 1.0000460147857666, Last lagvar Loss: 0.8448295593261719\n",
      "Step 8116/10000- lr: [1.9010424969696961e-06] - Loss total: 2.5590603351593018, Last rpr Loss: 1.0001389980316162, Last lagvar Loss: 0.8447353839874268\n",
      "Step 8117/10000- lr: [1.9000323999999994e-06] - Loss total: 2.5590431690216064, Last rpr Loss: 1.000009536743164, Last lagvar Loss: 0.8448635935783386\n",
      "Step 8118/10000- lr: [1.8990223030303027e-06] - Loss total: 2.559026002883911, Last rpr Loss: 0.9999202489852905, Last lagvar Loss: 0.8449516892433167\n",
      "Step 8119/10000- lr: [1.898012206060606e-06] - Loss total: 2.559009075164795, Last rpr Loss: 0.9998122453689575, Last lagvar Loss: 0.8450585603713989\n",
      "Step 8120/10000- lr: [1.8970021090909092e-06] - Loss total: 2.558992385864258, Last rpr Loss: 0.999888002872467, Last lagvar Loss: 0.8449819684028625\n",
      "Step 8121/10000- lr: [1.8959920121212125e-06] - Loss total: 2.5589756965637207, Last rpr Loss: 1.0000050067901611, Last lagvar Loss: 0.8448641300201416\n",
      "Step 8122/10000- lr: [1.894981915151514e-06] - Loss total: 2.5589590072631836, Last rpr Loss: 1.0001317262649536, Last lagvar Loss: 0.8447368144989014\n",
      "Step 8123/10000- lr: [1.893971818181819e-06] - Loss total: 2.5589420795440674, Last rpr Loss: 1.0001012086868286, Last lagvar Loss: 0.8447667360305786\n",
      "Step 8124/10000- lr: [1.8929617212121206e-06] - Loss total: 2.5589253902435303, Last rpr Loss: 0.9999840259552002, Last lagvar Loss: 0.844883382320404\n",
      "Step 8125/10000- lr: [1.891951624242424e-06] - Loss total: 2.558908700942993, Last rpr Loss: 0.9998656511306763, Last lagvar Loss: 0.8450011610984802\n",
      "Step 8126/10000- lr: [1.8909415272727272e-06] - Loss total: 2.558892250061035, Last rpr Loss: 0.9998612999916077, Last lagvar Loss: 0.8450048565864563\n",
      "Step 8127/10000- lr: [1.8899314303030305e-06] - Loss total: 2.558875560760498, Last rpr Loss: 0.9999492168426514, Last lagvar Loss: 0.8449161052703857\n",
      "Step 8128/10000- lr: [1.8889213333333337e-06] - Loss total: 2.558858871459961, Last rpr Loss: 1.0000425577163696, Last lagvar Loss: 0.844822108745575\n",
      "Step 8129/10000- lr: [1.887911236363637e-06] - Loss total: 2.558842420578003, Last rpr Loss: 1.000105857849121, Last lagvar Loss: 0.8447580933570862\n",
      "Step 8130/10000- lr: [1.8869011393939386e-06] - Loss total: 2.558825969696045, Last rpr Loss: 1.0000543594360352, Last lagvar Loss: 0.8448086977005005\n",
      "Step 8131/10000- lr: [1.8858910424242419e-06] - Loss total: 2.558809280395508, Last rpr Loss: 1.0000262260437012, Last lagvar Loss: 0.8448359370231628\n",
      "Step 8132/10000- lr: [1.8848809454545452e-06] - Loss total: 2.55879282951355, Last rpr Loss: 0.9999328851699829, Last lagvar Loss: 0.844928503036499\n",
      "Step 8133/10000- lr: [1.8838708484848484e-06] - Loss total: 2.558776378631592, Last rpr Loss: 0.9999521970748901, Last lagvar Loss: 0.8449082374572754\n",
      "Step 8134/10000- lr: [1.8828607515151517e-06] - Loss total: 2.558760404586792, Last rpr Loss: 0.9999308586120605, Last lagvar Loss: 0.8449286222457886\n",
      "Step 8135/10000- lr: [1.881850654545455e-06] - Loss total: 2.558743953704834, Last rpr Loss: 1.000032901763916, Last lagvar Loss: 0.8448253870010376\n",
      "Step 8136/10000- lr: [1.8808405575757566e-06] - Loss total: 2.558727741241455, Last rpr Loss: 1.0000417232513428, Last lagvar Loss: 0.8448155522346497\n",
      "Step 8137/10000- lr: [1.8798304606060615e-06] - Loss total: 2.558711051940918, Last rpr Loss: 1.000093936920166, Last lagvar Loss: 0.8447621464729309\n",
      "Step 8138/10000- lr: [1.8788203636363631e-06] - Loss total: 2.558694839477539, Last rpr Loss: 1.000016689300537, Last lagvar Loss: 0.84483802318573\n",
      "Step 8139/10000- lr: [1.8778102666666664e-06] - Loss total: 2.5586788654327393, Last rpr Loss: 1.0000081062316895, Last lagvar Loss: 0.8448450565338135\n",
      "Step 8140/10000- lr: [1.8768001696969697e-06] - Loss total: 2.5586624145507812, Last rpr Loss: 0.9999399185180664, Last lagvar Loss: 0.8449116945266724\n",
      "Step 8141/10000- lr: [1.875790072727273e-06] - Loss total: 2.558645725250244, Last rpr Loss: 0.9999903440475464, Last lagvar Loss: 0.8448594808578491\n",
      "Step 8142/10000- lr: [1.8747799757575745e-06] - Loss total: 2.558629274368286, Last rpr Loss: 0.9999803900718689, Last lagvar Loss: 0.8448673486709595\n",
      "Step 8143/10000- lr: [1.8737698787878795e-06] - Loss total: 2.5586133003234863, Last rpr Loss: 1.0000492334365845, Last lagvar Loss: 0.8447962999343872\n",
      "Step 8144/10000- lr: [1.872759781818181e-06] - Loss total: 2.5585968494415283, Last rpr Loss: 0.9999935626983643, Last lagvar Loss: 0.8448493480682373\n",
      "Step 8145/10000- lr: [1.8717496848484844e-06] - Loss total: 2.5585806369781494, Last rpr Loss: 1.0000324249267578, Last lagvar Loss: 0.8448077440261841\n",
      "Step 8146/10000- lr: [1.8707395878787876e-06] - Loss total: 2.5585644245147705, Last rpr Loss: 0.9999523758888245, Last lagvar Loss: 0.8448843955993652\n",
      "Step 8147/10000- lr: [1.869729490909091e-06] - Loss total: 2.5585482120513916, Last rpr Loss: 1.0000158548355103, Last lagvar Loss: 0.8448171615600586\n",
      "Step 8148/10000- lr: [1.8687193939393942e-06] - Loss total: 2.5585315227508545, Last rpr Loss: 0.9999704360961914, Last lagvar Loss: 0.8448581695556641\n",
      "Step 8149/10000- lr: [1.8677092969696975e-06] - Loss total: 2.5585148334503174, Last rpr Loss: 1.0000388622283936, Last lagvar Loss: 0.8447847366333008\n",
      "Step 8150/10000- lr: [1.866699199999999e-06] - Loss total: 2.5584986209869385, Last rpr Loss: 0.9999927282333374, Last lagvar Loss: 0.8448253870010376\n",
      "Step 8151/10000- lr: [1.8656891030303023e-06] - Loss total: 2.5584819316864014, Last rpr Loss: 1.0000354051589966, Last lagvar Loss: 0.8447763323783875\n",
      "Step 8152/10000- lr: [1.8646790060606056e-06] - Loss total: 2.5584652423858643, Last rpr Loss: 0.9999991059303284, Last lagvar Loss: 0.8448054194450378\n",
      "Step 8153/10000- lr: [1.863668909090909e-06] - Loss total: 2.558448314666748, Last rpr Loss: 1.0000214576721191, Last lagvar Loss: 0.8447750806808472\n",
      "Step 8154/10000- lr: [1.8626588121212122e-06] - Loss total: 2.55843186378479, Last rpr Loss: 1.0000158548355103, Last lagvar Loss: 0.844772219657898\n",
      "Step 8155/10000- lr: [1.8616487151515154e-06] - Loss total: 2.558415174484253, Last rpr Loss: 1.0000320672988892, Last lagvar Loss: 0.8447470664978027\n",
      "Step 8156/10000- lr: [1.860638618181817e-06] - Loss total: 2.5583982467651367, Last rpr Loss: 1.0000231266021729, Last lagvar Loss: 0.8447470664978027\n",
      "Step 8157/10000- lr: [1.859628521212122e-06] - Loss total: 2.5583815574645996, Last rpr Loss: 1.0000200271606445, Last lagvar Loss: 0.8447416424751282\n",
      "Step 8158/10000- lr: [1.8586184242424236e-06] - Loss total: 2.5583653450012207, Last rpr Loss: 1.0000017881393433, Last lagvar Loss: 0.8447521328926086\n",
      "Step 8159/10000- lr: [1.8576083272727269e-06] - Loss total: 2.5583486557006836, Last rpr Loss: 1.0000152587890625, Last lagvar Loss: 0.8447319269180298\n",
      "Step 8160/10000- lr: [1.8565982303030301e-06] - Loss total: 2.5583319664001465, Last rpr Loss: 1.0000011920928955, Last lagvar Loss: 0.8447404503822327\n",
      "Step 8161/10000- lr: [1.8555881333333334e-06] - Loss total: 2.558316230773926, Last rpr Loss: 1.000025749206543, Last lagvar Loss: 0.8447110652923584\n",
      "Step 8162/10000- lr: [1.854578036363635e-06] - Loss total: 2.5582993030548096, Last rpr Loss: 0.9999898672103882, Last lagvar Loss: 0.8447428941726685\n",
      "Step 8163/10000- lr: [1.85356793939394e-06] - Loss total: 2.5582830905914307, Last rpr Loss: 1.0000070333480835, Last lagvar Loss: 0.8447216749191284\n",
      "Step 8164/10000- lr: [1.8525578424242416e-06] - Loss total: 2.558267116546631, Last rpr Loss: 0.9999591112136841, Last lagvar Loss: 0.8447657227516174\n",
      "Step 8165/10000- lr: [1.8515477454545448e-06] - Loss total: 2.558250904083252, Last rpr Loss: 0.9999904632568359, Last lagvar Loss: 0.8447302579879761\n",
      "Step 8166/10000- lr: [1.8505376484848481e-06] - Loss total: 2.558234691619873, Last rpr Loss: 0.9999706149101257, Last lagvar Loss: 0.8447459936141968\n",
      "Step 8167/10000- lr: [1.8495275515151514e-06] - Loss total: 2.558218479156494, Last rpr Loss: 1.0000122785568237, Last lagvar Loss: 0.8447002172470093\n",
      "Step 8168/10000- lr: [1.8485174545454547e-06] - Loss total: 2.5582025051116943, Last rpr Loss: 0.999988317489624, Last lagvar Loss: 0.8447201251983643\n",
      "Step 8169/10000- lr: [1.847507357575758e-06] - Loss total: 2.5581862926483154, Last rpr Loss: 1.0000094175338745, Last lagvar Loss: 0.8446952104568481\n",
      "Step 8170/10000- lr: [1.8464972606060595e-06] - Loss total: 2.5581700801849365, Last rpr Loss: 0.9999710321426392, Last lagvar Loss: 0.8447301387786865\n",
      "Step 8171/10000- lr: [1.8454871636363628e-06] - Loss total: 2.558154344558716, Last rpr Loss: 0.9999906420707703, Last lagvar Loss: 0.8447072505950928\n",
      "Step 8172/10000- lr: [1.844477066666666e-06] - Loss total: 2.558138370513916, Last rpr Loss: 0.9999651312828064, Last lagvar Loss: 0.8447296619415283\n",
      "Step 8173/10000- lr: [1.8434669696969694e-06] - Loss total: 2.558122158050537, Last rpr Loss: 1.0000035762786865, Last lagvar Loss: 0.8446882367134094\n",
      "Step 8174/10000- lr: [1.8424568727272726e-06] - Loss total: 2.5581064224243164, Last rpr Loss: 0.9999778270721436, Last lagvar Loss: 0.844711422920227\n",
      "Step 8175/10000- lr: [1.841446775757576e-06] - Loss total: 2.5580906867980957, Last rpr Loss: 1.0000219345092773, Last lagvar Loss: 0.8446646928787231\n",
      "Step 8176/10000- lr: [1.8404366787878775e-06] - Loss total: 2.558074474334717, Last rpr Loss: 0.9999775886535645, Last lagvar Loss: 0.8447065949440002\n",
      "Step 8177/10000- lr: [1.8394265818181825e-06] - Loss total: 2.558058738708496, Last rpr Loss: 1.000024437904358, Last lagvar Loss: 0.844657301902771\n",
      "Step 8178/10000- lr: [1.838416484848484e-06] - Loss total: 2.5580427646636963, Last rpr Loss: 0.9999659657478333, Last lagvar Loss: 0.844713568687439\n",
      "Step 8179/10000- lr: [1.8374063878787873e-06] - Loss total: 2.5580270290374756, Last rpr Loss: 1.0000237226486206, Last lagvar Loss: 0.8446537852287292\n",
      "Step 8180/10000- lr: [1.8363962909090906e-06] - Loss total: 2.558011293411255, Last rpr Loss: 0.9999644756317139, Last lagvar Loss: 0.8447110056877136\n",
      "Step 8181/10000- lr: [1.8353861939393939e-06] - Loss total: 2.557995319366455, Last rpr Loss: 1.0000181198120117, Last lagvar Loss: 0.8446552753448486\n",
      "Step 8182/10000- lr: [1.8343760969696955e-06] - Loss total: 2.5579795837402344, Last rpr Loss: 0.9999737739562988, Last lagvar Loss: 0.8446978330612183\n",
      "Step 8183/10000- lr: [1.8333660000000004e-06] - Loss total: 2.5579638481140137, Last rpr Loss: 1.0000109672546387, Last lagvar Loss: 0.8446588516235352\n",
      "Step 8184/10000- lr: [1.832355903030302e-06] - Loss total: 2.557948350906372, Last rpr Loss: 0.9999785423278809, Last lagvar Loss: 0.8446896076202393\n",
      "Step 8185/10000- lr: [1.8313458060606053e-06] - Loss total: 2.5579328536987305, Last rpr Loss: 1.0000059604644775, Last lagvar Loss: 0.844660758972168\n",
      "Step 8186/10000- lr: [1.8303357090909086e-06] - Loss total: 2.5579168796539307, Last rpr Loss: 0.999984622001648, Last lagvar Loss: 0.8446804285049438\n",
      "Step 8187/10000- lr: [1.8293256121212118e-06] - Loss total: 2.55790114402771, Last rpr Loss: 1.000009298324585, Last lagvar Loss: 0.8446542620658875\n",
      "Step 8188/10000- lr: [1.8283155151515151e-06] - Loss total: 2.5578854084014893, Last rpr Loss: 0.9999891519546509, Last lagvar Loss: 0.8446730971336365\n",
      "Step 8189/10000- lr: [1.8273054181818184e-06] - Loss total: 2.5578699111938477, Last rpr Loss: 1.0000032186508179, Last lagvar Loss: 0.8446575999259949\n",
      "Step 8190/10000- lr: [1.82629532121212e-06] - Loss total: 2.557853937149048, Last rpr Loss: 0.9999895691871643, Last lagvar Loss: 0.8446699380874634\n",
      "Step 8191/10000- lr: [1.8252852242424233e-06] - Loss total: 2.557838201522827, Last rpr Loss: 1.0000041723251343, Last lagvar Loss: 0.8446541428565979\n",
      "Step 8192/10000- lr: [1.8242751272727265e-06] - Loss total: 2.5578229427337646, Last rpr Loss: 0.9999921321868896, Last lagvar Loss: 0.8446649312973022\n",
      "Step 8193/10000- lr: [1.8232650303030298e-06] - Loss total: 2.557807207107544, Last rpr Loss: 0.9999980926513672, Last lagvar Loss: 0.8446578979492188\n",
      "Step 8194/10000- lr: [1.822254933333333e-06] - Loss total: 2.5577919483184814, Last rpr Loss: 0.9999932646751404, Last lagvar Loss: 0.84466153383255\n",
      "Step 8195/10000- lr: [1.8212448363636364e-06] - Loss total: 2.5577762126922607, Last rpr Loss: 0.9999902248382568, Last lagvar Loss: 0.8446634411811829\n",
      "Step 8196/10000- lr: [1.820234739393938e-06] - Loss total: 2.557760715484619, Last rpr Loss: 0.99998939037323, Last lagvar Loss: 0.8446632623672485\n",
      "Step 8197/10000- lr: [1.819224642424243e-06] - Loss total: 2.5577449798583984, Last rpr Loss: 0.9999903440475464, Last lagvar Loss: 0.8446614146232605\n",
      "Step 8198/10000- lr: [1.8182145454545445e-06] - Loss total: 2.557729721069336, Last rpr Loss: 0.9999960660934448, Last lagvar Loss: 0.8446547985076904\n",
      "Step 8199/10000- lr: [1.8172044484848478e-06] - Loss total: 2.5577139854431152, Last rpr Loss: 0.9999891519546509, Last lagvar Loss: 0.844660758972168\n",
      "Step 8200/10000- lr: [1.816194351515151e-06] - Loss total: 2.5576984882354736, Last rpr Loss: 0.9999947547912598, Last lagvar Loss: 0.8446542620658875\n",
      "Step 8201/10000- lr: [1.8151842545454543e-06] - Loss total: 2.557683229446411, Last rpr Loss: 0.9999890923500061, Last lagvar Loss: 0.8446590304374695\n",
      "Step 8202/10000- lr: [1.814174157575756e-06] - Loss total: 2.5576677322387695, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8446524143218994\n",
      "Step 8203/10000- lr: [1.8131640606060609e-06] - Loss total: 2.557651996612549, Last rpr Loss: 0.9999865293502808, Last lagvar Loss: 0.8446600437164307\n",
      "Step 8204/10000- lr: [1.8121539636363625e-06] - Loss total: 2.5576364994049072, Last rpr Loss: 0.9999961256980896, Last lagvar Loss: 0.8446496725082397\n",
      "Step 8205/10000- lr: [1.8111438666666658e-06] - Loss total: 2.5576210021972656, Last rpr Loss: 0.9999899864196777, Last lagvar Loss: 0.84465491771698\n",
      "Step 8206/10000- lr: [1.8101337696969707e-06] - Loss total: 2.557605504989624, Last rpr Loss: 1.0000007152557373, Last lagvar Loss: 0.8446435332298279\n",
      "Step 8207/10000- lr: [1.8091236727272723e-06] - Loss total: 2.5575902462005615, Last rpr Loss: 0.9999886751174927, Last lagvar Loss: 0.8446550369262695\n",
      "Step 8208/10000- lr: [1.8081135757575756e-06] - Loss total: 2.557574987411499, Last rpr Loss: 1.0000033378601074, Last lagvar Loss: 0.8446394801139832\n",
      "Step 8209/10000- lr: [1.8071034787878789e-06] - Loss total: 2.5575592517852783, Last rpr Loss: 0.999988317489624, Last lagvar Loss: 0.8446539044380188\n",
      "Step 8210/10000- lr: [1.8060933818181821e-06] - Loss total: 2.557543992996216, Last rpr Loss: 0.999998152256012, Last lagvar Loss: 0.8446434736251831\n",
      "Step 8211/10000- lr: [1.8050832848484837e-06] - Loss total: 2.557528495788574, Last rpr Loss: 0.9999883770942688, Last lagvar Loss: 0.844652533531189\n",
      "Step 8212/10000- lr: [1.8040731878787887e-06] - Loss total: 2.5575132369995117, Last rpr Loss: 1.0000007152557373, Last lagvar Loss: 0.8446395993232727\n",
      "Step 8213/10000- lr: [1.8030630909090903e-06] - Loss total: 2.55749773979187, Last rpr Loss: 0.999994695186615, Last lagvar Loss: 0.8446449041366577\n",
      "Step 8214/10000- lr: [1.8020529939393935e-06] - Loss total: 2.5574822425842285, Last rpr Loss: 0.9999971389770508, Last lagvar Loss: 0.8446418642997742\n",
      "Step 8215/10000- lr: [1.8010428969696968e-06] - Loss total: 2.557467222213745, Last rpr Loss: 0.9999945163726807, Last lagvar Loss: 0.8446438312530518\n",
      "Step 8216/10000- lr: [1.8000328e-06] - Loss total: 2.5574517250061035, Last rpr Loss: 0.9999902248382568, Last lagvar Loss: 0.8446475267410278\n",
      "Step 8217/10000- lr: [1.7990227030303034e-06] - Loss total: 2.55743670463562, Last rpr Loss: 0.9999977350234985, Last lagvar Loss: 0.8446395397186279\n",
      "Step 8218/10000- lr: [1.7980126060606067e-06] - Loss total: 2.5574212074279785, Last rpr Loss: 0.9999840259552002, Last lagvar Loss: 0.8446527719497681\n",
      "Step 8219/10000- lr: [1.7970025090909082e-06] - Loss total: 2.557405710220337, Last rpr Loss: 1.000003457069397, Last lagvar Loss: 0.8446328639984131\n",
      "Step 8220/10000- lr: [1.7959924121212115e-06] - Loss total: 2.5573904514312744, Last rpr Loss: 0.9999843835830688, Last lagvar Loss: 0.8446512222290039\n",
      "Step 8221/10000- lr: [1.7949823151515148e-06] - Loss total: 2.557374954223633, Last rpr Loss: 1.000008463859558, Last lagvar Loss: 0.8446266651153564\n",
      "Step 8222/10000- lr: [1.793972218181818e-06] - Loss total: 2.5573596954345703, Last rpr Loss: 0.9999737739562988, Last lagvar Loss: 0.8446608781814575\n",
      "Step 8223/10000- lr: [1.7929621212121213e-06] - Loss total: 2.5573439598083496, Last rpr Loss: 1.0000163316726685, Last lagvar Loss: 0.8446177840232849\n",
      "Step 8224/10000- lr: [1.7919520242424246e-06] - Loss total: 2.557328701019287, Last rpr Loss: 0.9999704360961914, Last lagvar Loss: 0.8446632027626038\n",
      "Step 8225/10000- lr: [1.7909419272727262e-06] - Loss total: 2.5573136806488037, Last rpr Loss: 1.0000205039978027, Last lagvar Loss: 0.8446125984191895\n",
      "Step 8226/10000- lr: [1.7899318303030312e-06] - Loss total: 2.557298183441162, Last rpr Loss: 0.9999659061431885, Last lagvar Loss: 0.8446668386459351\n",
      "Step 8227/10000- lr: [1.7889217333333328e-06] - Loss total: 2.5572831630706787, Last rpr Loss: 1.0000215768814087, Last lagvar Loss: 0.8446106910705566\n",
      "Step 8228/10000- lr: [1.787911636363636e-06] - Loss total: 2.557267665863037, Last rpr Loss: 0.9999690651893616, Last lagvar Loss: 0.8446625471115112\n",
      "Step 8229/10000- lr: [1.7869015393939393e-06] - Loss total: 2.5572524070739746, Last rpr Loss: 1.0000183582305908, Last lagvar Loss: 0.8446128368377686\n",
      "Step 8230/10000- lr: [1.7858914424242426e-06] - Loss total: 2.557237148284912, Last rpr Loss: 0.9999740123748779, Last lagvar Loss: 0.8446568846702576\n",
      "Step 8231/10000- lr: [1.7848813454545442e-06] - Loss total: 2.5572218894958496, Last rpr Loss: 1.0000160932540894, Last lagvar Loss: 0.8446142673492432\n",
      "Step 8232/10000- lr: [1.7838712484848491e-06] - Loss total: 2.557206869125366, Last rpr Loss: 0.9999761581420898, Last lagvar Loss: 0.844653844833374\n",
      "Step 8233/10000- lr: [1.7828611515151507e-06] - Loss total: 2.5571911334991455, Last rpr Loss: 1.0000128746032715, Last lagvar Loss: 0.8446166515350342\n",
      "Step 8234/10000- lr: [1.781851054545454e-06] - Loss total: 2.557176113128662, Last rpr Loss: 0.9999818205833435, Last lagvar Loss: 0.8446474075317383\n",
      "Step 8235/10000- lr: [1.7808409575757573e-06] - Loss total: 2.5571608543395996, Last rpr Loss: 0.9999995231628418, Last lagvar Loss: 0.8446292281150818\n",
      "Step 8236/10000- lr: [1.7798308606060606e-06] - Loss total: 2.557145357131958, Last rpr Loss: 0.9999926090240479, Last lagvar Loss: 0.8446358442306519\n",
      "Step 8237/10000- lr: [1.7788207636363638e-06] - Loss total: 2.5571300983428955, Last rpr Loss: 0.9999961853027344, Last lagvar Loss: 0.8446319103240967\n",
      "Step 8238/10000- lr: [1.7778106666666671e-06] - Loss total: 2.557114839553833, Last rpr Loss: 0.9999986886978149, Last lagvar Loss: 0.8446290493011475\n",
      "Step 8239/10000- lr: [1.7768005696969687e-06] - Loss total: 2.5570995807647705, Last rpr Loss: 0.9999892711639404, Last lagvar Loss: 0.8446379899978638\n",
      "Step 8240/10000- lr: [1.775790472727272e-06] - Loss total: 2.557084321975708, Last rpr Loss: 1.0000035762786865, Last lagvar Loss: 0.8446233868598938\n",
      "Step 8241/10000- lr: [1.7747803757575753e-06] - Loss total: 2.5570690631866455, Last rpr Loss: 0.999983012676239, Last lagvar Loss: 0.8446435928344727\n",
      "Step 8242/10000- lr: [1.7737702787878785e-06] - Loss total: 2.557053565979004, Last rpr Loss: 1.000007152557373, Last lagvar Loss: 0.8446191549301147\n",
      "Step 8243/10000- lr: [1.7727601818181818e-06] - Loss total: 2.5570385456085205, Last rpr Loss: 0.9999821186065674, Last lagvar Loss: 0.844643771648407\n",
      "Step 8244/10000- lr: [1.771750084848485e-06] - Loss total: 2.557023048400879, Last rpr Loss: 1.0000090599060059, Last lagvar Loss: 0.8446166515350342\n",
      "Step 8245/10000- lr: [1.7707399878787867e-06] - Loss total: 2.5570080280303955, Last rpr Loss: 0.9999805688858032, Last lagvar Loss: 0.8446447253227234\n",
      "Step 8246/10000- lr: [1.7697298909090916e-06] - Loss total: 2.556992769241333, Last rpr Loss: 1.0000078678131104, Last lagvar Loss: 0.8446171283721924\n",
      "Step 8247/10000- lr: [1.7687197939393932e-06] - Loss total: 2.5569772720336914, Last rpr Loss: 0.9999804496765137, Last lagvar Loss: 0.8446441888809204\n",
      "Step 8248/10000- lr: [1.7677096969696965e-06] - Loss total: 2.55696177482605, Last rpr Loss: 1.0000121593475342, Last lagvar Loss: 0.8446123003959656\n",
      "Step 8249/10000- lr: [1.7666995999999998e-06] - Loss total: 2.556946277618408, Last rpr Loss: 0.9999808073043823, Last lagvar Loss: 0.844643235206604\n",
      "Step 8250/10000- lr: [1.765689503030303e-06] - Loss total: 2.5569310188293457, Last rpr Loss: 1.0000048875808716, Last lagvar Loss: 0.8446189761161804\n",
      "Step 8251/10000- lr: [1.7646794060606046e-06] - Loss total: 2.556915283203125, Last rpr Loss: 0.9999861717224121, Last lagvar Loss: 0.844637393951416\n",
      "Step 8252/10000- lr: [1.7636693090909096e-06] - Loss total: 2.5568997859954834, Last rpr Loss: 1.0000054836273193, Last lagvar Loss: 0.8446179628372192\n",
      "Step 8253/10000- lr: [1.7626592121212112e-06] - Loss total: 2.556884288787842, Last rpr Loss: 0.9999882578849792, Last lagvar Loss: 0.8446347713470459\n",
      "Step 8254/10000- lr: [1.7616491151515145e-06] - Loss total: 2.5568687915802, Last rpr Loss: 1.0000026226043701, Last lagvar Loss: 0.8446202278137207\n",
      "Step 8255/10000- lr: [1.7606390181818177e-06] - Loss total: 2.5568530559539795, Last rpr Loss: 0.9999916553497314, Last lagvar Loss: 0.8446309566497803\n",
      "Step 8256/10000- lr: [1.759628921212121e-06] - Loss total: 2.556837797164917, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8446274995803833\n",
      "Step 8257/10000- lr: [1.7586188242424243e-06] - Loss total: 2.556821823120117, Last rpr Loss: 1.0000014305114746, Last lagvar Loss: 0.8446207046508789\n",
      "Step 8258/10000- lr: [1.7576087272727276e-06] - Loss total: 2.5568058490753174, Last rpr Loss: 0.9999879002571106, Last lagvar Loss: 0.8446340560913086\n",
      "Step 8259/10000- lr: [1.7565986303030292e-06] - Loss total: 2.556790351867676, Last rpr Loss: 1.000013828277588, Last lagvar Loss: 0.844607949256897\n",
      "Step 8260/10000- lr: [1.7555885333333324e-06] - Loss total: 2.556774377822876, Last rpr Loss: 0.9999785423278809, Last lagvar Loss: 0.8446431159973145\n",
      "Step 8261/10000- lr: [1.7545784363636357e-06] - Loss total: 2.556758165359497, Last rpr Loss: 1.00001859664917, Last lagvar Loss: 0.8446029424667358\n",
      "Step 8262/10000- lr: [1.753568339393939e-06] - Loss total: 2.5567424297332764, Last rpr Loss: 0.9999728202819824, Last lagvar Loss: 0.8446487188339233\n",
      "Step 8263/10000- lr: [1.7525582424242423e-06] - Loss total: 2.5567257404327393, Last rpr Loss: 1.0000241994857788, Last lagvar Loss: 0.8445972204208374\n",
      "Step 8264/10000- lr: [1.7515481454545455e-06] - Loss total: 2.556709051132202, Last rpr Loss: 0.999972403049469, Last lagvar Loss: 0.8446489572525024\n",
      "Step 8265/10000- lr: [1.7505380484848471e-06] - Loss total: 2.556692123413086, Last rpr Loss: 1.000025749206543, Last lagvar Loss: 0.8445955514907837\n",
      "Step 8266/10000- lr: [1.749527951515152e-06] - Loss total: 2.5566749572753906, Last rpr Loss: 0.9999761581420898, Last lagvar Loss: 0.8446453809738159\n",
      "Step 8267/10000- lr: [1.7485178545454537e-06] - Loss total: 2.5566577911376953, Last rpr Loss: 1.0000293254852295, Last lagvar Loss: 0.8445923328399658\n",
      "Step 8268/10000- lr: [1.747507757575757e-06] - Loss total: 2.5566399097442627, Last rpr Loss: 0.9999736547470093, Last lagvar Loss: 0.8446483612060547\n",
      "Step 8269/10000- lr: [1.7464976606060602e-06] - Loss total: 2.5566213130950928, Last rpr Loss: 1.0000332593917847, Last lagvar Loss: 0.8445890545845032\n",
      "Step 8270/10000- lr: [1.7454875636363635e-06] - Loss total: 2.5566017627716064, Last rpr Loss: 0.9999708533287048, Last lagvar Loss: 0.8446520566940308\n",
      "Step 8271/10000- lr: [1.744477466666665e-06] - Loss total: 2.556581974029541, Last rpr Loss: 1.0000412464141846, Last lagvar Loss: 0.8445824384689331\n",
      "Step 8272/10000- lr: [1.74346736969697e-06] - Loss total: 2.556560754776001, Last rpr Loss: 0.9999700784683228, Last lagvar Loss: 0.844654381275177\n",
      "Step 8273/10000- lr: [1.7424572727272717e-06] - Loss total: 2.5565383434295654, Last rpr Loss: 1.000049352645874, Last lagvar Loss: 0.844576358795166\n",
      "Step 8274/10000- lr: [1.741447175757575e-06] - Loss total: 2.556514263153076, Last rpr Loss: 0.9999778866767883, Last lagvar Loss: 0.8446495532989502\n",
      "Step 8275/10000- lr: [1.7404370787878782e-06] - Loss total: 2.556487560272217, Last rpr Loss: 1.0000557899475098, Last lagvar Loss: 0.8445737361907959\n",
      "Step 8276/10000- lr: [1.7394269818181815e-06] - Loss total: 2.556459426879883, Last rpr Loss: 0.9999765753746033, Last lagvar Loss: 0.8446558117866516\n",
      "Step 8277/10000- lr: [1.7384168848484848e-06] - Loss total: 2.556429147720337, Last rpr Loss: 1.0000618696212769, Last lagvar Loss: 0.8445739150047302\n",
      "Step 8278/10000- lr: [1.737406787878788e-06] - Loss total: 2.556396007537842, Last rpr Loss: 0.999978244304657, Last lagvar Loss: 0.8446617126464844\n",
      "Step 8279/10000- lr: [1.7363966909090896e-06] - Loss total: 2.556361436843872, Last rpr Loss: 1.0000598430633545, Last lagvar Loss: 0.8445849418640137\n",
      "Step 8280/10000- lr: [1.735386593939393e-06] - Loss total: 2.556326150894165, Last rpr Loss: 0.9999697804450989, Last lagvar Loss: 0.8446803092956543\n",
      "Step 8281/10000- lr: [1.7343764969696962e-06] - Loss total: 2.5562918186187744, Last rpr Loss: 1.0000540018081665, Last lagvar Loss: 0.8446015119552612\n",
      "Step 8282/10000- lr: [1.7333663999999995e-06] - Loss total: 2.5562593936920166, Last rpr Loss: 0.9999539852142334, Last lagvar Loss: 0.844706118106842\n",
      "Step 8283/10000- lr: [1.7323563030303027e-06] - Loss total: 2.5562291145324707, Last rpr Loss: 1.0000312328338623, Last lagvar Loss: 0.8446327447891235\n",
      "Step 8284/10000- lr: [1.731346206060606e-06] - Loss total: 2.556201219558716, Last rpr Loss: 0.99993896484375, Last lagvar Loss: 0.8447272777557373\n",
      "Step 8285/10000- lr: [1.7303361090909076e-06] - Loss total: 2.5561749935150146, Last rpr Loss: 1.0000206232070923, Last lagvar Loss: 0.8446467518806458\n",
      "Step 8286/10000- lr: [1.7293260121212126e-06] - Loss total: 2.556150436401367, Last rpr Loss: 0.9999257326126099, Last lagvar Loss: 0.844741940498352\n",
      "Step 8287/10000- lr: [1.7283159151515141e-06] - Loss total: 2.556126594543457, Last rpr Loss: 0.9999945759773254, Last lagvar Loss: 0.8446725606918335\n",
      "Step 8288/10000- lr: [1.7273058181818174e-06] - Loss total: 2.5561037063598633, Last rpr Loss: 0.999897837638855, Last lagvar Loss: 0.8447684049606323\n",
      "Step 8289/10000- lr: [1.7262957212121207e-06] - Loss total: 2.5560810565948486, Last rpr Loss: 0.9999608397483826, Last lagvar Loss: 0.844704270362854\n",
      "Step 8290/10000- lr: [1.725285624242424e-06] - Loss total: 2.5560591220855713, Last rpr Loss: 0.9998780488967896, Last lagvar Loss: 0.8447858095169067\n",
      "Step 8291/10000- lr: [1.7242755272727256e-06] - Loss total: 2.556037425994873, Last rpr Loss: 0.9999685287475586, Last lagvar Loss: 0.8446941375732422\n",
      "Step 8292/10000- lr: [1.7232654303030305e-06] - Loss total: 2.556016206741333, Last rpr Loss: 0.9999111294746399, Last lagvar Loss: 0.8447502851486206\n",
      "Step 8293/10000- lr: [1.7222553333333338e-06] - Loss total: 2.555995225906372, Last rpr Loss: 1.0000190734863281, Last lagvar Loss: 0.8446409106254578\n",
      "Step 8294/10000- lr: [1.7212452363636354e-06] - Loss total: 2.555974245071411, Last rpr Loss: 0.9999571442604065, Last lagvar Loss: 0.8447016477584839\n",
      "Step 8295/10000- lr: [1.7202351393939404e-06] - Loss total: 2.5559535026550293, Last rpr Loss: 1.0000438690185547, Last lagvar Loss: 0.8446136713027954\n",
      "Step 8296/10000- lr: [1.719225042424242e-06] - Loss total: 2.5559327602386475, Last rpr Loss: 0.9999754428863525, Last lagvar Loss: 0.8446807861328125\n",
      "Step 8297/10000- lr: [1.7182149454545452e-06] - Loss total: 2.5559122562408447, Last rpr Loss: 1.000025749206543, Last lagvar Loss: 0.8446292877197266\n",
      "Step 8298/10000- lr: [1.7172048484848485e-06] - Loss total: 2.555891990661621, Last rpr Loss: 0.9999650716781616, Last lagvar Loss: 0.8446886539459229\n",
      "Step 8299/10000- lr: [1.7161947515151518e-06] - Loss total: 2.5558717250823975, Last rpr Loss: 1.000006914138794, Last lagvar Loss: 0.8446457386016846\n",
      "Step 8300/10000- lr: [1.7151846545454534e-06] - Loss total: 2.555851459503174, Last rpr Loss: 0.9999682903289795, Last lagvar Loss: 0.844683051109314\n",
      "Step 8301/10000- lr: [1.7141745575757583e-06] - Loss total: 2.55583119392395, Last rpr Loss: 0.9999936819076538, Last lagvar Loss: 0.8446565866470337\n",
      "Step 8302/10000- lr: [1.71316446060606e-06] - Loss total: 2.5558114051818848, Last rpr Loss: 0.9999818205833435, Last lagvar Loss: 0.8446673154830933\n",
      "Step 8303/10000- lr: [1.7121543636363632e-06] - Loss total: 2.5557918548583984, Last rpr Loss: 0.9999982714653015, Last lagvar Loss: 0.8446499109268188\n",
      "Step 8304/10000- lr: [1.7111442666666665e-06] - Loss total: 2.555771827697754, Last rpr Loss: 0.9999970197677612, Last lagvar Loss: 0.8446500897407532\n",
      "Step 8305/10000- lr: [1.7101341696969697e-06] - Loss total: 2.5557522773742676, Last rpr Loss: 1.0000027418136597, Last lagvar Loss: 0.8446433544158936\n",
      "Step 8306/10000- lr: [1.709124072727273e-06] - Loss total: 2.5557327270507812, Last rpr Loss: 1.000020146369934, Last lagvar Loss: 0.8446248173713684\n",
      "Step 8307/10000- lr: [1.7081139757575763e-06] - Loss total: 2.5557126998901367, Last rpr Loss: 1.0000078678131104, Last lagvar Loss: 0.8446362614631653\n",
      "Step 8308/10000- lr: [1.7071038787878779e-06] - Loss total: 2.5556936264038086, Last rpr Loss: 1.0000146627426147, Last lagvar Loss: 0.8446284532546997\n",
      "Step 8309/10000- lr: [1.7060937818181812e-06] - Loss total: 2.5556743144989014, Last rpr Loss: 1.0000033378601074, Last lagvar Loss: 0.8446389436721802\n",
      "Step 8310/10000- lr: [1.7050836848484844e-06] - Loss total: 2.555654764175415, Last rpr Loss: 1.000008225440979, Last lagvar Loss: 0.8446332812309265\n",
      "Step 8311/10000- lr: [1.7040735878787877e-06] - Loss total: 2.555635690689087, Last rpr Loss: 0.9999926090240479, Last lagvar Loss: 0.8446481823921204\n",
      "Step 8312/10000- lr: [1.703063490909091e-06] - Loss total: 2.5556163787841797, Last rpr Loss: 1.0000026226043701, Last lagvar Loss: 0.8446375131607056\n",
      "Step 8313/10000- lr: [1.7020533939393943e-06] - Loss total: 2.5555973052978516, Last rpr Loss: 0.9999880790710449, Last lagvar Loss: 0.8446514010429382\n",
      "Step 8314/10000- lr: [1.7010432969696958e-06] - Loss total: 2.5555779933929443, Last rpr Loss: 1.0000070333480835, Last lagvar Loss: 0.8446319103240967\n",
      "Step 8315/10000- lr: [1.7000332000000008e-06] - Loss total: 2.555558919906616, Last rpr Loss: 0.9999794960021973, Last lagvar Loss: 0.8446590304374695\n",
      "Step 8316/10000- lr: [1.6990231030303024e-06] - Loss total: 2.555539846420288, Last rpr Loss: 1.0000081062316895, Last lagvar Loss: 0.8446298837661743\n",
      "Step 8317/10000- lr: [1.6980130060606057e-06] - Loss total: 2.555521011352539, Last rpr Loss: 0.999974250793457, Last lagvar Loss: 0.8446635603904724\n",
      "Step 8318/10000- lr: [1.697002909090909e-06] - Loss total: 2.55550217628479, Last rpr Loss: 0.9999980926513672, Last lagvar Loss: 0.8446391820907593\n",
      "Step 8319/10000- lr: [1.6959928121212122e-06] - Loss total: 2.555482864379883, Last rpr Loss: 0.9999637603759766, Last lagvar Loss: 0.8446732759475708\n",
      "Step 8320/10000- lr: [1.6949827151515138e-06] - Loss total: 2.555464267730713, Last rpr Loss: 0.9999843835830688, Last lagvar Loss: 0.8446523547172546\n",
      "Step 8321/10000- lr: [1.6939726181818188e-06] - Loss total: 2.5554451942443848, Last rpr Loss: 0.9999630451202393, Last lagvar Loss: 0.8446734547615051\n",
      "Step 8322/10000- lr: [1.6929625212121204e-06] - Loss total: 2.5554263591766357, Last rpr Loss: 0.9999843835830688, Last lagvar Loss: 0.8446519374847412\n",
      "Step 8323/10000- lr: [1.6919524242424236e-06] - Loss total: 2.5554072856903076, Last rpr Loss: 0.9999775290489197, Last lagvar Loss: 0.8446585536003113\n",
      "Step 8324/10000- lr: [1.690942327272727e-06] - Loss total: 2.5553882122039795, Last rpr Loss: 0.9999901056289673, Last lagvar Loss: 0.8446459770202637\n",
      "Step 8325/10000- lr: [1.6899322303030302e-06] - Loss total: 2.5553691387176514, Last rpr Loss: 0.9999878406524658, Last lagvar Loss: 0.8446480631828308\n",
      "Step 8326/10000- lr: [1.6889221333333335e-06] - Loss total: 2.5553503036499023, Last rpr Loss: 0.9999881982803345, Last lagvar Loss: 0.8446477651596069\n",
      "Step 8327/10000- lr: [1.6879120363636368e-06] - Loss total: 2.555330991744995, Last rpr Loss: 0.9999926090240479, Last lagvar Loss: 0.8446435332298279\n",
      "Step 8328/10000- lr: [1.6869019393939383e-06] - Loss total: 2.5553112030029297, Last rpr Loss: 0.9999916553497314, Last lagvar Loss: 0.8446446061134338\n",
      "Step 8329/10000- lr: [1.6858918424242416e-06] - Loss total: 2.5552926063537598, Last rpr Loss: 0.9999963045120239, Last lagvar Loss: 0.8446401953697205\n",
      "Step 8330/10000- lr: [1.6848817454545449e-06] - Loss total: 2.5552728176116943, Last rpr Loss: 0.9999884963035583, Last lagvar Loss: 0.8446484804153442\n",
      "Step 8331/10000- lr: [1.6838716484848482e-06] - Loss total: 2.555253028869629, Last rpr Loss: 0.9999984502792358, Last lagvar Loss: 0.8446388244628906\n",
      "Step 8332/10000- lr: [1.6828615515151514e-06] - Loss total: 2.5552332401275635, Last rpr Loss: 0.9999860525131226, Last lagvar Loss: 0.8446518182754517\n",
      "Step 8333/10000- lr: [1.6818514545454547e-06] - Loss total: 2.555213451385498, Last rpr Loss: 1.0000017881393433, Last lagvar Loss: 0.844636857509613\n",
      "Step 8334/10000- lr: [1.6808413575757563e-06] - Loss total: 2.5551934242248535, Last rpr Loss: 0.9999828338623047, Last lagvar Loss: 0.8446565866470337\n",
      "Step 8335/10000- lr: [1.6798312606060613e-06] - Loss total: 2.555173397064209, Last rpr Loss: 1.000003457069397, Last lagvar Loss: 0.8446369171142578\n",
      "Step 8336/10000- lr: [1.6788211636363629e-06] - Loss total: 2.5551533699035645, Last rpr Loss: 0.9999780654907227, Last lagvar Loss: 0.8446633219718933\n",
      "Step 8337/10000- lr: [1.6778110666666661e-06] - Loss total: 2.555133104324341, Last rpr Loss: 1.0000040531158447, Last lagvar Loss: 0.8446382880210876\n",
      "Step 8338/10000- lr: [1.6768009696969694e-06] - Loss total: 2.555112838745117, Last rpr Loss: 0.9999798536300659, Last lagvar Loss: 0.8446635007858276\n",
      "Step 8339/10000- lr: [1.6757908727272727e-06] - Loss total: 2.5550928115844727, Last rpr Loss: 0.9999966621398926, Last lagvar Loss: 0.8446476459503174\n",
      "Step 8340/10000- lr: [1.6747807757575743e-06] - Loss total: 2.555072784423828, Last rpr Loss: 0.9999727010726929, Last lagvar Loss: 0.844672441482544\n",
      "Step 8341/10000- lr: [1.6737706787878792e-06] - Loss total: 2.5550525188446045, Last rpr Loss: 0.999985933303833, Last lagvar Loss: 0.8446598052978516\n",
      "Step 8342/10000- lr: [1.6727605818181808e-06] - Loss total: 2.555032730102539, Last rpr Loss: 0.9999676942825317, Last lagvar Loss: 0.8446783423423767\n",
      "Step 8343/10000- lr: [1.6717504848484841e-06] - Loss total: 2.5550131797790527, Last rpr Loss: 0.9999849796295166, Last lagvar Loss: 0.8446610569953918\n",
      "Step 8344/10000- lr: [1.6707403878787874e-06] - Loss total: 2.5549933910369873, Last rpr Loss: 0.9999633431434631, Last lagvar Loss: 0.8446824550628662\n",
      "Step 8345/10000- lr: [1.6697302909090907e-06] - Loss total: 2.5549745559692383, Last rpr Loss: 0.9999877214431763, Last lagvar Loss: 0.8446574211120605\n",
      "Step 8346/10000- lr: [1.668720193939394e-06] - Loss total: 2.554954767227173, Last rpr Loss: 0.9999606013298035, Last lagvar Loss: 0.8446837663650513\n",
      "Step 8347/10000- lr: [1.6677100969696972e-06] - Loss total: 2.554935932159424, Last rpr Loss: 0.9999907612800598, Last lagvar Loss: 0.8446526527404785\n",
      "Step 8348/10000- lr: [1.6666999999999988e-06] - Loss total: 2.5549163818359375, Last rpr Loss: 0.9999585151672363, Last lagvar Loss: 0.8446840047836304\n",
      "Step 8349/10000- lr: [1.665689903030302e-06] - Loss total: 2.5548977851867676, Last rpr Loss: 0.9999827146530151, Last lagvar Loss: 0.8446587324142456\n",
      "Step 8350/10000- lr: [1.6646798060606054e-06] - Loss total: 2.5548789501190186, Last rpr Loss: 0.9999649524688721, Last lagvar Loss: 0.8446754217147827\n",
      "Step 8351/10000- lr: [1.6636697090909086e-06] - Loss total: 2.5548603534698486, Last rpr Loss: 0.9999748468399048, Last lagvar Loss: 0.8446645736694336\n",
      "Step 8352/10000- lr: [1.662659612121212e-06] - Loss total: 2.5548415184020996, Last rpr Loss: 0.9999698400497437, Last lagvar Loss: 0.8446686267852783\n",
      "Step 8353/10000- lr: [1.6616495151515152e-06] - Loss total: 2.5548229217529297, Last rpr Loss: 0.999970555305481, Last lagvar Loss: 0.8446670770645142\n",
      "Step 8354/10000- lr: [1.6606394181818168e-06] - Loss total: 2.554804801940918, Last rpr Loss: 0.9999769926071167, Last lagvar Loss: 0.8446599841117859\n",
      "Step 8355/10000- lr: [1.6596293212121217e-06] - Loss total: 2.554786443710327, Last rpr Loss: 0.9999708533287048, Last lagvar Loss: 0.8446654081344604\n",
      "Step 8356/10000- lr: [1.6586192242424233e-06] - Loss total: 2.5547680854797363, Last rpr Loss: 0.9999808073043823, Last lagvar Loss: 0.84465491771698\n",
      "Step 8357/10000- lr: [1.6576091272727266e-06] - Loss total: 2.5547497272491455, Last rpr Loss: 0.9999754428863525, Last lagvar Loss: 0.844659686088562\n",
      "Step 8358/10000- lr: [1.6565990303030299e-06] - Loss total: 2.554731845855713, Last rpr Loss: 0.9999885559082031, Last lagvar Loss: 0.8446460962295532\n",
      "Step 8359/10000- lr: [1.6555889333333332e-06] - Loss total: 2.554713487625122, Last rpr Loss: 0.9999746084213257, Last lagvar Loss: 0.8446594476699829\n",
      "Step 8360/10000- lr: [1.6545788363636347e-06] - Loss total: 2.5546958446502686, Last rpr Loss: 0.9999861717224121, Last lagvar Loss: 0.8446475267410278\n",
      "Step 8361/10000- lr: [1.6535687393939397e-06] - Loss total: 2.554677724838257, Last rpr Loss: 0.9999815225601196, Last lagvar Loss: 0.8446516990661621\n",
      "Step 8362/10000- lr: [1.6525586424242413e-06] - Loss total: 2.554659605026245, Last rpr Loss: 0.9999852180480957, Last lagvar Loss: 0.8446476459503174\n",
      "Step 8363/10000- lr: [1.6515485454545446e-06] - Loss total: 2.5546417236328125, Last rpr Loss: 0.9999866485595703, Last lagvar Loss: 0.8446458578109741\n",
      "Step 8364/10000- lr: [1.6505384484848478e-06] - Loss total: 2.55462384223938, Last rpr Loss: 0.9999927878379822, Last lagvar Loss: 0.8446394801139832\n",
      "Step 8365/10000- lr: [1.6495283515151511e-06] - Loss total: 2.5546061992645264, Last rpr Loss: 0.9999872446060181, Last lagvar Loss: 0.8446446061134338\n",
      "Step 8366/10000- lr: [1.6485182545454544e-06] - Loss total: 2.5545878410339355, Last rpr Loss: 0.9999971389770508, Last lagvar Loss: 0.844634473323822\n",
      "Step 8367/10000- lr: [1.6475081575757577e-06] - Loss total: 2.554570436477661, Last rpr Loss: 0.9999886751174927, Last lagvar Loss: 0.8446426391601562\n",
      "Step 8368/10000- lr: [1.6464980606060593e-06] - Loss total: 2.5545525550842285, Last rpr Loss: 1.0000011920928955, Last lagvar Loss: 0.8446298837661743\n",
      "Step 8369/10000- lr: [1.6454879636363625e-06] - Loss total: 2.554534435272217, Last rpr Loss: 0.9999828338623047, Last lagvar Loss: 0.8446478843688965\n",
      "Step 8370/10000- lr: [1.6444778666666658e-06] - Loss total: 2.5545170307159424, Last rpr Loss: 1.000002384185791, Last lagvar Loss: 0.8446282148361206\n",
      "Step 8371/10000- lr: [1.643467769696969e-06] - Loss total: 2.554499387741089, Last rpr Loss: 0.9999842643737793, Last lagvar Loss: 0.8446460962295532\n",
      "Step 8372/10000- lr: [1.6424576727272724e-06] - Loss total: 2.5544815063476562, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8446353673934937\n",
      "Step 8373/10000- lr: [1.6414475757575756e-06] - Loss total: 2.554464101791382, Last rpr Loss: 0.9999871850013733, Last lagvar Loss: 0.8446428179740906\n",
      "Step 8374/10000- lr: [1.6404374787878772e-06] - Loss total: 2.5544464588165283, Last rpr Loss: 0.999995768070221, Last lagvar Loss: 0.8446339964866638\n",
      "Step 8375/10000- lr: [1.6394273818181822e-06] - Loss total: 2.554428815841675, Last rpr Loss: 0.9999849200248718, Last lagvar Loss: 0.8446446657180786\n",
      "Step 8376/10000- lr: [1.6384172848484838e-06] - Loss total: 2.5544111728668213, Last rpr Loss: 0.9999927282333374, Last lagvar Loss: 0.8446366786956787\n",
      "Step 8377/10000- lr: [1.637407187878787e-06] - Loss total: 2.5543935298919678, Last rpr Loss: 0.999981164932251, Last lagvar Loss: 0.8446480631828308\n",
      "Step 8378/10000- lr: [1.6363970909090903e-06] - Loss total: 2.5543763637542725, Last rpr Loss: 0.9999984502792358, Last lagvar Loss: 0.844630777835846\n",
      "Step 8379/10000- lr: [1.6353869939393936e-06] - Loss total: 2.554358720779419, Last rpr Loss: 0.9999778270721436, Last lagvar Loss: 0.8446510434150696\n",
      "Step 8380/10000- lr: [1.6343768969696969e-06] - Loss total: 2.5543413162231445, Last rpr Loss: 1.0000026226043701, Last lagvar Loss: 0.8446261882781982\n",
      "Step 8381/10000- lr: [1.6333668000000002e-06] - Loss total: 2.55432391166687, Last rpr Loss: 0.9999758005142212, Last lagvar Loss: 0.8446527719497681\n",
      "Step 8382/10000- lr: [1.6323567030303034e-06] - Loss total: 2.5543065071105957, Last rpr Loss: 1.0000009536743164, Last lagvar Loss: 0.844627320766449\n",
      "Step 8383/10000- lr: [1.631346606060605e-06] - Loss total: 2.5542891025543213, Last rpr Loss: 0.9999775886535645, Last lagvar Loss: 0.8446506261825562\n",
      "Step 8384/10000- lr: [1.63033650909091e-06] - Loss total: 2.5542714595794678, Last rpr Loss: 0.9999967217445374, Last lagvar Loss: 0.8446312546730042\n",
      "Step 8385/10000- lr: [1.6293264121212116e-06] - Loss total: 2.5542540550231934, Last rpr Loss: 0.9999843835830688, Last lagvar Loss: 0.8446434736251831\n",
      "Step 8386/10000- lr: [1.6283163151515149e-06] - Loss total: 2.554236650466919, Last rpr Loss: 0.9999963045120239, Last lagvar Loss: 0.8446313142776489\n",
      "Step 8387/10000- lr: [1.6273062181818181e-06] - Loss total: 2.5542194843292236, Last rpr Loss: 0.9999910593032837, Last lagvar Loss: 0.8446363210678101\n",
      "Step 8388/10000- lr: [1.6262961212121214e-06] - Loss total: 2.5542023181915283, Last rpr Loss: 0.9999939203262329, Last lagvar Loss: 0.8446332216262817\n",
      "Step 8389/10000- lr: [1.625286024242423e-06] - Loss total: 2.554184913635254, Last rpr Loss: 0.9999933838844299, Last lagvar Loss: 0.8446335792541504\n",
      "Step 8390/10000- lr: [1.624275927272728e-06] - Loss total: 2.5541675090789795, Last rpr Loss: 0.9999926686286926, Last lagvar Loss: 0.8446340560913086\n",
      "Step 8391/10000- lr: [1.6232658303030295e-06] - Loss total: 2.554150342941284, Last rpr Loss: 0.9999929070472717, Last lagvar Loss: 0.8446334600448608\n",
      "Step 8392/10000- lr: [1.6222557333333328e-06] - Loss total: 2.554133176803589, Last rpr Loss: 0.9999974370002747, Last lagvar Loss: 0.844628632068634\n",
      "Step 8393/10000- lr: [1.621245636363636e-06] - Loss total: 2.5541157722473145, Last rpr Loss: 0.9999929666519165, Last lagvar Loss: 0.8446326851844788\n",
      "Step 8394/10000- lr: [1.6202355393939394e-06] - Loss total: 2.5540988445281982, Last rpr Loss: 1.0000008344650269, Last lagvar Loss: 0.8446245193481445\n",
      "Step 8395/10000- lr: [1.6192254424242427e-06] - Loss total: 2.554081439971924, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8446301817893982\n",
      "Step 8396/10000- lr: [1.618215345454546e-06] - Loss total: 2.5540640354156494, Last rpr Loss: 1.0000014305114746, Last lagvar Loss: 0.8446230888366699\n",
      "Step 8397/10000- lr: [1.6172052484848475e-06] - Loss total: 2.554047107696533, Last rpr Loss: 1.0000008344650269, Last lagvar Loss: 0.8446232080459595\n",
      "Step 8398/10000- lr: [1.6161951515151508e-06] - Loss total: 2.554029941558838, Last rpr Loss: 1.0000038146972656, Last lagvar Loss: 0.8446195721626282\n",
      "Step 8399/10000- lr: [1.615185054545454e-06] - Loss total: 2.5540120601654053, Last rpr Loss: 0.9999988675117493, Last lagvar Loss: 0.8446236848831177\n",
      "Step 8400/10000- lr: [1.6141749575757573e-06] - Loss total: 2.553994655609131, Last rpr Loss: 1.0000104904174805, Last lagvar Loss: 0.8446112275123596\n",
      "Step 8401/10000- lr: [1.6131648606060606e-06] - Loss total: 2.5539772510528564, Last rpr Loss: 1.0000001192092896, Last lagvar Loss: 0.844620406627655\n",
      "Step 8402/10000- lr: [1.612154763636364e-06] - Loss total: 2.553959846496582, Last rpr Loss: 1.0000170469284058, Last lagvar Loss: 0.8446019291877747\n",
      "Step 8403/10000- lr: [1.6111446666666655e-06] - Loss total: 2.5539422035217285, Last rpr Loss: 1.0000038146972656, Last lagvar Loss: 0.8446131944656372\n",
      "Step 8404/10000- lr: [1.6101345696969705e-06] - Loss total: 2.553924083709717, Last rpr Loss: 1.0000290870666504, Last lagvar Loss: 0.8445853590965271\n",
      "Step 8405/10000- lr: [1.609124472727272e-06] - Loss total: 2.5539064407348633, Last rpr Loss: 1.0000053644180298, Last lagvar Loss: 0.8446058630943298\n",
      "Step 8406/10000- lr: [1.6081143757575753e-06] - Loss total: 2.5538876056671143, Last rpr Loss: 1.0000324249267578, Last lagvar Loss: 0.8445742726325989\n",
      "Step 8407/10000- lr: [1.6071042787878786e-06] - Loss total: 2.5538694858551025, Last rpr Loss: 1.0000191926956177, Last lagvar Loss: 0.8445816040039062\n",
      "Step 8408/10000- lr: [1.6060941818181819e-06] - Loss total: 2.5538504123687744, Last rpr Loss: 1.0000324249267578, Last lagvar Loss: 0.8445608615875244\n",
      "Step 8409/10000- lr: [1.6050840848484835e-06] - Loss total: 2.553831100463867, Last rpr Loss: 1.0000250339508057, Last lagvar Loss: 0.8445587754249573\n",
      "Step 8410/10000- lr: [1.6040739878787884e-06] - Loss total: 2.5538113117218018, Last rpr Loss: 1.0000356435775757, Last lagvar Loss: 0.8445372581481934\n",
      "Step 8411/10000- lr: [1.60306389090909e-06] - Loss total: 2.5537915229797363, Last rpr Loss: 1.0000299215316772, Last lagvar Loss: 0.8445310592651367\n",
      "Step 8412/10000- lr: [1.6020537939393933e-06] - Loss total: 2.5537712574005127, Last rpr Loss: 1.00002920627594, Last lagvar Loss: 0.8445193767547607\n",
      "Step 8413/10000- lr: [1.6010436969696966e-06] - Loss total: 2.553751230239868, Last rpr Loss: 1.0000276565551758, Last lagvar Loss: 0.8445090055465698\n",
      "Step 8414/10000- lr: [1.6000335999999998e-06] - Loss total: 2.5537312030792236, Last rpr Loss: 1.0000240802764893, Last lagvar Loss: 0.8445013761520386\n",
      "Step 8415/10000- lr: [1.5990235030303031e-06] - Loss total: 2.553711414337158, Last rpr Loss: 1.000013828277588, Last lagvar Loss: 0.8445016145706177\n",
      "Step 8416/10000- lr: [1.5980134060606064e-06] - Loss total: 2.5536913871765137, Last rpr Loss: 1.0000114440917969, Last lagvar Loss: 0.8444948196411133\n",
      "Step 8417/10000- lr: [1.597003309090908e-06] - Loss total: 2.5536718368530273, Last rpr Loss: 0.9999911785125732, Last lagvar Loss: 0.8445068597793579\n",
      "Step 8418/10000- lr: [1.5959932121212113e-06] - Loss total: 2.55365252494812, Last rpr Loss: 0.9999865889549255, Last lagvar Loss: 0.8445039987564087\n",
      "Step 8419/10000- lr: [1.5949831151515145e-06] - Loss total: 2.55363392829895, Last rpr Loss: 0.9999675750732422, Last lagvar Loss: 0.8445161581039429\n",
      "Step 8420/10000- lr: [1.5939730181818178e-06] - Loss total: 2.553615093231201, Last rpr Loss: 0.9999776482582092, Last lagvar Loss: 0.844499945640564\n",
      "Step 8421/10000- lr: [1.592962921212121e-06] - Loss total: 2.5535964965820312, Last rpr Loss: 0.999963641166687, Last lagvar Loss: 0.8445082902908325\n",
      "Step 8422/10000- lr: [1.5919528242424244e-06] - Loss total: 2.5535783767700195, Last rpr Loss: 0.9999812841415405, Last lagvar Loss: 0.8444854617118835\n",
      "Step 8423/10000- lr: [1.590942727272726e-06] - Loss total: 2.553560256958008, Last rpr Loss: 0.999964714050293, Last lagvar Loss: 0.8444974422454834\n",
      "Step 8424/10000- lr: [1.589932630303031e-06] - Loss total: 2.553542375564575, Last rpr Loss: 0.9999881982803345, Last lagvar Loss: 0.8444696664810181\n",
      "Step 8425/10000- lr: [1.5889225333333325e-06] - Loss total: 2.5535247325897217, Last rpr Loss: 0.9999674558639526, Last lagvar Loss: 0.8444865942001343\n",
      "Step 8426/10000- lr: [1.5879124363636358e-06] - Loss total: 2.553506374359131, Last rpr Loss: 0.9999924898147583, Last lagvar Loss: 0.8444579839706421\n",
      "Step 8427/10000- lr: [1.586902339393939e-06] - Loss total: 2.5534892082214355, Last rpr Loss: 0.9999786615371704, Last lagvar Loss: 0.8444687724113464\n",
      "Step 8428/10000- lr: [1.5858922424242423e-06] - Loss total: 2.553471803665161, Last rpr Loss: 1.0000020265579224, Last lagvar Loss: 0.8444427251815796\n",
      "Step 8429/10000- lr: [1.584882145454544e-06] - Loss total: 2.553455114364624, Last rpr Loss: 0.9999986290931702, Last lagvar Loss: 0.8444435596466064\n",
      "Step 8430/10000- lr: [1.5838720484848489e-06] - Loss total: 2.5534374713897705, Last rpr Loss: 1.0000098943710327, Last lagvar Loss: 0.844430148601532\n",
      "Step 8431/10000- lr: [1.5828619515151505e-06] - Loss total: 2.5534205436706543, Last rpr Loss: 1.000007152557373, Last lagvar Loss: 0.8444310426712036\n",
      "Step 8432/10000- lr: [1.5818518545454537e-06] - Loss total: 2.553403854370117, Last rpr Loss: 1.0000065565109253, Last lagvar Loss: 0.8444297909736633\n",
      "Step 8433/10000- lr: [1.580841757575757e-06] - Loss total: 2.553386926651001, Last rpr Loss: 0.9999970197677612, Last lagvar Loss: 0.844437837600708\n",
      "Step 8434/10000- lr: [1.5798316606060603e-06] - Loss total: 2.5533699989318848, Last rpr Loss: 0.9999822378158569, Last lagvar Loss: 0.8444511890411377\n",
      "Step 8435/10000- lr: [1.5788215636363636e-06] - Loss total: 2.5533535480499268, Last rpr Loss: 0.9999862909317017, Last lagvar Loss: 0.8444458246231079\n",
      "Step 8436/10000- lr: [1.5778114666666669e-06] - Loss total: 2.5533368587493896, Last rpr Loss: 0.9999658465385437, Last lagvar Loss: 0.8444652557373047\n",
      "Step 8437/10000- lr: [1.5768013696969684e-06] - Loss total: 2.5533204078674316, Last rpr Loss: 0.9999886155128479, Last lagvar Loss: 0.8444415330886841\n",
      "Step 8438/10000- lr: [1.5757912727272717e-06] - Loss total: 2.5533039569854736, Last rpr Loss: 0.9999644160270691, Last lagvar Loss: 0.8444646596908569\n",
      "Step 8439/10000- lr: [1.574781175757575e-06] - Loss total: 2.5532872676849365, Last rpr Loss: 0.9999943971633911, Last lagvar Loss: 0.8444337844848633\n",
      "Step 8440/10000- lr: [1.5737710787878783e-06] - Loss total: 2.5532712936401367, Last rpr Loss: 0.9999674558639526, Last lagvar Loss: 0.8444600105285645\n",
      "Step 8441/10000- lr: [1.5727609818181815e-06] - Loss total: 2.5532548427581787, Last rpr Loss: 1.0000015497207642, Last lagvar Loss: 0.8444251418113708\n",
      "Step 8442/10000- lr: [1.5717508848484848e-06] - Loss total: 2.5532386302948, Last rpr Loss: 0.999972939491272, Last lagvar Loss: 0.8444530963897705\n",
      "Step 8443/10000- lr: [1.5707407878787864e-06] - Loss total: 2.553222179412842, Last rpr Loss: 1.000004768371582, Last lagvar Loss: 0.8444206714630127\n",
      "Step 8444/10000- lr: [1.5697306909090914e-06] - Loss total: 2.553206205368042, Last rpr Loss: 0.9999827146530151, Last lagvar Loss: 0.8444419503211975\n",
      "Step 8445/10000- lr: [1.568720593939393e-06] - Loss total: 2.553189992904663, Last rpr Loss: 0.9999970197677612, Last lagvar Loss: 0.8444271683692932\n",
      "Step 8446/10000- lr: [1.5677104969696962e-06] - Loss total: 2.553173542022705, Last rpr Loss: 0.9999868869781494, Last lagvar Loss: 0.844436764717102\n",
      "Step 8447/10000- lr: [1.5667003999999995e-06] - Loss total: 2.5531575679779053, Last rpr Loss: 0.999984860420227, Last lagvar Loss: 0.8444382548332214\n",
      "Step 8448/10000- lr: [1.5656903030303028e-06] - Loss total: 2.5531418323516846, Last rpr Loss: 0.9999955892562866, Last lagvar Loss: 0.8444271087646484\n",
      "Step 8449/10000- lr: [1.5646802060606044e-06] - Loss total: 2.5531256198883057, Last rpr Loss: 0.9999688863754272, Last lagvar Loss: 0.8444532752037048\n",
      "Step 8450/10000- lr: [1.5636701090909093e-06] - Loss total: 2.5531094074249268, Last rpr Loss: 1.0000017881393433, Last lagvar Loss: 0.8444200158119202\n",
      "Step 8451/10000- lr: [1.562660012121211e-06] - Loss total: 2.553093671798706, Last rpr Loss: 0.9999632835388184, Last lagvar Loss: 0.8444580435752869\n",
      "Step 8452/10000- lr: [1.5616499151515142e-06] - Loss total: 2.553077459335327, Last rpr Loss: 1.0000004768371582, Last lagvar Loss: 0.8444205522537231\n",
      "Step 8453/10000- lr: [1.5606398181818175e-06] - Loss total: 2.5530617237091064, Last rpr Loss: 0.9999660849571228, Last lagvar Loss: 0.8444544672966003\n",
      "Step 8454/10000- lr: [1.5596297212121208e-06] - Loss total: 2.5530452728271484, Last rpr Loss: 0.9999955296516418, Last lagvar Loss: 0.8444247245788574\n",
      "Step 8455/10000- lr: [1.558619624242424e-06] - Loss total: 2.5530295372009277, Last rpr Loss: 0.9999829530715942, Last lagvar Loss: 0.8444369435310364\n",
      "Step 8456/10000- lr: [1.5576095272727273e-06] - Loss total: 2.553013801574707, Last rpr Loss: 0.9999923706054688, Last lagvar Loss: 0.844427227973938\n",
      "Step 8457/10000- lr: [1.556599430303029e-06] - Loss total: 2.552997589111328, Last rpr Loss: 0.9999939799308777, Last lagvar Loss: 0.8444252610206604\n",
      "Step 8458/10000- lr: [1.5555893333333322e-06] - Loss total: 2.5529818534851074, Last rpr Loss: 0.9999892711639404, Last lagvar Loss: 0.8444296717643738\n",
      "Step 8459/10000- lr: [1.5545792363636354e-06] - Loss total: 2.5529658794403076, Last rpr Loss: 1.0000007152557373, Last lagvar Loss: 0.8444180488586426\n",
      "Step 8460/10000- lr: [1.5535691393939387e-06] - Loss total: 2.552949905395508, Last rpr Loss: 0.9999872446060181, Last lagvar Loss: 0.8444312214851379\n",
      "Step 8461/10000- lr: [1.552559042424242e-06] - Loss total: 2.552933931350708, Last rpr Loss: 0.9999998807907104, Last lagvar Loss: 0.8444184064865112\n",
      "Step 8462/10000- lr: [1.5515489454545453e-06] - Loss total: 2.552917957305908, Last rpr Loss: 0.9999849796295166, Last lagvar Loss: 0.8444329500198364\n",
      "Step 8463/10000- lr: [1.5505388484848486e-06] - Loss total: 2.5529022216796875, Last rpr Loss: 1.0000004768371582, Last lagvar Loss: 0.8444173336029053\n",
      "Step 8464/10000- lr: [1.5495287515151518e-06] - Loss total: 2.5528862476348877, Last rpr Loss: 0.9999804496765137, Last lagvar Loss: 0.8444371819496155\n",
      "Step 8465/10000- lr: [1.5485186545454551e-06] - Loss total: 2.552870035171509, Last rpr Loss: 0.999998927116394, Last lagvar Loss: 0.8444185256958008\n",
      "Step 8466/10000- lr: [1.5475085575757567e-06] - Loss total: 2.552854061126709, Last rpr Loss: 0.9999840259552002, Last lagvar Loss: 0.8444332480430603\n",
      "Step 8467/10000- lr: [1.54649846060606e-06] - Loss total: 2.5528383255004883, Last rpr Loss: 0.9999966621398926, Last lagvar Loss: 0.8444204926490784\n",
      "Step 8468/10000- lr: [1.5454883636363632e-06] - Loss total: 2.5528223514556885, Last rpr Loss: 0.9999870657920837, Last lagvar Loss: 0.8444299697875977\n",
      "Step 8469/10000- lr: [1.5444782666666665e-06] - Loss total: 2.5528063774108887, Last rpr Loss: 0.9999934434890747, Last lagvar Loss: 0.8444234132766724\n",
      "Step 8470/10000- lr: [1.5434681696969698e-06] - Loss total: 2.552790403366089, Last rpr Loss: 0.9999909400939941, Last lagvar Loss: 0.8444257974624634\n",
      "Step 8471/10000- lr: [1.542458072727273e-06] - Loss total: 2.552774429321289, Last rpr Loss: 0.9999826550483704, Last lagvar Loss: 0.8444339632987976\n",
      "Step 8472/10000- lr: [1.5414479757575747e-06] - Loss total: 2.55275821685791, Last rpr Loss: 0.9999952912330627, Last lagvar Loss: 0.8444212079048157\n",
      "Step 8473/10000- lr: [1.5404378787878796e-06] - Loss total: 2.5527420043945312, Last rpr Loss: 0.9999824166297913, Last lagvar Loss: 0.8444339632987976\n",
      "Step 8474/10000- lr: [1.5394277818181812e-06] - Loss total: 2.5527260303497314, Last rpr Loss: 1.0000009536743164, Last lagvar Loss: 0.8444153070449829\n",
      "Step 8475/10000- lr: [1.5384176848484845e-06] - Loss total: 2.5527098178863525, Last rpr Loss: 0.9999772310256958, Last lagvar Loss: 0.8444390296936035\n",
      "Step 8476/10000- lr: [1.5374075878787878e-06] - Loss total: 2.5526936054229736, Last rpr Loss: 1.0000028610229492, Last lagvar Loss: 0.8444132208824158\n",
      "Step 8477/10000- lr: [1.536397490909091e-06] - Loss total: 2.5526771545410156, Last rpr Loss: 0.9999821186065674, Last lagvar Loss: 0.8444339036941528\n",
      "Step 8478/10000- lr: [1.5353873939393926e-06] - Loss total: 2.552661180496216, Last rpr Loss: 1.0000001192092896, Last lagvar Loss: 0.8444157838821411\n",
      "Step 8479/10000- lr: [1.5343772969696976e-06] - Loss total: 2.552644968032837, Last rpr Loss: 0.9999901056289673, Last lagvar Loss: 0.8444257378578186\n",
      "Step 8480/10000- lr: [1.5333671999999992e-06] - Loss total: 2.552628755569458, Last rpr Loss: 0.9999924898147583, Last lagvar Loss: 0.8444232940673828\n",
      "Step 8481/10000- lr: [1.5323571030303025e-06] - Loss total: 2.552612543106079, Last rpr Loss: 0.9999932050704956, Last lagvar Loss: 0.8444225192070007\n",
      "Step 8482/10000- lr: [1.5313470060606057e-06] - Loss total: 2.5525963306427, Last rpr Loss: 0.9999843239784241, Last lagvar Loss: 0.8444312810897827\n",
      "Step 8483/10000- lr: [1.530336909090909e-06] - Loss total: 2.5525803565979004, Last rpr Loss: 0.9999988079071045, Last lagvar Loss: 0.8444168567657471\n",
      "Step 8484/10000- lr: [1.5293268121212123e-06] - Loss total: 2.5525639057159424, Last rpr Loss: 0.9999842643737793, Last lagvar Loss: 0.8444312810897827\n",
      "Step 8485/10000- lr: [1.5283167151515156e-06] - Loss total: 2.5525481700897217, Last rpr Loss: 0.9999969005584717, Last lagvar Loss: 0.8444185256958008\n",
      "Step 8486/10000- lr: [1.5273066181818172e-06] - Loss total: 2.5525317192077637, Last rpr Loss: 0.9999833703041077, Last lagvar Loss: 0.8444318771362305\n",
      "Step 8487/10000- lr: [1.5262965212121204e-06] - Loss total: 2.552515745162964, Last rpr Loss: 0.9999954700469971, Last lagvar Loss: 0.8444197773933411\n",
      "Step 8488/10000- lr: [1.5252864242424237e-06] - Loss total: 2.552499532699585, Last rpr Loss: 0.9999810457229614, Last lagvar Loss: 0.8444339036941528\n",
      "Step 8489/10000- lr: [1.524276327272727e-06] - Loss total: 2.552483558654785, Last rpr Loss: 0.9999995231628418, Last lagvar Loss: 0.8444154262542725\n",
      "Step 8490/10000- lr: [1.5232662303030303e-06] - Loss total: 2.5524678230285645, Last rpr Loss: 0.9999803304672241, Last lagvar Loss: 0.844434380531311\n",
      "Step 8491/10000- lr: [1.5222561333333335e-06] - Loss total: 2.5524518489837646, Last rpr Loss: 0.9999899864196777, Last lagvar Loss: 0.8444247245788574\n",
      "Step 8492/10000- lr: [1.5212460363636351e-06] - Loss total: 2.552436113357544, Last rpr Loss: 0.9999862313270569, Last lagvar Loss: 0.8444281816482544\n",
      "Step 8493/10000- lr: [1.52023593939394e-06] - Loss total: 2.5524203777313232, Last rpr Loss: 0.9999828338623047, Last lagvar Loss: 0.844431459903717\n",
      "Step 8494/10000- lr: [1.5192258424242417e-06] - Loss total: 2.5524044036865234, Last rpr Loss: 0.9999890327453613, Last lagvar Loss: 0.8444250822067261\n",
      "Step 8495/10000- lr: [1.518215745454545e-06] - Loss total: 2.5523884296417236, Last rpr Loss: 0.9999837875366211, Last lagvar Loss: 0.844430148601532\n",
      "Step 8496/10000- lr: [1.5172056484848482e-06] - Loss total: 2.552372932434082, Last rpr Loss: 0.9999872446060181, Last lagvar Loss: 0.8444265127182007\n",
      "Step 8497/10000- lr: [1.5161955515151515e-06] - Loss total: 2.5523574352264404, Last rpr Loss: 0.9999821186065674, Last lagvar Loss: 0.8444314002990723\n",
      "Step 8498/10000- lr: [1.515185454545453e-06] - Loss total: 2.5523416996002197, Last rpr Loss: 0.9999802708625793, Last lagvar Loss: 0.844433069229126\n",
      "Step 8499/10000- lr: [1.514175357575758e-06] - Loss total: 2.552326202392578, Last rpr Loss: 0.9999903440475464, Last lagvar Loss: 0.8444228172302246\n",
      "Step 8500/10000- lr: [1.5131652606060596e-06] - Loss total: 2.5523104667663574, Last rpr Loss: 0.999977707862854, Last lagvar Loss: 0.8444352149963379\n",
      "Step 8501/10000- lr: [1.512155163636363e-06] - Loss total: 2.552294969558716, Last rpr Loss: 0.9999921321868896, Last lagvar Loss: 0.8444206714630127\n",
      "Step 8502/10000- lr: [1.5111450666666662e-06] - Loss total: 2.5522797107696533, Last rpr Loss: 0.999974250793457, Last lagvar Loss: 0.8444383144378662\n",
      "Step 8503/10000- lr: [1.5101349696969695e-06] - Loss total: 2.5522642135620117, Last rpr Loss: 0.9999942183494568, Last lagvar Loss: 0.8444182276725769\n",
      "Step 8504/10000- lr: [1.5091248727272728e-06] - Loss total: 2.552248954772949, Last rpr Loss: 0.9999740123748779, Last lagvar Loss: 0.8444381952285767\n",
      "Step 8505/10000- lr: [1.508114775757576e-06] - Loss total: 2.5522336959838867, Last rpr Loss: 0.9999904632568359, Last lagvar Loss: 0.8444216251373291\n",
      "Step 8506/10000- lr: [1.5071046787878776e-06] - Loss total: 2.552218198776245, Last rpr Loss: 0.9999841451644897, Last lagvar Loss: 0.8444277048110962\n",
      "Step 8507/10000- lr: [1.5060945818181809e-06] - Loss total: 2.5522029399871826, Last rpr Loss: 0.9999820590019226, Last lagvar Loss: 0.8444295525550842\n",
      "Step 8508/10000- lr: [1.5050844848484842e-06] - Loss total: 2.55218768119812, Last rpr Loss: 0.9999914765357971, Last lagvar Loss: 0.8444198369979858\n",
      "Step 8509/10000- lr: [1.5040743878787874e-06] - Loss total: 2.5521726608276367, Last rpr Loss: 0.9999758005142212, Last lagvar Loss: 0.8444355130195618\n",
      "Step 8510/10000- lr: [1.5030642909090907e-06] - Loss total: 2.552157163619995, Last rpr Loss: 0.9999962449073792, Last lagvar Loss: 0.8444148302078247\n",
      "Step 8511/10000- lr: [1.502054193939394e-06] - Loss total: 2.5521421432495117, Last rpr Loss: 0.9999719262123108, Last lagvar Loss: 0.8444389700889587\n",
      "Step 8512/10000- lr: [1.5010440969696956e-06] - Loss total: 2.5521271228790283, Last rpr Loss: 0.9999991655349731, Last lagvar Loss: 0.8444115519523621\n",
      "Step 8513/10000- lr: [1.5000340000000006e-06] - Loss total: 2.552111864089966, Last rpr Loss: 0.9999740719795227, Last lagvar Loss: 0.8444363474845886\n",
      "Step 8514/10000- lr: [1.4990239030303021e-06] - Loss total: 2.5520968437194824, Last rpr Loss: 0.9999987483024597, Last lagvar Loss: 0.8444115519523621\n",
      "Step 8515/10000- lr: [1.4980138060606054e-06] - Loss total: 2.552081823348999, Last rpr Loss: 0.9999735951423645, Last lagvar Loss: 0.8444366455078125\n",
      "Step 8516/10000- lr: [1.4970037090909087e-06] - Loss total: 2.5520665645599365, Last rpr Loss: 0.9999977946281433, Last lagvar Loss: 0.8444123268127441\n",
      "Step 8517/10000- lr: [1.495993612121212e-06] - Loss total: 2.552051544189453, Last rpr Loss: 0.999975323677063, Last lagvar Loss: 0.8444344997406006\n",
      "Step 8518/10000- lr: [1.4949835151515152e-06] - Loss total: 2.552036762237549, Last rpr Loss: 0.9999974370002747, Last lagvar Loss: 0.8444123268127441\n",
      "Step 8519/10000- lr: [1.4939734181818185e-06] - Loss total: 2.5520219802856445, Last rpr Loss: 0.9999809861183167, Last lagvar Loss: 0.844428539276123\n",
      "Step 8520/10000- lr: [1.49296332121212e-06] - Loss total: 2.552006959915161, Last rpr Loss: 0.9999913573265076, Last lagvar Loss: 0.8444181084632874\n",
      "Step 8521/10000- lr: [1.4919532242424234e-06] - Loss total: 2.5519917011260986, Last rpr Loss: 0.9999902248382568, Last lagvar Loss: 0.844419002532959\n",
      "Step 8522/10000- lr: [1.4909431272727267e-06] - Loss total: 2.5519769191741943, Last rpr Loss: 0.9999815225601196, Last lagvar Loss: 0.8444275856018066\n",
      "Step 8523/10000- lr: [1.48993303030303e-06] - Loss total: 2.55196213722229, Last rpr Loss: 0.9999887943267822, Last lagvar Loss: 0.8444201350212097\n",
      "Step 8524/10000- lr: [1.4889229333333332e-06] - Loss total: 2.5519473552703857, Last rpr Loss: 0.9999808669090271, Last lagvar Loss: 0.8444279432296753\n",
      "Step 8525/10000- lr: [1.4879128363636365e-06] - Loss total: 2.5519325733184814, Last rpr Loss: 0.9999976754188538, Last lagvar Loss: 0.8444110155105591\n",
      "Step 8526/10000- lr: [1.486902739393938e-06] - Loss total: 2.551917791366577, Last rpr Loss: 0.9999830722808838, Last lagvar Loss: 0.8444254398345947\n",
      "Step 8527/10000- lr: [1.4858926424242413e-06] - Loss total: 2.551903247833252, Last rpr Loss: 0.9999947547912598, Last lagvar Loss: 0.8444137573242188\n",
      "Step 8528/10000- lr: [1.4848825454545446e-06] - Loss total: 2.5518882274627686, Last rpr Loss: 0.9999833106994629, Last lagvar Loss: 0.8444249629974365\n",
      "Step 8529/10000- lr: [1.483872448484848e-06] - Loss total: 2.5518734455108643, Last rpr Loss: 0.9999886155128479, Last lagvar Loss: 0.844419538974762\n",
      "Step 8530/10000- lr: [1.4828623515151512e-06] - Loss total: 2.551858425140381, Last rpr Loss: 0.9999853372573853, Last lagvar Loss: 0.8444226980209351\n",
      "Step 8531/10000- lr: [1.4818522545454545e-06] - Loss total: 2.5518441200256348, Last rpr Loss: 0.9999926090240479, Last lagvar Loss: 0.8444152474403381\n",
      "Step 8532/10000- lr: [1.480842157575756e-06] - Loss total: 2.5518293380737305, Last rpr Loss: 0.9999899864196777, Last lagvar Loss: 0.8444178104400635\n",
      "Step 8533/10000- lr: [1.479832060606061e-06] - Loss total: 2.5518147945404053, Last rpr Loss: 0.9999826550483704, Last lagvar Loss: 0.8444250822067261\n",
      "Step 8534/10000- lr: [1.4788219636363626e-06] - Loss total: 2.551800012588501, Last rpr Loss: 0.9999926090240479, Last lagvar Loss: 0.844415009021759\n",
      "Step 8535/10000- lr: [1.4778118666666659e-06] - Loss total: 2.551785469055176, Last rpr Loss: 0.999983549118042, Last lagvar Loss: 0.8444238901138306\n",
      "Step 8536/10000- lr: [1.4768017696969691e-06] - Loss total: 2.5517706871032715, Last rpr Loss: 0.9999951124191284, Last lagvar Loss: 0.8444122076034546\n",
      "Step 8537/10000- lr: [1.4757916727272724e-06] - Loss total: 2.5517561435699463, Last rpr Loss: 0.9999843239784241, Last lagvar Loss: 0.8444229960441589\n",
      "Step 8538/10000- lr: [1.4747815757575757e-06] - Loss total: 2.551741361618042, Last rpr Loss: 0.9999952912330627, Last lagvar Loss: 0.8444118499755859\n",
      "Step 8539/10000- lr: [1.473771478787879e-06] - Loss total: 2.551726818084717, Last rpr Loss: 0.9999836683273315, Last lagvar Loss: 0.8444234132766724\n",
      "Step 8540/10000- lr: [1.4727613818181806e-06] - Loss total: 2.5517125129699707, Last rpr Loss: 0.9999915957450867, Last lagvar Loss: 0.8444154262542725\n",
      "Step 8541/10000- lr: [1.4717512848484838e-06] - Loss total: 2.5516977310180664, Last rpr Loss: 0.9999870657920837, Last lagvar Loss: 0.8444198369979858\n",
      "Step 8542/10000- lr: [1.4707411878787871e-06] - Loss total: 2.551682949066162, Last rpr Loss: 0.9999917149543762, Last lagvar Loss: 0.8444149494171143\n",
      "Step 8543/10000- lr: [1.4697310909090904e-06] - Loss total: 2.551668882369995, Last rpr Loss: 0.9999932050704956, Last lagvar Loss: 0.8444134593009949\n",
      "Step 8544/10000- lr: [1.4687209939393937e-06] - Loss total: 2.55165433883667, Last rpr Loss: 0.9999831318855286, Last lagvar Loss: 0.8444234132766724\n",
      "Step 8545/10000- lr: [1.467710896969697e-06] - Loss total: 2.5516395568847656, Last rpr Loss: 0.9999969601631165, Last lagvar Loss: 0.8444095849990845\n",
      "Step 8546/10000- lr: [1.4667007999999985e-06] - Loss total: 2.5516254901885986, Last rpr Loss: 0.9999808073043823, Last lagvar Loss: 0.844425618648529\n",
      "Step 8547/10000- lr: [1.4656907030303018e-06] - Loss total: 2.5516107082366943, Last rpr Loss: 1.0000004768371582, Last lagvar Loss: 0.8444059491157532\n",
      "Step 8548/10000- lr: [1.4646806060606068e-06] - Loss total: 2.5515964031219482, Last rpr Loss: 0.9999802112579346, Last lagvar Loss: 0.8444259762763977\n",
      "Step 8549/10000- lr: [1.4636705090909084e-06] - Loss total: 2.551581859588623, Last rpr Loss: 0.9999979734420776, Last lagvar Loss: 0.8444081544876099\n",
      "Step 8550/10000- lr: [1.4626604121212116e-06] - Loss total: 2.551567554473877, Last rpr Loss: 0.999985933303833, Last lagvar Loss: 0.8444200754165649\n",
      "Step 8551/10000- lr: [1.461650315151515e-06] - Loss total: 2.5515530109405518, Last rpr Loss: 0.9999891519546509, Last lagvar Loss: 0.8444167971611023\n",
      "Step 8552/10000- lr: [1.4606402181818182e-06] - Loss total: 2.5515389442443848, Last rpr Loss: 0.9999949932098389, Last lagvar Loss: 0.8444108963012695\n",
      "Step 8553/10000- lr: [1.4596301212121215e-06] - Loss total: 2.5515246391296387, Last rpr Loss: 0.9999868273735046, Last lagvar Loss: 0.8444188237190247\n",
      "Step 8554/10000- lr: [1.4586200242424247e-06] - Loss total: 2.5515100955963135, Last rpr Loss: 0.9999943971633911, Last lagvar Loss: 0.8444111943244934\n",
      "Step 8555/10000- lr: [1.4576099272727263e-06] - Loss total: 2.5514957904815674, Last rpr Loss: 0.999984860420227, Last lagvar Loss: 0.8444206714630127\n",
      "Step 8556/10000- lr: [1.4565998303030296e-06] - Loss total: 2.551481246948242, Last rpr Loss: 0.999995231628418, Last lagvar Loss: 0.8444103002548218\n",
      "Step 8557/10000- lr: [1.4555897333333329e-06] - Loss total: 2.551466941833496, Last rpr Loss: 0.9999894499778748, Last lagvar Loss: 0.8444159626960754\n",
      "Step 8558/10000- lr: [1.4545796363636362e-06] - Loss total: 2.55145263671875, Last rpr Loss: 0.9999892115592957, Last lagvar Loss: 0.8444161415100098\n",
      "Step 8559/10000- lr: [1.4535695393939394e-06] - Loss total: 2.551438570022583, Last rpr Loss: 0.999993085861206, Last lagvar Loss: 0.8444122076034546\n",
      "Step 8560/10000- lr: [1.4525594424242427e-06] - Loss total: 2.551424264907837, Last rpr Loss: 0.9999867677688599, Last lagvar Loss: 0.8444182276725769\n",
      "Step 8561/10000- lr: [1.4515493454545443e-06] - Loss total: 2.551409959793091, Last rpr Loss: 0.9999937415122986, Last lagvar Loss: 0.8444113731384277\n",
      "Step 8562/10000- lr: [1.4505392484848493e-06] - Loss total: 2.551395893096924, Last rpr Loss: 0.999984860420227, Last lagvar Loss: 0.8444200754165649\n",
      "Step 8563/10000- lr: [1.4495291515151509e-06] - Loss total: 2.5513813495635986, Last rpr Loss: 0.9999997615814209, Last lagvar Loss: 0.8444052338600159\n",
      "Step 8564/10000- lr: [1.4485190545454541e-06] - Loss total: 2.5513675212860107, Last rpr Loss: 0.9999822378158569, Last lagvar Loss: 0.8444225788116455\n",
      "Step 8565/10000- lr: [1.4475089575757574e-06] - Loss total: 2.5513532161712646, Last rpr Loss: 1.0000009536743164, Last lagvar Loss: 0.8444037437438965\n",
      "Step 8566/10000- lr: [1.4464988606060607e-06] - Loss total: 2.5513389110565186, Last rpr Loss: 0.9999797344207764, Last lagvar Loss: 0.8444249629974365\n",
      "Step 8567/10000- lr: [1.445488763636364e-06] - Loss total: 2.5513246059417725, Last rpr Loss: 0.9999998211860657, Last lagvar Loss: 0.8444046974182129\n",
      "Step 8568/10000- lr: [1.4444786666666672e-06] - Loss total: 2.5513105392456055, Last rpr Loss: 0.9999845027923584, Last lagvar Loss: 0.8444199562072754\n",
      "Step 8569/10000- lr: [1.4434685696969688e-06] - Loss total: 2.5512962341308594, Last rpr Loss: 0.9999932050704956, Last lagvar Loss: 0.8444110751152039\n",
      "Step 8570/10000- lr: [1.442458472727272e-06] - Loss total: 2.5512821674346924, Last rpr Loss: 0.9999914765357971, Last lagvar Loss: 0.8444129824638367\n",
      "Step 8571/10000- lr: [1.4414483757575754e-06] - Loss total: 2.5512681007385254, Last rpr Loss: 0.9999874830245972, Last lagvar Loss: 0.8444168567657471\n",
      "Step 8572/10000- lr: [1.4404382787878787e-06] - Loss total: 2.5512540340423584, Last rpr Loss: 1.0, Last lagvar Loss: 0.8444041013717651\n",
      "Step 8573/10000- lr: [1.439428181818182e-06] - Loss total: 2.5512399673461914, Last rpr Loss: 0.999979555606842, Last lagvar Loss: 0.8444245457649231\n",
      "Step 8574/10000- lr: [1.4384180848484852e-06] - Loss total: 2.5512256622314453, Last rpr Loss: 1.000002145767212, Last lagvar Loss: 0.8444019556045532\n",
      "Step 8575/10000- lr: [1.4374079878787868e-06] - Loss total: 2.5512115955352783, Last rpr Loss: 0.9999796152114868, Last lagvar Loss: 0.8444243669509888\n",
      "Step 8576/10000- lr: [1.43639789090909e-06] - Loss total: 2.5511977672576904, Last rpr Loss: 1.0000016689300537, Last lagvar Loss: 0.8444021940231323\n",
      "Step 8577/10000- lr: [1.4353877939393933e-06] - Loss total: 2.5511837005615234, Last rpr Loss: 0.9999781847000122, Last lagvar Loss: 0.8444256782531738\n",
      "Step 8578/10000- lr: [1.4343776969696966e-06] - Loss total: 2.5511696338653564, Last rpr Loss: 0.9999996423721313, Last lagvar Loss: 0.8444039821624756\n",
      "Step 8579/10000- lr: [1.4333676e-06] - Loss total: 2.5511553287506104, Last rpr Loss: 0.9999869465827942, Last lagvar Loss: 0.844416618347168\n",
      "Step 8580/10000- lr: [1.4323575030303032e-06] - Loss total: 2.5511410236358643, Last rpr Loss: 0.999993622303009, Last lagvar Loss: 0.8444098234176636\n",
      "Step 8581/10000- lr: [1.4313474060606048e-06] - Loss total: 2.5511274337768555, Last rpr Loss: 0.9999881386756897, Last lagvar Loss: 0.8444153070449829\n",
      "Step 8582/10000- lr: [1.4303373090909097e-06] - Loss total: 2.5511133670806885, Last rpr Loss: 0.9999914169311523, Last lagvar Loss: 0.8444119095802307\n",
      "Step 8583/10000- lr: [1.4293272121212113e-06] - Loss total: 2.5510993003845215, Last rpr Loss: 0.9999955892562866, Last lagvar Loss: 0.8444076776504517\n",
      "Step 8584/10000- lr: [1.4283171151515146e-06] - Loss total: 2.5510854721069336, Last rpr Loss: 0.9999839067459106, Last lagvar Loss: 0.8444193601608276\n",
      "Step 8585/10000- lr: [1.4273070181818179e-06] - Loss total: 2.5510711669921875, Last rpr Loss: 0.9999977946281433, Last lagvar Loss: 0.8444054126739502\n",
      "Step 8586/10000- lr: [1.4262969212121211e-06] - Loss total: 2.5510575771331787, Last rpr Loss: 0.9999847412109375, Last lagvar Loss: 0.8444183468818665\n",
      "Step 8587/10000- lr: [1.4252868242424244e-06] - Loss total: 2.551043748855591, Last rpr Loss: 0.9999937415122986, Last lagvar Loss: 0.8444092869758606\n",
      "Step 8588/10000- lr: [1.4242767272727277e-06] - Loss total: 2.5510294437408447, Last rpr Loss: 0.9999869465827942, Last lagvar Loss: 0.8444159626960754\n",
      "Step 8589/10000- lr: [1.4232666303030293e-06] - Loss total: 2.551015615463257, Last rpr Loss: 0.9999908208847046, Last lagvar Loss: 0.844412088394165\n",
      "Step 8590/10000- lr: [1.4222565333333326e-06] - Loss total: 2.551001787185669, Last rpr Loss: 0.9999957084655762, Last lagvar Loss: 0.8444070816040039\n",
      "Step 8591/10000- lr: [1.4212464363636358e-06] - Loss total: 2.550987720489502, Last rpr Loss: 0.9999872446060181, Last lagvar Loss: 0.8444154858589172\n",
      "Step 8592/10000- lr: [1.4202363393939391e-06] - Loss total: 2.550973653793335, Last rpr Loss: 0.9999949932098389, Last lagvar Loss: 0.8444076180458069\n",
      "Step 8593/10000- lr: [1.4192262424242424e-06] - Loss total: 2.550959825515747, Last rpr Loss: 0.9999836683273315, Last lagvar Loss: 0.844419002532959\n",
      "Step 8594/10000- lr: [1.4182161454545457e-06] - Loss total: 2.5509462356567383, Last rpr Loss: 0.9999940991401672, Last lagvar Loss: 0.844408392906189\n",
      "Step 8595/10000- lr: [1.4172060484848473e-06] - Loss total: 2.5509324073791504, Last rpr Loss: 0.999984085559845, Last lagvar Loss: 0.8444182276725769\n",
      "Step 8596/10000- lr: [1.4161959515151505e-06] - Loss total: 2.5509183406829834, Last rpr Loss: 0.9999997019767761, Last lagvar Loss: 0.8444026112556458\n",
      "Step 8597/10000- lr: [1.4151858545454538e-06] - Loss total: 2.5509045124053955, Last rpr Loss: 0.9999818205833435, Last lagvar Loss: 0.8444204926490784\n",
      "Step 8598/10000- lr: [1.414175757575757e-06] - Loss total: 2.5508909225463867, Last rpr Loss: 0.999997615814209, Last lagvar Loss: 0.8444045782089233\n",
      "Step 8599/10000- lr: [1.4131656606060604e-06] - Loss total: 2.5508768558502197, Last rpr Loss: 0.999983549118042, Last lagvar Loss: 0.8444185256958008\n",
      "Step 8600/10000- lr: [1.4121555636363636e-06] - Loss total: 2.550863027572632, Last rpr Loss: 0.9999922513961792, Last lagvar Loss: 0.8444098234176636\n",
      "Step 8601/10000- lr: [1.4111454666666652e-06] - Loss total: 2.550849199295044, Last rpr Loss: 0.9999927878379822, Last lagvar Loss: 0.844409167766571\n",
      "Step 8602/10000- lr: [1.4101353696969702e-06] - Loss total: 2.550835371017456, Last rpr Loss: 0.9999826550483704, Last lagvar Loss: 0.8444191813468933\n",
      "Step 8603/10000- lr: [1.4091252727272718e-06] - Loss total: 2.550821542739868, Last rpr Loss: 0.9999991655349731, Last lagvar Loss: 0.8444027304649353\n",
      "Step 8604/10000- lr: [1.408115175757575e-06] - Loss total: 2.5508077144622803, Last rpr Loss: 0.9999821186065674, Last lagvar Loss: 0.8444195985794067\n",
      "Step 8605/10000- lr: [1.4071050787878783e-06] - Loss total: 2.5507938861846924, Last rpr Loss: 0.9999927282333374, Last lagvar Loss: 0.8444088697433472\n",
      "Step 8606/10000- lr: [1.4060949818181816e-06] - Loss total: 2.5507802963256836, Last rpr Loss: 0.9999847412109375, Last lagvar Loss: 0.8444167375564575\n",
      "Step 8607/10000- lr: [1.4050848848484849e-06] - Loss total: 2.5507664680480957, Last rpr Loss: 0.9999891519546509, Last lagvar Loss: 0.8444122076034546\n",
      "Step 8608/10000- lr: [1.4040747878787882e-06] - Loss total: 2.550752639770508, Last rpr Loss: 0.9999939799308777, Last lagvar Loss: 0.8444073796272278\n",
      "Step 8609/10000- lr: [1.4030646909090897e-06] - Loss total: 2.550739049911499, Last rpr Loss: 0.9999821186065674, Last lagvar Loss: 0.844419002532959\n",
      "Step 8610/10000- lr: [1.402054593939393e-06] - Loss total: 2.550725221633911, Last rpr Loss: 0.9999963045120239, Last lagvar Loss: 0.8444048166275024\n",
      "Step 8611/10000- lr: [1.4010444969696963e-06] - Loss total: 2.550711154937744, Last rpr Loss: 0.9999786019325256, Last lagvar Loss: 0.8444223999977112\n",
      "Step 8612/10000- lr: [1.4000343999999996e-06] - Loss total: 2.550697088241577, Last rpr Loss: 0.999994158744812, Last lagvar Loss: 0.8444068431854248\n",
      "Step 8613/10000- lr: [1.3990243030303029e-06] - Loss total: 2.5506834983825684, Last rpr Loss: 0.9999828338623047, Last lagvar Loss: 0.844417929649353\n",
      "Step 8614/10000- lr: [1.3980142060606061e-06] - Loss total: 2.5506699085235596, Last rpr Loss: 0.9999871253967285, Last lagvar Loss: 0.8444136381149292\n",
      "Step 8615/10000- lr: [1.3970041090909077e-06] - Loss total: 2.5506558418273926, Last rpr Loss: 0.9999911189079285, Last lagvar Loss: 0.8444095849990845\n",
      "Step 8616/10000- lr: [1.3959940121212127e-06] - Loss total: 2.5506420135498047, Last rpr Loss: 0.9999762773513794, Last lagvar Loss: 0.8444242477416992\n",
      "Step 8617/10000- lr: [1.3949839151515143e-06] - Loss total: 2.550628185272217, Last rpr Loss: 0.9999961853027344, Last lagvar Loss: 0.8444041609764099\n",
      "Step 8618/10000- lr: [1.3939738181818175e-06] - Loss total: 2.550614356994629, Last rpr Loss: 0.9999713897705078, Last lagvar Loss: 0.8444288372993469\n",
      "Step 8619/10000- lr: [1.3929637212121208e-06] - Loss total: 2.550600528717041, Last rpr Loss: 0.999995231628418, Last lagvar Loss: 0.844404935836792\n",
      "Step 8620/10000- lr: [1.391953624242424e-06] - Loss total: 2.550586462020874, Last rpr Loss: 0.999975860118866, Last lagvar Loss: 0.8444241285324097\n",
      "Step 8621/10000- lr: [1.3909435272727257e-06] - Loss total: 2.550571918487549, Last rpr Loss: 0.9999847412109375, Last lagvar Loss: 0.8444150686264038\n",
      "Step 8622/10000- lr: [1.3899334303030307e-06] - Loss total: 2.550557851791382, Last rpr Loss: 0.9999842643737793, Last lagvar Loss: 0.8444153070449829\n",
      "Step 8623/10000- lr: [1.3889233333333322e-06] - Loss total: 2.550543785095215, Last rpr Loss: 0.9999739527702332, Last lagvar Loss: 0.8444254398345947\n",
      "Step 8624/10000- lr: [1.3879132363636355e-06] - Loss total: 2.5505292415618896, Last rpr Loss: 0.9999863505363464, Last lagvar Loss: 0.8444128036499023\n",
      "Step 8625/10000- lr: [1.3869031393939388e-06] - Loss total: 2.5505146980285645, Last rpr Loss: 0.9999685287475586, Last lagvar Loss: 0.8444303274154663\n",
      "Step 8626/10000- lr: [1.385893042424242e-06] - Loss total: 2.5505001544952393, Last rpr Loss: 0.9999879598617554, Last lagvar Loss: 0.8444103598594666\n",
      "Step 8627/10000- lr: [1.3848829454545453e-06] - Loss total: 2.5504848957061768, Last rpr Loss: 0.9999644756317139, Last lagvar Loss: 0.8444332480430603\n",
      "Step 8628/10000- lr: [1.3838728484848486e-06] - Loss total: 2.5504705905914307, Last rpr Loss: 0.9999790787696838, Last lagvar Loss: 0.844417929649353\n",
      "Step 8629/10000- lr: [1.3828627515151502e-06] - Loss total: 2.550455093383789, Last rpr Loss: 0.9999722242355347, Last lagvar Loss: 0.8444238305091858\n",
      "Step 8630/10000- lr: [1.3818526545454535e-06] - Loss total: 2.5504403114318848, Last rpr Loss: 0.9999722242355347, Last lagvar Loss: 0.8444223999977112\n",
      "Step 8631/10000- lr: [1.3808425575757568e-06] - Loss total: 2.5504250526428223, Last rpr Loss: 0.9999729990959167, Last lagvar Loss: 0.8444197177886963\n",
      "Step 8632/10000- lr: [1.37983246060606e-06] - Loss total: 2.5504097938537598, Last rpr Loss: 0.9999656677246094, Last lagvar Loss: 0.8444244861602783\n",
      "Step 8633/10000- lr: [1.3788223636363633e-06] - Loss total: 2.5503947734832764, Last rpr Loss: 0.9999724626541138, Last lagvar Loss: 0.8444142937660217\n",
      "Step 8634/10000- lr: [1.3778122666666666e-06] - Loss total: 2.5503792762756348, Last rpr Loss: 0.9999558329582214, Last lagvar Loss: 0.8444262742996216\n",
      "Step 8635/10000- lr: [1.3768021696969699e-06] - Loss total: 2.550363779067993, Last rpr Loss: 0.9999656081199646, Last lagvar Loss: 0.8444101810455322\n",
      "Step 8636/10000- lr: [1.3757920727272731e-06] - Loss total: 2.5503485202789307, Last rpr Loss: 0.9999556541442871, Last lagvar Loss: 0.8444117903709412\n",
      "Step 8637/10000- lr: [1.3747819757575764e-06] - Loss total: 2.5503323078155518, Last rpr Loss: 0.9999473690986633, Last lagvar Loss: 0.8444092273712158\n",
      "Step 8638/10000- lr: [1.373771878787878e-06] - Loss total: 2.55031681060791, Last rpr Loss: 0.9999474883079529, Last lagvar Loss: 0.8443949818611145\n",
      "Step 8639/10000- lr: [1.3727617818181813e-06] - Loss total: 2.550300359725952, Last rpr Loss: 0.9999333024024963, Last lagvar Loss: 0.8443912267684937\n",
      "Step 8640/10000- lr: [1.3717516848484846e-06] - Loss total: 2.550283432006836, Last rpr Loss: 0.9999397397041321, Last lagvar Loss: 0.844362735748291\n",
      "Step 8641/10000- lr: [1.3707415878787878e-06] - Loss total: 2.5502662658691406, Last rpr Loss: 0.9999268054962158, Last lagvar Loss: 0.8443496227264404\n",
      "Step 8642/10000- lr: [1.3697314909090911e-06] - Loss total: 2.5502490997314453, Last rpr Loss: 0.9999325275421143, Last lagvar Loss: 0.8443155288696289\n",
      "Step 8643/10000- lr: [1.3687213939393944e-06] - Loss total: 2.5502312183380127, Last rpr Loss: 0.9999380707740784, Last lagvar Loss: 0.8442807197570801\n",
      "Step 8644/10000- lr: [1.367711296969696e-06] - Loss total: 2.5502142906188965, Last rpr Loss: 0.9999490976333618, Last lagvar Loss: 0.8442413806915283\n",
      "Step 8645/10000- lr: [1.3667011999999992e-06] - Loss total: 2.550197124481201, Last rpr Loss: 0.9999721050262451, Last lagvar Loss: 0.8441925644874573\n",
      "Step 8646/10000- lr: [1.3656911030303025e-06] - Loss total: 2.550180196762085, Last rpr Loss: 0.9999791979789734, Last lagvar Loss: 0.8441619873046875\n",
      "Step 8647/10000- lr: [1.3646810060606058e-06] - Loss total: 2.550163745880127, Last rpr Loss: 0.9999963045120239, Last lagvar Loss: 0.8441239595413208\n",
      "Step 8648/10000- lr: [1.363670909090909e-06] - Loss total: 2.55014705657959, Last rpr Loss: 0.999993085861206, Last lagvar Loss: 0.8441083431243896\n",
      "Step 8649/10000- lr: [1.3626608121212124e-06] - Loss total: 2.550130844116211, Last rpr Loss: 0.9999970197677612, Last lagvar Loss: 0.844087541103363\n",
      "Step 8650/10000- lr: [1.361650715151514e-06] - Loss total: 2.550114631652832, Last rpr Loss: 0.9999846816062927, Last lagvar Loss: 0.8440845012664795\n",
      "Step 8651/10000- lr: [1.360640618181819e-06] - Loss total: 2.550098180770874, Last rpr Loss: 0.9999788999557495, Last lagvar Loss: 0.8440762758255005\n",
      "Step 8652/10000- lr: [1.3596305212121205e-06] - Loss total: 2.550082206726074, Last rpr Loss: 0.9999738335609436, Last lagvar Loss: 0.8440686464309692\n",
      "Step 8653/10000- lr: [1.3586204242424238e-06] - Loss total: 2.550065755844116, Last rpr Loss: 0.9999550580978394, Last lagvar Loss: 0.8440760374069214\n",
      "Step 8654/10000- lr: [1.357610327272727e-06] - Loss total: 2.5500497817993164, Last rpr Loss: 0.9999646544456482, Last lagvar Loss: 0.8440560102462769\n",
      "Step 8655/10000- lr: [1.3566002303030303e-06] - Loss total: 2.5500333309173584, Last rpr Loss: 0.9999369978904724, Last lagvar Loss: 0.8440743088722229\n",
      "Step 8656/10000- lr: [1.3555901333333336e-06] - Loss total: 2.5500171184539795, Last rpr Loss: 0.9999523162841797, Last lagvar Loss: 0.8440505266189575\n",
      "Step 8657/10000- lr: [1.3545800363636369e-06] - Loss total: 2.5500004291534424, Last rpr Loss: 0.99993896484375, Last lagvar Loss: 0.8440561890602112\n",
      "Step 8658/10000- lr: [1.3535699393939385e-06] - Loss total: 2.5499839782714844, Last rpr Loss: 0.999942421913147, Last lagvar Loss: 0.8440459370613098\n",
      "Step 8659/10000- lr: [1.3525598424242417e-06] - Loss total: 2.549967050552368, Last rpr Loss: 0.9999486804008484, Last lagvar Loss: 0.8440336585044861\n",
      "Step 8660/10000- lr: [1.351549745454545e-06] - Loss total: 2.549949884414673, Last rpr Loss: 0.9999358654022217, Last lagvar Loss: 0.8440411686897278\n",
      "Step 8661/10000- lr: [1.3505396484848483e-06] - Loss total: 2.5499327182769775, Last rpr Loss: 0.9999634623527527, Last lagvar Loss: 0.8440089225769043\n",
      "Step 8662/10000- lr: [1.3495295515151516e-06] - Loss total: 2.549915313720703, Last rpr Loss: 0.9999495148658752, Last lagvar Loss: 0.8440188765525818\n",
      "Step 8663/10000- lr: [1.3485194545454548e-06] - Loss total: 2.5498976707458496, Last rpr Loss: 0.9999797940254211, Last lagvar Loss: 0.8439850807189941\n",
      "Step 8664/10000- lr: [1.3475093575757564e-06] - Loss total: 2.549880266189575, Last rpr Loss: 0.9999709129333496, Last lagvar Loss: 0.8439909815788269\n",
      "Step 8665/10000- lr: [1.3464992606060597e-06] - Loss total: 2.549862861633301, Last rpr Loss: 0.9999829530715942, Last lagvar Loss: 0.8439762592315674\n",
      "Step 8666/10000- lr: [1.345489163636363e-06] - Loss total: 2.5498452186584473, Last rpr Loss: 0.9999866485595703, Last lagvar Loss: 0.8439702391624451\n",
      "Step 8667/10000- lr: [1.3444790666666663e-06] - Loss total: 2.549828052520752, Last rpr Loss: 0.9999803304672241, Last lagvar Loss: 0.8439746499061584\n",
      "Step 8668/10000- lr: [1.3434689696969695e-06] - Loss total: 2.5498111248016357, Last rpr Loss: 1.0000078678131104, Last lagvar Loss: 0.843945324420929\n",
      "Step 8669/10000- lr: [1.3424588727272728e-06] - Loss total: 2.5497944355010986, Last rpr Loss: 0.9999915361404419, Last lagvar Loss: 0.843960165977478\n",
      "Step 8670/10000- lr: [1.3414487757575744e-06] - Loss total: 2.5497782230377197, Last rpr Loss: 1.00002121925354, Last lagvar Loss: 0.84392911195755\n",
      "Step 8671/10000- lr: [1.3404386787878794e-06] - Loss total: 2.549762010574341, Last rpr Loss: 1.0000033378601074, Last lagvar Loss: 0.8439458012580872\n",
      "Step 8672/10000- lr: [1.339428581818181e-06] - Loss total: 2.549746036529541, Last rpr Loss: 1.000017762184143, Last lagvar Loss: 0.8439304232597351\n",
      "Step 8673/10000- lr: [1.3384184848484842e-06] - Loss total: 2.5497303009033203, Last rpr Loss: 1.0000050067901611, Last lagvar Loss: 0.8439422845840454\n",
      "Step 8674/10000- lr: [1.3374083878787875e-06] - Loss total: 2.5497145652770996, Last rpr Loss: 0.9999938011169434, Last lagvar Loss: 0.8439527750015259\n",
      "Step 8675/10000- lr: [1.3363982909090908e-06] - Loss total: 2.549699068069458, Last rpr Loss: 1.0000059604644775, Last lagvar Loss: 0.8439398407936096\n",
      "Step 8676/10000- lr: [1.335388193939394e-06] - Loss total: 2.5496838092803955, Last rpr Loss: 0.9999869465827942, Last lagvar Loss: 0.84395831823349\n",
      "Step 8677/10000- lr: [1.3343780969696973e-06] - Loss total: 2.549668312072754, Last rpr Loss: 0.9999977946281433, Last lagvar Loss: 0.8439469337463379\n",
      "Step 8678/10000- lr: [1.333367999999999e-06] - Loss total: 2.5496532917022705, Last rpr Loss: 0.9999932050704956, Last lagvar Loss: 0.8439510464668274\n",
      "Step 8679/10000- lr: [1.3323579030303022e-06] - Loss total: 2.549638032913208, Last rpr Loss: 0.9999894499778748, Last lagvar Loss: 0.84395432472229\n",
      "Step 8680/10000- lr: [1.3313478060606055e-06] - Loss total: 2.5496225357055664, Last rpr Loss: 0.9999973177909851, Last lagvar Loss: 0.8439462184906006\n",
      "Step 8681/10000- lr: [1.3303377090909088e-06] - Loss total: 2.549607515335083, Last rpr Loss: 0.9999754428863525, Last lagvar Loss: 0.8439677953720093\n",
      "Step 8682/10000- lr: [1.329327612121212e-06] - Loss total: 2.5495922565460205, Last rpr Loss: 0.9999960660934448, Last lagvar Loss: 0.8439469933509827\n",
      "Step 8683/10000- lr: [1.3283175151515153e-06] - Loss total: 2.549576997756958, Last rpr Loss: 0.9999699592590332, Last lagvar Loss: 0.8439728617668152\n",
      "Step 8684/10000- lr: [1.3273074181818169e-06] - Loss total: 2.5495622158050537, Last rpr Loss: 0.9999829530715942, Last lagvar Loss: 0.8439598083496094\n",
      "Step 8685/10000- lr: [1.3262973212121219e-06] - Loss total: 2.5495471954345703, Last rpr Loss: 0.9999780654907227, Last lagvar Loss: 0.8439645171165466\n",
      "Step 8686/10000- lr: [1.3252872242424234e-06] - Loss total: 2.549532175064087, Last rpr Loss: 0.9999792575836182, Last lagvar Loss: 0.8439632654190063\n",
      "Step 8687/10000- lr: [1.3242771272727267e-06] - Loss total: 2.5495173931121826, Last rpr Loss: 0.999988317489624, Last lagvar Loss: 0.8439540863037109\n",
      "Step 8688/10000- lr: [1.32326703030303e-06] - Loss total: 2.5495026111602783, Last rpr Loss: 0.9999799728393555, Last lagvar Loss: 0.8439623713493347\n",
      "Step 8689/10000- lr: [1.3222569333333333e-06] - Loss total: 2.549487352371216, Last rpr Loss: 0.999994158744812, Last lagvar Loss: 0.8439481258392334\n",
      "Step 8690/10000- lr: [1.3212468363636349e-06] - Loss total: 2.5494723320007324, Last rpr Loss: 0.9999804496765137, Last lagvar Loss: 0.8439617156982422\n",
      "Step 8691/10000- lr: [1.3202367393939398e-06] - Loss total: 2.5494577884674072, Last rpr Loss: 0.9999971985816956, Last lagvar Loss: 0.8439449667930603\n",
      "Step 8692/10000- lr: [1.3192266424242414e-06] - Loss total: 2.549443244934082, Last rpr Loss: 0.999995768070221, Last lagvar Loss: 0.8439463376998901\n",
      "Step 8693/10000- lr: [1.3182165454545447e-06] - Loss total: 2.5494282245635986, Last rpr Loss: 0.999997615814209, Last lagvar Loss: 0.8439444899559021\n",
      "Step 8694/10000- lr: [1.317206448484848e-06] - Loss total: 2.5494134426116943, Last rpr Loss: 1.0000072717666626, Last lagvar Loss: 0.8439345359802246\n",
      "Step 8695/10000- lr: [1.3161963515151512e-06] - Loss total: 2.54939866065979, Last rpr Loss: 0.9999949336051941, Last lagvar Loss: 0.8439468145370483\n",
      "Step 8696/10000- lr: [1.3151862545454545e-06] - Loss total: 2.549384355545044, Last rpr Loss: 1.0000088214874268, Last lagvar Loss: 0.8439328670501709\n",
      "Step 8697/10000- lr: [1.3141761575757578e-06] - Loss total: 2.5493695735931396, Last rpr Loss: 0.9999920129776001, Last lagvar Loss: 0.8439494967460632\n",
      "Step 8698/10000- lr: [1.3131660606060594e-06] - Loss total: 2.5493550300598145, Last rpr Loss: 1.0000067949295044, Last lagvar Loss: 0.8439346551895142\n",
      "Step 8699/10000- lr: [1.3121559636363627e-06] - Loss total: 2.5493407249450684, Last rpr Loss: 0.9999964833259583, Last lagvar Loss: 0.8439446687698364\n",
      "Step 8700/10000- lr: [1.311145866666666e-06] - Loss total: 2.5493264198303223, Last rpr Loss: 0.9999949932098389, Last lagvar Loss: 0.8439459800720215\n",
      "Step 8701/10000- lr: [1.3101357696969692e-06] - Loss total: 2.549311876296997, Last rpr Loss: 1.0000022649765015, Last lagvar Loss: 0.8439385294914246\n",
      "Step 8702/10000- lr: [1.3091256727272725e-06] - Loss total: 2.549297571182251, Last rpr Loss: 0.9999876022338867, Last lagvar Loss: 0.8439528942108154\n",
      "Step 8703/10000- lr: [1.3081155757575758e-06] - Loss total: 2.549283266067505, Last rpr Loss: 1.000006079673767, Last lagvar Loss: 0.8439342975616455\n",
      "Step 8704/10000- lr: [1.3071054787878773e-06] - Loss total: 2.5492687225341797, Last rpr Loss: 0.9999892711639404, Last lagvar Loss: 0.8439507484436035\n",
      "Step 8705/10000- lr: [1.3060953818181823e-06] - Loss total: 2.5492546558380127, Last rpr Loss: 1.0000019073486328, Last lagvar Loss: 0.843937873840332\n",
      "Step 8706/10000- lr: [1.305085284848484e-06] - Loss total: 2.549240827560425, Last rpr Loss: 0.9999943971633911, Last lagvar Loss: 0.8439451456069946\n",
      "Step 8707/10000- lr: [1.3040751878787872e-06] - Loss total: 2.5492260456085205, Last rpr Loss: 0.9999856948852539, Last lagvar Loss: 0.8439534902572632\n",
      "Step 8708/10000- lr: [1.3030650909090905e-06] - Loss total: 2.5492122173309326, Last rpr Loss: 1.000004529953003, Last lagvar Loss: 0.8439344167709351\n",
      "Step 8709/10000- lr: [1.3020549939393937e-06] - Loss total: 2.5491983890533447, Last rpr Loss: 0.9999843835830688, Last lagvar Loss: 0.8439542055130005\n",
      "Step 8710/10000- lr: [1.3010448969696953e-06] - Loss total: 2.5491840839385986, Last rpr Loss: 1.0000046491622925, Last lagvar Loss: 0.843933641910553\n",
      "Step 8711/10000- lr: [1.3000348000000003e-06] - Loss total: 2.5491700172424316, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.8439415693283081\n",
      "Step 8712/10000- lr: [1.2990247030303019e-06] - Loss total: 2.549156427383423, Last rpr Loss: 1.000002145767212, Last lagvar Loss: 0.8439353704452515\n",
      "Step 8713/10000- lr: [1.2980146060606051e-06] - Loss total: 2.5491421222686768, Last rpr Loss: 1.0000019073486328, Last lagvar Loss: 0.8439353704452515\n",
      "Step 8714/10000- lr: [1.2970045090909084e-06] - Loss total: 2.549128293991089, Last rpr Loss: 0.9999935030937195, Last lagvar Loss: 0.8439434766769409\n",
      "Step 8715/10000- lr: [1.2959944121212117e-06] - Loss total: 2.549114465713501, Last rpr Loss: 1.0000046491622925, Last lagvar Loss: 0.8439319729804993\n",
      "Step 8716/10000- lr: [1.294984315151515e-06] - Loss total: 2.549100637435913, Last rpr Loss: 0.9999894499778748, Last lagvar Loss: 0.8439468145370483\n",
      "Step 8717/10000- lr: [1.2939742181818183e-06] - Loss total: 2.549086809158325, Last rpr Loss: 0.9999988079071045, Last lagvar Loss: 0.8439370393753052\n",
      "Step 8718/10000- lr: [1.2929641212121215e-06] - Loss total: 2.5490734577178955, Last rpr Loss: 0.9999986886978149, Last lagvar Loss: 0.8439369201660156\n",
      "Step 8719/10000- lr: [1.2919540242424231e-06] - Loss total: 2.5490593910217285, Last rpr Loss: 0.9999953508377075, Last lagvar Loss: 0.8439398407936096\n",
      "Step 8720/10000- lr: [1.290943927272728e-06] - Loss total: 2.5490458011627197, Last rpr Loss: 1.0000017881393433, Last lagvar Loss: 0.8439331650733948\n",
      "Step 8721/10000- lr: [1.2899338303030297e-06] - Loss total: 2.549032211303711, Last rpr Loss: 0.9999918937683105, Last lagvar Loss: 0.8439426422119141\n",
      "Step 8722/10000- lr: [1.288923733333333e-06] - Loss total: 2.549018383026123, Last rpr Loss: 1.0000005960464478, Last lagvar Loss: 0.843933641910553\n",
      "Step 8723/10000- lr: [1.2879136363636362e-06] - Loss total: 2.5490047931671143, Last rpr Loss: 0.9999994039535522, Last lagvar Loss: 0.8439344763755798\n",
      "Step 8724/10000- lr: [1.2869035393939395e-06] - Loss total: 2.5489914417266846, Last rpr Loss: 0.9999942779541016, Last lagvar Loss: 0.8439393043518066\n",
      "Step 8725/10000- lr: [1.2858934424242428e-06] - Loss total: 2.548977851867676, Last rpr Loss: 1.0000019073486328, Last lagvar Loss: 0.8439313173294067\n",
      "Step 8726/10000- lr: [1.284883345454546e-06] - Loss total: 2.548964262008667, Last rpr Loss: 0.9999932646751404, Last lagvar Loss: 0.8439396023750305\n",
      "Step 8727/10000- lr: [1.2838732484848476e-06] - Loss total: 2.5489509105682373, Last rpr Loss: 1.0000035762786865, Last lagvar Loss: 0.8439290523529053\n",
      "Step 8728/10000- lr: [1.282863151515151e-06] - Loss total: 2.5489370822906494, Last rpr Loss: 0.9999940395355225, Last lagvar Loss: 0.8439382314682007\n",
      "Step 8729/10000- lr: [1.2818530545454542e-06] - Loss total: 2.5489237308502197, Last rpr Loss: 0.9999995827674866, Last lagvar Loss: 0.8439323902130127\n",
      "Step 8730/10000- lr: [1.2808429575757575e-06] - Loss total: 2.548910140991211, Last rpr Loss: 1.0000014305114746, Last lagvar Loss: 0.8439301252365112\n",
      "Step 8731/10000- lr: [1.2798328606060607e-06] - Loss total: 2.5488967895507812, Last rpr Loss: 0.9999977350234985, Last lagvar Loss: 0.8439335823059082\n",
      "Step 8732/10000- lr: [1.278822763636364e-06] - Loss total: 2.5488834381103516, Last rpr Loss: 0.9999986886978149, Last lagvar Loss: 0.8439323306083679\n",
      "Step 8733/10000- lr: [1.2778126666666656e-06] - Loss total: 2.5488698482513428, Last rpr Loss: 0.9999985694885254, Last lagvar Loss: 0.8439321517944336\n",
      "Step 8734/10000- lr: [1.2768025696969706e-06] - Loss total: 2.548856735229492, Last rpr Loss: 0.999999463558197, Last lagvar Loss: 0.8439309597015381\n",
      "Step 8735/10000- lr: [1.2757924727272722e-06] - Loss total: 2.5488433837890625, Last rpr Loss: 1.0000014305114746, Last lagvar Loss: 0.8439286947250366\n",
      "Step 8736/10000- lr: [1.2747823757575754e-06] - Loss total: 2.548830032348633, Last rpr Loss: 0.999997079372406, Last lagvar Loss: 0.8439326286315918\n",
      "Step 8737/10000- lr: [1.2737722787878787e-06] - Loss total: 2.548816680908203, Last rpr Loss: 0.9999964833259583, Last lagvar Loss: 0.8439329862594604\n",
      "Step 8738/10000- lr: [1.272762181818182e-06] - Loss total: 2.5488035678863525, Last rpr Loss: 0.9999990463256836, Last lagvar Loss: 0.8439300656318665\n",
      "Step 8739/10000- lr: [1.2717520848484836e-06] - Loss total: 2.548790454864502, Last rpr Loss: 0.9999967813491821, Last lagvar Loss: 0.8439319729804993\n",
      "Step 8740/10000- lr: [1.2707419878787885e-06] - Loss total: 2.548776626586914, Last rpr Loss: 0.9999970197677612, Last lagvar Loss: 0.8439313173294067\n",
      "Step 8741/10000- lr: [1.2697318909090901e-06] - Loss total: 2.5487637519836426, Last rpr Loss: 1.0000009536743164, Last lagvar Loss: 0.8439271450042725\n",
      "Step 8742/10000- lr: [1.2687217939393934e-06] - Loss total: 2.548750400543213, Last rpr Loss: 0.9999971985816956, Last lagvar Loss: 0.8439304828643799\n",
      "Step 8743/10000- lr: [1.2677116969696967e-06] - Loss total: 2.548736810684204, Last rpr Loss: 1.0000007152557373, Last lagvar Loss: 0.8439265489578247\n",
      "Step 8744/10000- lr: [1.2667016e-06] - Loss total: 2.5487239360809326, Last rpr Loss: 0.9999976754188538, Last lagvar Loss: 0.8439291715621948\n",
      "Step 8745/10000- lr: [1.2656915030303032e-06] - Loss total: 2.548710346221924, Last rpr Loss: 0.9999961853027344, Last lagvar Loss: 0.8439302444458008\n",
      "Step 8746/10000- lr: [1.2646814060606065e-06] - Loss total: 2.548696994781494, Last rpr Loss: 1.0000072717666626, Last lagvar Loss: 0.8439186215400696\n",
      "Step 8747/10000- lr: [1.263671309090908e-06] - Loss total: 2.5486841201782227, Last rpr Loss: 0.9999937415122986, Last lagvar Loss: 0.8439317345619202\n",
      "Step 8748/10000- lr: [1.2626612121212114e-06] - Loss total: 2.548670768737793, Last rpr Loss: 1.0000054836273193, Last lagvar Loss: 0.8439194560050964\n",
      "Step 8749/10000- lr: [1.2616511151515147e-06] - Loss total: 2.5486574172973633, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8439286351203918\n",
      "Step 8750/10000- lr: [1.260641018181818e-06] - Loss total: 2.5486440658569336, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8439279794692993\n",
      "Step 8751/10000- lr: [1.2596309212121212e-06] - Loss total: 2.548630714416504, Last rpr Loss: 1.0000035762786865, Last lagvar Loss: 0.843919575214386\n",
      "Step 8752/10000- lr: [1.2586208242424245e-06] - Loss total: 2.5486176013946533, Last rpr Loss: 0.999995768070221, Last lagvar Loss: 0.8439266681671143\n",
      "Step 8753/10000- lr: [1.257610727272726e-06] - Loss total: 2.5486042499542236, Last rpr Loss: 1.0000052452087402, Last lagvar Loss: 0.8439165353775024\n",
      "Step 8754/10000- lr: [1.256600630303031e-06] - Loss total: 2.548590898513794, Last rpr Loss: 0.9999948143959045, Last lagvar Loss: 0.8439260721206665\n",
      "Step 8755/10000- lr: [1.2555905333333326e-06] - Loss total: 2.5485775470733643, Last rpr Loss: 0.9999990463256836, Last lagvar Loss: 0.8439210057258606\n",
      "Step 8756/10000- lr: [1.254580436363636e-06] - Loss total: 2.5485644340515137, Last rpr Loss: 0.9999977350234985, Last lagvar Loss: 0.8439212441444397\n",
      "Step 8757/10000- lr: [1.2535703393939392e-06] - Loss total: 2.548551082611084, Last rpr Loss: 1.000001072883606, Last lagvar Loss: 0.8439168930053711\n",
      "Step 8758/10000- lr: [1.2525602424242425e-06] - Loss total: 2.5485377311706543, Last rpr Loss: 0.9999988079071045, Last lagvar Loss: 0.8439179062843323\n",
      "Step 8759/10000- lr: [1.251550145454544e-06] - Loss total: 2.5485246181488037, Last rpr Loss: 0.9999985694885254, Last lagvar Loss: 0.8439167737960815\n",
      "Step 8760/10000- lr: [1.250540048484849e-06] - Loss total: 2.548511266708374, Last rpr Loss: 0.9999971389770508, Last lagvar Loss: 0.8439167141914368\n",
      "Step 8761/10000- lr: [1.2495299515151506e-06] - Loss total: 2.5484976768493652, Last rpr Loss: 0.9999950528144836, Last lagvar Loss: 0.8439170122146606\n",
      "Step 8762/10000- lr: [1.2485198545454539e-06] - Loss total: 2.5484840869903564, Last rpr Loss: 0.9999986886978149, Last lagvar Loss: 0.8439112901687622\n",
      "Step 8763/10000- lr: [1.2475097575757571e-06] - Loss total: 2.5484707355499268, Last rpr Loss: 0.9999992251396179, Last lagvar Loss: 0.8439086675643921\n",
      "Step 8764/10000- lr: [1.2464996606060604e-06] - Loss total: 2.548457384109497, Last rpr Loss: 0.9999960064888, Last lagvar Loss: 0.8439093232154846\n",
      "Step 8765/10000- lr: [1.2454895636363637e-06] - Loss total: 2.5484437942504883, Last rpr Loss: 0.9999955296516418, Last lagvar Loss: 0.8439068794250488\n",
      "Step 8766/10000- lr: [1.244479466666667e-06] - Loss total: 2.5484297275543213, Last rpr Loss: 0.999991774559021, Last lagvar Loss: 0.8439072370529175\n",
      "Step 8767/10000- lr: [1.2434693696969686e-06] - Loss total: 2.5484161376953125, Last rpr Loss: 0.9999940991401672, Last lagvar Loss: 0.8439009189605713\n",
      "Step 8768/10000- lr: [1.2424592727272718e-06] - Loss total: 2.5484025478363037, Last rpr Loss: 0.9999935626983643, Last lagvar Loss: 0.8438971042633057\n",
      "Step 8769/10000- lr: [1.2414491757575751e-06] - Loss total: 2.5483884811401367, Last rpr Loss: 0.9999918341636658, Last lagvar Loss: 0.8438935279846191\n",
      "Step 8770/10000- lr: [1.2404390787878784e-06] - Loss total: 2.5483744144439697, Last rpr Loss: 0.9999897480010986, Last lagvar Loss: 0.843889594078064\n",
      "Step 8771/10000- lr: [1.2394289818181817e-06] - Loss total: 2.5483598709106445, Last rpr Loss: 0.9999873042106628, Last lagvar Loss: 0.8438851237297058\n",
      "Step 8772/10000- lr: [1.238418884848485e-06] - Loss total: 2.5483458042144775, Last rpr Loss: 0.9999895691871643, Last lagvar Loss: 0.8438750505447388\n",
      "Step 8773/10000- lr: [1.2374087878787865e-06] - Loss total: 2.5483314990997314, Last rpr Loss: 0.9999866485595703, Last lagvar Loss: 0.8438692092895508\n",
      "Step 8774/10000- lr: [1.2363986909090915e-06] - Loss total: 2.548316717147827, Last rpr Loss: 0.9999839067459106, Last lagvar Loss: 0.8438622951507568\n",
      "Step 8775/10000- lr: [1.235388593939393e-06] - Loss total: 2.548302173614502, Last rpr Loss: 0.999987006187439, Last lagvar Loss: 0.8438485860824585\n",
      "Step 8776/10000- lr: [1.2343784969696964e-06] - Loss total: 2.5482873916625977, Last rpr Loss: 0.9999773502349854, Last lagvar Loss: 0.8438470363616943\n",
      "Step 8777/10000- lr: [1.2333683999999996e-06] - Loss total: 2.5482723712921143, Last rpr Loss: 0.9999815225601196, Last lagvar Loss: 0.8438310623168945\n",
      "Step 8778/10000- lr: [1.232358303030303e-06] - Loss total: 2.5482571125030518, Last rpr Loss: 0.9999799728393555, Last lagvar Loss: 0.8438207507133484\n",
      "Step 8779/10000- lr: [1.2313482060606045e-06] - Loss total: 2.5482425689697266, Last rpr Loss: 0.9999810457229614, Last lagvar Loss: 0.8438078761100769\n",
      "Step 8780/10000- lr: [1.2303381090909095e-06] - Loss total: 2.548227310180664, Last rpr Loss: 0.9999859929084778, Last lagvar Loss: 0.8437913060188293\n",
      "Step 8781/10000- lr: [1.229328012121211e-06] - Loss total: 2.5482125282287598, Last rpr Loss: 0.9999809265136719, Last lagvar Loss: 0.8437850475311279\n",
      "Step 8782/10000- lr: [1.2283179151515143e-06] - Loss total: 2.5481972694396973, Last rpr Loss: 0.999989926815033, Last lagvar Loss: 0.8437652587890625\n",
      "Step 8783/10000- lr: [1.2273078181818176e-06] - Loss total: 2.5481820106506348, Last rpr Loss: 0.9999899864196777, Last lagvar Loss: 0.8437548279762268\n",
      "Step 8784/10000- lr: [1.2262977212121209e-06] - Loss total: 2.5481669902801514, Last rpr Loss: 0.9999914169311523, Last lagvar Loss: 0.8437433242797852\n",
      "Step 8785/10000- lr: [1.2252876242424242e-06] - Loss total: 2.548151731491089, Last rpr Loss: 0.9999929666519165, Last lagvar Loss: 0.8437324166297913\n",
      "Step 8786/10000- lr: [1.2242775272727274e-06] - Loss total: 2.5481364727020264, Last rpr Loss: 0.9999955296516418, Last lagvar Loss: 0.8437207937240601\n",
      "Step 8787/10000- lr: [1.223267430303029e-06] - Loss total: 2.5481209754943848, Last rpr Loss: 1.0000009536743164, Last lagvar Loss: 0.8437064290046692\n",
      "Step 8788/10000- lr: [1.2222573333333323e-06] - Loss total: 2.548105478286743, Last rpr Loss: 1.000000238418579, Last lagvar Loss: 0.8436985015869141\n",
      "Step 8789/10000- lr: [1.2212472363636356e-06] - Loss total: 2.5480892658233643, Last rpr Loss: 1.0000081062316895, Last lagvar Loss: 0.8436824083328247\n",
      "Step 8790/10000- lr: [1.2202371393939388e-06] - Loss total: 2.5480732917785645, Last rpr Loss: 1.000000238418579, Last lagvar Loss: 0.8436819314956665\n",
      "Step 8791/10000- lr: [1.2192270424242421e-06] - Loss total: 2.5480566024780273, Last rpr Loss: 1.0000030994415283, Last lagvar Loss: 0.8436709642410278\n",
      "Step 8792/10000- lr: [1.2182169454545454e-06] - Loss total: 2.548039436340332, Last rpr Loss: 1.0000083446502686, Last lagvar Loss: 0.8436576724052429\n",
      "Step 8793/10000- lr: [1.217206848484847e-06] - Loss total: 2.5480213165283203, Last rpr Loss: 1.0000027418136597, Last lagvar Loss: 0.8436551094055176\n",
      "Step 8794/10000- lr: [1.216196751515152e-06] - Loss total: 2.548002243041992, Last rpr Loss: 1.0000115633010864, Last lagvar Loss: 0.8436381816864014\n",
      "Step 8795/10000- lr: [1.2151866545454535e-06] - Loss total: 2.5479819774627686, Last rpr Loss: 1.0000073909759521, Last lagvar Loss: 0.8436340689659119\n",
      "Step 8796/10000- lr: [1.2141765575757568e-06] - Loss total: 2.5479609966278076, Last rpr Loss: 1.0000115633010864, Last lagvar Loss: 0.8436214327812195\n",
      "Step 8797/10000- lr: [1.21316646060606e-06] - Loss total: 2.5479390621185303, Last rpr Loss: 1.0000073909759521, Last lagvar Loss: 0.8436169624328613\n",
      "Step 8798/10000- lr: [1.2121563636363634e-06] - Loss total: 2.5479161739349365, Last rpr Loss: 1.0000014305114746, Last lagvar Loss: 0.8436140418052673\n",
      "Step 8799/10000- lr: [1.211146266666665e-06] - Loss total: 2.5478928089141846, Last rpr Loss: 1.0000050067901611, Last lagvar Loss: 0.8436012268066406\n",
      "Step 8800/10000- lr: [1.21013616969697e-06] - Loss total: 2.547870397567749, Last rpr Loss: 0.9999915361404419, Last lagvar Loss: 0.8436053991317749\n",
      "Step 8801/10000- lr: [1.2091260727272715e-06] - Loss total: 2.5478484630584717, Last rpr Loss: 0.9999797344207764, Last lagvar Loss: 0.8436077833175659\n",
      "Step 8802/10000- lr: [1.2081159757575748e-06] - Loss total: 2.5478272438049316, Last rpr Loss: 0.9999798536300659, Last lagvar Loss: 0.8435981869697571\n",
      "Step 8803/10000- lr: [1.207105878787878e-06] - Loss total: 2.547806739807129, Last rpr Loss: 0.9999687671661377, Last lagvar Loss: 0.8436000347137451\n",
      "Step 8804/10000- lr: [1.2060957818181813e-06] - Loss total: 2.5477869510650635, Last rpr Loss: 0.9999784827232361, Last lagvar Loss: 0.8435816168785095\n",
      "Step 8805/10000- lr: [1.2050856848484846e-06] - Loss total: 2.5477678775787354, Last rpr Loss: 0.9999887943267822, Last lagvar Loss: 0.843563437461853\n",
      "Step 8806/10000- lr: [1.2040755878787879e-06] - Loss total: 2.5477492809295654, Last rpr Loss: 0.9999974966049194, Last lagvar Loss: 0.8435475826263428\n",
      "Step 8807/10000- lr: [1.2030654909090912e-06] - Loss total: 2.547731399536133, Last rpr Loss: 1.0000157356262207, Last lagvar Loss: 0.843523383140564\n",
      "Step 8808/10000- lr: [1.2020553939393928e-06] - Loss total: 2.5477137565612793, Last rpr Loss: 1.0000004768371582, Last lagvar Loss: 0.8435335159301758\n",
      "Step 8809/10000- lr: [1.2010452969696977e-06] - Loss total: 2.547697067260742, Last rpr Loss: 0.9999897480010986, Last lagvar Loss: 0.8435404300689697\n",
      "Step 8810/10000- lr: [1.2000351999999993e-06] - Loss total: 2.5476808547973633, Last rpr Loss: 0.9999711513519287, Last lagvar Loss: 0.8435559272766113\n",
      "Step 8811/10000- lr: [1.1990251030303026e-06] - Loss total: 2.5476646423339844, Last rpr Loss: 0.9999502897262573, Last lagvar Loss: 0.8435747623443604\n",
      "Step 8812/10000- lr: [1.1980150060606059e-06] - Loss total: 2.5476486682891846, Last rpr Loss: 0.9999557137489319, Last lagvar Loss: 0.8435678482055664\n",
      "Step 8813/10000- lr: [1.1970049090909091e-06] - Loss total: 2.547633409500122, Last rpr Loss: 0.9999598264694214, Last lagvar Loss: 0.8435628414154053\n",
      "Step 8814/10000- lr: [1.1959948121212124e-06] - Loss total: 2.5476181507110596, Last rpr Loss: 0.999981164932251, Last lagvar Loss: 0.8435410261154175\n",
      "Step 8815/10000- lr: [1.1949847151515157e-06] - Loss total: 2.5476033687591553, Last rpr Loss: 0.9999923706054688, Last lagvar Loss: 0.8435297012329102\n",
      "Step 8816/10000- lr: [1.1939746181818173e-06] - Loss total: 2.547588586807251, Last rpr Loss: 1.0000057220458984, Last lagvar Loss: 0.8435164093971252\n",
      "Step 8817/10000- lr: [1.1929645212121206e-06] - Loss total: 2.547574043273926, Last rpr Loss: 0.9999949932098389, Last lagvar Loss: 0.84352707862854\n",
      "Step 8818/10000- lr: [1.1919544242424238e-06] - Loss total: 2.5475597381591797, Last rpr Loss: 0.9999887943267822, Last lagvar Loss: 0.8435330390930176\n",
      "Step 8819/10000- lr: [1.1909443272727271e-06] - Loss total: 2.5475456714630127, Last rpr Loss: 0.999981164932251, Last lagvar Loss: 0.8435403108596802\n",
      "Step 8820/10000- lr: [1.1899342303030304e-06] - Loss total: 2.5475313663482666, Last rpr Loss: 0.9999659061431885, Last lagvar Loss: 0.8435548543930054\n",
      "Step 8821/10000- lr: [1.1889241333333337e-06] - Loss total: 2.5475172996520996, Last rpr Loss: 0.9999732971191406, Last lagvar Loss: 0.8435467481613159\n",
      "Step 8822/10000- lr: [1.1879140363636352e-06] - Loss total: 2.5475032329559326, Last rpr Loss: 0.9999763369560242, Last lagvar Loss: 0.8435426950454712\n",
      "Step 8823/10000- lr: [1.1869039393939402e-06] - Loss total: 2.5474891662597656, Last rpr Loss: 0.9999833106994629, Last lagvar Loss: 0.8435343503952026\n",
      "Step 8824/10000- lr: [1.1858938424242418e-06] - Loss total: 2.5474753379821777, Last rpr Loss: 0.9999918937683105, Last lagvar Loss: 0.8435244560241699\n",
      "Step 8825/10000- lr: [1.184883745454545e-06] - Loss total: 2.547461748123169, Last rpr Loss: 0.9999901056289673, Last lagvar Loss: 0.8435248136520386\n",
      "Step 8826/10000- lr: [1.1838736484848484e-06] - Loss total: 2.54744815826416, Last rpr Loss: 1.0000004768371582, Last lagvar Loss: 0.8435129523277283\n",
      "Step 8827/10000- lr: [1.1828635515151516e-06] - Loss total: 2.5474345684051514, Last rpr Loss: 0.9999945759773254, Last lagvar Loss: 0.8435174226760864\n",
      "Step 8828/10000- lr: [1.1818534545454532e-06] - Loss total: 2.5474207401275635, Last rpr Loss: 0.9999962449073792, Last lagvar Loss: 0.8435142040252686\n",
      "Step 8829/10000- lr: [1.1808433575757582e-06] - Loss total: 2.5474071502685547, Last rpr Loss: 1.000002145767212, Last lagvar Loss: 0.8435068130493164\n",
      "Step 8830/10000- lr: [1.1798332606060598e-06] - Loss total: 2.547393798828125, Last rpr Loss: 1.0000007152557373, Last lagvar Loss: 0.8435068726539612\n",
      "Step 8831/10000- lr: [1.178823163636363e-06] - Loss total: 2.547380208969116, Last rpr Loss: 1.0000077486038208, Last lagvar Loss: 0.8434983491897583\n",
      "Step 8832/10000- lr: [1.1778130666666663e-06] - Loss total: 2.5473668575286865, Last rpr Loss: 1.0000064373016357, Last lagvar Loss: 0.8434983491897583\n",
      "Step 8833/10000- lr: [1.1768029696969696e-06] - Loss total: 2.547353744506836, Last rpr Loss: 1.000011682510376, Last lagvar Loss: 0.8434920310974121\n",
      "Step 8834/10000- lr: [1.1757928727272729e-06] - Loss total: 2.5473406314849854, Last rpr Loss: 1.0000016689300537, Last lagvar Loss: 0.8435007929801941\n",
      "Step 8835/10000- lr: [1.1747827757575762e-06] - Loss total: 2.5473272800445557, Last rpr Loss: 1.0000029802322388, Last lagvar Loss: 0.8434984683990479\n",
      "Step 8836/10000- lr: [1.1737726787878777e-06] - Loss total: 2.547314167022705, Last rpr Loss: 0.9999961256980896, Last lagvar Loss: 0.8435043692588806\n",
      "Step 8837/10000- lr: [1.172762581818181e-06] - Loss total: 2.5473010540008545, Last rpr Loss: 0.9999930262565613, Last lagvar Loss: 0.8435064554214478\n",
      "Step 8838/10000- lr: [1.1717524848484843e-06] - Loss total: 2.547288179397583, Last rpr Loss: 0.9999983310699463, Last lagvar Loss: 0.8435002565383911\n",
      "Step 8839/10000- lr: [1.1707423878787876e-06] - Loss total: 2.5472748279571533, Last rpr Loss: 0.9999927878379822, Last lagvar Loss: 0.8435050249099731\n",
      "Step 8840/10000- lr: [1.1697322909090908e-06] - Loss total: 2.547261953353882, Last rpr Loss: 1.0000009536743164, Last lagvar Loss: 0.8434962034225464\n",
      "Step 8841/10000- lr: [1.1687221939393941e-06] - Loss total: 2.5472490787506104, Last rpr Loss: 0.9999970197677612, Last lagvar Loss: 0.8434993028640747\n",
      "Step 8842/10000- lr: [1.1677120969696957e-06] - Loss total: 2.5472357273101807, Last rpr Loss: 0.9999926090240479, Last lagvar Loss: 0.8435031771659851\n",
      "Step 8843/10000- lr: [1.1667020000000007e-06] - Loss total: 2.5472233295440674, Last rpr Loss: 0.9999977946281433, Last lagvar Loss: 0.8434973359107971\n",
      "Step 8844/10000- lr: [1.1656919030303023e-06] - Loss total: 2.547210454940796, Last rpr Loss: 0.9999940395355225, Last lagvar Loss: 0.843500554561615\n",
      "Step 8845/10000- lr: [1.1646818060606055e-06] - Loss total: 2.5471978187561035, Last rpr Loss: 0.9999933242797852, Last lagvar Loss: 0.8435008525848389\n",
      "Step 8846/10000- lr: [1.1636717090909088e-06] - Loss total: 2.547184944152832, Last rpr Loss: 0.9999973773956299, Last lagvar Loss: 0.8434962034225464\n",
      "Step 8847/10000- lr: [1.162661612121212e-06] - Loss total: 2.5471718311309814, Last rpr Loss: 0.9999940395355225, Last lagvar Loss: 0.843498945236206\n",
      "Step 8848/10000- lr: [1.1616515151515137e-06] - Loss total: 2.547159433364868, Last rpr Loss: 1.0000003576278687, Last lagvar Loss: 0.8434923887252808\n",
      "Step 8849/10000- lr: [1.1606414181818186e-06] - Loss total: 2.547146797180176, Last rpr Loss: 0.9999904036521912, Last lagvar Loss: 0.8435018062591553\n",
      "Step 8850/10000- lr: [1.1596313212121202e-06] - Loss total: 2.5471339225769043, Last rpr Loss: 0.9999911189079285, Last lagvar Loss: 0.8435007929801941\n",
      "Step 8851/10000- lr: [1.1586212242424235e-06] - Loss total: 2.547121524810791, Last rpr Loss: 0.9999933242797852, Last lagvar Loss: 0.843498170375824\n",
      "Step 8852/10000- lr: [1.1576111272727268e-06] - Loss total: 2.5471091270446777, Last rpr Loss: 0.9999855756759644, Last lagvar Loss: 0.8435056209564209\n",
      "Step 8853/10000- lr: [1.15660103030303e-06] - Loss total: 2.5470962524414062, Last rpr Loss: 0.9999877214431763, Last lagvar Loss: 0.8435031175613403\n",
      "Step 8854/10000- lr: [1.1555909333333333e-06] - Loss total: 2.547083854675293, Last rpr Loss: 0.9999845027923584, Last lagvar Loss: 0.843505859375\n",
      "Step 8855/10000- lr: [1.1545808363636366e-06] - Loss total: 2.5470712184906006, Last rpr Loss: 0.9999878406524658, Last lagvar Loss: 0.843502402305603\n",
      "Step 8856/10000- lr: [1.1535707393939382e-06] - Loss total: 2.547058582305908, Last rpr Loss: 0.9999886155128479, Last lagvar Loss: 0.8435013890266418\n",
      "Step 8857/10000- lr: [1.1525606424242415e-06] - Loss total: 2.547045946121216, Last rpr Loss: 0.9999895095825195, Last lagvar Loss: 0.8435001373291016\n",
      "Step 8858/10000- lr: [1.1515505454545447e-06] - Loss total: 2.5470340251922607, Last rpr Loss: 0.9999905824661255, Last lagvar Loss: 0.8434987664222717\n",
      "Step 8859/10000- lr: [1.150540448484848e-06] - Loss total: 2.5470213890075684, Last rpr Loss: 0.9999949932098389, Last lagvar Loss: 0.843494176864624\n",
      "Step 8860/10000- lr: [1.1495303515151513e-06] - Loss total: 2.547008752822876, Last rpr Loss: 0.9999898672103882, Last lagvar Loss: 0.8434990644454956\n",
      "Step 8861/10000- lr: [1.1485202545454546e-06] - Loss total: 2.546996593475342, Last rpr Loss: 0.9999920129776001, Last lagvar Loss: 0.843496561050415\n",
      "Step 8862/10000- lr: [1.1475101575757562e-06] - Loss total: 2.5469844341278076, Last rpr Loss: 0.9999912977218628, Last lagvar Loss: 0.8434970378875732\n",
      "Step 8863/10000- lr: [1.1465000606060611e-06] - Loss total: 2.546971559524536, Last rpr Loss: 0.9999906420707703, Last lagvar Loss: 0.8434973955154419\n",
      "Step 8864/10000- lr: [1.1454899636363627e-06] - Loss total: 2.546959161758423, Last rpr Loss: 0.9999910593032837, Last lagvar Loss: 0.8434966802597046\n",
      "Step 8865/10000- lr: [1.144479866666666e-06] - Loss total: 2.5469472408294678, Last rpr Loss: 0.9999933242797852, Last lagvar Loss: 0.8434943556785583\n",
      "Step 8866/10000- lr: [1.1434697696969693e-06] - Loss total: 2.5469353199005127, Last rpr Loss: 0.9999943375587463, Last lagvar Loss: 0.8434931039810181\n",
      "Step 8867/10000- lr: [1.1424596727272725e-06] - Loss total: 2.546922445297241, Last rpr Loss: 0.999990701675415, Last lagvar Loss: 0.843496561050415\n",
      "Step 8868/10000- lr: [1.1414495757575741e-06] - Loss total: 2.546910524368286, Last rpr Loss: 0.999994158744812, Last lagvar Loss: 0.8434928059577942\n",
      "Step 8869/10000- lr: [1.140439478787879e-06] - Loss total: 2.5468978881835938, Last rpr Loss: 0.9999932050704956, Last lagvar Loss: 0.8434935808181763\n",
      "Step 8870/10000- lr: [1.1394293818181807e-06] - Loss total: 2.5468857288360596, Last rpr Loss: 0.9999921917915344, Last lagvar Loss: 0.8434944152832031\n",
      "Step 8871/10000- lr: [1.138419284848484e-06] - Loss total: 2.5468738079071045, Last rpr Loss: 0.9999972581863403, Last lagvar Loss: 0.8434891700744629\n",
      "Step 8872/10000- lr: [1.1374091878787872e-06] - Loss total: 2.5468616485595703, Last rpr Loss: 0.999990701675415, Last lagvar Loss: 0.8434955477714539\n",
      "Step 8873/10000- lr: [1.1363990909090905e-06] - Loss total: 2.546849489212036, Last rpr Loss: 0.999997615814209, Last lagvar Loss: 0.843488335609436\n",
      "Step 8874/10000- lr: [1.1353889939393938e-06] - Loss total: 2.546837329864502, Last rpr Loss: 0.9999932646751404, Last lagvar Loss: 0.8434925079345703\n",
      "Step 8875/10000- lr: [1.134378896969697e-06] - Loss total: 2.5468249320983887, Last rpr Loss: 0.9999929666519165, Last lagvar Loss: 0.8434926867485046\n",
      "Step 8876/10000- lr: [1.1333687999999987e-06] - Loss total: 2.5468132495880127, Last rpr Loss: 0.9999946355819702, Last lagvar Loss: 0.8434907793998718\n",
      "Step 8877/10000- lr: [1.132358703030302e-06] - Loss total: 2.5468010902404785, Last rpr Loss: 0.9999871253967285, Last lagvar Loss: 0.8434982299804688\n",
      "Step 8878/10000- lr: [1.1313486060606052e-06] - Loss total: 2.5467886924743652, Last rpr Loss: 0.9999959468841553, Last lagvar Loss: 0.8434891104698181\n",
      "Step 8879/10000- lr: [1.1303385090909085e-06] - Loss total: 2.546776533126831, Last rpr Loss: 0.9999883770942688, Last lagvar Loss: 0.8434964418411255\n",
      "Step 8880/10000- lr: [1.1293284121212118e-06] - Loss total: 2.546764850616455, Last rpr Loss: 0.9999915957450867, Last lagvar Loss: 0.8434931039810181\n",
      "Step 8881/10000- lr: [1.128318315151515e-06] - Loss total: 2.546752691268921, Last rpr Loss: 0.9999947547912598, Last lagvar Loss: 0.8434898853302002\n",
      "Step 8882/10000- lr: [1.1273082181818166e-06] - Loss total: 2.546740770339966, Last rpr Loss: 0.9999862909317017, Last lagvar Loss: 0.8434981107711792\n",
      "Step 8883/10000- lr: [1.1262981212121216e-06] - Loss total: 2.5467288494110107, Last rpr Loss: 0.9999948143959045, Last lagvar Loss: 0.8434894680976868\n",
      "Step 8884/10000- lr: [1.1252880242424232e-06] - Loss total: 2.5467164516448975, Last rpr Loss: 0.9999908208847046, Last lagvar Loss: 0.8434932827949524\n",
      "Step 8885/10000- lr: [1.1242779272727265e-06] - Loss total: 2.5467047691345215, Last rpr Loss: 0.9999890923500061, Last lagvar Loss: 0.8434948921203613\n",
      "Step 8886/10000- lr: [1.1232678303030297e-06] - Loss total: 2.5466928482055664, Last rpr Loss: 0.9999936819076538, Last lagvar Loss: 0.8434900641441345\n",
      "Step 8887/10000- lr: [1.122257733333333e-06] - Loss total: 2.5466806888580322, Last rpr Loss: 0.9999852180480957, Last lagvar Loss: 0.8434984683990479\n",
      "Step 8888/10000- lr: [1.1212476363636346e-06] - Loss total: 2.546668529510498, Last rpr Loss: 0.9999924898147583, Last lagvar Loss: 0.8434910178184509\n",
      "Step 8889/10000- lr: [1.1202375393939396e-06] - Loss total: 2.546656847000122, Last rpr Loss: 0.9999871253967285, Last lagvar Loss: 0.8434963226318359\n",
      "Step 8890/10000- lr: [1.1192274424242428e-06] - Loss total: 2.546644926071167, Last rpr Loss: 0.999993085861206, Last lagvar Loss: 0.8434901833534241\n",
      "Step 8891/10000- lr: [1.1182173454545444e-06] - Loss total: 2.546633243560791, Last rpr Loss: 0.9999933838844299, Last lagvar Loss: 0.8434897661209106\n",
      "Step 8892/10000- lr: [1.1172072484848494e-06] - Loss total: 2.5466208457946777, Last rpr Loss: 0.9999940991401672, Last lagvar Loss: 0.8434890508651733\n",
      "Step 8893/10000- lr: [1.116197151515151e-06] - Loss total: 2.5466091632843018, Last rpr Loss: 0.9999890327453613, Last lagvar Loss: 0.8434938192367554\n",
      "Step 8894/10000- lr: [1.1151870545454543e-06] - Loss total: 2.546597480773926, Last rpr Loss: 0.9999912977218628, Last lagvar Loss: 0.8434915542602539\n",
      "Step 8895/10000- lr: [1.1141769575757575e-06] - Loss total: 2.5465853214263916, Last rpr Loss: 0.9999889135360718, Last lagvar Loss: 0.8434938192367554\n",
      "Step 8896/10000- lr: [1.1131668606060608e-06] - Loss total: 2.5465736389160156, Last rpr Loss: 0.9999877214431763, Last lagvar Loss: 0.8434948325157166\n",
      "Step 8897/10000- lr: [1.1121567636363624e-06] - Loss total: 2.5465614795684814, Last rpr Loss: 0.999993085861206, Last lagvar Loss: 0.8434893488883972\n",
      "Step 8898/10000- lr: [1.1111466666666674e-06] - Loss total: 2.5465497970581055, Last rpr Loss: 0.9999916553497314, Last lagvar Loss: 0.843490481376648\n",
      "Step 8899/10000- lr: [1.110136569696969e-06] - Loss total: 2.5465381145477295, Last rpr Loss: 0.9999889731407166, Last lagvar Loss: 0.8434932231903076\n",
      "Step 8900/10000- lr: [1.1091264727272722e-06] - Loss total: 2.5465261936187744, Last rpr Loss: 0.9999904036521912, Last lagvar Loss: 0.8434915542602539\n",
      "Step 8901/10000- lr: [1.1081163757575755e-06] - Loss total: 2.5465142726898193, Last rpr Loss: 0.9999898076057434, Last lagvar Loss: 0.8434921503067017\n",
      "Step 8902/10000- lr: [1.1071062787878788e-06] - Loss total: 2.5465023517608643, Last rpr Loss: 0.9999849796295166, Last lagvar Loss: 0.8434968590736389\n",
      "Step 8903/10000- lr: [1.106096181818182e-06] - Loss total: 2.5464906692504883, Last rpr Loss: 0.9999935626983643, Last lagvar Loss: 0.843488335609436\n",
      "Step 8904/10000- lr: [1.1050860848484853e-06] - Loss total: 2.546478748321533, Last rpr Loss: 0.9999873042106628, Last lagvar Loss: 0.8434942960739136\n",
      "Step 8905/10000- lr: [1.104075987878787e-06] - Loss total: 2.546466827392578, Last rpr Loss: 0.9999881386756897, Last lagvar Loss: 0.8434934616088867\n",
      "Step 8906/10000- lr: [1.1030658909090902e-06] - Loss total: 2.546454906463623, Last rpr Loss: 0.9999873638153076, Last lagvar Loss: 0.8434940576553345\n",
      "Step 8907/10000- lr: [1.1020557939393935e-06] - Loss total: 2.546442985534668, Last rpr Loss: 0.9999871253967285, Last lagvar Loss: 0.843494176864624\n",
      "Step 8908/10000- lr: [1.1010456969696967e-06] - Loss total: 2.546431064605713, Last rpr Loss: 0.9999911785125732, Last lagvar Loss: 0.8434900045394897\n",
      "Step 8909/10000- lr: [1.1000356e-06] - Loss total: 2.546419143676758, Last rpr Loss: 0.9999871253967285, Last lagvar Loss: 0.843494176864624\n",
      "Step 8910/10000- lr: [1.0990255030303033e-06] - Loss total: 2.5464072227478027, Last rpr Loss: 0.9999827146530151, Last lagvar Loss: 0.8434984087944031\n",
      "Step 8911/10000- lr: [1.0980154060606049e-06] - Loss total: 2.5463955402374268, Last rpr Loss: 0.9999895691871643, Last lagvar Loss: 0.8434914946556091\n",
      "Step 8912/10000- lr: [1.0970053090909099e-06] - Loss total: 2.5463836193084717, Last rpr Loss: 0.999984622001648, Last lagvar Loss: 0.8434963226318359\n",
      "Step 8913/10000- lr: [1.0959952121212114e-06] - Loss total: 2.5463714599609375, Last rpr Loss: 0.9999820590019226, Last lagvar Loss: 0.8434988856315613\n",
      "Step 8914/10000- lr: [1.0949851151515147e-06] - Loss total: 2.5463593006134033, Last rpr Loss: 0.9999898672103882, Last lagvar Loss: 0.8434909582138062\n",
      "Step 8915/10000- lr: [1.093975018181818e-06] - Loss total: 2.5463473796844482, Last rpr Loss: 0.9999829530715942, Last lagvar Loss: 0.8434978723526001\n",
      "Step 8916/10000- lr: [1.0929649212121213e-06] - Loss total: 2.546335458755493, Last rpr Loss: 0.9999892711639404, Last lagvar Loss: 0.8434916138648987\n",
      "Step 8917/10000- lr: [1.0919548242424229e-06] - Loss total: 2.54632306098938, Last rpr Loss: 0.999984085559845, Last lagvar Loss: 0.8434966206550598\n",
      "Step 8918/10000- lr: [1.0909447272727278e-06] - Loss total: 2.546311140060425, Last rpr Loss: 0.9999826550483704, Last lagvar Loss: 0.8434980511665344\n",
      "Step 8919/10000- lr: [1.0899346303030294e-06] - Loss total: 2.5462985038757324, Last rpr Loss: 0.99998539686203, Last lagvar Loss: 0.8434951901435852\n",
      "Step 8920/10000- lr: [1.0889245333333327e-06] - Loss total: 2.5462863445281982, Last rpr Loss: 0.9999855756759644, Last lagvar Loss: 0.8434950113296509\n",
      "Step 8921/10000- lr: [1.087914436363636e-06] - Loss total: 2.546273946762085, Last rpr Loss: 0.9999818205833435, Last lagvar Loss: 0.8434988260269165\n",
      "Step 8922/10000- lr: [1.0869043393939392e-06] - Loss total: 2.546261787414551, Last rpr Loss: 0.9999868869781494, Last lagvar Loss: 0.8434935808181763\n",
      "Step 8923/10000- lr: [1.0858942424242425e-06] - Loss total: 2.5462493896484375, Last rpr Loss: 0.9999862313270569, Last lagvar Loss: 0.843494176864624\n",
      "Step 8924/10000- lr: [1.0848841454545458e-06] - Loss total: 2.5462372303009033, Last rpr Loss: 0.9999793767929077, Last lagvar Loss: 0.8435007929801941\n",
      "Step 8925/10000- lr: [1.0838740484848474e-06] - Loss total: 2.546224355697632, Last rpr Loss: 0.999986469745636, Last lagvar Loss: 0.8434935808181763\n",
      "Step 8926/10000- lr: [1.0828639515151507e-06] - Loss total: 2.5462114810943604, Last rpr Loss: 0.9999852180480957, Last lagvar Loss: 0.8434944748878479\n",
      "Step 8927/10000- lr: [1.081853854545454e-06] - Loss total: 2.546199083328247, Last rpr Loss: 0.9999819993972778, Last lagvar Loss: 0.8434974551200867\n",
      "Step 8928/10000- lr: [1.0808437575757572e-06] - Loss total: 2.546186685562134, Last rpr Loss: 0.9999858140945435, Last lagvar Loss: 0.8434932231903076\n",
      "Step 8929/10000- lr: [1.0798336606060605e-06] - Loss total: 2.5461742877960205, Last rpr Loss: 0.9999791383743286, Last lagvar Loss: 0.8434993028640747\n",
      "Step 8930/10000- lr: [1.0788235636363638e-06] - Loss total: 2.546161413192749, Last rpr Loss: 0.9999831318855286, Last lagvar Loss: 0.8434945344924927\n",
      "Step 8931/10000- lr: [1.0778134666666653e-06] - Loss total: 2.5461485385894775, Last rpr Loss: 0.9999855756759644, Last lagvar Loss: 0.8434911370277405\n",
      "Step 8932/10000- lr: [1.0768033696969703e-06] - Loss total: 2.5461361408233643, Last rpr Loss: 0.9999805092811584, Last lagvar Loss: 0.8434950113296509\n",
      "Step 8933/10000- lr: [1.075793272727272e-06] - Loss total: 2.5461230278015137, Last rpr Loss: 0.999980628490448, Last lagvar Loss: 0.8434933423995972\n",
      "Step 8934/10000- lr: [1.0747831757575752e-06] - Loss total: 2.5461103916168213, Last rpr Loss: 0.9999802708625793, Last lagvar Loss: 0.8434919118881226\n",
      "Step 8935/10000- lr: [1.0737730787878785e-06] - Loss total: 2.546097993850708, Last rpr Loss: 0.9999738335609436, Last lagvar Loss: 0.8434962034225464\n",
      "Step 8936/10000- lr: [1.0727629818181817e-06] - Loss total: 2.5460848808288574, Last rpr Loss: 0.9999845027923584, Last lagvar Loss: 0.8434829711914062\n",
      "Step 8937/10000- lr: [1.0717528848484833e-06] - Loss total: 2.546072006225586, Last rpr Loss: 0.9999737739562988, Last lagvar Loss: 0.8434906005859375\n",
      "Step 8938/10000- lr: [1.0707427878787883e-06] - Loss total: 2.5460593700408936, Last rpr Loss: 0.9999783039093018, Last lagvar Loss: 0.8434823751449585\n",
      "Step 8939/10000- lr: [1.0697326909090899e-06] - Loss total: 2.546046495437622, Last rpr Loss: 0.9999779462814331, Last lagvar Loss: 0.8434784412384033\n",
      "Step 8940/10000- lr: [1.0687225939393931e-06] - Loss total: 2.5460338592529297, Last rpr Loss: 0.9999702572822571, Last lagvar Loss: 0.8434813618659973\n",
      "Step 8941/10000- lr: [1.0677124969696964e-06] - Loss total: 2.5460212230682373, Last rpr Loss: 0.999975860118866, Last lagvar Loss: 0.8434703946113586\n",
      "Step 8942/10000- lr: [1.0667023999999997e-06] - Loss total: 2.5460081100463867, Last rpr Loss: 0.9999766945838928, Last lagvar Loss: 0.8434635996818542\n",
      "Step 8943/10000- lr: [1.065692303030303e-06] - Loss total: 2.5459954738616943, Last rpr Loss: 0.9999747276306152, Last lagvar Loss: 0.8434592485427856\n",
      "Step 8944/10000- lr: [1.0646822060606062e-06] - Loss total: 2.545982599258423, Last rpr Loss: 0.9999780058860779, Last lagvar Loss: 0.8434492349624634\n",
      "Step 8945/10000- lr: [1.0636721090909078e-06] - Loss total: 2.5459702014923096, Last rpr Loss: 0.999976634979248, Last lagvar Loss: 0.843443751335144\n",
      "Step 8946/10000- lr: [1.0626620121212111e-06] - Loss total: 2.545957326889038, Last rpr Loss: 0.9999836683273315, Last lagvar Loss: 0.8434299230575562\n",
      "Step 8947/10000- lr: [1.0616519151515144e-06] - Loss total: 2.545945167541504, Last rpr Loss: 0.9999866485595703, Last lagvar Loss: 0.8434203267097473\n",
      "Step 8948/10000- lr: [1.0606418181818177e-06] - Loss total: 2.5459325313568115, Last rpr Loss: 0.9999877214431763, Last lagvar Loss: 0.8434128165245056\n",
      "Step 8949/10000- lr: [1.059631721212121e-06] - Loss total: 2.5459203720092773, Last rpr Loss: 0.9999935030937195, Last lagvar Loss: 0.843401312828064\n",
      "Step 8950/10000- lr: [1.0586216242424242e-06] - Loss total: 2.545908212661743, Last rpr Loss: 0.9999951720237732, Last lagvar Loss: 0.8433942198753357\n",
      "Step 8951/10000- lr: [1.0576115272727258e-06] - Loss total: 2.54589581489563, Last rpr Loss: 0.9999972581863403, Last lagvar Loss: 0.8433873057365417\n",
      "Step 8952/10000- lr: [1.0566014303030308e-06] - Loss total: 2.545884132385254, Last rpr Loss: 0.9999995827674866, Last lagvar Loss: 0.8433808088302612\n",
      "Step 8953/10000- lr: [1.0555913333333324e-06] - Loss total: 2.5458719730377197, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8433806300163269\n",
      "Step 8954/10000- lr: [1.0545812363636356e-06] - Loss total: 2.5458602905273438, Last rpr Loss: 1.0000011920928955, Last lagvar Loss: 0.8433718681335449\n",
      "Step 8955/10000- lr: [1.053571139393939e-06] - Loss total: 2.5458486080169678, Last rpr Loss: 0.9999924898147583, Last lagvar Loss: 0.8433777093887329\n",
      "Step 8956/10000- lr: [1.0525610424242422e-06] - Loss total: 2.545836925506592, Last rpr Loss: 0.9999939203262329, Last lagvar Loss: 0.8433738946914673\n",
      "Step 8957/10000- lr: [1.0515509454545438e-06] - Loss total: 2.545825242996216, Last rpr Loss: 0.9999959468841553, Last lagvar Loss: 0.8433694839477539\n",
      "Step 8958/10000- lr: [1.0505408484848487e-06] - Loss total: 2.545813798904419, Last rpr Loss: 0.9999900460243225, Last lagvar Loss: 0.8433734178543091\n",
      "Step 8959/10000- lr: [1.0495307515151503e-06] - Loss total: 2.545802354812622, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.8433653116226196\n",
      "Step 8960/10000- lr: [1.0485206545454536e-06] - Loss total: 2.545790910720825, Last rpr Loss: 0.9999879598617554, Last lagvar Loss: 0.8433722257614136\n",
      "Step 8961/10000- lr: [1.0475105575757569e-06] - Loss total: 2.5457794666290283, Last rpr Loss: 0.9999946355819702, Last lagvar Loss: 0.8433642387390137\n",
      "Step 8962/10000- lr: [1.0465004606060602e-06] - Loss total: 2.5457680225372314, Last rpr Loss: 0.999993085861206, Last lagvar Loss: 0.8433646559715271\n",
      "Step 8963/10000- lr: [1.0454903636363634e-06] - Loss total: 2.5457568168640137, Last rpr Loss: 0.9999871253967285, Last lagvar Loss: 0.8433694243431091\n",
      "Step 8964/10000- lr: [1.0444802666666667e-06] - Loss total: 2.545745611190796, Last rpr Loss: 0.9999984502792358, Last lagvar Loss: 0.8433571457862854\n",
      "Step 8965/10000- lr: [1.0434701696969683e-06] - Loss total: 2.545734405517578, Last rpr Loss: 0.9999921917915344, Last lagvar Loss: 0.84336256980896\n",
      "Step 8966/10000- lr: [1.0424600727272716e-06] - Loss total: 2.5457229614257812, Last rpr Loss: 0.9999913573265076, Last lagvar Loss: 0.84336256980896\n",
      "Step 8967/10000- lr: [1.0414499757575748e-06] - Loss total: 2.5457117557525635, Last rpr Loss: 0.999998152256012, Last lagvar Loss: 0.8433550596237183\n",
      "Step 8968/10000- lr: [1.0404398787878781e-06] - Loss total: 2.5457003116607666, Last rpr Loss: 0.9999907612800598, Last lagvar Loss: 0.8433617353439331\n",
      "Step 8969/10000- lr: [1.0394297818181814e-06] - Loss total: 2.545689582824707, Last rpr Loss: 0.9999968409538269, Last lagvar Loss: 0.843355119228363\n",
      "Step 8970/10000- lr: [1.0384196848484847e-06] - Loss total: 2.5456783771514893, Last rpr Loss: 0.9999945163726807, Last lagvar Loss: 0.8433569073677063\n",
      "Step 8971/10000- lr: [1.0374095878787863e-06] - Loss total: 2.5456674098968506, Last rpr Loss: 0.9999929666519165, Last lagvar Loss: 0.8433579206466675\n",
      "Step 8972/10000- lr: [1.0363994909090912e-06] - Loss total: 2.5456559658050537, Last rpr Loss: 0.9999951124191284, Last lagvar Loss: 0.8433552980422974\n",
      "Step 8973/10000- lr: [1.0353893939393928e-06] - Loss total: 2.545644998550415, Last rpr Loss: 0.9999924302101135, Last lagvar Loss: 0.8433575630187988\n",
      "Step 8974/10000- lr: [1.034379296969696e-06] - Loss total: 2.5456337928771973, Last rpr Loss: 0.9999932050704956, Last lagvar Loss: 0.8433563113212585\n",
      "Step 8975/10000- lr: [1.0333691999999994e-06] - Loss total: 2.5456230640411377, Last rpr Loss: 0.9999963045120239, Last lagvar Loss: 0.8433528542518616\n",
      "Step 8976/10000- lr: [1.0323591030303026e-06] - Loss total: 2.545611619949341, Last rpr Loss: 0.999992847442627, Last lagvar Loss: 0.8433559536933899\n",
      "Step 8977/10000- lr: [1.031349006060606e-06] - Loss total: 2.5456008911132812, Last rpr Loss: 0.9999914169311523, Last lagvar Loss: 0.8433570861816406\n",
      "Step 8978/10000- lr: [1.0303389090909092e-06] - Loss total: 2.5455901622772217, Last rpr Loss: 0.9999949336051941, Last lagvar Loss: 0.843353271484375\n",
      "Step 8979/10000- lr: [1.0293288121212125e-06] - Loss total: 2.545579195022583, Last rpr Loss: 0.9999898672103882, Last lagvar Loss: 0.8433579802513123\n",
      "Step 8980/10000- lr: [1.028318715151514e-06] - Loss total: 2.5455679893493652, Last rpr Loss: 0.9999967813491821, Last lagvar Loss: 0.8433507084846497\n",
      "Step 8981/10000- lr: [1.027308618181819e-06] - Loss total: 2.5455570220947266, Last rpr Loss: 0.9999897480010986, Last lagvar Loss: 0.8433575630187988\n",
      "Step 8982/10000- lr: [1.0262985212121206e-06] - Loss total: 2.545545816421509, Last rpr Loss: 0.9999945163726807, Last lagvar Loss: 0.8433525562286377\n",
      "Step 8983/10000- lr: [1.0252884242424239e-06] - Loss total: 2.545535087585449, Last rpr Loss: 0.9999933838844299, Last lagvar Loss: 0.8433533906936646\n",
      "Step 8984/10000- lr: [1.0242783272727272e-06] - Loss total: 2.5455243587493896, Last rpr Loss: 0.99998939037323, Last lagvar Loss: 0.8433570861816406\n",
      "Step 8985/10000- lr: [1.0232682303030304e-06] - Loss total: 2.54551362991333, Last rpr Loss: 0.9999937415122986, Last lagvar Loss: 0.8433524966239929\n",
      "Step 8986/10000- lr: [1.022258133333332e-06] - Loss total: 2.5455029010772705, Last rpr Loss: 0.9999911189079285, Last lagvar Loss: 0.8433550000190735\n",
      "Step 8987/10000- lr: [1.021248036363637e-06] - Loss total: 2.545491933822632, Last rpr Loss: 0.9999909996986389, Last lagvar Loss: 0.8433548212051392\n",
      "Step 8988/10000- lr: [1.0202379393939386e-06] - Loss total: 2.545480728149414, Last rpr Loss: 0.9999933242797852, Last lagvar Loss: 0.8433523178100586\n",
      "Step 8989/10000- lr: [1.0192278424242419e-06] - Loss total: 2.5454702377319336, Last rpr Loss: 0.9999903440475464, Last lagvar Loss: 0.8433551788330078\n",
      "Step 8990/10000- lr: [1.0182177454545451e-06] - Loss total: 2.545459270477295, Last rpr Loss: 0.9999927282333374, Last lagvar Loss: 0.8433524966239929\n",
      "Step 8991/10000- lr: [1.0172076484848484e-06] - Loss total: 2.5454485416412354, Last rpr Loss: 0.9999920129776001, Last lagvar Loss: 0.8433530330657959\n",
      "Step 8992/10000- lr: [1.0161975515151517e-06] - Loss total: 2.545437812805176, Last rpr Loss: 0.9999926686286926, Last lagvar Loss: 0.843352198600769\n",
      "Step 8993/10000- lr: [1.015187454545455e-06] - Loss total: 2.545427083969116, Last rpr Loss: 0.9999915957450867, Last lagvar Loss: 0.8433530926704407\n",
      "Step 8994/10000- lr: [1.0141773575757566e-06] - Loss total: 2.5454163551330566, Last rpr Loss: 0.9999901056289673, Last lagvar Loss: 0.843354344367981\n",
      "Step 8995/10000- lr: [1.0131672606060598e-06] - Loss total: 2.545405626296997, Last rpr Loss: 0.999991774559021, Last lagvar Loss: 0.8433525562286377\n",
      "Step 8996/10000- lr: [1.012157163636363e-06] - Loss total: 2.5453946590423584, Last rpr Loss: 0.9999940395355225, Last lagvar Loss: 0.8433501720428467\n",
      "Step 8997/10000- lr: [1.0111470666666664e-06] - Loss total: 2.545384168624878, Last rpr Loss: 0.9999934434890747, Last lagvar Loss: 0.8433505892753601\n",
      "Step 8998/10000- lr: [1.0101369696969697e-06] - Loss total: 2.5453732013702393, Last rpr Loss: 0.999994158744812, Last lagvar Loss: 0.843349814414978\n",
      "Step 8999/10000- lr: [1.009126872727273e-06] - Loss total: 2.545362949371338, Last rpr Loss: 0.9999909400939941, Last lagvar Loss: 0.8433527946472168\n",
      "Step 9000/10000- lr: [1.0081167757575745e-06] - Loss total: 2.5453522205352783, Last rpr Loss: 0.9999938011169434, Last lagvar Loss: 0.8433499336242676\n",
      "Step 9001/10000- lr: [1.0071066787878795e-06] - Loss total: 2.5453414916992188, Last rpr Loss: 0.9999897480010986, Last lagvar Loss: 0.8433536887168884\n",
      "Step 9002/10000- lr: [1.006096581818181e-06] - Loss total: 2.5453310012817383, Last rpr Loss: 0.9999940991401672, Last lagvar Loss: 0.8433492183685303\n",
      "Step 9003/10000- lr: [1.0050864848484844e-06] - Loss total: 2.5453197956085205, Last rpr Loss: 0.9999951124191284, Last lagvar Loss: 0.8433480262756348\n",
      "Step 9004/10000- lr: [1.0040763878787876e-06] - Loss total: 2.545308828353882, Last rpr Loss: 0.9999902248382568, Last lagvar Loss: 0.8433528542518616\n",
      "Step 9005/10000- lr: [1.003066290909091e-06] - Loss total: 2.5452985763549805, Last rpr Loss: 0.9999958872795105, Last lagvar Loss: 0.8433470129966736\n",
      "Step 9006/10000- lr: [1.0020561939393925e-06] - Loss total: 2.545287847518921, Last rpr Loss: 0.999991774559021, Last lagvar Loss: 0.8433510065078735\n",
      "Step 9007/10000- lr: [1.0010460969696975e-06] - Loss total: 2.5452775955200195, Last rpr Loss: 0.9999976754188538, Last lagvar Loss: 0.8433449268341064\n",
      "Step 9008/10000- lr: [1.000035999999999e-06] - Loss total: 2.54526686668396, Last rpr Loss: 0.9999943971633911, Last lagvar Loss: 0.8433480858802795\n",
      "Step 9009/10000- lr: [9.990259030303023e-07] - Loss total: 2.5452563762664795, Last rpr Loss: 0.9999898672103882, Last lagvar Loss: 0.8433525562286377\n",
      "Step 9010/10000- lr: [9.980158060606056e-07] - Loss total: 2.545245885848999, Last rpr Loss: 0.999995768070221, Last lagvar Loss: 0.8433465957641602\n",
      "Step 9011/10000- lr: [9.970057090909089e-07] - Loss total: 2.5452351570129395, Last rpr Loss: 0.9999947547912598, Last lagvar Loss: 0.8433473110198975\n",
      "Step 9012/10000- lr: [9.959956121212122e-07] - Loss total: 2.54522442817688, Last rpr Loss: 0.9999904036521912, Last lagvar Loss: 0.8433516025543213\n",
      "Step 9013/10000- lr: [9.949855151515154e-07] - Loss total: 2.5452139377593994, Last rpr Loss: 0.9999954700469971, Last lagvar Loss: 0.8433464765548706\n",
      "Step 9014/10000- lr: [9.93975418181817e-07] - Loss total: 2.545203685760498, Last rpr Loss: 0.9999960660934448, Last lagvar Loss: 0.8433457016944885\n",
      "Step 9015/10000- lr: [9.929653212121203e-07] - Loss total: 2.5451929569244385, Last rpr Loss: 0.9999926686286926, Last lagvar Loss: 0.843349039554596\n",
      "Step 9016/10000- lr: [9.919552242424236e-07] - Loss total: 2.545182466506958, Last rpr Loss: 0.999998927116394, Last lagvar Loss: 0.843342661857605\n",
      "Step 9017/10000- lr: [9.909451272727268e-07] - Loss total: 2.5451722145080566, Last rpr Loss: 0.9999922513961792, Last lagvar Loss: 0.8433492183685303\n",
      "Step 9018/10000- lr: [9.899350303030301e-07] - Loss total: 2.545161247253418, Last rpr Loss: 0.9999890327453613, Last lagvar Loss: 0.843352198600769\n",
      "Step 9019/10000- lr: [9.889249333333334e-07] - Loss total: 2.5451509952545166, Last rpr Loss: 0.9999991059303284, Last lagvar Loss: 0.8433421850204468\n",
      "Step 9020/10000- lr: [9.87914836363635e-07] - Loss total: 2.545140504837036, Last rpr Loss: 0.9999904632568359, Last lagvar Loss: 0.8433507084846497\n",
      "Step 9021/10000- lr: [9.8690473939394e-07] - Loss total: 2.5451300144195557, Last rpr Loss: 0.999994158744812, Last lagvar Loss: 0.8433469533920288\n",
      "Step 9022/10000- lr: [9.858946424242415e-07] - Loss total: 2.545119524002075, Last rpr Loss: 0.9999980330467224, Last lagvar Loss: 0.8433429002761841\n",
      "Step 9023/10000- lr: [9.848845454545448e-07] - Loss total: 2.5451090335845947, Last rpr Loss: 0.999991774559021, Last lagvar Loss: 0.8433490991592407\n",
      "Step 9024/10000- lr: [9.83874448484848e-07] - Loss total: 2.5450987815856934, Last rpr Loss: 0.9999980330467224, Last lagvar Loss: 0.843342661857605\n",
      "Step 9025/10000- lr: [9.828643515151514e-07] - Loss total: 2.545088529586792, Last rpr Loss: 0.9999936819076538, Last lagvar Loss: 0.8433469533920288\n",
      "Step 9026/10000- lr: [9.81854254545453e-07] - Loss total: 2.5450775623321533, Last rpr Loss: 0.9999908208847046, Last lagvar Loss: 0.8433496952056885\n",
      "Step 9027/10000- lr: [9.80844157575758e-07] - Loss total: 2.545067548751831, Last rpr Loss: 0.9999949932098389, Last lagvar Loss: 0.8433455228805542\n",
      "Step 9028/10000- lr: [9.798340606060595e-07] - Loss total: 2.5450570583343506, Last rpr Loss: 0.9999929666519165, Last lagvar Loss: 0.8433475494384766\n",
      "Step 9029/10000- lr: [9.788239636363628e-07] - Loss total: 2.54504656791687, Last rpr Loss: 0.9999984502792358, Last lagvar Loss: 0.8433418869972229\n",
      "Step 9030/10000- lr: [9.77813866666666e-07] - Loss total: 2.5450360774993896, Last rpr Loss: 0.9999970197677612, Last lagvar Loss: 0.843343198299408\n",
      "Step 9031/10000- lr: [9.768037696969693e-07] - Loss total: 2.5450258255004883, Last rpr Loss: 0.9999907612800598, Last lagvar Loss: 0.8433493971824646\n",
      "Step 9032/10000- lr: [9.757936727272726e-07] - Loss total: 2.545015335083008, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.8433436155319214\n",
      "Step 9033/10000- lr: [9.747835757575759e-07] - Loss total: 2.5450050830841064, Last rpr Loss: 0.9999939203262329, Last lagvar Loss: 0.8433459997177124\n",
      "Step 9034/10000- lr: [9.737734787878775e-07] - Loss total: 2.544994831085205, Last rpr Loss: 0.999990701675415, Last lagvar Loss: 0.8433492183685303\n",
      "Step 9035/10000- lr: [9.727633818181807e-07] - Loss total: 2.5449845790863037, Last rpr Loss: 0.9999982118606567, Last lagvar Loss: 0.843341588973999\n",
      "Step 9036/10000- lr: [9.71753284848484e-07] - Loss total: 2.5449743270874023, Last rpr Loss: 0.9999936819076538, Last lagvar Loss: 0.843346118927002\n",
      "Step 9037/10000- lr: [9.707431878787873e-07] - Loss total: 2.544963836669922, Last rpr Loss: 0.9999952912330627, Last lagvar Loss: 0.8433443307876587\n",
      "Step 9038/10000- lr: [9.697330909090906e-07] - Loss total: 2.5449535846710205, Last rpr Loss: 0.9999953508377075, Last lagvar Loss: 0.8433442711830139\n",
      "Step 9039/10000- lr: [9.687229939393939e-07] - Loss total: 2.54494309425354, Last rpr Loss: 0.999991774559021, Last lagvar Loss: 0.8433477282524109\n",
      "Step 9040/10000- lr: [9.677128969696954e-07] - Loss total: 2.5449328422546387, Last rpr Loss: 0.9999967813491821, Last lagvar Loss: 0.8433427214622498\n",
      "Step 9041/10000- lr: [9.667028000000004e-07] - Loss total: 2.5449225902557373, Last rpr Loss: 0.9999939203262329, Last lagvar Loss: 0.8433454632759094\n",
      "Step 9042/10000- lr: [9.65692703030302e-07] - Loss total: 2.544912338256836, Last rpr Loss: 0.9999935030937195, Last lagvar Loss: 0.8433457612991333\n",
      "Step 9043/10000- lr: [9.646826060606053e-07] - Loss total: 2.5449020862579346, Last rpr Loss: 0.9999951124191284, Last lagvar Loss: 0.8433440923690796\n",
      "Step 9044/10000- lr: [9.636725090909085e-07] - Loss total: 2.544891834259033, Last rpr Loss: 0.9999920129776001, Last lagvar Loss: 0.8433471918106079\n",
      "Step 9045/10000- lr: [9.626624121212118e-07] - Loss total: 2.544881582260132, Last rpr Loss: 0.999997615814209, Last lagvar Loss: 0.8433414697647095\n",
      "Step 9046/10000- lr: [9.616523151515134e-07] - Loss total: 2.5448715686798096, Last rpr Loss: 0.9999949932098389, Last lagvar Loss: 0.84334397315979\n",
      "Step 9047/10000- lr: [9.606422181818184e-07] - Loss total: 2.544861316680908, Last rpr Loss: 0.999989926815033, Last lagvar Loss: 0.8433490991592407\n",
      "Step 9048/10000- lr: [9.5963212121212e-07] - Loss total: 2.544851064682007, Last rpr Loss: 1.000000238418579, Last lagvar Loss: 0.843338668346405\n",
      "Step 9049/10000- lr: [9.586220242424232e-07] - Loss total: 2.5448410511016846, Last rpr Loss: 0.9999923706054688, Last lagvar Loss: 0.843346357345581\n",
      "Step 9050/10000- lr: [9.576119272727265e-07] - Loss total: 2.544830799102783, Last rpr Loss: 0.9999933838844299, Last lagvar Loss: 0.8433454036712646\n",
      "Step 9051/10000- lr: [9.566018303030298e-07] - Loss total: 2.544820547103882, Last rpr Loss: 0.9999956488609314, Last lagvar Loss: 0.8433430194854736\n",
      "Step 9052/10000- lr: [9.55591733333333e-07] - Loss total: 2.5448105335235596, Last rpr Loss: 0.9999936819076538, Last lagvar Loss: 0.8433448672294617\n",
      "Step 9053/10000- lr: [9.545816363636363e-07] - Loss total: 2.5448005199432373, Last rpr Loss: 0.9999963045120239, Last lagvar Loss: 0.8433423042297363\n",
      "Step 9054/10000- lr: [9.535715393939379e-07] - Loss total: 2.544790029525757, Last rpr Loss: 0.9999936819076538, Last lagvar Loss: 0.8433448672294617\n",
      "Step 9055/10000- lr: [9.525614424242412e-07] - Loss total: 2.5447795391082764, Last rpr Loss: 0.9999903440475464, Last lagvar Loss: 0.8433480262756348\n",
      "Step 9056/10000- lr: [9.515513454545445e-07] - Loss total: 2.544769525527954, Last rpr Loss: 0.9999985694885254, Last lagvar Loss: 0.8433398008346558\n",
      "Step 9057/10000- lr: [9.505412484848478e-07] - Loss total: 2.5447592735290527, Last rpr Loss: 0.9999963045120239, Last lagvar Loss: 0.8433419466018677\n",
      "Step 9058/10000- lr: [9.49531151515151e-07] - Loss total: 2.5447492599487305, Last rpr Loss: 0.9999942183494568, Last lagvar Loss: 0.84334397315979\n",
      "Step 9059/10000- lr: [9.485210545454543e-07] - Loss total: 2.5447394847869873, Last rpr Loss: 0.9999961256980896, Last lagvar Loss: 0.8433419466018677\n",
      "Step 9060/10000- lr: [9.475109575757576e-07] - Loss total: 2.544729232788086, Last rpr Loss: 0.9999901652336121, Last lagvar Loss: 0.84334796667099\n",
      "Step 9061/10000- lr: [9.465008606060609e-07] - Loss total: 2.5447189807891846, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8433423042297363\n",
      "Step 9062/10000- lr: [9.454907636363641e-07] - Loss total: 2.5447092056274414, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.843343198299408\n",
      "Step 9063/10000- lr: [9.444806666666657e-07] - Loss total: 2.544699192047119, Last rpr Loss: 0.9999926686286926, Last lagvar Loss: 0.8433452844619751\n",
      "Step 9064/10000- lr: [9.43470569696969e-07] - Loss total: 2.5446889400482178, Last rpr Loss: 1.0000007152557373, Last lagvar Loss: 0.8433371186256409\n",
      "Step 9065/10000- lr: [9.424604727272723e-07] - Loss total: 2.5446791648864746, Last rpr Loss: 0.9999921321868896, Last lagvar Loss: 0.8433457016944885\n",
      "Step 9066/10000- lr: [9.414503757575756e-07] - Loss total: 2.5446691513061523, Last rpr Loss: 0.9999935626983643, Last lagvar Loss: 0.8433442115783691\n",
      "Step 9067/10000- lr: [9.404402787878788e-07] - Loss total: 2.544659376144409, Last rpr Loss: 0.9999971389770508, Last lagvar Loss: 0.8433405160903931\n",
      "Step 9068/10000- lr: [9.394301818181821e-07] - Loss total: 2.5446488857269287, Last rpr Loss: 0.9999900460243225, Last lagvar Loss: 0.8433476686477661\n",
      "Step 9069/10000- lr: [9.384200848484837e-07] - Loss total: 2.5446391105651855, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8433418273925781\n",
      "Step 9070/10000- lr: [9.374099878787887e-07] - Loss total: 2.544628858566284, Last rpr Loss: 0.9999960064888, Last lagvar Loss: 0.8433415293693542\n",
      "Step 9071/10000- lr: [9.363998909090903e-07] - Loss total: 2.544618844985962, Last rpr Loss: 0.9999936819076538, Last lagvar Loss: 0.8433439135551453\n",
      "Step 9072/10000- lr: [9.353897939393935e-07] - Loss total: 2.5446088314056396, Last rpr Loss: 0.9999955892562866, Last lagvar Loss: 0.8433419466018677\n",
      "Step 9073/10000- lr: [9.343796969696968e-07] - Loss total: 2.5445988178253174, Last rpr Loss: 0.9999960064888, Last lagvar Loss: 0.8433414101600647\n",
      "Step 9074/10000- lr: [9.333696000000001e-07] - Loss total: 2.5445892810821533, Last rpr Loss: 0.9999953508377075, Last lagvar Loss: 0.8433419466018677\n",
      "Step 9075/10000- lr: [9.323595030303017e-07] - Loss total: 2.544579267501831, Last rpr Loss: 0.9999953508377075, Last lagvar Loss: 0.8433419466018677\n",
      "Step 9076/10000- lr: [9.313494060606066e-07] - Loss total: 2.544569253921509, Last rpr Loss: 0.9999911785125732, Last lagvar Loss: 0.8433459997177124\n",
      "Step 9077/10000- lr: [9.303393090909082e-07] - Loss total: 2.5445592403411865, Last rpr Loss: 0.9999954104423523, Last lagvar Loss: 0.8433418273925781\n",
      "Step 9078/10000- lr: [9.293292121212115e-07] - Loss total: 2.5445492267608643, Last rpr Loss: 0.9999960064888, Last lagvar Loss: 0.8433411717414856\n",
      "Step 9079/10000- lr: [9.283191151515148e-07] - Loss total: 2.544539451599121, Last rpr Loss: 0.9999932646751404, Last lagvar Loss: 0.8433438539505005\n",
      "Step 9080/10000- lr: [9.27309018181818e-07] - Loss total: 2.544529676437378, Last rpr Loss: 0.9999949932098389, Last lagvar Loss: 0.843342125415802\n",
      "Step 9081/10000- lr: [9.262989212121213e-07] - Loss total: 2.5445194244384766, Last rpr Loss: 0.999992847442627, Last lagvar Loss: 0.8433441519737244\n",
      "Step 9082/10000- lr: [9.252888242424246e-07] - Loss total: 2.5445096492767334, Last rpr Loss: 0.9999973177909851, Last lagvar Loss: 0.8433396220207214\n",
      "Step 9083/10000- lr: [9.242787272727262e-07] - Loss total: 2.5444998741149902, Last rpr Loss: 0.9999949932098389, Last lagvar Loss: 0.8433418869972229\n",
      "Step 9084/10000- lr: [9.232686303030295e-07] - Loss total: 2.544490098953247, Last rpr Loss: 0.9999924898147583, Last lagvar Loss: 0.8433444499969482\n",
      "Step 9085/10000- lr: [9.222585333333327e-07] - Loss total: 2.544480562210083, Last rpr Loss: 0.9999992847442627, Last lagvar Loss: 0.8433375358581543\n",
      "Step 9086/10000- lr: [9.21248436363636e-07] - Loss total: 2.5444705486297607, Last rpr Loss: 0.9999929666519165, Last lagvar Loss: 0.8433438539505005\n",
      "Step 9087/10000- lr: [9.202383393939393e-07] - Loss total: 2.5444607734680176, Last rpr Loss: 0.9999936819076538, Last lagvar Loss: 0.8433431386947632\n",
      "Step 9088/10000- lr: [9.192282424242426e-07] - Loss total: 2.5444509983062744, Last rpr Loss: 0.9999959468841553, Last lagvar Loss: 0.8433408141136169\n",
      "Step 9089/10000- lr: [9.182181454545442e-07] - Loss total: 2.544440746307373, Last rpr Loss: 0.9999900460243225, Last lagvar Loss: 0.8433465957641602\n",
      "Step 9090/10000- lr: [9.172080484848491e-07] - Loss total: 2.544431209564209, Last rpr Loss: 0.9999969005584717, Last lagvar Loss: 0.8433396816253662\n",
      "Step 9091/10000- lr: [9.161979515151507e-07] - Loss total: 2.544421434402466, Last rpr Loss: 0.9999960660934448, Last lagvar Loss: 0.8433405160903931\n",
      "Step 9092/10000- lr: [9.15187854545454e-07] - Loss total: 2.5444116592407227, Last rpr Loss: 0.9999955892562866, Last lagvar Loss: 0.8433409929275513\n",
      "Step 9093/10000- lr: [9.141777575757573e-07] - Loss total: 2.5444018840789795, Last rpr Loss: 0.999994695186615, Last lagvar Loss: 0.8433417081832886\n",
      "Step 9094/10000- lr: [9.131676606060605e-07] - Loss total: 2.5443921089172363, Last rpr Loss: 0.9999942779541016, Last lagvar Loss: 0.8433421850204468\n",
      "Step 9095/10000- lr: [9.121575636363621e-07] - Loss total: 2.544382333755493, Last rpr Loss: 0.9999957084655762, Last lagvar Loss: 0.8433406352996826\n",
      "Step 9096/10000- lr: [9.111474666666671e-07] - Loss total: 2.54437255859375, Last rpr Loss: 0.9999918937683105, Last lagvar Loss: 0.8433444499969482\n",
      "Step 9097/10000- lr: [9.101373696969687e-07] - Loss total: 2.544362783432007, Last rpr Loss: 0.9999943971633911, Last lagvar Loss: 0.8433419466018677\n",
      "Step 9098/10000- lr: [9.09127272727272e-07] - Loss total: 2.5443532466888428, Last rpr Loss: 0.9999961853027344, Last lagvar Loss: 0.8433400392532349\n",
      "Step 9099/10000- lr: [9.081171757575752e-07] - Loss total: 2.5443432331085205, Last rpr Loss: 0.999994158744812, Last lagvar Loss: 0.8433420658111572\n",
      "Step 9100/10000- lr: [9.071070787878785e-07] - Loss total: 2.5443336963653564, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.843339741230011\n",
      "Step 9101/10000- lr: [9.060969818181818e-07] - Loss total: 2.5443241596221924, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.8433396816253662\n",
      "Step 9102/10000- lr: [9.050868848484851e-07] - Loss total: 2.5443146228790283, Last rpr Loss: 0.9999882578849792, Last lagvar Loss: 0.8433479070663452\n",
      "Step 9103/10000- lr: [9.040767878787866e-07] - Loss total: 2.544304609298706, Last rpr Loss: 0.9999989867210388, Last lagvar Loss: 0.8433370590209961\n",
      "Step 9104/10000- lr: [9.030666909090899e-07] - Loss total: 2.544295072555542, Last rpr Loss: 0.999997615814209, Last lagvar Loss: 0.8433384299278259\n",
      "Step 9105/10000- lr: [9.020565939393932e-07] - Loss total: 2.544285535812378, Last rpr Loss: 0.9999878406524658, Last lagvar Loss: 0.8433481454849243\n",
      "Step 9106/10000- lr: [9.010464969696965e-07] - Loss total: 2.5442757606506348, Last rpr Loss: 0.9999980926513672, Last lagvar Loss: 0.843337893486023\n",
      "Step 9107/10000- lr: [9.000363999999998e-07] - Loss total: 2.5442659854888916, Last rpr Loss: 0.9999968409538269, Last lagvar Loss: 0.8433389663696289\n",
      "Step 9108/10000- lr: [8.99026303030303e-07] - Loss total: 2.5442566871643066, Last rpr Loss: 0.9999877214431763, Last lagvar Loss: 0.8433481454849243\n",
      "Step 9109/10000- lr: [8.980162060606046e-07] - Loss total: 2.5442473888397217, Last rpr Loss: 1.0, Last lagvar Loss: 0.8433358073234558\n",
      "Step 9110/10000- lr: [8.970061090909096e-07] - Loss total: 2.544236898422241, Last rpr Loss: 0.9999969005584717, Last lagvar Loss: 0.8433388471603394\n",
      "Step 9111/10000- lr: [8.959960121212112e-07] - Loss total: 2.544227361679077, Last rpr Loss: 0.9999890327453613, Last lagvar Loss: 0.8433467149734497\n",
      "Step 9112/10000- lr: [8.949859151515144e-07] - Loss total: 2.544217824935913, Last rpr Loss: 0.9999997615814209, Last lagvar Loss: 0.8433359265327454\n",
      "Step 9113/10000- lr: [8.939758181818177e-07] - Loss total: 2.544208288192749, Last rpr Loss: 0.9999931454658508, Last lagvar Loss: 0.8433425426483154\n",
      "Step 9114/10000- lr: [8.92965721212121e-07] - Loss total: 2.544198751449585, Last rpr Loss: 0.9999898672103882, Last lagvar Loss: 0.8433458209037781\n",
      "Step 9115/10000- lr: [8.919556242424226e-07] - Loss total: 2.544189453125, Last rpr Loss: 1.0000019073486328, Last lagvar Loss: 0.8433336019515991\n",
      "Step 9116/10000- lr: [8.909455272727276e-07] - Loss total: 2.544179677963257, Last rpr Loss: 0.9999911785125732, Last lagvar Loss: 0.8433443307876587\n",
      "Step 9117/10000- lr: [8.899354303030291e-07] - Loss total: 2.5441701412200928, Last rpr Loss: 0.9999902248382568, Last lagvar Loss: 0.8433452844619751\n",
      "Step 9118/10000- lr: [8.889253333333324e-07] - Loss total: 2.544160842895508, Last rpr Loss: 1.000001311302185, Last lagvar Loss: 0.8433340787887573\n",
      "Step 9119/10000- lr: [8.879152363636357e-07] - Loss total: 2.5441510677337646, Last rpr Loss: 0.9999912977218628, Last lagvar Loss: 0.8433441519737244\n",
      "Step 9120/10000- lr: [8.86905139393939e-07] - Loss total: 2.5441417694091797, Last rpr Loss: 0.9999924302101135, Last lagvar Loss: 0.8433430194854736\n",
      "Step 9121/10000- lr: [8.858950424242422e-07] - Loss total: 2.5441322326660156, Last rpr Loss: 1.000000238418579, Last lagvar Loss: 0.8433351516723633\n",
      "Step 9122/10000- lr: [8.848849454545455e-07] - Loss total: 2.5441226959228516, Last rpr Loss: 0.999993085861206, Last lagvar Loss: 0.8433423042297363\n",
      "Step 9123/10000- lr: [8.838748484848471e-07] - Loss total: 2.5441131591796875, Last rpr Loss: 0.9999914169311523, Last lagvar Loss: 0.8433439135551453\n",
      "Step 9124/10000- lr: [8.828647515151504e-07] - Loss total: 2.5441038608551025, Last rpr Loss: 0.9999979734420776, Last lagvar Loss: 0.8433372974395752\n",
      "Step 9125/10000- lr: [8.818546545454537e-07] - Loss total: 2.5440945625305176, Last rpr Loss: 0.9999934434890747, Last lagvar Loss: 0.8433417677879333\n",
      "Step 9126/10000- lr: [8.808445575757569e-07] - Loss total: 2.5440847873687744, Last rpr Loss: 0.9999939203262329, Last lagvar Loss: 0.8433412313461304\n",
      "Step 9127/10000- lr: [8.798344606060602e-07] - Loss total: 2.5440754890441895, Last rpr Loss: 0.9999946355819702, Last lagvar Loss: 0.8433405756950378\n",
      "Step 9128/10000- lr: [8.788243636363635e-07] - Loss total: 2.5440661907196045, Last rpr Loss: 0.9999950528144836, Last lagvar Loss: 0.8433401584625244\n",
      "Step 9129/10000- lr: [8.778142666666651e-07] - Loss total: 2.5440564155578613, Last rpr Loss: 0.9999945163726807, Last lagvar Loss: 0.8433405160903931\n",
      "Step 9130/10000- lr: [8.7680416969697e-07] - Loss total: 2.5440471172332764, Last rpr Loss: 0.9999952912330627, Last lagvar Loss: 0.8433396816253662\n",
      "Step 9131/10000- lr: [8.757940727272716e-07] - Loss total: 2.544037342071533, Last rpr Loss: 0.9999929666519165, Last lagvar Loss: 0.8433420658111572\n",
      "Step 9132/10000- lr: [8.747839757575749e-07] - Loss total: 2.5440282821655273, Last rpr Loss: 0.9999945163726807, Last lagvar Loss: 0.8433405160903931\n",
      "Step 9133/10000- lr: [8.737738787878782e-07] - Loss total: 2.5440187454223633, Last rpr Loss: 0.9999947547912598, Last lagvar Loss: 0.843340277671814\n",
      "Step 9134/10000- lr: [8.727637818181815e-07] - Loss total: 2.5440094470977783, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8433399796485901\n",
      "Step 9135/10000- lr: [8.71753684848483e-07] - Loss total: 2.5439999103546143, Last rpr Loss: 0.9999961853027344, Last lagvar Loss: 0.8433387279510498\n",
      "Step 9136/10000- lr: [8.70743587878788e-07] - Loss total: 2.54399037361145, Last rpr Loss: 0.9999932050704956, Last lagvar Loss: 0.8433416485786438\n",
      "Step 9137/10000- lr: [8.697334909090896e-07] - Loss total: 2.5439813137054443, Last rpr Loss: 0.9999942779541016, Last lagvar Loss: 0.8433405756950378\n",
      "Step 9138/10000- lr: [8.687233939393929e-07] - Loss total: 2.543971538543701, Last rpr Loss: 0.999995768070221, Last lagvar Loss: 0.8433389663696289\n",
      "Step 9139/10000- lr: [8.677132969696962e-07] - Loss total: 2.5439624786376953, Last rpr Loss: 0.9999930262565613, Last lagvar Loss: 0.8433417081832886\n",
      "Step 9140/10000- lr: [8.667031999999994e-07] - Loss total: 2.5439531803131104, Last rpr Loss: 0.9999923706054688, Last lagvar Loss: 0.8433423638343811\n",
      "Step 9141/10000- lr: [8.656931030303027e-07] - Loss total: 2.5439438819885254, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.8433383107185364\n",
      "Step 9142/10000- lr: [8.64683006060606e-07] - Loss total: 2.5439343452453613, Last rpr Loss: 0.9999921321868896, Last lagvar Loss: 0.8433425426483154\n",
      "Step 9143/10000- lr: [8.636729090909076e-07] - Loss total: 2.5439255237579346, Last rpr Loss: 0.9999974966049194, Last lagvar Loss: 0.8433371186256409\n",
      "Step 9144/10000- lr: [8.626628121212108e-07] - Loss total: 2.5439159870147705, Last rpr Loss: 0.9999982118606567, Last lagvar Loss: 0.8433364033699036\n",
      "Step 9145/10000- lr: [8.616527151515158e-07] - Loss total: 2.5439066886901855, Last rpr Loss: 0.9999907612800598, Last lagvar Loss: 0.8433437347412109\n",
      "Step 9146/10000- lr: [8.606426181818174e-07] - Loss total: 2.5438973903656006, Last rpr Loss: 0.9999973773956299, Last lagvar Loss: 0.8433371782302856\n",
      "Step 9147/10000- lr: [8.596325212121207e-07] - Loss total: 2.5438880920410156, Last rpr Loss: 0.9999930262565613, Last lagvar Loss: 0.8433415293693542\n",
      "Step 9148/10000- lr: [8.58622424242424e-07] - Loss total: 2.5438790321350098, Last rpr Loss: 0.9999876618385315, Last lagvar Loss: 0.8433467745780945\n",
      "Step 9149/10000- lr: [8.576123272727272e-07] - Loss total: 2.543869733810425, Last rpr Loss: 0.9999967813491821, Last lagvar Loss: 0.8433376550674438\n",
      "Step 9150/10000- lr: [8.566022303030305e-07] - Loss total: 2.54386043548584, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.843338668346405\n",
      "Step 9151/10000- lr: [8.555921333333338e-07] - Loss total: 2.543851137161255, Last rpr Loss: 0.9999931454658508, Last lagvar Loss: 0.8433411121368408\n",
      "Step 9152/10000- lr: [8.545820363636354e-07] - Loss total: 2.543842077255249, Last rpr Loss: 0.9999978542327881, Last lagvar Loss: 0.8433364629745483\n",
      "Step 9153/10000- lr: [8.535719393939386e-07] - Loss total: 2.543832540512085, Last rpr Loss: 0.9999953508377075, Last lagvar Loss: 0.8433389663696289\n",
      "Step 9154/10000- lr: [8.525618424242419e-07] - Loss total: 2.543823719024658, Last rpr Loss: 0.9999921917915344, Last lagvar Loss: 0.843342125415802\n",
      "Step 9155/10000- lr: [8.515517454545452e-07] - Loss total: 2.543814182281494, Last rpr Loss: 0.999997615814209, Last lagvar Loss: 0.8433367013931274\n",
      "Step 9156/10000- lr: [8.505416484848485e-07] - Loss total: 2.5438051223754883, Last rpr Loss: 0.9999918341636658, Last lagvar Loss: 0.8433424830436707\n",
      "Step 9157/10000- lr: [8.495315515151518e-07] - Loss total: 2.5437958240509033, Last rpr Loss: 0.999993085861206, Last lagvar Loss: 0.8433411121368408\n",
      "Step 9158/10000- lr: [8.485214545454533e-07] - Loss total: 2.5437867641448975, Last rpr Loss: 0.9999969005584717, Last lagvar Loss: 0.84333735704422\n",
      "Step 9159/10000- lr: [8.475113575757583e-07] - Loss total: 2.5437774658203125, Last rpr Loss: 0.9999909400939941, Last lagvar Loss: 0.8433432579040527\n",
      "Step 9160/10000- lr: [8.465012606060599e-07] - Loss total: 2.5437686443328857, Last rpr Loss: 0.999993622303009, Last lagvar Loss: 0.8433405160903931\n",
      "Step 9161/10000- lr: [8.454911636363632e-07] - Loss total: 2.543759346008301, Last rpr Loss: 0.999996542930603, Last lagvar Loss: 0.8433375954627991\n",
      "Step 9162/10000- lr: [8.444810666666664e-07] - Loss total: 2.543750047683716, Last rpr Loss: 0.9999929666519165, Last lagvar Loss: 0.8433411121368408\n",
      "Step 9163/10000- lr: [8.434709696969697e-07] - Loss total: 2.5437405109405518, Last rpr Loss: 0.9999951124191284, Last lagvar Loss: 0.8433390259742737\n",
      "Step 9164/10000- lr: [8.424608727272713e-07] - Loss total: 2.543731451034546, Last rpr Loss: 0.9999959468841553, Last lagvar Loss: 0.843338131904602\n",
      "Step 9165/10000- lr: [8.414507757575763e-07] - Loss total: 2.54372239112854, Last rpr Loss: 0.999994695186615, Last lagvar Loss: 0.8433393239974976\n",
      "Step 9166/10000- lr: [8.404406787878779e-07] - Loss total: 2.543713331222534, Last rpr Loss: 0.9999933838844299, Last lagvar Loss: 0.8433406949043274\n",
      "Step 9167/10000- lr: [8.394305818181811e-07] - Loss total: 2.5437042713165283, Last rpr Loss: 0.9999955892562866, Last lagvar Loss: 0.8433383703231812\n",
      "Step 9168/10000- lr: [8.384204848484844e-07] - Loss total: 2.5436952114105225, Last rpr Loss: 0.9999929070472717, Last lagvar Loss: 0.8433409929275513\n",
      "Step 9169/10000- lr: [8.374103878787877e-07] - Loss total: 2.5436861515045166, Last rpr Loss: 0.9999918341636658, Last lagvar Loss: 0.8433420658111572\n",
      "Step 9170/10000- lr: [8.36400290909091e-07] - Loss total: 2.54367733001709, Last rpr Loss: 0.9999952912330627, Last lagvar Loss: 0.843338668346405\n",
      "Step 9171/10000- lr: [8.353901939393942e-07] - Loss total: 2.543668031692505, Last rpr Loss: 0.9999953508377075, Last lagvar Loss: 0.8433386087417603\n",
      "Step 9172/10000- lr: [8.343800969696958e-07] - Loss total: 2.543658971786499, Last rpr Loss: 0.9999940395355225, Last lagvar Loss: 0.8433398604393005\n",
      "Step 9173/10000- lr: [8.333699999999991e-07] - Loss total: 2.5436501502990723, Last rpr Loss: 0.9999966025352478, Last lagvar Loss: 0.8433372378349304\n",
      "Step 9174/10000- lr: [8.323599030303024e-07] - Loss total: 2.5436410903930664, Last rpr Loss: 0.9999940395355225, Last lagvar Loss: 0.843339741230011\n",
      "Step 9175/10000- lr: [8.313498060606057e-07] - Loss total: 2.5436317920684814, Last rpr Loss: 0.9999926686286926, Last lagvar Loss: 0.8433411121368408\n",
      "Step 9176/10000- lr: [8.303397090909089e-07] - Loss total: 2.5436227321624756, Last rpr Loss: 0.9999954700469971, Last lagvar Loss: 0.8433383107185364\n",
      "Step 9177/10000- lr: [8.293296121212122e-07] - Loss total: 2.543613910675049, Last rpr Loss: 0.9999935626983643, Last lagvar Loss: 0.8433401584625244\n",
      "Step 9178/10000- lr: [8.283195151515138e-07] - Loss total: 2.543604850769043, Last rpr Loss: 0.9999912977218628, Last lagvar Loss: 0.8433424234390259\n",
      "Step 9179/10000- lr: [8.273094181818188e-07] - Loss total: 2.543595790863037, Last rpr Loss: 0.9999939203262329, Last lagvar Loss: 0.843339741230011\n",
      "Step 9180/10000- lr: [8.262993212121203e-07] - Loss total: 2.5435869693756104, Last rpr Loss: 0.999995231628418, Last lagvar Loss: 0.8433384895324707\n",
      "Step 9181/10000- lr: [8.252892242424236e-07] - Loss total: 2.5435776710510254, Last rpr Loss: 0.9999946355819702, Last lagvar Loss: 0.8433390259742737\n",
      "Step 9182/10000- lr: [8.242791272727269e-07] - Loss total: 2.5435688495635986, Last rpr Loss: 0.9999945759773254, Last lagvar Loss: 0.8433390855789185\n",
      "Step 9183/10000- lr: [8.232690303030302e-07] - Loss total: 2.5435595512390137, Last rpr Loss: 0.9999969005584717, Last lagvar Loss: 0.8433367013931274\n",
      "Step 9184/10000- lr: [8.222589333333318e-07] - Loss total: 2.543550729751587, Last rpr Loss: 0.9999935030937195, Last lagvar Loss: 0.8433400392532349\n",
      "Step 9185/10000- lr: [8.212488363636367e-07] - Loss total: 2.543541669845581, Last rpr Loss: 0.999992847442627, Last lagvar Loss: 0.8433407545089722\n",
      "Step 9186/10000- lr: [8.202387393939383e-07] - Loss total: 2.5435328483581543, Last rpr Loss: 0.999996542930603, Last lagvar Loss: 0.8433369994163513\n",
      "Step 9187/10000- lr: [8.192286424242416e-07] - Loss total: 2.5435240268707275, Last rpr Loss: 0.9999921917915344, Last lagvar Loss: 0.8433412313461304\n",
      "Step 9188/10000- lr: [8.182185454545449e-07] - Loss total: 2.543515205383301, Last rpr Loss: 0.9999904036521912, Last lagvar Loss: 0.8433431386947632\n",
      "Step 9189/10000- lr: [8.172084484848481e-07] - Loss total: 2.543505907058716, Last rpr Loss: 0.9999973773956299, Last lagvar Loss: 0.8433361649513245\n",
      "Step 9190/10000- lr: [8.161983515151514e-07] - Loss total: 2.543497323989868, Last rpr Loss: 0.9999918341636658, Last lagvar Loss: 0.8433417081832886\n",
      "Step 9191/10000- lr: [8.151882545454547e-07] - Loss total: 2.5434885025024414, Last rpr Loss: 0.9999943375587463, Last lagvar Loss: 0.8433391451835632\n",
      "Step 9192/10000- lr: [8.141781575757563e-07] - Loss total: 2.5434796810150146, Last rpr Loss: 0.999999463558197, Last lagvar Loss: 0.8433339595794678\n",
      "Step 9193/10000- lr: [8.131680606060596e-07] - Loss total: 2.543470621109009, Last rpr Loss: 0.9999920725822449, Last lagvar Loss: 0.8433413505554199\n",
      "Step 9194/10000- lr: [8.121579636363628e-07] - Loss total: 2.543461799621582, Last rpr Loss: 0.9999925494194031, Last lagvar Loss: 0.8433408737182617\n",
      "Step 9195/10000- lr: [8.111478666666661e-07] - Loss total: 2.5434529781341553, Last rpr Loss: 0.999997079372406, Last lagvar Loss: 0.8433362245559692\n",
      "Step 9196/10000- lr: [8.101377696969694e-07] - Loss total: 2.5434441566467285, Last rpr Loss: 0.9999920129776001, Last lagvar Loss: 0.8433414101600647\n",
      "Step 9197/10000- lr: [8.091276727272727e-07] - Loss total: 2.5434353351593018, Last rpr Loss: 0.9999904036521912, Last lagvar Loss: 0.8433428406715393\n",
      "Step 9198/10000- lr: [8.081175757575743e-07] - Loss total: 2.543426036834717, Last rpr Loss: 0.9999967217445374, Last lagvar Loss: 0.8433366417884827\n",
      "Step 9199/10000- lr: [8.071074787878792e-07] - Loss total: 2.543417453765869, Last rpr Loss: 0.999993622303009, Last lagvar Loss: 0.8433395624160767\n",
      "Step 9200/10000- lr: [8.060973818181808e-07] - Loss total: 2.5434086322784424, Last rpr Loss: 0.9999921917915344, Last lagvar Loss: 0.843341052532196\n",
      "Step 9201/10000- lr: [8.050872848484841e-07] - Loss total: 2.5433998107910156, Last rpr Loss: 0.9999995231628418, Last lagvar Loss: 0.8433338403701782\n",
      "Step 9202/10000- lr: [8.040771878787874e-07] - Loss total: 2.543390989303589, Last rpr Loss: 0.9999915957450867, Last lagvar Loss: 0.8433415293693542\n",
      "Step 9203/10000- lr: [8.030670909090906e-07] - Loss total: 2.543381929397583, Last rpr Loss: 0.9999926686286926, Last lagvar Loss: 0.8433405160903931\n",
      "Step 9204/10000- lr: [8.020569939393939e-07] - Loss total: 2.5433731079101562, Last rpr Loss: 0.9999968409538269, Last lagvar Loss: 0.8433363437652588\n",
      "Step 9205/10000- lr: [8.010468969696972e-07] - Loss total: 2.5433645248413086, Last rpr Loss: 0.9999933838844299, Last lagvar Loss: 0.8433398008346558\n",
      "Step 9206/10000- lr: [8.000367999999988e-07] - Loss total: 2.543355703353882, Last rpr Loss: 0.9999923706054688, Last lagvar Loss: 0.8433407545089722\n",
      "Step 9207/10000- lr: [7.990267030303021e-07] - Loss total: 2.543347120285034, Last rpr Loss: 0.9999943971633911, Last lagvar Loss: 0.8433387279510498\n",
      "Step 9208/10000- lr: [7.980166060606053e-07] - Loss total: 2.5433380603790283, Last rpr Loss: 0.9999939203262329, Last lagvar Loss: 0.8433391451835632\n",
      "Step 9209/10000- lr: [7.970065090909086e-07] - Loss total: 2.5433292388916016, Last rpr Loss: 0.9999921321868896, Last lagvar Loss: 0.8433409929275513\n",
      "Step 9210/10000- lr: [7.959964121212119e-07] - Loss total: 2.543320655822754, Last rpr Loss: 0.9999953508377075, Last lagvar Loss: 0.8433376550674438\n",
      "Step 9211/10000- lr: [7.949863151515152e-07] - Loss total: 2.5433120727539062, Last rpr Loss: 0.9999948143959045, Last lagvar Loss: 0.8433382511138916\n",
      "Step 9212/10000- lr: [7.939762181818167e-07] - Loss total: 2.5433032512664795, Last rpr Loss: 0.999994158744812, Last lagvar Loss: 0.8433388471603394\n",
      "Step 9213/10000- lr: [7.9296612121212e-07] - Loss total: 2.5432944297790527, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8433371782302856\n",
      "Step 9214/10000- lr: [7.919560242424233e-07] - Loss total: 2.543285846710205, Last rpr Loss: 0.9999925494194031, Last lagvar Loss: 0.8433404564857483\n",
      "Step 9215/10000- lr: [7.909459272727266e-07] - Loss total: 2.5432772636413574, Last rpr Loss: 0.999991774559021, Last lagvar Loss: 0.8433411121368408\n",
      "Step 9216/10000- lr: [7.899358303030299e-07] - Loss total: 2.5432684421539307, Last rpr Loss: 0.9999943375587463, Last lagvar Loss: 0.8433386087417603\n",
      "Step 9217/10000- lr: [7.889257333333331e-07] - Loss total: 2.543259859085083, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8433379530906677\n",
      "Step 9218/10000- lr: [7.879156363636347e-07] - Loss total: 2.5432512760162354, Last rpr Loss: 0.9999927282333374, Last lagvar Loss: 0.8433400988578796\n",
      "Step 9219/10000- lr: [7.869055393939397e-07] - Loss total: 2.5432424545288086, Last rpr Loss: 0.9999942779541016, Last lagvar Loss: 0.8433384895324707\n",
      "Step 9220/10000- lr: [7.858954424242413e-07] - Loss total: 2.543233871459961, Last rpr Loss: 0.9999944567680359, Last lagvar Loss: 0.8433383703231812\n",
      "Step 9221/10000- lr: [7.848853454545445e-07] - Loss total: 2.5432252883911133, Last rpr Loss: 0.9999925494194031, Last lagvar Loss: 0.843340277671814\n",
      "Step 9222/10000- lr: [7.838752484848478e-07] - Loss total: 2.5432167053222656, Last rpr Loss: 0.9999942779541016, Last lagvar Loss: 0.8433386087417603\n",
      "Step 9223/10000- lr: [7.828651515151511e-07] - Loss total: 2.543208122253418, Last rpr Loss: 0.9999951124191284, Last lagvar Loss: 0.8433376550674438\n",
      "Step 9224/10000- lr: [7.818550545454544e-07] - Loss total: 2.5431995391845703, Last rpr Loss: 0.9999930262565613, Last lagvar Loss: 0.8433398008346558\n",
      "Step 9225/10000- lr: [7.808449575757577e-07] - Loss total: 2.5431911945343018, Last rpr Loss: 0.9999949932098389, Last lagvar Loss: 0.8433377146720886\n",
      "Step 9226/10000- lr: [7.798348606060592e-07] - Loss total: 2.543182134628296, Last rpr Loss: 0.9999935030937195, Last lagvar Loss: 0.843339204788208\n",
      "Step 9227/10000- lr: [7.788247636363625e-07] - Loss total: 2.5431737899780273, Last rpr Loss: 0.9999918937683105, Last lagvar Loss: 0.8433408141136169\n",
      "Step 9228/10000- lr: [7.778146666666658e-07] - Loss total: 2.5431649684906006, Last rpr Loss: 0.9999933242797852, Last lagvar Loss: 0.8433393836021423\n",
      "Step 9229/10000- lr: [7.768045696969691e-07] - Loss total: 2.543156623840332, Last rpr Loss: 0.9999950528144836, Last lagvar Loss: 0.8433376550674438\n",
      "Step 9230/10000- lr: [7.757944727272723e-07] - Loss total: 2.5431478023529053, Last rpr Loss: 0.999996542930603, Last lagvar Loss: 0.8433360457420349\n",
      "Step 9231/10000- lr: [7.747843757575756e-07] - Loss total: 2.5431394577026367, Last rpr Loss: 0.9999927282333374, Last lagvar Loss: 0.8433399200439453\n",
      "Step 9232/10000- lr: [7.737742787878789e-07] - Loss total: 2.54313063621521, Last rpr Loss: 0.9999931454658508, Last lagvar Loss: 0.8433394432067871\n",
      "Step 9233/10000- lr: [7.727641818181805e-07] - Loss total: 2.5431222915649414, Last rpr Loss: 0.9999936819076538, Last lagvar Loss: 0.8433389067649841\n",
      "Step 9234/10000- lr: [7.717540848484855e-07] - Loss total: 2.5431134700775146, Last rpr Loss: 0.9999918937683105, Last lagvar Loss: 0.8433406949043274\n",
      "Step 9235/10000- lr: [7.70743987878787e-07] - Loss total: 2.543105363845825, Last rpr Loss: 0.9999933838844299, Last lagvar Loss: 0.843339204788208\n",
      "Step 9236/10000- lr: [7.697338909090903e-07] - Loss total: 2.5430967807769775, Last rpr Loss: 0.9999947547912598, Last lagvar Loss: 0.8433378338813782\n",
      "Step 9237/10000- lr: [7.687237939393936e-07] - Loss total: 2.543087959289551, Last rpr Loss: 0.999992311000824, Last lagvar Loss: 0.8433402180671692\n",
      "Step 9238/10000- lr: [7.677136969696969e-07] - Loss total: 2.5430798530578613, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8433367013931274\n",
      "Step 9239/10000- lr: [7.667036000000001e-07] - Loss total: 2.5430712699890137, Last rpr Loss: 0.9999955892562866, Last lagvar Loss: 0.8433369398117065\n",
      "Step 9240/10000- lr: [7.656935030303034e-07] - Loss total: 2.543062686920166, Last rpr Loss: 0.9999925494194031, Last lagvar Loss: 0.8433400392532349\n",
      "Step 9241/10000- lr: [7.64683406060605e-07] - Loss total: 2.5430543422698975, Last rpr Loss: 0.999993622303009, Last lagvar Loss: 0.8433389663696289\n",
      "Step 9242/10000- lr: [7.636733090909083e-07] - Loss total: 2.5430455207824707, Last rpr Loss: 0.9999958872795105, Last lagvar Loss: 0.8433365821838379\n",
      "Step 9243/10000- lr: [7.626632121212116e-07] - Loss total: 2.5430374145507812, Last rpr Loss: 0.9999905824661255, Last lagvar Loss: 0.8433418273925781\n",
      "Step 9244/10000- lr: [7.616531151515148e-07] - Loss total: 2.5430285930633545, Last rpr Loss: 0.9999938011169434, Last lagvar Loss: 0.8433386087417603\n",
      "Step 9245/10000- lr: [7.606430181818181e-07] - Loss total: 2.543020486831665, Last rpr Loss: 0.9999951124191284, Last lagvar Loss: 0.8433371782302856\n",
      "Step 9246/10000- lr: [7.596329212121214e-07] - Loss total: 2.5430119037628174, Last rpr Loss: 0.9999922513961792, Last lagvar Loss: 0.8433401584625244\n",
      "Step 9247/10000- lr: [7.58622824242423e-07] - Loss total: 2.543003559112549, Last rpr Loss: 0.9999940395355225, Last lagvar Loss: 0.8433383703231812\n",
      "Step 9248/10000- lr: [7.576127272727279e-07] - Loss total: 2.5429952144622803, Last rpr Loss: 0.9999943971633911, Last lagvar Loss: 0.8433379530906677\n",
      "Step 9249/10000- lr: [7.566026303030295e-07] - Loss total: 2.5429866313934326, Last rpr Loss: 0.9999917149543762, Last lagvar Loss: 0.8433405756950378\n",
      "Step 9250/10000- lr: [7.555925333333328e-07] - Loss total: 2.542978286743164, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8433364629745483\n",
      "Step 9251/10000- lr: [7.545824363636361e-07] - Loss total: 2.5429699420928955, Last rpr Loss: 0.9999932050704956, Last lagvar Loss: 0.8433390855789185\n",
      "Step 9252/10000- lr: [7.535723393939394e-07] - Loss total: 2.542961359024048, Last rpr Loss: 0.999993085861206, Last lagvar Loss: 0.843339204788208\n",
      "Step 9253/10000- lr: [7.525622424242426e-07] - Loss total: 2.5429532527923584, Last rpr Loss: 0.9999953508377075, Last lagvar Loss: 0.8433369398117065\n",
      "Step 9254/10000- lr: [7.515521454545459e-07] - Loss total: 2.54294490814209, Last rpr Loss: 0.9999936819076538, Last lagvar Loss: 0.8433385491371155\n",
      "Step 9255/10000- lr: [7.505420484848475e-07] - Loss total: 2.5429365634918213, Last rpr Loss: 0.9999915361404419, Last lagvar Loss: 0.8433406352996826\n",
      "Step 9256/10000- lr: [7.495319515151508e-07] - Loss total: 2.5429282188415527, Last rpr Loss: 0.9999937415122986, Last lagvar Loss: 0.8433384895324707\n",
      "Step 9257/10000- lr: [7.48521854545454e-07] - Loss total: 2.5429201126098633, Last rpr Loss: 0.9999940991401672, Last lagvar Loss: 0.843338131904602\n",
      "Step 9258/10000- lr: [7.475117575757573e-07] - Loss total: 2.5429115295410156, Last rpr Loss: 0.9999936819076538, Last lagvar Loss: 0.8433385491371155\n",
      "Step 9259/10000- lr: [7.465016606060606e-07] - Loss total: 2.542903184890747, Last rpr Loss: 0.9999946355819702, Last lagvar Loss: 0.8433375954627991\n",
      "Step 9260/10000- lr: [7.454915636363639e-07] - Loss total: 2.5428950786590576, Last rpr Loss: 0.9999908208847046, Last lagvar Loss: 0.8433413505554199\n",
      "Step 9261/10000- lr: [7.444814666666655e-07] - Loss total: 2.542886972427368, Last rpr Loss: 0.999994695186615, Last lagvar Loss: 0.8433374166488647\n",
      "Step 9262/10000- lr: [7.434713696969687e-07] - Loss total: 2.5428783893585205, Last rpr Loss: 0.9999953508377075, Last lagvar Loss: 0.8433367013931274\n",
      "Step 9263/10000- lr: [7.42461272727272e-07] - Loss total: 2.542870283126831, Last rpr Loss: 0.9999940991401672, Last lagvar Loss: 0.8433379530906677\n",
      "Step 9264/10000- lr: [7.414511757575753e-07] - Loss total: 2.5428621768951416, Last rpr Loss: 0.9999939203262329, Last lagvar Loss: 0.843338131904602\n",
      "Step 9265/10000- lr: [7.404410787878786e-07] - Loss total: 2.542853832244873, Last rpr Loss: 0.9999937415122986, Last lagvar Loss: 0.8433383107185364\n",
      "Step 9266/10000- lr: [7.394309818181818e-07] - Loss total: 2.5428457260131836, Last rpr Loss: 0.9999920129776001, Last lagvar Loss: 0.8433400392532349\n",
      "Step 9267/10000- lr: [7.384208848484834e-07] - Loss total: 2.542837142944336, Last rpr Loss: 0.999992847442627, Last lagvar Loss: 0.843339204788208\n",
      "Step 9268/10000- lr: [7.374107878787884e-07] - Loss total: 2.5428290367126465, Last rpr Loss: 0.9999958872795105, Last lagvar Loss: 0.8433361649513245\n",
      "Step 9269/10000- lr: [7.3640069090909e-07] - Loss total: 2.542821168899536, Last rpr Loss: 0.999993622303009, Last lagvar Loss: 0.8433383703231812\n",
      "Step 9270/10000- lr: [7.353905939393933e-07] - Loss total: 2.5428125858306885, Last rpr Loss: 0.9999890327453613, Last lagvar Loss: 0.8433429598808289\n",
      "Step 9271/10000- lr: [7.343804969696965e-07] - Loss total: 2.542804479598999, Last rpr Loss: 0.9999966621398926, Last lagvar Loss: 0.8433352112770081\n",
      "Step 9272/10000- lr: [7.333703999999998e-07] - Loss total: 2.5427963733673096, Last rpr Loss: 0.9999936819076538, Last lagvar Loss: 0.8433382511138916\n",
      "Step 9273/10000- lr: [7.323603030303031e-07] - Loss total: 2.542788505554199, Last rpr Loss: 0.9999915361404419, Last lagvar Loss: 0.8433403968811035\n",
      "Step 9274/10000- lr: [7.313502060606064e-07] - Loss total: 2.5427801609039307, Last rpr Loss: 0.9999947547912598, Last lagvar Loss: 0.8433371782302856\n",
      "Step 9275/10000- lr: [7.30340109090908e-07] - Loss total: 2.542772054672241, Last rpr Loss: 0.9999942183494568, Last lagvar Loss: 0.8433376550674438\n",
      "Step 9276/10000- lr: [7.293300121212112e-07] - Loss total: 2.5427637100219727, Last rpr Loss: 0.9999935626983643, Last lagvar Loss: 0.8433383703231812\n",
      "Step 9277/10000- lr: [7.283199151515145e-07] - Loss total: 2.542755603790283, Last rpr Loss: 0.9999956488609314, Last lagvar Loss: 0.8433362245559692\n",
      "Step 9278/10000- lr: [7.273098181818178e-07] - Loss total: 2.5427474975585938, Last rpr Loss: 0.9999936819076538, Last lagvar Loss: 0.8433382511138916\n",
      "Step 9279/10000- lr: [7.262997212121211e-07] - Loss total: 2.5427393913269043, Last rpr Loss: 0.9999920129776001, Last lagvar Loss: 0.8433398008346558\n",
      "Step 9280/10000- lr: [7.252896242424243e-07] - Loss total: 2.542731523513794, Last rpr Loss: 0.9999936819076538, Last lagvar Loss: 0.843338131904602\n",
      "Step 9281/10000- lr: [7.242795272727259e-07] - Loss total: 2.5427234172821045, Last rpr Loss: 0.999994158744812, Last lagvar Loss: 0.8433376550674438\n",
      "Step 9282/10000- lr: [7.232694303030292e-07] - Loss total: 2.542715311050415, Last rpr Loss: 0.9999921321868896, Last lagvar Loss: 0.843339741230011\n",
      "Step 9283/10000- lr: [7.222593333333325e-07] - Loss total: 2.5427072048187256, Last rpr Loss: 0.9999931454658508, Last lagvar Loss: 0.8433386087417603\n",
      "Step 9284/10000- lr: [7.212492363636358e-07] - Loss total: 2.542699098587036, Last rpr Loss: 0.9999922513961792, Last lagvar Loss: 0.8433394432067871\n",
      "Step 9285/10000- lr: [7.20239139393939e-07] - Loss total: 2.542691230773926, Last rpr Loss: 0.9999942183494568, Last lagvar Loss: 0.8433374762535095\n",
      "Step 9286/10000- lr: [7.192290424242423e-07] - Loss total: 2.5426833629608154, Last rpr Loss: 0.9999967813491821, Last lagvar Loss: 0.843334972858429\n",
      "Step 9287/10000- lr: [7.182189454545439e-07] - Loss total: 2.542675018310547, Last rpr Loss: 0.9999938011169434, Last lagvar Loss: 0.843337893486023\n",
      "Step 9288/10000- lr: [7.172088484848489e-07] - Loss total: 2.5426669120788574, Last rpr Loss: 0.9999933242797852, Last lagvar Loss: 0.8433383107185364\n",
      "Step 9289/10000- lr: [7.161987515151504e-07] - Loss total: 2.542659044265747, Last rpr Loss: 0.9999939203262329, Last lagvar Loss: 0.8433377146720886\n",
      "Step 9290/10000- lr: [7.151886545454537e-07] - Loss total: 2.5426511764526367, Last rpr Loss: 0.9999924898147583, Last lagvar Loss: 0.8433391451835632\n",
      "Step 9291/10000- lr: [7.14178557575757e-07] - Loss total: 2.5426433086395264, Last rpr Loss: 0.9999920725822449, Last lagvar Loss: 0.8433395624160767\n",
      "Step 9292/10000- lr: [7.131684606060603e-07] - Loss total: 2.542635202407837, Last rpr Loss: 0.9999940991401672, Last lagvar Loss: 0.8433375358581543\n",
      "Step 9293/10000- lr: [7.121583636363636e-07] - Loss total: 2.5426270961761475, Last rpr Loss: 0.999993622303009, Last lagvar Loss: 0.8433380126953125\n",
      "Step 9294/10000- lr: [7.111482666666668e-07] - Loss total: 2.542619466781616, Last rpr Loss: 0.9999938607215881, Last lagvar Loss: 0.8433377742767334\n",
      "Step 9295/10000- lr: [7.101381696969684e-07] - Loss total: 2.5426113605499268, Last rpr Loss: 0.9999921917915344, Last lagvar Loss: 0.8433393239974976\n",
      "Step 9296/10000- lr: [7.091280727272717e-07] - Loss total: 2.5426034927368164, Last rpr Loss: 0.9999938607215881, Last lagvar Loss: 0.8433376550674438\n",
      "Step 9297/10000- lr: [7.08117975757575e-07] - Loss total: 2.542595386505127, Last rpr Loss: 0.9999936819076538, Last lagvar Loss: 0.8433378338813782\n",
      "Step 9298/10000- lr: [7.071078787878782e-07] - Loss total: 2.5425877571105957, Last rpr Loss: 0.9999932050704956, Last lagvar Loss: 0.8433383107185364\n",
      "Step 9299/10000- lr: [7.060977818181815e-07] - Loss total: 2.542579412460327, Last rpr Loss: 0.999995768070221, Last lagvar Loss: 0.8433356881141663\n",
      "Step 9300/10000- lr: [7.050876848484848e-07] - Loss total: 2.542571544647217, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8433365225791931\n",
      "Step 9301/10000- lr: [7.040775878787864e-07] - Loss total: 2.5425636768341064, Last rpr Loss: 0.9999905824661255, Last lagvar Loss: 0.8433408141136169\n",
      "Step 9302/10000- lr: [7.030674909090897e-07] - Loss total: 2.542555809020996, Last rpr Loss: 0.9999932050704956, Last lagvar Loss: 0.8433381915092468\n",
      "Step 9303/10000- lr: [7.020573939393929e-07] - Loss total: 2.5425479412078857, Last rpr Loss: 0.9999946355819702, Last lagvar Loss: 0.8433367609977722\n",
      "Step 9304/10000- lr: [7.010472969696962e-07] - Loss total: 2.5425400733947754, Last rpr Loss: 0.999994158744812, Last lagvar Loss: 0.8433371782302856\n",
      "Step 9305/10000- lr: [7.000371999999995e-07] - Loss total: 2.542532205581665, Last rpr Loss: 0.9999927282333374, Last lagvar Loss: 0.8433386087417603\n",
      "Step 9306/10000- lr: [6.990271030303028e-07] - Loss total: 2.5425243377685547, Last rpr Loss: 0.9999924898147583, Last lagvar Loss: 0.8433387875556946\n",
      "Step 9307/10000- lr: [6.980170060606044e-07] - Loss total: 2.5425164699554443, Last rpr Loss: 0.9999940395355225, Last lagvar Loss: 0.8433372974395752\n",
      "Step 9308/10000- lr: [6.970069090909093e-07] - Loss total: 2.542508840560913, Last rpr Loss: 0.9999955892562866, Last lagvar Loss: 0.843335747718811\n",
      "Step 9309/10000- lr: [6.959968121212109e-07] - Loss total: 2.5425009727478027, Last rpr Loss: 0.999993085861206, Last lagvar Loss: 0.843338131904602\n",
      "Step 9310/10000- lr: [6.949867151515142e-07] - Loss total: 2.5424933433532715, Last rpr Loss: 0.9999914169311523, Last lagvar Loss: 0.8433398604393005\n",
      "Step 9311/10000- lr: [6.939766181818175e-07] - Loss total: 2.542485475540161, Last rpr Loss: 0.9999936819076538, Last lagvar Loss: 0.8433377146720886\n",
      "Step 9312/10000- lr: [6.929665212121207e-07] - Loss total: 2.54247784614563, Last rpr Loss: 0.9999944567680359, Last lagvar Loss: 0.843336820602417\n",
      "Step 9313/10000- lr: [6.91956424242424e-07] - Loss total: 2.5424702167510986, Last rpr Loss: 0.9999931454658508, Last lagvar Loss: 0.8433380722999573\n",
      "Step 9314/10000- lr: [6.909463272727273e-07] - Loss total: 2.5424625873565674, Last rpr Loss: 0.9999927878379822, Last lagvar Loss: 0.8433384299278259\n",
      "Step 9315/10000- lr: [6.899362303030289e-07] - Loss total: 2.542454719543457, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8433353304862976\n",
      "Step 9316/10000- lr: [6.889261333333322e-07] - Loss total: 2.542447090148926, Last rpr Loss: 0.9999925494194031, Last lagvar Loss: 0.843338668346405\n",
      "Step 9317/10000- lr: [6.879160363636371e-07] - Loss total: 2.5424394607543945, Last rpr Loss: 0.9999929070472717, Last lagvar Loss: 0.8433382511138916\n",
      "Step 9318/10000- lr: [6.869059393939387e-07] - Loss total: 2.542431592941284, Last rpr Loss: 0.9999943971633911, Last lagvar Loss: 0.843336820602417\n",
      "Step 9319/10000- lr: [6.85895842424242e-07] - Loss total: 2.542423963546753, Last rpr Loss: 0.9999914765357971, Last lagvar Loss: 0.8433396816253662\n",
      "Step 9320/10000- lr: [6.848857454545453e-07] - Loss total: 2.542416572570801, Last rpr Loss: 0.9999938607215881, Last lagvar Loss: 0.8433372378349304\n",
      "Step 9321/10000- lr: [6.838756484848485e-07] - Loss total: 2.5424087047576904, Last rpr Loss: 0.9999942183494568, Last lagvar Loss: 0.843336820602417\n",
      "Step 9322/10000- lr: [6.828655515151518e-07] - Loss total: 2.542401075363159, Last rpr Loss: 0.9999949932098389, Last lagvar Loss: 0.8433361053466797\n",
      "Step 9323/10000- lr: [6.818554545454551e-07] - Loss total: 2.542393207550049, Last rpr Loss: 0.999993085861206, Last lagvar Loss: 0.8433380126953125\n",
      "Step 9324/10000- lr: [6.808453575757567e-07] - Loss total: 2.5423855781555176, Last rpr Loss: 0.999992847442627, Last lagvar Loss: 0.843338131904602\n",
      "Step 9325/10000- lr: [6.7983526060606e-07] - Loss total: 2.5423779487609863, Last rpr Loss: 0.9999938011169434, Last lagvar Loss: 0.8433372974395752\n",
      "Step 9326/10000- lr: [6.788251636363632e-07] - Loss total: 2.542370080947876, Last rpr Loss: 0.9999933242797852, Last lagvar Loss: 0.8433377742767334\n",
      "Step 9327/10000- lr: [6.778150666666665e-07] - Loss total: 2.542362689971924, Last rpr Loss: 0.9999935626983643, Last lagvar Loss: 0.8433374166488647\n",
      "Step 9328/10000- lr: [6.768049696969698e-07] - Loss total: 2.5423548221588135, Last rpr Loss: 0.9999939203262329, Last lagvar Loss: 0.8433371186256409\n",
      "Step 9329/10000- lr: [6.757948727272731e-07] - Loss total: 2.5423474311828613, Last rpr Loss: 0.9999910593032837, Last lagvar Loss: 0.8433398604393005\n",
      "Step 9330/10000- lr: [6.747847757575746e-07] - Loss total: 2.542340040206909, Last rpr Loss: 0.9999942779541016, Last lagvar Loss: 0.8433367013931274\n",
      "Step 9331/10000- lr: [6.737746787878779e-07] - Loss total: 2.542332410812378, Last rpr Loss: 0.9999943971633911, Last lagvar Loss: 0.8433365821838379\n",
      "Step 9332/10000- lr: [6.727645818181812e-07] - Loss total: 2.5423247814178467, Last rpr Loss: 0.9999944567680359, Last lagvar Loss: 0.8433365225791931\n",
      "Step 9333/10000- lr: [6.717544848484845e-07] - Loss total: 2.5423173904418945, Last rpr Loss: 0.9999944567680359, Last lagvar Loss: 0.8433364629745483\n",
      "Step 9334/10000- lr: [6.707443878787878e-07] - Loss total: 2.5423097610473633, Last rpr Loss: 0.9999932646751404, Last lagvar Loss: 0.8433376550674438\n",
      "Step 9335/10000- lr: [6.69734290909091e-07] - Loss total: 2.542302131652832, Last rpr Loss: 0.999992847442627, Last lagvar Loss: 0.8433380126953125\n",
      "Step 9336/10000- lr: [6.687241939393926e-07] - Loss total: 2.54229474067688, Last rpr Loss: 0.9999934434890747, Last lagvar Loss: 0.8433374166488647\n",
      "Step 9337/10000- lr: [6.677140969696976e-07] - Loss total: 2.5422871112823486, Last rpr Loss: 0.999994158744812, Last lagvar Loss: 0.8433366417884827\n",
      "Step 9338/10000- lr: [6.667039999999992e-07] - Loss total: 2.5422797203063965, Last rpr Loss: 0.9999922513961792, Last lagvar Loss: 0.8433386087417603\n",
      "Step 9339/10000- lr: [6.656939030303024e-07] - Loss total: 2.5422723293304443, Last rpr Loss: 0.9999908804893494, Last lagvar Loss: 0.8433399200439453\n",
      "Step 9340/10000- lr: [6.646838060606057e-07] - Loss total: 2.542264699935913, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8433349132537842\n",
      "Step 9341/10000- lr: [6.63673709090909e-07] - Loss total: 2.542257308959961, Last rpr Loss: 0.999995231628418, Last lagvar Loss: 0.8433355093002319\n",
      "Step 9342/10000- lr: [6.626636121212123e-07] - Loss total: 2.542249917984009, Last rpr Loss: 0.999990701675415, Last lagvar Loss: 0.8433400392532349\n",
      "Step 9343/10000- lr: [6.616535151515156e-07] - Loss total: 2.5422425270080566, Last rpr Loss: 0.9999957084655762, Last lagvar Loss: 0.8433350920677185\n",
      "Step 9344/10000- lr: [6.606434181818171e-07] - Loss total: 2.5422351360321045, Last rpr Loss: 0.9999945759773254, Last lagvar Loss: 0.8433361053466797\n",
      "Step 9345/10000- lr: [6.596333212121204e-07] - Loss total: 2.5422275066375732, Last rpr Loss: 0.9999916553497314, Last lagvar Loss: 0.8433390855789185\n",
      "Step 9346/10000- lr: [6.586232242424237e-07] - Loss total: 2.542219877243042, Last rpr Loss: 0.9999932646751404, Last lagvar Loss: 0.84333735704422\n",
      "Step 9347/10000- lr: [6.57613127272727e-07] - Loss total: 2.542212724685669, Last rpr Loss: 0.9999963045120239, Last lagvar Loss: 0.8433343172073364\n",
      "Step 9348/10000- lr: [6.566030303030302e-07] - Loss total: 2.5422050952911377, Last rpr Loss: 0.9999915957450867, Last lagvar Loss: 0.8433390855789185\n",
      "Step 9349/10000- lr: [6.555929333333335e-07] - Loss total: 2.5421977043151855, Last rpr Loss: 0.999992311000824, Last lagvar Loss: 0.8433383107185364\n",
      "Step 9350/10000- lr: [6.545828363636351e-07] - Loss total: 2.5421903133392334, Last rpr Loss: 0.9999962449073792, Last lagvar Loss: 0.8433343172073364\n",
      "Step 9351/10000- lr: [6.535727393939384e-07] - Loss total: 2.5421829223632812, Last rpr Loss: 0.9999914169311523, Last lagvar Loss: 0.8433390855789185\n",
      "Step 9352/10000- lr: [6.525626424242417e-07] - Loss total: 2.542175531387329, Last rpr Loss: 0.9999913573265076, Last lagvar Loss: 0.843339204788208\n",
      "Step 9353/10000- lr: [6.515525454545449e-07] - Loss total: 2.542168378829956, Last rpr Loss: 0.9999951720237732, Last lagvar Loss: 0.8433353900909424\n",
      "Step 9354/10000- lr: [6.505424484848482e-07] - Loss total: 2.542161226272583, Last rpr Loss: 0.9999935626983643, Last lagvar Loss: 0.8433369398117065\n",
      "Step 9355/10000- lr: [6.495323515151515e-07] - Loss total: 2.5421535968780518, Last rpr Loss: 0.9999938607215881, Last lagvar Loss: 0.8433366417884827\n",
      "Step 9356/10000- lr: [6.485222545454531e-07] - Loss total: 2.5421462059020996, Last rpr Loss: 0.9999955892562866, Last lagvar Loss: 0.8433349132537842\n",
      "Step 9357/10000- lr: [6.47512157575758e-07] - Loss total: 2.5421390533447266, Last rpr Loss: 0.9999945163726807, Last lagvar Loss: 0.8433359861373901\n",
      "Step 9358/10000- lr: [6.465020606060596e-07] - Loss total: 2.5421319007873535, Last rpr Loss: 0.9999910593032837, Last lagvar Loss: 0.8433393239974976\n",
      "Step 9359/10000- lr: [6.454919636363629e-07] - Loss total: 2.5421245098114014, Last rpr Loss: 0.9999918937683105, Last lagvar Loss: 0.8433386087417603\n",
      "Step 9360/10000- lr: [6.444818666666662e-07] - Loss total: 2.5421173572540283, Last rpr Loss: 0.9999926090240479, Last lagvar Loss: 0.8433378338813782\n",
      "Step 9361/10000- lr: [6.434717696969695e-07] - Loss total: 2.542109727859497, Last rpr Loss: 0.9999919533729553, Last lagvar Loss: 0.8433384299278259\n",
      "Step 9362/10000- lr: [6.424616727272727e-07] - Loss total: 2.542102813720703, Last rpr Loss: 0.9999966621398926, Last lagvar Loss: 0.8433337211608887\n",
      "Step 9363/10000- lr: [6.41451575757576e-07] - Loss total: 2.54209566116333, Last rpr Loss: 0.9999960660934448, Last lagvar Loss: 0.843334436416626\n",
      "Step 9364/10000- lr: [6.404414787878776e-07] - Loss total: 2.542088508605957, Last rpr Loss: 0.9999923706054688, Last lagvar Loss: 0.8433380126953125\n",
      "Step 9365/10000- lr: [6.394313818181809e-07] - Loss total: 2.542081117630005, Last rpr Loss: 0.9999938607215881, Last lagvar Loss: 0.8433364629745483\n",
      "Step 9366/10000- lr: [6.384212848484841e-07] - Loss total: 2.542073965072632, Last rpr Loss: 0.9999938011169434, Last lagvar Loss: 0.8433365821838379\n",
      "Step 9367/10000- lr: [6.374111878787874e-07] - Loss total: 2.542066812515259, Last rpr Loss: 0.9999914169311523, Last lagvar Loss: 0.8433388471603394\n",
      "Step 9368/10000- lr: [6.364010909090907e-07] - Loss total: 2.542059898376465, Last rpr Loss: 0.9999907612800598, Last lagvar Loss: 0.8433394432067871\n",
      "Step 9369/10000- lr: [6.35390993939394e-07] - Loss total: 2.5420525074005127, Last rpr Loss: 0.9999961853027344, Last lagvar Loss: 0.8433340787887573\n",
      "Step 9370/10000- lr: [6.343808969696956e-07] - Loss total: 2.5420453548431396, Last rpr Loss: 0.9999961256980896, Last lagvar Loss: 0.8433340787887573\n",
      "Step 9371/10000- lr: [6.333708000000005e-07] - Loss total: 2.5420382022857666, Last rpr Loss: 0.9999926090240479, Last lagvar Loss: 0.8433376550674438\n",
      "Step 9372/10000- lr: [6.323607030303021e-07] - Loss total: 2.5420310497283936, Last rpr Loss: 0.9999935626983643, Last lagvar Loss: 0.8433367013931274\n",
      "Step 9373/10000- lr: [6.313506060606054e-07] - Loss total: 2.5420238971710205, Last rpr Loss: 0.9999945759773254, Last lagvar Loss: 0.8433356285095215\n",
      "Step 9374/10000- lr: [6.303405090909087e-07] - Loss total: 2.5420165061950684, Last rpr Loss: 0.9999938011169434, Last lagvar Loss: 0.8433364629745483\n",
      "Step 9375/10000- lr: [6.293304121212119e-07] - Loss total: 2.5420095920562744, Last rpr Loss: 0.9999915957450867, Last lagvar Loss: 0.8433387279510498\n",
      "Step 9376/10000- lr: [6.283203151515135e-07] - Loss total: 2.5420024394989014, Last rpr Loss: 0.9999931454658508, Last lagvar Loss: 0.8433369994163513\n",
      "Step 9377/10000- lr: [6.273102181818185e-07] - Loss total: 2.5419952869415283, Last rpr Loss: 0.9999934434890747, Last lagvar Loss: 0.843336820602417\n",
      "Step 9378/10000- lr: [6.263001212121201e-07] - Loss total: 2.5419883728027344, Last rpr Loss: 0.9999924302101135, Last lagvar Loss: 0.8433376550674438\n",
      "Step 9379/10000- lr: [6.252900242424234e-07] - Loss total: 2.5419812202453613, Last rpr Loss: 0.9999949336051941, Last lagvar Loss: 0.8433352112770081\n",
      "Step 9380/10000- lr: [6.242799272727266e-07] - Loss total: 2.5419743061065674, Last rpr Loss: 0.9999950528144836, Last lagvar Loss: 0.8433350920677185\n",
      "Step 9381/10000- lr: [6.232698303030299e-07] - Loss total: 2.5419669151306152, Last rpr Loss: 0.9999921321868896, Last lagvar Loss: 0.843337893486023\n",
      "Step 9382/10000- lr: [6.222597333333332e-07] - Loss total: 2.5419602394104004, Last rpr Loss: 0.999992311000824, Last lagvar Loss: 0.8433377742767334\n",
      "Step 9383/10000- lr: [6.212496363636365e-07] - Loss total: 2.5419530868530273, Last rpr Loss: 0.999995231628418, Last lagvar Loss: 0.8433347940444946\n",
      "Step 9384/10000- lr: [6.20239539393938e-07] - Loss total: 2.5419459342956543, Last rpr Loss: 0.9999935626983643, Last lagvar Loss: 0.8433364629745483\n",
      "Step 9385/10000- lr: [6.192294424242413e-07] - Loss total: 2.5419387817382812, Last rpr Loss: 0.9999934434890747, Last lagvar Loss: 0.8433365225791931\n",
      "Step 9386/10000- lr: [6.182193454545446e-07] - Loss total: 2.5419321060180664, Last rpr Loss: 0.9999938607215881, Last lagvar Loss: 0.8433359861373901\n",
      "Step 9387/10000- lr: [6.172092484848479e-07] - Loss total: 2.5419249534606934, Last rpr Loss: 0.9999953508377075, Last lagvar Loss: 0.8433346748352051\n",
      "Step 9388/10000- lr: [6.161991515151512e-07] - Loss total: 2.5419182777404785, Last rpr Loss: 0.9999927282333374, Last lagvar Loss: 0.8433372974395752\n",
      "Step 9389/10000- lr: [6.151890545454544e-07] - Loss total: 2.5419113636016846, Last rpr Loss: 0.999992847442627, Last lagvar Loss: 0.8433371186256409\n",
      "Step 9390/10000- lr: [6.14178957575756e-07] - Loss total: 2.5419039726257324, Last rpr Loss: 0.9999932050704956, Last lagvar Loss: 0.8433367609977722\n",
      "Step 9391/10000- lr: [6.13168860606061e-07] - Loss total: 2.5418972969055176, Last rpr Loss: 0.9999944567680359, Last lagvar Loss: 0.8433355093002319\n",
      "Step 9392/10000- lr: [6.121587636363626e-07] - Loss total: 2.5418903827667236, Last rpr Loss: 0.9999916553497314, Last lagvar Loss: 0.8433382511138916\n",
      "Step 9393/10000- lr: [6.111486666666659e-07] - Loss total: 2.5418834686279297, Last rpr Loss: 0.9999920725822449, Last lagvar Loss: 0.843337893486023\n",
      "Step 9394/10000- lr: [6.101385696969691e-07] - Loss total: 2.5418765544891357, Last rpr Loss: 0.9999953508377075, Last lagvar Loss: 0.8433344960212708\n",
      "Step 9395/10000- lr: [6.091284727272724e-07] - Loss total: 2.541869640350342, Last rpr Loss: 0.9999947547912598, Last lagvar Loss: 0.8433350920677185\n",
      "Step 9396/10000- lr: [6.08118375757574e-07] - Loss total: 2.5418624877929688, Last rpr Loss: 0.999994158744812, Last lagvar Loss: 0.843335747718811\n",
      "Step 9397/10000- lr: [6.07108278787879e-07] - Loss total: 2.541855812072754, Last rpr Loss: 0.9999938607215881, Last lagvar Loss: 0.8433359861373901\n",
      "Step 9398/10000- lr: [6.060981818181805e-07] - Loss total: 2.54184889793396, Last rpr Loss: 0.9999925494194031, Last lagvar Loss: 0.8433372378349304\n",
      "Step 9399/10000- lr: [6.050880848484838e-07] - Loss total: 2.541841745376587, Last rpr Loss: 0.9999924898147583, Last lagvar Loss: 0.8433372974395752\n",
      "Step 9400/10000- lr: [6.040779878787871e-07] - Loss total: 2.541835069656372, Last rpr Loss: 0.9999957084655762, Last lagvar Loss: 0.8433339595794678\n",
      "Step 9401/10000- lr: [6.030678909090904e-07] - Loss total: 2.541828155517578, Last rpr Loss: 0.9999940395355225, Last lagvar Loss: 0.843335747718811\n",
      "Step 9402/10000- lr: [6.020577939393937e-07] - Loss total: 2.541821241378784, Last rpr Loss: 0.9999921917915344, Last lagvar Loss: 0.8433375358581543\n",
      "Step 9403/10000- lr: [6.010476969696969e-07] - Loss total: 2.5418145656585693, Last rpr Loss: 0.9999920129776001, Last lagvar Loss: 0.8433377742767334\n",
      "Step 9404/10000- lr: [6.000376000000002e-07] - Loss total: 2.5418076515197754, Last rpr Loss: 0.9999952912330627, Last lagvar Loss: 0.8433343172073364\n",
      "Step 9405/10000- lr: [5.990275030303018e-07] - Loss total: 2.5418007373809814, Last rpr Loss: 0.9999954700469971, Last lagvar Loss: 0.8433341979980469\n",
      "Step 9406/10000- lr: [5.980174060606068e-07] - Loss total: 2.5417940616607666, Last rpr Loss: 0.9999915957450867, Last lagvar Loss: 0.8433380126953125\n",
      "Step 9407/10000- lr: [5.970073090909083e-07] - Loss total: 2.5417873859405518, Last rpr Loss: 0.9999927282333374, Last lagvar Loss: 0.8433369398117065\n",
      "Step 9408/10000- lr: [5.959972121212116e-07] - Loss total: 2.541780471801758, Last rpr Loss: 0.9999930262565613, Last lagvar Loss: 0.8433365821838379\n",
      "Step 9409/10000- lr: [5.949871151515149e-07] - Loss total: 2.541774034500122, Last rpr Loss: 0.9999924898147583, Last lagvar Loss: 0.8433371782302856\n",
      "Step 9410/10000- lr: [5.939770181818182e-07] - Loss total: 2.54176664352417, Last rpr Loss: 0.9999942779541016, Last lagvar Loss: 0.8433353900909424\n",
      "Step 9411/10000- lr: [5.929669212121215e-07] - Loss total: 2.5417604446411133, Last rpr Loss: 0.9999979734420776, Last lagvar Loss: 0.8433316349983215\n",
      "Step 9412/10000- lr: [5.919568242424247e-07] - Loss total: 2.5417532920837402, Last rpr Loss: 0.9999935030937195, Last lagvar Loss: 0.8433361053466797\n",
      "Step 9413/10000- lr: [5.909467272727263e-07] - Loss total: 2.5417468547821045, Last rpr Loss: 0.9999897480010986, Last lagvar Loss: 0.8433398604393005\n",
      "Step 9414/10000- lr: [5.899366303030296e-07] - Loss total: 2.5417401790618896, Last rpr Loss: 0.9999939203262329, Last lagvar Loss: 0.8433356285095215\n",
      "Step 9415/10000- lr: [5.889265333333329e-07] - Loss total: 2.541733503341675, Last rpr Loss: 0.9999945759773254, Last lagvar Loss: 0.8433350324630737\n",
      "Step 9416/10000- lr: [5.879164363636361e-07] - Loss total: 2.541726589202881, Last rpr Loss: 0.9999931454658508, Last lagvar Loss: 0.8433364033699036\n",
      "Step 9417/10000- lr: [5.869063393939394e-07] - Loss total: 2.541719913482666, Last rpr Loss: 0.9999937415122986, Last lagvar Loss: 0.8433356881141663\n",
      "Step 9418/10000- lr: [5.858962424242427e-07] - Loss total: 2.541713237762451, Last rpr Loss: 0.9999955892562866, Last lagvar Loss: 0.8433339595794678\n",
      "Step 9419/10000- lr: [5.848861454545443e-07] - Loss total: 2.5417068004608154, Last rpr Loss: 0.9999931454658508, Last lagvar Loss: 0.8433363437652588\n",
      "Step 9420/10000- lr: [5.838760484848493e-07] - Loss total: 2.5416996479034424, Last rpr Loss: 0.9999933242797852, Last lagvar Loss: 0.8433362245559692\n",
      "Step 9421/10000- lr: [5.828659515151508e-07] - Loss total: 2.5416934490203857, Last rpr Loss: 0.9999940395355225, Last lagvar Loss: 0.8433354496955872\n",
      "Step 9422/10000- lr: [5.818558545454541e-07] - Loss total: 2.5416862964630127, Last rpr Loss: 0.999993085861206, Last lagvar Loss: 0.843336284160614\n",
      "Step 9423/10000- lr: [5.808457575757574e-07] - Loss total: 2.541680097579956, Last rpr Loss: 0.9999924302101135, Last lagvar Loss: 0.8433369994163513\n",
      "Step 9424/10000- lr: [5.798356606060607e-07] - Loss total: 2.541673421859741, Last rpr Loss: 0.9999933838844299, Last lagvar Loss: 0.8433359861373901\n",
      "Step 9425/10000- lr: [5.788255636363622e-07] - Loss total: 2.5416669845581055, Last rpr Loss: 0.9999957084655762, Last lagvar Loss: 0.8433336615562439\n",
      "Step 9426/10000- lr: [5.778154666666672e-07] - Loss total: 2.5416603088378906, Last rpr Loss: 0.9999939203262329, Last lagvar Loss: 0.8433353900909424\n",
      "Step 9427/10000- lr: [5.768053696969688e-07] - Loss total: 2.541653633117676, Last rpr Loss: 0.999992311000824, Last lagvar Loss: 0.8433369994163513\n",
      "Step 9428/10000- lr: [5.757952727272721e-07] - Loss total: 2.54164719581604, Last rpr Loss: 0.9999927282333374, Last lagvar Loss: 0.8433365821838379\n",
      "Step 9429/10000- lr: [5.747851757575754e-07] - Loss total: 2.5416407585144043, Last rpr Loss: 0.9999939203262329, Last lagvar Loss: 0.8433353900909424\n",
      "Step 9430/10000- lr: [5.737750787878786e-07] - Loss total: 2.5416343212127686, Last rpr Loss: 0.9999933242797852, Last lagvar Loss: 0.8433359861373901\n",
      "Step 9431/10000- lr: [5.727649818181819e-07] - Loss total: 2.5416276454925537, Last rpr Loss: 0.9999942779541016, Last lagvar Loss: 0.843334972858429\n",
      "Step 9432/10000- lr: [5.717548848484852e-07] - Loss total: 2.541620969772339, Last rpr Loss: 0.9999949336051941, Last lagvar Loss: 0.8433343172073364\n",
      "Step 9433/10000- lr: [5.707447878787868e-07] - Loss total: 2.541614532470703, Last rpr Loss: 0.9999933242797852, Last lagvar Loss: 0.8433359265327454\n",
      "Step 9434/10000- lr: [5.6973469090909e-07] - Loss total: 2.5416080951690674, Last rpr Loss: 0.9999943971633911, Last lagvar Loss: 0.8433348536491394\n",
      "Step 9435/10000- lr: [5.687245939393933e-07] - Loss total: 2.5416016578674316, Last rpr Loss: 0.9999945163726807, Last lagvar Loss: 0.8433347344398499\n",
      "Step 9436/10000- lr: [5.677144969696966e-07] - Loss total: 2.541594982147217, Last rpr Loss: 0.9999923706054688, Last lagvar Loss: 0.843336820602417\n",
      "Step 9437/10000- lr: [5.667043999999999e-07] - Loss total: 2.54158878326416, Last rpr Loss: 0.9999911189079285, Last lagvar Loss: 0.8433380126953125\n",
      "Step 9438/10000- lr: [5.656943030303032e-07] - Loss total: 2.5415821075439453, Last rpr Loss: 0.9999939203262329, Last lagvar Loss: 0.8433351516723633\n",
      "Step 9439/10000- lr: [5.646842060606047e-07] - Loss total: 2.5415756702423096, Last rpr Loss: 0.9999953508377075, Last lagvar Loss: 0.8433338403701782\n",
      "Step 9440/10000- lr: [5.636741090909097e-07] - Loss total: 2.541569232940674, Last rpr Loss: 0.9999938607215881, Last lagvar Loss: 0.8433352708816528\n",
      "Step 9441/10000- lr: [5.626640121212113e-07] - Loss total: 2.541562795639038, Last rpr Loss: 0.999994158744812, Last lagvar Loss: 0.843334972858429\n",
      "Step 9442/10000- lr: [5.616539151515146e-07] - Loss total: 2.5415565967559814, Last rpr Loss: 0.9999940395355225, Last lagvar Loss: 0.8433350920677185\n",
      "Step 9443/10000- lr: [5.606438181818178e-07] - Loss total: 2.5415499210357666, Last rpr Loss: 0.9999918341636658, Last lagvar Loss: 0.8433371782302856\n",
      "Step 9444/10000- lr: [5.596337212121211e-07] - Loss total: 2.5415432453155518, Last rpr Loss: 0.9999924898147583, Last lagvar Loss: 0.8433367013931274\n",
      "Step 9445/10000- lr: [5.586236242424227e-07] - Loss total: 2.541536808013916, Last rpr Loss: 0.9999954700469971, Last lagvar Loss: 0.8433336019515991\n",
      "Step 9446/10000- lr: [5.576135272727277e-07] - Loss total: 2.5415303707122803, Last rpr Loss: 0.9999936819076538, Last lagvar Loss: 0.8433354496955872\n",
      "Step 9447/10000- lr: [5.566034303030293e-07] - Loss total: 2.5415241718292236, Last rpr Loss: 0.9999924898147583, Last lagvar Loss: 0.8433365821838379\n",
      "Step 9448/10000- lr: [5.555933333333325e-07] - Loss total: 2.541517734527588, Last rpr Loss: 0.9999951720237732, Last lagvar Loss: 0.8433338403701782\n",
      "Step 9449/10000- lr: [5.545832363636358e-07] - Loss total: 2.5415115356445312, Last rpr Loss: 0.9999943971633911, Last lagvar Loss: 0.8433346748352051\n",
      "Step 9450/10000- lr: [5.535731393939391e-07] - Loss total: 2.5415050983428955, Last rpr Loss: 0.9999956488609314, Last lagvar Loss: 0.84333336353302\n",
      "Step 9451/10000- lr: [5.525630424242424e-07] - Loss total: 2.541498899459839, Last rpr Loss: 0.9999934434890747, Last lagvar Loss: 0.8433355093002319\n",
      "Step 9452/10000- lr: [5.515529454545456e-07] - Loss total: 2.541491985321045, Last rpr Loss: 0.9999919533729553, Last lagvar Loss: 0.8433370590209961\n",
      "Step 9453/10000- lr: [5.505428484848472e-07] - Loss total: 2.5414860248565674, Last rpr Loss: 0.9999922513961792, Last lagvar Loss: 0.8433367013931274\n",
      "Step 9454/10000- lr: [5.495327515151505e-07] - Loss total: 2.5414798259735107, Last rpr Loss: 0.9999930262565613, Last lagvar Loss: 0.8433359265327454\n",
      "Step 9455/10000- lr: [5.485226545454538e-07] - Loss total: 2.541473388671875, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8433340191841125\n",
      "Step 9456/10000- lr: [5.475125575757571e-07] - Loss total: 2.5414674282073975, Last rpr Loss: 0.9999931454658508, Last lagvar Loss: 0.843335747718811\n",
      "Step 9457/10000- lr: [5.465024606060603e-07] - Loss total: 2.5414607524871826, Last rpr Loss: 0.999994158744812, Last lagvar Loss: 0.8433346748352051\n",
      "Step 9458/10000- lr: [5.454923636363636e-07] - Loss total: 2.541454315185547, Last rpr Loss: 0.9999961256980896, Last lagvar Loss: 0.8433326482772827\n",
      "Step 9459/10000- lr: [5.444822666666652e-07] - Loss total: 2.5414481163024902, Last rpr Loss: 0.9999939799308777, Last lagvar Loss: 0.8433348536491394\n",
      "Step 9460/10000- lr: [5.434721696969702e-07] - Loss total: 2.5414421558380127, Last rpr Loss: 0.9999917149543762, Last lagvar Loss: 0.8433371186256409\n",
      "Step 9461/10000- lr: [5.424620727272718e-07] - Loss total: 2.541435956954956, Last rpr Loss: 0.9999925494194031, Last lagvar Loss: 0.843336284160614\n",
      "Step 9462/10000- lr: [5.41451975757575e-07] - Loss total: 2.5414297580718994, Last rpr Loss: 0.9999938011169434, Last lagvar Loss: 0.8433351516723633\n",
      "Step 9463/10000- lr: [5.404418787878783e-07] - Loss total: 2.5414233207702637, Last rpr Loss: 0.9999940991401672, Last lagvar Loss: 0.8433347940444946\n",
      "Step 9464/10000- lr: [5.394317818181816e-07] - Loss total: 2.541417360305786, Last rpr Loss: 0.9999940395355225, Last lagvar Loss: 0.8433347940444946\n",
      "Step 9465/10000- lr: [5.384216848484832e-07] - Loss total: 2.5414109230041504, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8433338403701782\n",
      "Step 9466/10000- lr: [5.374115878787881e-07] - Loss total: 2.541404962539673, Last rpr Loss: 0.9999951124191284, Last lagvar Loss: 0.8433336615562439\n",
      "Step 9467/10000- lr: [5.364014909090897e-07] - Loss total: 2.541398525238037, Last rpr Loss: 0.9999926686286926, Last lagvar Loss: 0.8433361053466797\n",
      "Step 9468/10000- lr: [5.35391393939393e-07] - Loss total: 2.5413925647735596, Last rpr Loss: 0.9999915361404419, Last lagvar Loss: 0.8433371782302856\n",
      "Step 9469/10000- lr: [5.343812969696963e-07] - Loss total: 2.541386365890503, Last rpr Loss: 0.9999937415122986, Last lagvar Loss: 0.843334972858429\n",
      "Step 9470/10000- lr: [5.333711999999996e-07] - Loss total: 2.5413801670074463, Last rpr Loss: 0.999995231628418, Last lagvar Loss: 0.8433334231376648\n",
      "Step 9471/10000- lr: [5.323611030303028e-07] - Loss total: 2.5413739681243896, Last rpr Loss: 0.9999929666519165, Last lagvar Loss: 0.843335747718811\n",
      "Step 9472/10000- lr: [5.313510060606061e-07] - Loss total: 2.541367769241333, Last rpr Loss: 0.9999919533729553, Last lagvar Loss: 0.8433367013931274\n",
      "Step 9473/10000- lr: [5.303409090909077e-07] - Loss total: 2.5413618087768555, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.8433322906494141\n",
      "Step 9474/10000- lr: [5.29330812121211e-07] - Loss total: 2.5413553714752197, Last rpr Loss: 0.999995231628418, Last lagvar Loss: 0.8433334827423096\n",
      "Step 9475/10000- lr: [5.283207151515142e-07] - Loss total: 2.541349411010742, Last rpr Loss: 0.9999951124191284, Last lagvar Loss: 0.8433335423469543\n",
      "Step 9476/10000- lr: [5.273106181818175e-07] - Loss total: 2.5413434505462646, Last rpr Loss: 0.9999919533729553, Last lagvar Loss: 0.8433367013931274\n",
      "Step 9477/10000- lr: [5.263005212121208e-07] - Loss total: 2.541337251663208, Last rpr Loss: 0.9999927282333374, Last lagvar Loss: 0.8433358669281006\n",
      "Step 9478/10000- lr: [5.252904242424241e-07] - Loss total: 2.5413312911987305, Last rpr Loss: 0.9999942779541016, Last lagvar Loss: 0.8433343768119812\n",
      "Step 9479/10000- lr: [5.242803272727257e-07] - Loss total: 2.541325092315674, Last rpr Loss: 0.9999915957450867, Last lagvar Loss: 0.8433369398117065\n",
      "Step 9480/10000- lr: [5.232702303030306e-07] - Loss total: 2.5413191318511963, Last rpr Loss: 0.9999935626983643, Last lagvar Loss: 0.8433349132537842\n",
      "Step 9481/10000- lr: [5.222601333333322e-07] - Loss total: 2.5413129329681396, Last rpr Loss: 0.9999963641166687, Last lagvar Loss: 0.8433321714401245\n",
      "Step 9482/10000- lr: [5.212500363636355e-07] - Loss total: 2.541306972503662, Last rpr Loss: 0.9999929666519165, Last lagvar Loss: 0.8433355093002319\n",
      "Step 9483/10000- lr: [5.202399393939388e-07] - Loss total: 2.5413010120391846, Last rpr Loss: 0.9999915361404419, Last lagvar Loss: 0.8433369398117065\n",
      "Step 9484/10000- lr: [5.19229842424242e-07] - Loss total: 2.541295051574707, Last rpr Loss: 0.999996542930603, Last lagvar Loss: 0.8433319330215454\n",
      "Step 9485/10000- lr: [5.182197454545436e-07] - Loss total: 2.5412890911102295, Last rpr Loss: 0.9999979734420776, Last lagvar Loss: 0.8433305025100708\n",
      "Step 9486/10000- lr: [5.172096484848486e-07] - Loss total: 2.541283130645752, Last rpr Loss: 0.9999926686286926, Last lagvar Loss: 0.8433358669281006\n",
      "Step 9487/10000- lr: [5.161995515151519e-07] - Loss total: 2.5412771701812744, Last rpr Loss: 0.9999901652336121, Last lagvar Loss: 0.8433383107185364\n",
      "Step 9488/10000- lr: [5.151894545454535e-07] - Loss total: 2.541271209716797, Last rpr Loss: 0.999992847442627, Last lagvar Loss: 0.8433355689048767\n",
      "Step 9489/10000- lr: [5.141793575757584e-07] - Loss total: 2.5412652492523193, Last rpr Loss: 0.9999958872795105, Last lagvar Loss: 0.8433325290679932\n",
      "Step 9490/10000- lr: [5.1316926060606e-07] - Loss total: 2.541259288787842, Last rpr Loss: 0.9999937415122986, Last lagvar Loss: 0.8433346748352051\n",
      "Step 9491/10000- lr: [5.121591636363633e-07] - Loss total: 2.5412533283233643, Last rpr Loss: 0.999993085861206, Last lagvar Loss: 0.8433353900909424\n",
      "Step 9492/10000- lr: [5.111490666666666e-07] - Loss total: 2.541247606277466, Last rpr Loss: 0.9999942779541016, Last lagvar Loss: 0.8433340787887573\n",
      "Step 9493/10000- lr: [5.101389696969698e-07] - Loss total: 2.5412416458129883, Last rpr Loss: 0.9999943971633911, Last lagvar Loss: 0.8433340191841125\n",
      "Step 9494/10000- lr: [5.091288727272714e-07] - Loss total: 2.54123592376709, Last rpr Loss: 0.9999940395355225, Last lagvar Loss: 0.8433343172073364\n",
      "Step 9495/10000- lr: [5.081187757575764e-07] - Loss total: 2.541229724884033, Last rpr Loss: 0.9999923706054688, Last lagvar Loss: 0.8433359265327454\n",
      "Step 9496/10000- lr: [5.07108678787878e-07] - Loss total: 2.5412240028381348, Last rpr Loss: 0.9999943971633911, Last lagvar Loss: 0.8433339595794678\n",
      "Step 9497/10000- lr: [5.060985818181813e-07] - Loss total: 2.5412180423736572, Last rpr Loss: 0.999993622303009, Last lagvar Loss: 0.8433346748352051\n",
      "Step 9498/10000- lr: [5.050884848484845e-07] - Loss total: 2.5412120819091797, Last rpr Loss: 0.9999943375587463, Last lagvar Loss: 0.8433339595794678\n",
      "Step 9499/10000- lr: [5.040783878787878e-07] - Loss total: 2.5412063598632812, Last rpr Loss: 0.9999936819076538, Last lagvar Loss: 0.8433346152305603\n",
      "Step 9500/10000- lr: [5.030682909090911e-07] - Loss total: 2.541200637817383, Last rpr Loss: 0.9999933242797852, Last lagvar Loss: 0.8433350324630737\n",
      "Step 9501/10000- lr: [5.020581939393944e-07] - Loss total: 2.5411946773529053, Last rpr Loss: 0.9999943971633911, Last lagvar Loss: 0.843333899974823\n",
      "Step 9502/10000- lr: [5.01048096969696e-07] - Loss total: 2.5411887168884277, Last rpr Loss: 0.999994158744812, Last lagvar Loss: 0.8433341979980469\n",
      "Step 9503/10000- lr: [5.000379999999992e-07] - Loss total: 2.5411832332611084, Last rpr Loss: 0.999994158744812, Last lagvar Loss: 0.8433341979980469\n",
      "Step 9504/10000- lr: [4.990279030303025e-07] - Loss total: 2.5411770343780518, Last rpr Loss: 0.9999942779541016, Last lagvar Loss: 0.8433339595794678\n",
      "Step 9505/10000- lr: [4.980178060606058e-07] - Loss total: 2.5411713123321533, Last rpr Loss: 0.999995231628418, Last lagvar Loss: 0.8433330655097961\n",
      "Step 9506/10000- lr: [4.970077090909091e-07] - Loss total: 2.541165590286255, Last rpr Loss: 0.999993085861206, Last lagvar Loss: 0.8433351516723633\n",
      "Step 9507/10000- lr: [4.959976121212123e-07] - Loss total: 2.5411598682403564, Last rpr Loss: 0.9999935030937195, Last lagvar Loss: 0.8433346748352051\n",
      "Step 9508/10000- lr: [4.949875151515139e-07] - Loss total: 2.541154146194458, Last rpr Loss: 0.9999947547912598, Last lagvar Loss: 0.8433334231376648\n",
      "Step 9509/10000- lr: [4.939774181818189e-07] - Loss total: 2.5411481857299805, Last rpr Loss: 0.9999937415122986, Last lagvar Loss: 0.843334436416626\n",
      "Step 9510/10000- lr: [4.929673212121205e-07] - Loss total: 2.541142702102661, Last rpr Loss: 0.9999915957450867, Last lagvar Loss: 0.8433365821838379\n",
      "Step 9511/10000- lr: [4.919572242424237e-07] - Loss total: 2.5411367416381836, Last rpr Loss: 0.9999926090240479, Last lagvar Loss: 0.8433355093002319\n",
      "Step 9512/10000- lr: [4.90947127272727e-07] - Loss total: 2.541131019592285, Last rpr Loss: 0.9999954700469971, Last lagvar Loss: 0.8433327078819275\n",
      "Step 9513/10000- lr: [4.899370303030303e-07] - Loss total: 2.5411252975463867, Last rpr Loss: 0.9999949932098389, Last lagvar Loss: 0.8433331251144409\n",
      "Step 9514/10000- lr: [4.889269333333319e-07] - Loss total: 2.5411198139190674, Last rpr Loss: 0.9999945163726807, Last lagvar Loss: 0.8433336019515991\n",
      "Step 9515/10000- lr: [4.879168363636369e-07] - Loss total: 2.54111385345459, Last rpr Loss: 0.9999957084655762, Last lagvar Loss: 0.8433324098587036\n",
      "Step 9516/10000- lr: [4.869067393939384e-07] - Loss total: 2.5411081314086914, Last rpr Loss: 0.9999940991401672, Last lagvar Loss: 0.8433340787887573\n",
      "Step 9517/10000- lr: [4.858966424242417e-07] - Loss total: 2.541102647781372, Last rpr Loss: 0.9999926686286926, Last lagvar Loss: 0.8433353900909424\n",
      "Step 9518/10000- lr: [4.84886545454545e-07] - Loss total: 2.5410969257354736, Last rpr Loss: 0.999994158744812, Last lagvar Loss: 0.8433339595794678\n",
      "Step 9519/10000- lr: [4.838764484848483e-07] - Loss total: 2.541091203689575, Last rpr Loss: 0.9999933242797852, Last lagvar Loss: 0.8433346748352051\n",
      "Step 9520/10000- lr: [4.828663515151515e-07] - Loss total: 2.5410854816436768, Last rpr Loss: 0.999993622303009, Last lagvar Loss: 0.843334436416626\n",
      "Step 9521/10000- lr: [4.818562545454548e-07] - Loss total: 2.5410797595977783, Last rpr Loss: 0.999992847442627, Last lagvar Loss: 0.8433352112770081\n",
      "Step 9522/10000- lr: [4.808461575757564e-07] - Loss total: 2.54107403755188, Last rpr Loss: 0.9999935626983643, Last lagvar Loss: 0.8433345556259155\n",
      "Step 9523/10000- lr: [4.798360606060597e-07] - Loss total: 2.5410685539245605, Last rpr Loss: 0.9999944567680359, Last lagvar Loss: 0.8433336615562439\n",
      "Step 9524/10000- lr: [4.78825963636363e-07] - Loss total: 2.541062831878662, Last rpr Loss: 0.9999939203262329, Last lagvar Loss: 0.8433341383934021\n",
      "Step 9525/10000- lr: [4.778158666666662e-07] - Loss total: 2.5410573482513428, Last rpr Loss: 0.9999940395355225, Last lagvar Loss: 0.8433339595794678\n",
      "Step 9526/10000- lr: [4.768057696969695e-07] - Loss total: 2.5410516262054443, Last rpr Loss: 0.9999959468841553, Last lagvar Loss: 0.8433321118354797\n",
      "Step 9527/10000- lr: [4.757956727272728e-07] - Loss total: 2.541046142578125, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8433331251144409\n",
      "Step 9528/10000- lr: [4.747855757575744e-07] - Loss total: 2.5410406589508057, Last rpr Loss: 0.9999922513961792, Last lagvar Loss: 0.843335747718811\n",
      "Step 9529/10000- lr: [4.7377547878787935e-07] - Loss total: 2.5410351753234863, Last rpr Loss: 0.9999942779541016, Last lagvar Loss: 0.8433336615562439\n",
      "Step 9530/10000- lr: [4.7276538181818093e-07] - Loss total: 2.541029453277588, Last rpr Loss: 0.999995768070221, Last lagvar Loss: 0.8433322310447693\n",
      "Step 9531/10000- lr: [4.717552848484842e-07] - Loss total: 2.5410242080688477, Last rpr Loss: 0.999993085861206, Last lagvar Loss: 0.8433349132537842\n",
      "Step 9532/10000- lr: [4.707451878787875e-07] - Loss total: 2.541018486022949, Last rpr Loss: 0.999993085861206, Last lagvar Loss: 0.8433348536491394\n",
      "Step 9533/10000- lr: [4.6973509090909076e-07] - Loss total: 2.54101300239563, Last rpr Loss: 0.9999943375587463, Last lagvar Loss: 0.8433336019515991\n",
      "Step 9534/10000- lr: [4.6872499393939235e-07] - Loss total: 2.5410072803497314, Last rpr Loss: 0.9999946355819702, Last lagvar Loss: 0.8433332443237305\n",
      "Step 9535/10000- lr: [4.677148969696973e-07] - Loss total: 2.541001796722412, Last rpr Loss: 0.9999935030937195, Last lagvar Loss: 0.843334436416626\n",
      "Step 9536/10000- lr: [4.667047999999989e-07] - Loss total: 2.5409960746765137, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.843332052230835\n",
      "Step 9537/10000- lr: [4.656947030303022e-07] - Loss total: 2.5409908294677734, Last rpr Loss: 0.9999949932098389, Last lagvar Loss: 0.843332827091217\n",
      "Step 9538/10000- lr: [4.6468460606060545e-07] - Loss total: 2.540985345840454, Last rpr Loss: 0.9999926686286926, Last lagvar Loss: 0.8433351516723633\n",
      "Step 9539/10000- lr: [4.6367450909090873e-07] - Loss total: 2.540980100631714, Last rpr Loss: 0.9999920129776001, Last lagvar Loss: 0.8433358669281006\n",
      "Step 9540/10000- lr: [4.62664412121212e-07] - Loss total: 2.5409748554229736, Last rpr Loss: 0.9999934434890747, Last lagvar Loss: 0.843334436416626\n",
      "Step 9541/10000- lr: [4.616543151515153e-07] - Loss total: 2.540969133377075, Last rpr Loss: 0.999994695186615, Last lagvar Loss: 0.8433331251144409\n",
      "Step 9542/10000- lr: [4.6064421818181687e-07] - Loss total: 2.540963649749756, Last rpr Loss: 0.9999959468841553, Last lagvar Loss: 0.8433318138122559\n",
      "Step 9543/10000- lr: [4.5963412121212015e-07] - Loss total: 2.5409581661224365, Last rpr Loss: 0.9999951124191284, Last lagvar Loss: 0.8433326482772827\n",
      "Step 9544/10000- lr: [4.586240242424234e-07] - Loss total: 2.5409529209136963, Last rpr Loss: 0.999993085861206, Last lagvar Loss: 0.8433347940444946\n",
      "Step 9545/10000- lr: [4.576139272727267e-07] - Loss total: 2.540947675704956, Last rpr Loss: 0.9999926090240479, Last lagvar Loss: 0.8433351516723633\n",
      "Step 9546/10000- lr: [4.5660383030303e-07] - Loss total: 2.540942430496216, Last rpr Loss: 0.999994695186615, Last lagvar Loss: 0.8433330059051514\n",
      "Step 9547/10000- lr: [4.5559373333333325e-07] - Loss total: 2.5409367084503174, Last rpr Loss: 0.999995231628418, Last lagvar Loss: 0.8433325290679932\n",
      "Step 9548/10000- lr: [4.5458363636363484e-07] - Loss total: 2.540931463241577, Last rpr Loss: 0.9999936819076538, Last lagvar Loss: 0.8433341383934021\n",
      "Step 9549/10000- lr: [4.535735393939398e-07] - Loss total: 2.5409257411956787, Last rpr Loss: 0.9999926090240479, Last lagvar Loss: 0.8433351516723633\n",
      "Step 9550/10000- lr: [4.525634424242414e-07] - Loss total: 2.5409207344055176, Last rpr Loss: 0.9999948143959045, Last lagvar Loss: 0.8433330059051514\n",
      "Step 9551/10000- lr: [4.5155334545454467e-07] - Loss total: 2.5409152507781982, Last rpr Loss: 0.9999954700469971, Last lagvar Loss: 0.8433322310447693\n",
      "Step 9552/10000- lr: [4.5054324848484795e-07] - Loss total: 2.540910005569458, Last rpr Loss: 0.999993622303009, Last lagvar Loss: 0.8433340787887573\n",
      "Step 9553/10000- lr: [4.495331515151512e-07] - Loss total: 2.5409045219421387, Last rpr Loss: 0.999993085861206, Last lagvar Loss: 0.8433346748352051\n",
      "Step 9554/10000- lr: [4.485230545454528e-07] - Loss total: 2.5408995151519775, Last rpr Loss: 0.9999946355819702, Last lagvar Loss: 0.8433330059051514\n",
      "Step 9555/10000- lr: [4.475129575757578e-07] - Loss total: 2.5408942699432373, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.8433312177658081\n",
      "Step 9556/10000- lr: [4.4650286060605936e-07] - Loss total: 2.540888786315918, Last rpr Loss: 0.9999943375587463, Last lagvar Loss: 0.8433333039283752\n",
      "Step 9557/10000- lr: [4.4549276363636264e-07] - Loss total: 2.5408835411071777, Last rpr Loss: 0.9999922513961792, Last lagvar Loss: 0.8433353900909424\n",
      "Step 9558/10000- lr: [4.444826666666659e-07] - Loss total: 2.5408782958984375, Last rpr Loss: 0.9999931454658508, Last lagvar Loss: 0.843334436416626\n",
      "Step 9559/10000- lr: [4.434725696969692e-07] - Loss total: 2.5408730506896973, Last rpr Loss: 0.9999940395355225, Last lagvar Loss: 0.8433336615562439\n",
      "Step 9560/10000- lr: [4.4246247272727247e-07] - Loss total: 2.540868043899536, Last rpr Loss: 0.9999932646751404, Last lagvar Loss: 0.8433343172073364\n",
      "Step 9561/10000- lr: [4.4145237575757574e-07] - Loss total: 2.540862560272217, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8433327674865723\n",
      "Step 9562/10000- lr: [4.4044227878787733e-07] - Loss total: 2.5408575534820557, Last rpr Loss: 0.9999959468841553, Last lagvar Loss: 0.8433316946029663\n",
      "Step 9563/10000- lr: [4.394321818181806e-07] - Loss total: 2.5408520698547363, Last rpr Loss: 0.9999961256980896, Last lagvar Loss: 0.8433314561843872\n",
      "Step 9564/10000- lr: [4.384220848484839e-07] - Loss total: 2.540847063064575, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8433327674865723\n",
      "Step 9565/10000- lr: [4.3741198787878716e-07] - Loss total: 2.540841579437256, Last rpr Loss: 0.9999942779541016, Last lagvar Loss: 0.84333336353302\n",
      "Step 9566/10000- lr: [4.3640189090909044e-07] - Loss total: 2.5408363342285156, Last rpr Loss: 0.9999929070472717, Last lagvar Loss: 0.8433347344398499\n",
      "Step 9567/10000- lr: [4.353917939393937e-07] - Loss total: 2.5408315658569336, Last rpr Loss: 0.9999927282333374, Last lagvar Loss: 0.8433347940444946\n",
      "Step 9568/10000- lr: [4.343816969696953e-07] - Loss total: 2.5408260822296143, Last rpr Loss: 0.999993085861206, Last lagvar Loss: 0.843334436416626\n",
      "Step 9569/10000- lr: [4.3337160000000027e-07] - Loss total: 2.540821075439453, Last rpr Loss: 0.9999938011169434, Last lagvar Loss: 0.8433338403701782\n",
      "Step 9570/10000- lr: [4.3236150303030185e-07] - Loss total: 2.540815830230713, Last rpr Loss: 0.9999953508377075, Last lagvar Loss: 0.8433322310447693\n",
      "Step 9571/10000- lr: [4.3135140606060513e-07] - Loss total: 2.5408108234405518, Last rpr Loss: 0.9999958872795105, Last lagvar Loss: 0.8433315753936768\n",
      "Step 9572/10000- lr: [4.303413090909084e-07] - Loss total: 2.5408055782318115, Last rpr Loss: 0.9999951124191284, Last lagvar Loss: 0.8433324098587036\n",
      "Step 9573/10000- lr: [4.293312121212117e-07] - Loss total: 2.5408005714416504, Last rpr Loss: 0.9999939799308777, Last lagvar Loss: 0.8433336019515991\n",
      "Step 9574/10000- lr: [4.2832111515151496e-07] - Loss total: 2.5407955646514893, Last rpr Loss: 0.9999938011169434, Last lagvar Loss: 0.8433336019515991\n",
      "Step 9575/10000- lr: [4.2731101818181824e-07] - Loss total: 2.540790319442749, Last rpr Loss: 0.9999935030937195, Last lagvar Loss: 0.8433339595794678\n",
      "Step 9576/10000- lr: [4.263009212121215e-07] - Loss total: 2.540785312652588, Last rpr Loss: 0.9999949932098389, Last lagvar Loss: 0.8433324694633484\n",
      "Step 9577/10000- lr: [4.252908242424231e-07] - Loss total: 2.5407803058624268, Last rpr Loss: 0.9999945163726807, Last lagvar Loss: 0.8433328866958618\n",
      "Step 9578/10000- lr: [4.2428072727272807e-07] - Loss total: 2.5407752990722656, Last rpr Loss: 0.9999932050704956, Last lagvar Loss: 0.8433341979980469\n",
      "Step 9579/10000- lr: [4.2327063030302965e-07] - Loss total: 2.5407702922821045, Last rpr Loss: 0.9999936819076538, Last lagvar Loss: 0.8433337211608887\n",
      "Step 9580/10000- lr: [4.2226053333333293e-07] - Loss total: 2.5407650470733643, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.843330979347229\n",
      "Step 9581/10000- lr: [4.212504363636362e-07] - Loss total: 2.540760040283203, Last rpr Loss: 0.9999945163726807, Last lagvar Loss: 0.8433330059051514\n",
      "Step 9582/10000- lr: [4.202403393939395e-07] - Loss total: 2.540755271911621, Last rpr Loss: 0.9999940395355225, Last lagvar Loss: 0.84333336353302\n",
      "Step 9583/10000- lr: [4.1923024242424106e-07] - Loss total: 2.540750026702881, Last rpr Loss: 0.9999937415122986, Last lagvar Loss: 0.8433336615562439\n",
      "Step 9584/10000- lr: [4.1822014545454604e-07] - Loss total: 2.540745258331299, Last rpr Loss: 0.9999930262565613, Last lagvar Loss: 0.8433343768119812\n",
      "Step 9585/10000- lr: [4.172100484848476e-07] - Loss total: 2.5407402515411377, Last rpr Loss: 0.9999942183494568, Last lagvar Loss: 0.8433331251144409\n",
      "Step 9586/10000- lr: [4.161999515151509e-07] - Loss total: 2.5407352447509766, Last rpr Loss: 0.9999945163726807, Last lagvar Loss: 0.8433328866958618\n",
      "Step 9587/10000- lr: [4.1518985454545417e-07] - Loss total: 2.5407302379608154, Last rpr Loss: 0.9999940395355225, Last lagvar Loss: 0.84333336353302\n",
      "Step 9588/10000- lr: [4.1417975757575745e-07] - Loss total: 2.5407254695892334, Last rpr Loss: 0.9999950528144836, Last lagvar Loss: 0.8433324098587036\n",
      "Step 9589/10000- lr: [4.1316966060606073e-07] - Loss total: 2.5407204627990723, Last rpr Loss: 0.9999955892562866, Last lagvar Loss: 0.8433318734169006\n",
      "Step 9590/10000- lr: [4.12159563636364e-07] - Loss total: 2.540715456008911, Last rpr Loss: 0.9999949336051941, Last lagvar Loss: 0.8433324694633484\n",
      "Step 9591/10000- lr: [4.111494666666656e-07] - Loss total: 2.54071044921875, Last rpr Loss: 0.9999939203262329, Last lagvar Loss: 0.8433334827423096\n",
      "Step 9592/10000- lr: [4.1013936969696886e-07] - Loss total: 2.540705680847168, Last rpr Loss: 0.9999943971633911, Last lagvar Loss: 0.8433328866958618\n",
      "Step 9593/10000- lr: [4.0912927272727214e-07] - Loss total: 2.540700674057007, Last rpr Loss: 0.999994158744812, Last lagvar Loss: 0.8433331251144409\n",
      "Step 9594/10000- lr: [4.081191757575754e-07] - Loss total: 2.540695905685425, Last rpr Loss: 0.9999947547912598, Last lagvar Loss: 0.8433326482772827\n",
      "Step 9595/10000- lr: [4.071090787878787e-07] - Loss total: 2.5406908988952637, Last rpr Loss: 0.9999943971633911, Last lagvar Loss: 0.8433328866958618\n",
      "Step 9596/10000- lr: [4.0609898181818197e-07] - Loss total: 2.5406858921051025, Last rpr Loss: 0.9999950528144836, Last lagvar Loss: 0.8433322906494141\n",
      "Step 9597/10000- lr: [4.0508888484848356e-07] - Loss total: 2.5406813621520996, Last rpr Loss: 0.9999946355819702, Last lagvar Loss: 0.8433325886726379\n",
      "Step 9598/10000- lr: [4.040787878787885e-07] - Loss total: 2.5406761169433594, Last rpr Loss: 0.9999932646751404, Last lagvar Loss: 0.8433340787887573\n",
      "Step 9599/10000- lr: [4.030686909090901e-07] - Loss total: 2.5406715869903564, Last rpr Loss: 0.9999929070472717, Last lagvar Loss: 0.843334436416626\n",
      "Step 9600/10000- lr: [4.020585939393934e-07] - Loss total: 2.5406668186187744, Last rpr Loss: 0.9999945759773254, Last lagvar Loss: 0.8433326482772827\n",
      "Step 9601/10000- lr: [4.0104849696969666e-07] - Loss total: 2.540661334991455, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8433324098587036\n",
      "Step 9602/10000- lr: [4.0003839999999994e-07] - Loss total: 2.540656566619873, Last rpr Loss: 0.9999945163726807, Last lagvar Loss: 0.8433326482772827\n",
      "Step 9603/10000- lr: [3.990283030303015e-07] - Loss total: 2.54065203666687, Last rpr Loss: 0.9999951124191284, Last lagvar Loss: 0.8433322310447693\n",
      "Step 9604/10000- lr: [3.980182060606065e-07] - Loss total: 2.54064679145813, Last rpr Loss: 0.9999957084655762, Last lagvar Loss: 0.8433315753936768\n",
      "Step 9605/10000- lr: [3.970081090909081e-07] - Loss total: 2.540642261505127, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8433324098587036\n",
      "Step 9606/10000- lr: [3.9599801212121136e-07] - Loss total: 2.540637493133545, Last rpr Loss: 0.9999938011169434, Last lagvar Loss: 0.8433334231376648\n",
      "Step 9607/10000- lr: [3.9498791515151463e-07] - Loss total: 2.540632963180542, Last rpr Loss: 0.9999927282333374, Last lagvar Loss: 0.843334436416626\n",
      "Step 9608/10000- lr: [3.939778181818179e-07] - Loss total: 2.5406277179718018, Last rpr Loss: 0.9999934434890747, Last lagvar Loss: 0.8433337807655334\n",
      "Step 9609/10000- lr: [3.929677212121212e-07] - Loss total: 2.540623188018799, Last rpr Loss: 0.9999949932098389, Last lagvar Loss: 0.8433321714401245\n",
      "Step 9610/10000- lr: [3.9195762424242446e-07] - Loss total: 2.540618419647217, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8433322906494141\n",
      "Step 9611/10000- lr: [3.9094752727272605e-07] - Loss total: 2.5406136512756348, Last rpr Loss: 0.9999945163726807, Last lagvar Loss: 0.8433327078819275\n",
      "Step 9612/10000- lr: [3.899374303030293e-07] - Loss total: 2.5406088829040527, Last rpr Loss: 0.9999955892562866, Last lagvar Loss: 0.843331515789032\n",
      "Step 9613/10000- lr: [3.889273333333326e-07] - Loss total: 2.540604591369629, Last rpr Loss: 0.9999957084655762, Last lagvar Loss: 0.8433314561843872\n",
      "Step 9614/10000- lr: [3.879172363636359e-07] - Loss total: 2.5405995845794678, Last rpr Loss: 0.9999957084655762, Last lagvar Loss: 0.843331515789032\n",
      "Step 9615/10000- lr: [3.8690713939393915e-07] - Loss total: 2.540595054626465, Last rpr Loss: 0.999993622303009, Last lagvar Loss: 0.8433335423469543\n",
      "Step 9616/10000- lr: [3.8589704242424243e-07] - Loss total: 2.5405900478363037, Last rpr Loss: 0.9999936819076538, Last lagvar Loss: 0.8433334231376648\n",
      "Step 9617/10000- lr: [3.84886945454544e-07] - Loss total: 2.54058575630188, Last rpr Loss: 0.9999943375587463, Last lagvar Loss: 0.8433328866958618\n",
      "Step 9618/10000- lr: [3.83876848484849e-07] - Loss total: 2.540580987930298, Last rpr Loss: 0.9999952912330627, Last lagvar Loss: 0.8433318734169006\n",
      "Step 9619/10000- lr: [3.8286675151515057e-07] - Loss total: 2.540576219558716, Last rpr Loss: 0.9999939799308777, Last lagvar Loss: 0.8433330655097961\n",
      "Step 9620/10000- lr: [3.8185665454545385e-07] - Loss total: 2.540571689605713, Last rpr Loss: 0.9999929666519165, Last lagvar Loss: 0.8433340787887573\n",
      "Step 9621/10000- lr: [3.808465575757571e-07] - Loss total: 2.540566921234131, Last rpr Loss: 0.9999951720237732, Last lagvar Loss: 0.8433318734169006\n",
      "Step 9622/10000- lr: [3.798364606060604e-07] - Loss total: 2.540562391281128, Last rpr Loss: 0.999995768070221, Last lagvar Loss: 0.8433313369750977\n",
      "Step 9623/10000- lr: [3.78826363636362e-07] - Loss total: 2.540557861328125, Last rpr Loss: 0.9999954700469971, Last lagvar Loss: 0.8433316946029663\n",
      "Step 9624/10000- lr: [3.7781626666666695e-07] - Loss total: 2.540553331375122, Last rpr Loss: 0.9999933242797852, Last lagvar Loss: 0.8433338403701782\n",
      "Step 9625/10000- lr: [3.7680616969696854e-07] - Loss total: 2.540548801422119, Last rpr Loss: 0.9999945163726807, Last lagvar Loss: 0.8433325886726379\n",
      "Step 9626/10000- lr: [3.757960727272718e-07] - Loss total: 2.540544271469116, Last rpr Loss: 0.9999961853027344, Last lagvar Loss: 0.8433308601379395\n",
      "Step 9627/10000- lr: [3.747859757575751e-07] - Loss total: 2.5405397415161133, Last rpr Loss: 0.999995231628418, Last lagvar Loss: 0.8433318734169006\n",
      "Step 9628/10000- lr: [3.7377587878787837e-07] - Loss total: 2.5405349731445312, Last rpr Loss: 0.9999934434890747, Last lagvar Loss: 0.8433336019515991\n",
      "Step 9629/10000- lr: [3.7276578181818165e-07] - Loss total: 2.5405304431915283, Last rpr Loss: 0.9999938607215881, Last lagvar Loss: 0.8433331251144409\n",
      "Step 9630/10000- lr: [3.717556848484849e-07] - Loss total: 2.5405261516571045, Last rpr Loss: 0.999995768070221, Last lagvar Loss: 0.8433313369750977\n",
      "Step 9631/10000- lr: [3.707455878787865e-07] - Loss total: 2.5405216217041016, Last rpr Loss: 0.9999953508377075, Last lagvar Loss: 0.8433316946029663\n",
      "Step 9632/10000- lr: [3.697354909090898e-07] - Loss total: 2.5405170917510986, Last rpr Loss: 0.9999939799308777, Last lagvar Loss: 0.8433330655097961\n",
      "Step 9633/10000- lr: [3.6872539393939306e-07] - Loss total: 2.5405125617980957, Last rpr Loss: 0.9999927282333374, Last lagvar Loss: 0.8433343172073364\n",
      "Step 9634/10000- lr: [3.6771529696969634e-07] - Loss total: 2.5405080318450928, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8433321714401245\n",
      "Step 9635/10000- lr: [3.667051999999996e-07] - Loss total: 2.540503740310669, Last rpr Loss: 0.9999951720237732, Last lagvar Loss: 0.8433318734169006\n",
      "Step 9636/10000- lr: [3.656951030303029e-07] - Loss total: 2.540499210357666, Last rpr Loss: 0.9999945163726807, Last lagvar Loss: 0.8433325886726379\n",
      "Step 9637/10000- lr: [3.646850060606045e-07] - Loss total: 2.540494680404663, Last rpr Loss: 0.9999951124191284, Last lagvar Loss: 0.8433318734169006\n",
      "Step 9638/10000- lr: [3.6367490909090945e-07] - Loss total: 2.5404903888702393, Last rpr Loss: 0.9999949932098389, Last lagvar Loss: 0.843332052230835\n",
      "Step 9639/10000- lr: [3.6266481212121103e-07] - Loss total: 2.5404860973358154, Last rpr Loss: 0.9999967813491821, Last lagvar Loss: 0.8433302640914917\n",
      "Step 9640/10000- lr: [3.616547151515143e-07] - Loss total: 2.5404813289642334, Last rpr Loss: 0.9999954104423523, Last lagvar Loss: 0.8433315753936768\n",
      "Step 9641/10000- lr: [3.606446181818176e-07] - Loss total: 2.5404770374298096, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8433321714401245\n",
      "Step 9642/10000- lr: [3.5963452121212086e-07] - Loss total: 2.5404727458953857, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8433321118354797\n",
      "Step 9643/10000- lr: [3.5862442424242244e-07] - Loss total: 2.540468215942383, Last rpr Loss: 0.999992847442627, Last lagvar Loss: 0.8433341383934021\n",
      "Step 9644/10000- lr: [3.576143272727274e-07] - Loss total: 2.54046368598938, Last rpr Loss: 0.9999932646751404, Last lagvar Loss: 0.8433337211608887\n",
      "Step 9645/10000- lr: [3.56604230303029e-07] - Loss total: 2.540459632873535, Last rpr Loss: 0.9999935030937195, Last lagvar Loss: 0.8433334231376648\n",
      "Step 9646/10000- lr: [3.555941333333323e-07] - Loss total: 2.5404553413391113, Last rpr Loss: 0.9999935030937195, Last lagvar Loss: 0.8433334827423096\n",
      "Step 9647/10000- lr: [3.5458403636363555e-07] - Loss total: 2.5404505729675293, Last rpr Loss: 0.9999956488609314, Last lagvar Loss: 0.8433312773704529\n",
      "Step 9648/10000- lr: [3.5357393939393883e-07] - Loss total: 2.5404465198516846, Last rpr Loss: 0.9999962449073792, Last lagvar Loss: 0.8433307409286499\n",
      "Step 9649/10000- lr: [3.525638424242421e-07] - Loss total: 2.5404422283172607, Last rpr Loss: 0.999996542930603, Last lagvar Loss: 0.8433303833007812\n",
      "Step 9650/10000- lr: [3.515537454545454e-07] - Loss total: 2.540437698364258, Last rpr Loss: 0.9999955892562866, Last lagvar Loss: 0.8433313965797424\n",
      "Step 9651/10000- lr: [3.5054364848484697e-07] - Loss total: 2.540433406829834, Last rpr Loss: 0.9999945163726807, Last lagvar Loss: 0.8433324098587036\n",
      "Step 9652/10000- lr: [3.4953355151515024e-07] - Loss total: 2.5404293537139893, Last rpr Loss: 0.9999947547912598, Last lagvar Loss: 0.8433321714401245\n",
      "Step 9653/10000- lr: [3.485234545454535e-07] - Loss total: 2.5404250621795654, Last rpr Loss: 0.999993622303009, Last lagvar Loss: 0.8433332443237305\n",
      "Step 9654/10000- lr: [3.475133575757568e-07] - Loss total: 2.5404205322265625, Last rpr Loss: 0.9999948143959045, Last lagvar Loss: 0.8433321714401245\n",
      "Step 9655/10000- lr: [3.465032606060601e-07] - Loss total: 2.5404160022735596, Last rpr Loss: 0.9999954700469971, Last lagvar Loss: 0.8433313965797424\n",
      "Step 9656/10000- lr: [3.4549316363636335e-07] - Loss total: 2.540411949157715, Last rpr Loss: 0.9999948143959045, Last lagvar Loss: 0.843332052230835\n",
      "Step 9657/10000- lr: [3.4448306666666663e-07] - Loss total: 2.540407657623291, Last rpr Loss: 0.9999951124191284, Last lagvar Loss: 0.8433316946029663\n",
      "Step 9658/10000- lr: [3.434729696969699e-07] - Loss total: 2.540403366088867, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8433319330215454\n",
      "Step 9659/10000- lr: [3.424628727272732e-07] - Loss total: 2.5403988361358643, Last rpr Loss: 0.9999942183494568, Last lagvar Loss: 0.8433326482772827\n",
      "Step 9660/10000- lr: [3.4145277575757477e-07] - Loss total: 2.5403950214385986, Last rpr Loss: 0.9999946355819702, Last lagvar Loss: 0.8433322906494141\n",
      "Step 9661/10000- lr: [3.4044267878787804e-07] - Loss total: 2.540390968322754, Last rpr Loss: 0.999996542930603, Last lagvar Loss: 0.8433303833007812\n",
      "Step 9662/10000- lr: [3.394325818181813e-07] - Loss total: 2.540386438369751, Last rpr Loss: 0.9999956488609314, Last lagvar Loss: 0.8433312177658081\n",
      "Step 9663/10000- lr: [3.384224848484846e-07] - Loss total: 2.5403823852539062, Last rpr Loss: 0.9999951124191284, Last lagvar Loss: 0.8433316946029663\n",
      "Step 9664/10000- lr: [3.3741238787878787e-07] - Loss total: 2.5403780937194824, Last rpr Loss: 0.9999931454658508, Last lagvar Loss: 0.8433337211608887\n",
      "Step 9665/10000- lr: [3.3640229090909115e-07] - Loss total: 2.5403740406036377, Last rpr Loss: 0.999993622303009, Last lagvar Loss: 0.8433332443237305\n",
      "Step 9666/10000- lr: [3.3539219393939273e-07] - Loss total: 2.540369987487793, Last rpr Loss: 0.9999966621398926, Last lagvar Loss: 0.8433302640914917\n",
      "Step 9667/10000- lr: [3.343820969696977e-07] - Loss total: 2.5403659343719482, Last rpr Loss: 0.9999957084655762, Last lagvar Loss: 0.8433310985565186\n",
      "Step 9668/10000- lr: [3.333719999999993e-07] - Loss total: 2.5403616428375244, Last rpr Loss: 0.9999945163726807, Last lagvar Loss: 0.8433323502540588\n",
      "Step 9669/10000- lr: [3.3236190303030256e-07] - Loss total: 2.5403575897216797, Last rpr Loss: 0.9999948143959045, Last lagvar Loss: 0.843332052230835\n",
      "Step 9670/10000- lr: [3.3135180606060584e-07] - Loss total: 2.540353536605835, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8433318734169006\n",
      "Step 9671/10000- lr: [3.303417090909091e-07] - Loss total: 2.540349245071411, Last rpr Loss: 0.9999933242797852, Last lagvar Loss: 0.8433334827423096\n",
      "Step 9672/10000- lr: [3.293316121212107e-07] - Loss total: 2.5403454303741455, Last rpr Loss: 0.9999948143959045, Last lagvar Loss: 0.8433319330215454\n",
      "Step 9673/10000- lr: [3.2832151515151567e-07] - Loss total: 2.540341377258301, Last rpr Loss: 0.9999953508377075, Last lagvar Loss: 0.8433314561843872\n",
      "Step 9674/10000- lr: [3.2731141818181726e-07] - Loss total: 2.540337324142456, Last rpr Loss: 0.9999966025352478, Last lagvar Loss: 0.8433301448822021\n",
      "Step 9675/10000- lr: [3.2630132121212053e-07] - Loss total: 2.5403332710266113, Last rpr Loss: 0.9999952912330627, Last lagvar Loss: 0.843331515789032\n",
      "Step 9676/10000- lr: [3.252912242424238e-07] - Loss total: 2.5403292179107666, Last rpr Loss: 0.9999932646751404, Last lagvar Loss: 0.8433334827423096\n",
      "Step 9677/10000- lr: [3.242811272727271e-07] - Loss total: 2.5403249263763428, Last rpr Loss: 0.999995231628418, Last lagvar Loss: 0.8433316946029663\n",
      "Step 9678/10000- lr: [3.2327103030303036e-07] - Loss total: 2.540320873260498, Last rpr Loss: 0.9999951720237732, Last lagvar Loss: 0.8433316349983215\n",
      "Step 9679/10000- lr: [3.2226093333333364e-07] - Loss total: 2.5403170585632324, Last rpr Loss: 0.9999954104423523, Last lagvar Loss: 0.8433314561843872\n",
      "Step 9680/10000- lr: [3.212508363636352e-07] - Loss total: 2.5403130054473877, Last rpr Loss: 0.9999949336051941, Last lagvar Loss: 0.8433317542076111\n",
      "Step 9681/10000- lr: [3.202407393939385e-07] - Loss total: 2.540309190750122, Last rpr Loss: 0.9999961256980896, Last lagvar Loss: 0.8433306217193604\n",
      "Step 9682/10000- lr: [3.192306424242418e-07] - Loss total: 2.5403051376342773, Last rpr Loss: 0.9999954700469971, Last lagvar Loss: 0.8433313369750977\n",
      "Step 9683/10000- lr: [3.1822054545454506e-07] - Loss total: 2.5403013229370117, Last rpr Loss: 0.999994695186615, Last lagvar Loss: 0.843332052230835\n",
      "Step 9684/10000- lr: [3.1721044848484833e-07] - Loss total: 2.540297269821167, Last rpr Loss: 0.999993622303009, Last lagvar Loss: 0.8433332443237305\n",
      "Step 9685/10000- lr: [3.162003515151516e-07] - Loss total: 2.5402934551239014, Last rpr Loss: 0.999993622303009, Last lagvar Loss: 0.8433331847190857\n",
      "Step 9686/10000- lr: [3.151902545454532e-07] - Loss total: 2.5402894020080566, Last rpr Loss: 0.9999957084655762, Last lagvar Loss: 0.8433310985565186\n",
      "Step 9687/10000- lr: [3.1418015757575816e-07] - Loss total: 2.540285587310791, Last rpr Loss: 0.9999968409538269, Last lagvar Loss: 0.843329906463623\n",
      "Step 9688/10000- lr: [3.1317006060605975e-07] - Loss total: 2.5402815341949463, Last rpr Loss: 0.9999960660934448, Last lagvar Loss: 0.8433307409286499\n",
      "Step 9689/10000- lr: [3.12159963636363e-07] - Loss total: 2.5402777194976807, Last rpr Loss: 0.9999954700469971, Last lagvar Loss: 0.8433313369750977\n",
      "Step 9690/10000- lr: [3.111498666666663e-07] - Loss total: 2.540273904800415, Last rpr Loss: 0.9999952912330627, Last lagvar Loss: 0.8433314561843872\n",
      "Step 9691/10000- lr: [3.101397696969696e-07] - Loss total: 2.5402698516845703, Last rpr Loss: 0.9999939799308777, Last lagvar Loss: 0.8433327674865723\n",
      "Step 9692/10000- lr: [3.0912967272727116e-07] - Loss total: 2.5402660369873047, Last rpr Loss: 0.9999943971633911, Last lagvar Loss: 0.8433323502540588\n",
      "Step 9693/10000- lr: [3.0811957575757613e-07] - Loss total: 2.540261745452881, Last rpr Loss: 0.999994695186615, Last lagvar Loss: 0.843332052230835\n",
      "Step 9694/10000- lr: [3.071094787878777e-07] - Loss total: 2.5402581691741943, Last rpr Loss: 0.9999954104423523, Last lagvar Loss: 0.8433313965797424\n",
      "Step 9695/10000- lr: [3.06099381818181e-07] - Loss total: 2.540254592895508, Last rpr Loss: 0.999995231628418, Last lagvar Loss: 0.843331515789032\n",
      "Step 9696/10000- lr: [3.0508928484848427e-07] - Loss total: 2.540250778198242, Last rpr Loss: 0.9999952912330627, Last lagvar Loss: 0.8433314561843872\n",
      "Step 9697/10000- lr: [3.0407918787878755e-07] - Loss total: 2.5402469635009766, Last rpr Loss: 0.9999953508377075, Last lagvar Loss: 0.8433312177658081\n",
      "Step 9698/10000- lr: [3.030690909090908e-07] - Loss total: 2.5402426719665527, Last rpr Loss: 0.9999949932098389, Last lagvar Loss: 0.8433316349983215\n",
      "Step 9699/10000- lr: [3.020589939393941e-07] - Loss total: 2.540239095687866, Last rpr Loss: 0.9999943971633911, Last lagvar Loss: 0.8433323502540588\n",
      "Step 9700/10000- lr: [3.010488969696957e-07] - Loss total: 2.5402352809906006, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8433308601379395\n",
      "Step 9701/10000- lr: [3.0003879999999896e-07] - Loss total: 2.540231466293335, Last rpr Loss: 0.9999951720237732, Last lagvar Loss: 0.8433314561843872\n",
      "Step 9702/10000- lr: [2.9902870303030224e-07] - Loss total: 2.5402276515960693, Last rpr Loss: 0.9999953508377075, Last lagvar Loss: 0.8433312773704529\n",
      "Step 9703/10000- lr: [2.980186060606055e-07] - Loss total: 2.540224075317383, Last rpr Loss: 0.9999957084655762, Last lagvar Loss: 0.8433310985565186\n",
      "Step 9704/10000- lr: [2.970085090909088e-07] - Loss total: 2.540220260620117, Last rpr Loss: 0.9999951124191284, Last lagvar Loss: 0.8433315753936768\n",
      "Step 9705/10000- lr: [2.9599841212121207e-07] - Loss total: 2.5402166843414307, Last rpr Loss: 0.9999940991401672, Last lagvar Loss: 0.8433326482772827\n",
      "Step 9706/10000- lr: [2.9498831515151365e-07] - Loss total: 2.540213108062744, Last rpr Loss: 0.9999949336051941, Last lagvar Loss: 0.8433316946029663\n",
      "Step 9707/10000- lr: [2.939782181818186e-07] - Loss total: 2.5402090549468994, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.8433302640914917\n",
      "Step 9708/10000- lr: [2.929681212121202e-07] - Loss total: 2.540205478668213, Last rpr Loss: 0.9999970197677612, Last lagvar Loss: 0.8433297872543335\n",
      "Step 9709/10000- lr: [2.919580242424235e-07] - Loss total: 2.5402019023895264, Last rpr Loss: 0.9999963045120239, Last lagvar Loss: 0.843330442905426\n",
      "Step 9710/10000- lr: [2.9094792727272676e-07] - Loss total: 2.5401980876922607, Last rpr Loss: 0.9999950528144836, Last lagvar Loss: 0.8433315753936768\n",
      "Step 9711/10000- lr: [2.8993783030303004e-07] - Loss total: 2.5401947498321533, Last rpr Loss: 0.9999935626983643, Last lagvar Loss: 0.8433331251144409\n",
      "Step 9712/10000- lr: [2.889277333333316e-07] - Loss total: 2.5401909351348877, Last rpr Loss: 0.9999924302101135, Last lagvar Loss: 0.8433341979980469\n",
      "Step 9713/10000- lr: [2.879176363636366e-07] - Loss total: 2.540187120437622, Last rpr Loss: 0.9999943971633911, Last lagvar Loss: 0.8433321714401245\n",
      "Step 9714/10000- lr: [2.869075393939382e-07] - Loss total: 2.5401835441589355, Last rpr Loss: 0.9999967813491821, Last lagvar Loss: 0.8433299660682678\n",
      "Step 9715/10000- lr: [2.8589744242424145e-07] - Loss total: 2.540179967880249, Last rpr Loss: 0.9999960064888, Last lagvar Loss: 0.8433306217193604\n",
      "Step 9716/10000- lr: [2.8488734545454473e-07] - Loss total: 2.5401763916015625, Last rpr Loss: 0.9999959468841553, Last lagvar Loss: 0.8433306217193604\n",
      "Step 9717/10000- lr: [2.83877248484848e-07] - Loss total: 2.540172815322876, Last rpr Loss: 0.9999943971633911, Last lagvar Loss: 0.8433322906494141\n",
      "Step 9718/10000- lr: [2.828671515151513e-07] - Loss total: 2.5401692390441895, Last rpr Loss: 0.9999955892562866, Last lagvar Loss: 0.8433310389518738\n",
      "Step 9719/10000- lr: [2.8185705454545456e-07] - Loss total: 2.540165662765503, Last rpr Loss: 0.9999963641166687, Last lagvar Loss: 0.8433302640914917\n",
      "Step 9720/10000- lr: [2.8084695757575614e-07] - Loss total: 2.5401623249053955, Last rpr Loss: 0.9999954700469971, Last lagvar Loss: 0.8433310985565186\n",
      "Step 9721/10000- lr: [2.798368606060594e-07] - Loss total: 2.54015851020813, Last rpr Loss: 0.9999942183494568, Last lagvar Loss: 0.8433324098587036\n",
      "Step 9722/10000- lr: [2.788267636363627e-07] - Loss total: 2.5401549339294434, Last rpr Loss: 0.9999951720237732, Last lagvar Loss: 0.8433314561843872\n",
      "Step 9723/10000- lr: [2.77816666666666e-07] - Loss total: 2.540151357650757, Last rpr Loss: 0.9999955892562866, Last lagvar Loss: 0.8433310985565186\n",
      "Step 9724/10000- lr: [2.7680656969696925e-07] - Loss total: 2.5401480197906494, Last rpr Loss: 0.9999959468841553, Last lagvar Loss: 0.8433306813240051\n",
      "Step 9725/10000- lr: [2.7579647272727253e-07] - Loss total: 2.540144205093384, Last rpr Loss: 0.9999953508377075, Last lagvar Loss: 0.8433312177658081\n",
      "Step 9726/10000- lr: [2.747863757575741e-07] - Loss total: 2.5401411056518555, Last rpr Loss: 0.9999938011169434, Last lagvar Loss: 0.8433327674865723\n",
      "Step 9727/10000- lr: [2.737762787878791e-07] - Loss total: 2.540137529373169, Last rpr Loss: 0.9999949336051941, Last lagvar Loss: 0.8433315753936768\n",
      "Step 9728/10000- lr: [2.7276618181818067e-07] - Loss total: 2.5401341915130615, Last rpr Loss: 0.999995768070221, Last lagvar Loss: 0.8433308601379395\n",
      "Step 9729/10000- lr: [2.7175608484848394e-07] - Loss total: 2.540130376815796, Last rpr Loss: 0.9999964833259583, Last lagvar Loss: 0.8433301448822021\n",
      "Step 9730/10000- lr: [2.707459878787872e-07] - Loss total: 2.5401268005371094, Last rpr Loss: 0.9999951720237732, Last lagvar Loss: 0.8433313369750977\n",
      "Step 9731/10000- lr: [2.697358909090905e-07] - Loss total: 2.540123462677002, Last rpr Loss: 0.9999944567680359, Last lagvar Loss: 0.8433321118354797\n",
      "Step 9732/10000- lr: [2.687257939393921e-07] - Loss total: 2.5401201248168945, Last rpr Loss: 0.9999949932098389, Last lagvar Loss: 0.8433315753936768\n",
      "Step 9733/10000- lr: [2.6771569696969705e-07] - Loss total: 2.540116548538208, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8433307409286499\n",
      "Step 9734/10000- lr: [2.6670559999999863e-07] - Loss total: 2.5401132106781006, Last rpr Loss: 0.9999966621398926, Last lagvar Loss: 0.8433299660682678\n",
      "Step 9735/10000- lr: [2.656955030303019e-07] - Loss total: 2.540109872817993, Last rpr Loss: 0.9999969601631165, Last lagvar Loss: 0.843329668045044\n",
      "Step 9736/10000- lr: [2.646854060606052e-07] - Loss total: 2.5401065349578857, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8433308601379395\n",
      "Step 9737/10000- lr: [2.6367530909090847e-07] - Loss total: 2.5401031970977783, Last rpr Loss: 0.9999955892562866, Last lagvar Loss: 0.8433310389518738\n",
      "Step 9738/10000- lr: [2.6266521212121174e-07] - Loss total: 2.540099620819092, Last rpr Loss: 0.9999945759773254, Last lagvar Loss: 0.843332052230835\n",
      "Step 9739/10000- lr: [2.61655115151515e-07] - Loss total: 2.5400962829589844, Last rpr Loss: 0.9999963045120239, Last lagvar Loss: 0.8433302640914917\n",
      "Step 9740/10000- lr: [2.606450181818166e-07] - Loss total: 2.540092945098877, Last rpr Loss: 0.9999961853027344, Last lagvar Loss: 0.8433303833007812\n",
      "Step 9741/10000- lr: [2.596349212121199e-07] - Loss total: 2.5400898456573486, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8433316946029663\n",
      "Step 9742/10000- lr: [2.5862482424242485e-07] - Loss total: 2.540086030960083, Last rpr Loss: 0.9999954104423523, Last lagvar Loss: 0.8433310985565186\n",
      "Step 9743/10000- lr: [2.5761472727272643e-07] - Loss total: 2.540083169937134, Last rpr Loss: 0.999995231628418, Last lagvar Loss: 0.8433312773704529\n",
      "Step 9744/10000- lr: [2.566046303030297e-07] - Loss total: 2.5400795936584473, Last rpr Loss: 0.9999937415122986, Last lagvar Loss: 0.8433328866958618\n",
      "Step 9745/10000- lr: [2.55594533333333e-07] - Loss total: 2.540076494216919, Last rpr Loss: 0.9999945163726807, Last lagvar Loss: 0.8433321714401245\n",
      "Step 9746/10000- lr: [2.5458443636363627e-07] - Loss total: 2.5400733947753906, Last rpr Loss: 0.9999951720237732, Last lagvar Loss: 0.8433314561843872\n",
      "Step 9747/10000- lr: [2.5357433939393954e-07] - Loss total: 2.540070056915283, Last rpr Loss: 0.9999957084655762, Last lagvar Loss: 0.8433308601379395\n",
      "Step 9748/10000- lr: [2.525642424242428e-07] - Loss total: 2.540066719055176, Last rpr Loss: 0.9999963641166687, Last lagvar Loss: 0.8433302640914917\n",
      "Step 9749/10000- lr: [2.515541454545444e-07] - Loss total: 2.5400636196136475, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8433308005332947\n",
      "Step 9750/10000- lr: [2.505440484848477e-07] - Loss total: 2.540060043334961, Last rpr Loss: 0.9999959468841553, Last lagvar Loss: 0.8433305025100708\n",
      "Step 9751/10000- lr: [2.4953395151515096e-07] - Loss total: 2.5400571823120117, Last rpr Loss: 0.999995768070221, Last lagvar Loss: 0.8433307409286499\n",
      "Step 9752/10000- lr: [2.4852385454545423e-07] - Loss total: 2.540053606033325, Last rpr Loss: 0.999995231628418, Last lagvar Loss: 0.8433313369750977\n",
      "Step 9753/10000- lr: [2.475137575757575e-07] - Loss total: 2.540050745010376, Last rpr Loss: 0.9999961853027344, Last lagvar Loss: 0.8433303833007812\n",
      "Step 9754/10000- lr: [2.465036606060608e-07] - Loss total: 2.5400476455688477, Last rpr Loss: 0.9999964833259583, Last lagvar Loss: 0.8433300256729126\n",
      "Step 9755/10000- lr: [2.4549356363636237e-07] - Loss total: 2.540044069290161, Last rpr Loss: 0.9999967813491821, Last lagvar Loss: 0.8433297872543335\n",
      "Step 9756/10000- lr: [2.4448346666666734e-07] - Loss total: 2.540040969848633, Last rpr Loss: 0.9999969005584717, Last lagvar Loss: 0.843329668045044\n",
      "Step 9757/10000- lr: [2.434733696969689e-07] - Loss total: 2.5400381088256836, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8433308005332947\n",
      "Step 9758/10000- lr: [2.424632727272722e-07] - Loss total: 2.540034770965576, Last rpr Loss: 0.9999946355819702, Last lagvar Loss: 0.8433318138122559\n",
      "Step 9759/10000- lr: [2.414531757575755e-07] - Loss total: 2.540031671524048, Last rpr Loss: 0.9999949932098389, Last lagvar Loss: 0.8433315753936768\n",
      "Step 9760/10000- lr: [2.4044307878787876e-07] - Loss total: 2.5400288105010986, Last rpr Loss: 0.9999957084655762, Last lagvar Loss: 0.8433308601379395\n",
      "Step 9761/10000- lr: [2.3943298181818034e-07] - Loss total: 2.540025234222412, Last rpr Loss: 0.9999950528144836, Last lagvar Loss: 0.843331515789032\n",
      "Step 9762/10000- lr: [2.384228848484853e-07] - Loss total: 2.540022373199463, Last rpr Loss: 0.9999945163726807, Last lagvar Loss: 0.8433319926261902\n",
      "Step 9763/10000- lr: [2.374127878787869e-07] - Loss total: 2.5400192737579346, Last rpr Loss: 0.9999943375587463, Last lagvar Loss: 0.8433321714401245\n",
      "Step 9764/10000- lr: [2.3640269090909017e-07] - Loss total: 2.5400164127349854, Last rpr Loss: 0.9999954700469971, Last lagvar Loss: 0.8433310985565186\n",
      "Step 9765/10000- lr: [2.3539259393939345e-07] - Loss total: 2.540013313293457, Last rpr Loss: 0.9999956488609314, Last lagvar Loss: 0.843330979347229\n",
      "Step 9766/10000- lr: [2.3438249696969672e-07] - Loss total: 2.5400099754333496, Last rpr Loss: 0.9999963045120239, Last lagvar Loss: 0.8433301448822021\n",
      "Step 9767/10000- lr: [2.333724e-07] - Loss total: 2.5400071144104004, Last rpr Loss: 0.9999979138374329, Last lagvar Loss: 0.843328595161438\n",
      "Step 9768/10000- lr: [2.3236230303030328e-07] - Loss total: 2.540004014968872, Last rpr Loss: 0.9999960064888, Last lagvar Loss: 0.8433305621147156\n",
      "Step 9769/10000- lr: [2.3135220606060486e-07] - Loss total: 2.5400009155273438, Last rpr Loss: 0.9999963045120239, Last lagvar Loss: 0.8433302044868469\n",
      "Step 9770/10000- lr: [2.3034210909090814e-07] - Loss total: 2.5399980545043945, Last rpr Loss: 0.9999959468841553, Last lagvar Loss: 0.8433306217193604\n",
      "Step 9771/10000- lr: [2.2933201212121142e-07] - Loss total: 2.539994955062866, Last rpr Loss: 0.9999957084655762, Last lagvar Loss: 0.8433308601379395\n",
      "Step 9772/10000- lr: [2.283219151515147e-07] - Loss total: 2.539992094039917, Last rpr Loss: 0.9999957084655762, Last lagvar Loss: 0.8433308005332947\n",
      "Step 9773/10000- lr: [2.2731181818181797e-07] - Loss total: 2.5399889945983887, Last rpr Loss: 0.999995768070221, Last lagvar Loss: 0.8433306217193604\n",
      "Step 9774/10000- lr: [2.2630172121212125e-07] - Loss total: 2.5399863719940186, Last rpr Loss: 0.9999951720237732, Last lagvar Loss: 0.8433313369750977\n",
      "Step 9775/10000- lr: [2.2529162424242283e-07] - Loss total: 2.539983034133911, Last rpr Loss: 0.9999954700469971, Last lagvar Loss: 0.843330979347229\n",
      "Step 9776/10000- lr: [2.242815272727278e-07] - Loss total: 2.539980173110962, Last rpr Loss: 0.9999950528144836, Last lagvar Loss: 0.8433314561843872\n",
      "Step 9777/10000- lr: [2.2327143030302938e-07] - Loss total: 2.5399773120880127, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8433306217193604\n",
      "Step 9778/10000- lr: [2.2226133333333266e-07] - Loss total: 2.5399744510650635, Last rpr Loss: 0.9999963641166687, Last lagvar Loss: 0.8433302044868469\n",
      "Step 9779/10000- lr: [2.2125123636363594e-07] - Loss total: 2.5399715900421143, Last rpr Loss: 0.9999949932098389, Last lagvar Loss: 0.8433315753936768\n",
      "Step 9780/10000- lr: [2.2024113939393922e-07] - Loss total: 2.539968729019165, Last rpr Loss: 0.9999953508377075, Last lagvar Loss: 0.8433310985565186\n",
      "Step 9781/10000- lr: [2.192310424242408e-07] - Loss total: 2.539965867996216, Last rpr Loss: 0.9999960660934448, Last lagvar Loss: 0.843330442905426\n",
      "Step 9782/10000- lr: [2.1822094545454577e-07] - Loss total: 2.5399630069732666, Last rpr Loss: 0.9999982714653015, Last lagvar Loss: 0.8433282375335693\n",
      "Step 9783/10000- lr: [2.1721084848484735e-07] - Loss total: 2.5399601459503174, Last rpr Loss: 0.9999982118606567, Last lagvar Loss: 0.8433282375335693\n",
      "Step 9784/10000- lr: [2.1620075151515063e-07] - Loss total: 2.5399575233459473, Last rpr Loss: 0.9999960660934448, Last lagvar Loss: 0.843330442905426\n",
      "Step 9785/10000- lr: [2.151906545454539e-07] - Loss total: 2.539954423904419, Last rpr Loss: 0.9999942779541016, Last lagvar Loss: 0.8433322906494141\n",
      "Step 9786/10000- lr: [2.1418055757575718e-07] - Loss total: 2.539951801300049, Last rpr Loss: 0.9999927878379822, Last lagvar Loss: 0.8433337211608887\n",
      "Step 9787/10000- lr: [2.1317046060606046e-07] - Loss total: 2.5399489402770996, Last rpr Loss: 0.9999949932098389, Last lagvar Loss: 0.843331515789032\n",
      "Step 9788/10000- lr: [2.1216036363636374e-07] - Loss total: 2.5399463176727295, Last rpr Loss: 0.9999973773956299, Last lagvar Loss: 0.8433291912078857\n",
      "Step 9789/10000- lr: [2.1115026666666532e-07] - Loss total: 2.5399434566497803, Last rpr Loss: 0.9999967813491821, Last lagvar Loss: 0.8433297276496887\n",
      "Step 9790/10000- lr: [2.101401696969686e-07] - Loss total: 2.53994083404541, Last rpr Loss: 0.9999953508377075, Last lagvar Loss: 0.8433310985565186\n",
      "Step 9791/10000- lr: [2.0913007272727188e-07] - Loss total: 2.539937734603882, Last rpr Loss: 0.9999934434890747, Last lagvar Loss: 0.8433330655097961\n",
      "Step 9792/10000- lr: [2.0811997575757515e-07] - Loss total: 2.5399351119995117, Last rpr Loss: 0.9999954700469971, Last lagvar Loss: 0.843330979347229\n",
      "Step 9793/10000- lr: [2.0710987878787843e-07] - Loss total: 2.5399324893951416, Last rpr Loss: 0.9999967813491821, Last lagvar Loss: 0.8433296084403992\n",
      "Step 9794/10000- lr: [2.060997818181817e-07] - Loss total: 2.5399296283721924, Last rpr Loss: 0.999998152256012, Last lagvar Loss: 0.8433282971382141\n",
      "Step 9795/10000- lr: [2.050896848484833e-07] - Loss total: 2.5399272441864014, Last rpr Loss: 0.9999972581863403, Last lagvar Loss: 0.8433291912078857\n",
      "Step 9796/10000- lr: [2.0407958787878826e-07] - Loss total: 2.539924383163452, Last rpr Loss: 0.9999954700469971, Last lagvar Loss: 0.843330979347229\n",
      "Step 9797/10000- lr: [2.0306949090908984e-07] - Loss total: 2.539921998977661, Last rpr Loss: 0.9999958872795105, Last lagvar Loss: 0.8433305621147156\n",
      "Step 9798/10000- lr: [2.0205939393939312e-07] - Loss total: 2.539919137954712, Last rpr Loss: 0.9999958872795105, Last lagvar Loss: 0.8433306217193604\n",
      "Step 9799/10000- lr: [2.010492969696964e-07] - Loss total: 2.5399162769317627, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.8433300852775574\n",
      "Step 9800/10000- lr: [2.0003919999999968e-07] - Loss total: 2.5399136543273926, Last rpr Loss: 0.9999961256980896, Last lagvar Loss: 0.8433303833007812\n",
      "Step 9801/10000- lr: [1.9902910303030126e-07] - Loss total: 2.5399110317230225, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.843331515789032\n",
      "Step 9802/10000- lr: [1.9801900606060623e-07] - Loss total: 2.5399086475372314, Last rpr Loss: 0.999995231628418, Last lagvar Loss: 0.8433312177658081\n",
      "Step 9803/10000- lr: [1.970089090909078e-07] - Loss total: 2.5399060249328613, Last rpr Loss: 0.9999955296516418, Last lagvar Loss: 0.843330979347229\n",
      "Step 9804/10000- lr: [1.959988121212111e-07] - Loss total: 2.539903402328491, Last rpr Loss: 0.9999955296516418, Last lagvar Loss: 0.8433308601379395\n",
      "Step 9805/10000- lr: [1.9498871515151437e-07] - Loss total: 2.5399010181427, Last rpr Loss: 0.9999961256980896, Last lagvar Loss: 0.8433303833007812\n",
      "Step 9806/10000- lr: [1.9397861818181764e-07] - Loss total: 2.53989839553833, Last rpr Loss: 0.9999955296516418, Last lagvar Loss: 0.8433308601379395\n",
      "Step 9807/10000- lr: [1.9296852121212092e-07] - Loss total: 2.53989577293396, Last rpr Loss: 0.9999967813491821, Last lagvar Loss: 0.843329668045044\n",
      "Step 9808/10000- lr: [1.919584242424242e-07] - Loss total: 2.53989315032959, Last rpr Loss: 0.9999951720237732, Last lagvar Loss: 0.8433312773704529\n",
      "Step 9809/10000- lr: [1.9094832727272578e-07] - Loss total: 2.539890766143799, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.8433299660682678\n",
      "Step 9810/10000- lr: [1.8993823030302906e-07] - Loss total: 2.5398881435394287, Last rpr Loss: 0.999997079372406, Last lagvar Loss: 0.8433293700218201\n",
      "Step 9811/10000- lr: [1.8892813333333234e-07] - Loss total: 2.5398855209350586, Last rpr Loss: 0.9999967813491821, Last lagvar Loss: 0.8433297276496887\n",
      "Step 9812/10000- lr: [1.879180363636356e-07] - Loss total: 2.5398831367492676, Last rpr Loss: 0.9999954104423523, Last lagvar Loss: 0.8433310985565186\n",
      "Step 9813/10000- lr: [1.869079393939389e-07] - Loss total: 2.5398807525634766, Last rpr Loss: 0.9999956488609314, Last lagvar Loss: 0.8433307409286499\n",
      "Step 9814/10000- lr: [1.8589784242424217e-07] - Loss total: 2.5398781299591064, Last rpr Loss: 0.9999960660934448, Last lagvar Loss: 0.8433305025100708\n",
      "Step 9815/10000- lr: [1.8488774545454375e-07] - Loss total: 2.5398757457733154, Last rpr Loss: 0.9999963641166687, Last lagvar Loss: 0.8433300256729126\n",
      "Step 9816/10000- lr: [1.8387764848484872e-07] - Loss total: 2.5398731231689453, Last rpr Loss: 0.9999973177909851, Last lagvar Loss: 0.8433291912078857\n",
      "Step 9817/10000- lr: [1.828675515151503e-07] - Loss total: 2.5398707389831543, Last rpr Loss: 0.999995768070221, Last lagvar Loss: 0.8433307409286499\n",
      "Step 9818/10000- lr: [1.8185745454545358e-07] - Loss total: 2.5398685932159424, Last rpr Loss: 0.9999954700469971, Last lagvar Loss: 0.843330979347229\n",
      "Step 9819/10000- lr: [1.8084735757575686e-07] - Loss total: 2.5398659706115723, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8433305621147156\n",
      "Step 9820/10000- lr: [1.7983726060606013e-07] - Loss total: 2.5398635864257812, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8433306217193604\n",
      "Step 9821/10000- lr: [1.7882716363636172e-07] - Loss total: 2.5398612022399902, Last rpr Loss: 0.9999952912330627, Last lagvar Loss: 0.8433310985565186\n",
      "Step 9822/10000- lr: [1.778170666666667e-07] - Loss total: 2.5398590564727783, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8433306217193604\n",
      "Step 9823/10000- lr: [1.7680696969696827e-07] - Loss total: 2.5398566722869873, Last rpr Loss: 0.999995768070221, Last lagvar Loss: 0.8433306813240051\n",
      "Step 9824/10000- lr: [1.7579687272727155e-07] - Loss total: 2.539854049682617, Last rpr Loss: 0.9999951124191284, Last lagvar Loss: 0.8433313369750977\n",
      "Step 9825/10000- lr: [1.7478677575757483e-07] - Loss total: 2.5398519039154053, Last rpr Loss: 0.9999951124191284, Last lagvar Loss: 0.8433313369750977\n",
      "Step 9826/10000- lr: [1.737766787878781e-07] - Loss total: 2.5398495197296143, Last rpr Loss: 0.9999959468841553, Last lagvar Loss: 0.8433305025100708\n",
      "Step 9827/10000- lr: [1.7276658181818138e-07] - Loss total: 2.5398471355438232, Last rpr Loss: 0.9999969005584717, Last lagvar Loss: 0.8433295488357544\n",
      "Step 9828/10000- lr: [1.7175648484848466e-07] - Loss total: 2.5398449897766113, Last rpr Loss: 0.9999986886978149, Last lagvar Loss: 0.8433277010917664\n",
      "Step 9829/10000- lr: [1.7074638787878793e-07] - Loss total: 2.5398426055908203, Last rpr Loss: 0.999997615814209, Last lagvar Loss: 0.8433288335800171\n",
      "Step 9830/10000- lr: [1.6973629090908952e-07] - Loss total: 2.5398404598236084, Last rpr Loss: 0.9999973773956299, Last lagvar Loss: 0.8433291912078857\n",
      "Step 9831/10000- lr: [1.687261939393945e-07] - Loss total: 2.5398380756378174, Last rpr Loss: 0.9999951124191284, Last lagvar Loss: 0.8433313369750977\n",
      "Step 9832/10000- lr: [1.6771609696969607e-07] - Loss total: 2.5398359298706055, Last rpr Loss: 0.9999948740005493, Last lagvar Loss: 0.8433316349983215\n",
      "Step 9833/10000- lr: [1.6670599999999935e-07] - Loss total: 2.5398335456848145, Last rpr Loss: 0.9999957084655762, Last lagvar Loss: 0.8433307409286499\n",
      "Step 9834/10000- lr: [1.6569590303030263e-07] - Loss total: 2.5398313999176025, Last rpr Loss: 0.9999973177909851, Last lagvar Loss: 0.8433291912078857\n",
      "Step 9835/10000- lr: [1.646858060606059e-07] - Loss total: 2.5398292541503906, Last rpr Loss: 0.9999973177909851, Last lagvar Loss: 0.8433291912078857\n",
      "Step 9836/10000- lr: [1.6367570909090918e-07] - Loss total: 2.5398268699645996, Last rpr Loss: 0.9999963045120239, Last lagvar Loss: 0.8433301448822021\n",
      "Step 9837/10000- lr: [1.6266561212121246e-07] - Loss total: 2.5398247241973877, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8433306813240051\n",
      "Step 9838/10000- lr: [1.6165551515151404e-07] - Loss total: 2.539822816848755, Last rpr Loss: 0.9999933838844299, Last lagvar Loss: 0.8433331251144409\n",
      "Step 9839/10000- lr: [1.6064541818181732e-07] - Loss total: 2.539820432662964, Last rpr Loss: 0.9999949932098389, Last lagvar Loss: 0.843331515789032\n",
      "Step 9840/10000- lr: [1.596353212121206e-07] - Loss total: 2.539818286895752, Last rpr Loss: 0.999996542930603, Last lagvar Loss: 0.843329906463623\n",
      "Step 9841/10000- lr: [1.5862522424242387e-07] - Loss total: 2.53981614112854, Last rpr Loss: 0.9999978542327881, Last lagvar Loss: 0.8433286547660828\n",
      "Step 9842/10000- lr: [1.5761512727272715e-07] - Loss total: 2.539813995361328, Last rpr Loss: 0.9999982118606567, Last lagvar Loss: 0.8433282375335693\n",
      "Step 9843/10000- lr: [1.5660503030303043e-07] - Loss total: 2.539811849594116, Last rpr Loss: 0.999996542930603, Last lagvar Loss: 0.8433297872543335\n",
      "Step 9844/10000- lr: [1.55594933333332e-07] - Loss total: 2.5398097038269043, Last rpr Loss: 0.9999950528144836, Last lagvar Loss: 0.8433314561843872\n",
      "Step 9845/10000- lr: [1.5458483636363698e-07] - Loss total: 2.5398075580596924, Last rpr Loss: 0.9999948143959045, Last lagvar Loss: 0.8433316946029663\n",
      "Step 9846/10000- lr: [1.5357473939393856e-07] - Loss total: 2.5398056507110596, Last rpr Loss: 0.9999951720237732, Last lagvar Loss: 0.8433313369750977\n",
      "Step 9847/10000- lr: [1.5256464242424184e-07] - Loss total: 2.5398037433624268, Last rpr Loss: 0.9999971389770508, Last lagvar Loss: 0.8433293104171753\n",
      "Step 9848/10000- lr: [1.5155454545454512e-07] - Loss total: 2.539801836013794, Last rpr Loss: 0.999997615814209, Last lagvar Loss: 0.8433288335800171\n",
      "Step 9849/10000- lr: [1.505444484848484e-07] - Loss total: 2.539799213409424, Last rpr Loss: 0.9999974966049194, Last lagvar Loss: 0.8433289527893066\n",
      "Step 9850/10000- lr: [1.4953435151514998e-07] - Loss total: 2.53979754447937, Last rpr Loss: 0.9999966025352478, Last lagvar Loss: 0.8433297872543335\n",
      "Step 9851/10000- lr: [1.4852425454545495e-07] - Loss total: 2.539795398712158, Last rpr Loss: 0.9999949932098389, Last lagvar Loss: 0.8433314561843872\n",
      "Step 9852/10000- lr: [1.4751415757575653e-07] - Loss total: 2.5397937297821045, Last rpr Loss: 0.9999955892562866, Last lagvar Loss: 0.8433309197425842\n",
      "Step 9853/10000- lr: [1.465040606060598e-07] - Loss total: 2.5397915840148926, Last rpr Loss: 0.9999959468841553, Last lagvar Loss: 0.8433305025100708\n",
      "Step 9854/10000- lr: [1.4549396363636309e-07] - Loss total: 2.5397894382476807, Last rpr Loss: 0.9999961853027344, Last lagvar Loss: 0.8433303236961365\n",
      "Step 9855/10000- lr: [1.4448386666666636e-07] - Loss total: 2.5397872924804688, Last rpr Loss: 0.9999970197677612, Last lagvar Loss: 0.8433293700218201\n",
      "Step 9856/10000- lr: [1.4347376969696964e-07] - Loss total: 2.539785623550415, Last rpr Loss: 0.9999971985816956, Last lagvar Loss: 0.8433292508125305\n",
      "Step 9857/10000- lr: [1.4246367272727292e-07] - Loss total: 2.539783477783203, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.8433300256729126\n",
      "Step 9858/10000- lr: [1.414535757575745e-07] - Loss total: 2.539781332015991, Last rpr Loss: 0.999995231628418, Last lagvar Loss: 0.8433312773704529\n",
      "Step 9859/10000- lr: [1.4044347878787778e-07] - Loss total: 2.5397796630859375, Last rpr Loss: 0.9999942183494568, Last lagvar Loss: 0.8433322310447693\n",
      "Step 9860/10000- lr: [1.3943338181818105e-07] - Loss total: 2.5397775173187256, Last rpr Loss: 0.9999963045120239, Last lagvar Loss: 0.8433302044868469\n",
      "Step 9861/10000- lr: [1.3842328484848433e-07] - Loss total: 2.539775848388672, Last rpr Loss: 0.9999967217445374, Last lagvar Loss: 0.8433297872543335\n",
      "Step 9862/10000- lr: [1.374131878787876e-07] - Loss total: 2.539773941040039, Last rpr Loss: 0.9999971389770508, Last lagvar Loss: 0.8433293700218201\n",
      "Step 9863/10000- lr: [1.3640309090909089e-07] - Loss total: 2.5397720336914062, Last rpr Loss: 0.9999961256980896, Last lagvar Loss: 0.8433303236961365\n",
      "Step 9864/10000- lr: [1.3539299393939247e-07] - Loss total: 2.5397703647613525, Last rpr Loss: 0.9999958872795105, Last lagvar Loss: 0.8433306217193604\n",
      "Step 9865/10000- lr: [1.3438289696969744e-07] - Loss total: 2.5397682189941406, Last rpr Loss: 0.9999962449073792, Last lagvar Loss: 0.8433302044868469\n",
      "Step 9866/10000- lr: [1.3337279999999902e-07] - Loss total: 2.539766550064087, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8433306813240051\n",
      "Step 9867/10000- lr: [1.323627030303023e-07] - Loss total: 2.539764642715454, Last rpr Loss: 0.9999967813491821, Last lagvar Loss: 0.8433296084403992\n",
      "Step 9868/10000- lr: [1.3135260606060558e-07] - Loss total: 2.5397629737854004, Last rpr Loss: 0.9999971389770508, Last lagvar Loss: 0.8433292508125305\n",
      "Step 9869/10000- lr: [1.3034250909090885e-07] - Loss total: 2.5397610664367676, Last rpr Loss: 0.9999980926513672, Last lagvar Loss: 0.8433284759521484\n",
      "Step 9870/10000- lr: [1.2933241212121044e-07] - Loss total: 2.5397591590881348, Last rpr Loss: 0.9999974966049194, Last lagvar Loss: 0.8433289527893066\n",
      "Step 9871/10000- lr: [1.283223151515154e-07] - Loss total: 2.539757490158081, Last rpr Loss: 0.9999972581863403, Last lagvar Loss: 0.8433291912078857\n",
      "Step 9872/10000- lr: [1.27312218181817e-07] - Loss total: 2.5397560596466064, Last rpr Loss: 0.9999957084655762, Last lagvar Loss: 0.8433307409286499\n",
      "Step 9873/10000- lr: [1.2630212121212027e-07] - Loss total: 2.5397541522979736, Last rpr Loss: 0.9999951124191284, Last lagvar Loss: 0.8433313369750977\n",
      "Step 9874/10000- lr: [1.2529202424242354e-07] - Loss total: 2.539752244949341, Last rpr Loss: 0.999995768070221, Last lagvar Loss: 0.8433306813240051\n",
      "Step 9875/10000- lr: [1.2428192727272682e-07] - Loss total: 2.539750576019287, Last rpr Loss: 0.9999959468841553, Last lagvar Loss: 0.8433305025100708\n",
      "Step 9876/10000- lr: [1.232718303030301e-07] - Loss total: 2.5397489070892334, Last rpr Loss: 0.9999958872795105, Last lagvar Loss: 0.8433305025100708\n",
      "Step 9877/10000- lr: [1.2226173333333338e-07] - Loss total: 2.5397472381591797, Last rpr Loss: 0.9999960660934448, Last lagvar Loss: 0.8433302640914917\n",
      "Step 9878/10000- lr: [1.2125163636363496e-07] - Loss total: 2.539745569229126, Last rpr Loss: 0.9999971389770508, Last lagvar Loss: 0.8433294296264648\n",
      "Step 9879/10000- lr: [1.2024153939393824e-07] - Loss total: 2.5397441387176514, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.8433300256729126\n",
      "Step 9880/10000- lr: [1.1923144242424151e-07] - Loss total: 2.5397424697875977, Last rpr Loss: 0.999996542930603, Last lagvar Loss: 0.843329906463623\n",
      "Step 9881/10000- lr: [1.1822134545454479e-07] - Loss total: 2.539740800857544, Last rpr Loss: 0.9999966621398926, Last lagvar Loss: 0.8433298468589783\n",
      "Step 9882/10000- lr: [1.1721124848484807e-07] - Loss total: 2.5397391319274902, Last rpr Loss: 0.9999966621398926, Last lagvar Loss: 0.8433297276496887\n",
      "Step 9883/10000- lr: [1.1620115151515134e-07] - Loss total: 2.5397374629974365, Last rpr Loss: 0.9999973773956299, Last lagvar Loss: 0.8433290719985962\n",
      "Step 9884/10000- lr: [1.1519105454545293e-07] - Loss total: 2.539736032485962, Last rpr Loss: 0.9999974966049194, Last lagvar Loss: 0.8433288931846619\n",
      "Step 9885/10000- lr: [1.141809575757579e-07] - Loss total: 2.539734363555908, Last rpr Loss: 0.9999970197677612, Last lagvar Loss: 0.8433294296264648\n",
      "Step 9886/10000- lr: [1.1317086060605948e-07] - Loss total: 2.5397329330444336, Last rpr Loss: 0.9999969601631165, Last lagvar Loss: 0.8433295488357544\n",
      "Step 9887/10000- lr: [1.1216076363636276e-07] - Loss total: 2.53973126411438, Last rpr Loss: 0.9999966025352478, Last lagvar Loss: 0.843329906463623\n",
      "Step 9888/10000- lr: [1.1115066666666604e-07] - Loss total: 2.539729595184326, Last rpr Loss: 0.9999961853027344, Last lagvar Loss: 0.8433302640914917\n",
      "Step 9889/10000- lr: [1.1014056969696931e-07] - Loss total: 2.5397284030914307, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8433305025100708\n",
      "Step 9890/10000- lr: [1.0913047272727259e-07] - Loss total: 2.539726734161377, Last rpr Loss: 0.9999954700469971, Last lagvar Loss: 0.8433310389518738\n",
      "Step 9891/10000- lr: [1.0812037575757587e-07] - Loss total: 2.5397250652313232, Last rpr Loss: 0.9999956488609314, Last lagvar Loss: 0.8433307409286499\n",
      "Step 9892/10000- lr: [1.0711027878787745e-07] - Loss total: 2.5397236347198486, Last rpr Loss: 0.9999961256980896, Last lagvar Loss: 0.8433303833007812\n",
      "Step 9893/10000- lr: [1.0610018181818073e-07] - Loss total: 2.539722204208374, Last rpr Loss: 0.9999969005584717, Last lagvar Loss: 0.8433295488357544\n",
      "Step 9894/10000- lr: [1.05090084848484e-07] - Loss total: 2.5397207736968994, Last rpr Loss: 0.9999966621398926, Last lagvar Loss: 0.8433297276496887\n",
      "Step 9895/10000- lr: [1.0407998787878728e-07] - Loss total: 2.539719581604004, Last rpr Loss: 0.9999967217445374, Last lagvar Loss: 0.8433297872543335\n",
      "Step 9896/10000- lr: [1.0306989090909056e-07] - Loss total: 2.53971791267395, Last rpr Loss: 0.9999964833259583, Last lagvar Loss: 0.843329906463623\n",
      "Step 9897/10000- lr: [1.0205979393939384e-07] - Loss total: 2.5397164821624756, Last rpr Loss: 0.9999966621398926, Last lagvar Loss: 0.843329668045044\n",
      "Step 9898/10000- lr: [1.0104969696969542e-07] - Loss total: 2.539715051651001, Last rpr Loss: 0.9999968409538269, Last lagvar Loss: 0.843329668045044\n",
      "Step 9899/10000- lr: [1.000395999999987e-07] - Loss total: 2.5397136211395264, Last rpr Loss: 0.9999974966049194, Last lagvar Loss: 0.8433289527893066\n",
      "Step 9900/10000- lr: [9.902950303030197e-08] - Loss total: 2.5397121906280518, Last rpr Loss: 0.9999970197677612, Last lagvar Loss: 0.8433294296264648\n",
      "Step 9901/10000- lr: [9.801940606060525e-08] - Loss total: 2.5397109985351562, Last rpr Loss: 0.9999966621398926, Last lagvar Loss: 0.8433297872543335\n",
      "Step 9902/10000- lr: [9.700930909090853e-08] - Loss total: 2.5397095680236816, Last rpr Loss: 0.9999963641166687, Last lagvar Loss: 0.8433300256729126\n",
      "Step 9903/10000- lr: [9.59992121212118e-08] - Loss total: 2.539708375930786, Last rpr Loss: 0.9999963045120239, Last lagvar Loss: 0.8433301448822021\n",
      "Step 9904/10000- lr: [9.498911515151339e-08] - Loss total: 2.5397067070007324, Last rpr Loss: 0.9999974966049194, Last lagvar Loss: 0.8433289527893066\n",
      "Step 9905/10000- lr: [9.397901818181836e-08] - Loss total: 2.539705514907837, Last rpr Loss: 0.9999972581863403, Last lagvar Loss: 0.8433291912078857\n",
      "Step 9906/10000- lr: [9.296892121211994e-08] - Loss total: 2.5397043228149414, Last rpr Loss: 0.9999961256980896, Last lagvar Loss: 0.8433303236961365\n",
      "Step 9907/10000- lr: [9.195882424242322e-08] - Loss total: 2.539702892303467, Last rpr Loss: 0.9999959468841553, Last lagvar Loss: 0.8433305025100708\n",
      "Step 9908/10000- lr: [9.09487272727265e-08] - Loss total: 2.5397017002105713, Last rpr Loss: 0.9999956488609314, Last lagvar Loss: 0.8433308005332947\n",
      "Step 9909/10000- lr: [8.993863030302977e-08] - Loss total: 2.539700508117676, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.8433300256729126\n",
      "Step 9910/10000- lr: [8.892853333333305e-08] - Loss total: 2.5396993160247803, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.8433300852775574\n",
      "Step 9911/10000- lr: [8.791843636363633e-08] - Loss total: 2.5396981239318848, Last rpr Loss: 0.9999959468841553, Last lagvar Loss: 0.8433305025100708\n",
      "Step 9912/10000- lr: [8.690833939393791e-08] - Loss total: 2.5396969318389893, Last rpr Loss: 0.9999957084655762, Last lagvar Loss: 0.8433307409286499\n",
      "Step 9913/10000- lr: [8.589824242424119e-08] - Loss total: 2.5396955013275146, Last rpr Loss: 0.999996542930603, Last lagvar Loss: 0.8433297872543335\n",
      "Step 9914/10000- lr: [8.488814545454616e-08] - Loss total: 2.5396945476531982, Last rpr Loss: 0.999997079372406, Last lagvar Loss: 0.8433293104171753\n",
      "Step 9915/10000- lr: [8.387804848484774e-08] - Loss total: 2.5396931171417236, Last rpr Loss: 0.9999974370002747, Last lagvar Loss: 0.8433290123939514\n",
      "Step 9916/10000- lr: [8.286795151515102e-08] - Loss total: 2.5396921634674072, Last rpr Loss: 0.9999973773956299, Last lagvar Loss: 0.8433290719985962\n",
      "Step 9917/10000- lr: [8.18578545454543e-08] - Loss total: 2.539691209793091, Last rpr Loss: 0.9999975562095642, Last lagvar Loss: 0.8433288931846619\n",
      "Step 9918/10000- lr: [8.084775757575757e-08] - Loss total: 2.539689540863037, Last rpr Loss: 0.9999969601631165, Last lagvar Loss: 0.8433294296264648\n",
      "Step 9919/10000- lr: [7.983766060605916e-08] - Loss total: 2.5396885871887207, Last rpr Loss: 0.9999971389770508, Last lagvar Loss: 0.8433293104171753\n",
      "Step 9920/10000- lr: [7.882756363636413e-08] - Loss total: 2.539687395095825, Last rpr Loss: 0.9999971389770508, Last lagvar Loss: 0.8433293104171753\n",
      "Step 9921/10000- lr: [7.781746666666571e-08] - Loss total: 2.539686441421509, Last rpr Loss: 0.999996542930603, Last lagvar Loss: 0.843329906463623\n",
      "Step 9922/10000- lr: [7.680736969696899e-08] - Loss total: 2.5396854877471924, Last rpr Loss: 0.9999961853027344, Last lagvar Loss: 0.8433302640914917\n",
      "Step 9923/10000- lr: [7.579727272727226e-08] - Loss total: 2.539684295654297, Last rpr Loss: 0.9999963045120239, Last lagvar Loss: 0.8433300256729126\n",
      "Step 9924/10000- lr: [7.478717575757554e-08] - Loss total: 2.5396833419799805, Last rpr Loss: 0.9999963045120239, Last lagvar Loss: 0.8433301448822021\n",
      "Step 9925/10000- lr: [7.377707878787882e-08] - Loss total: 2.539682149887085, Last rpr Loss: 0.9999963045120239, Last lagvar Loss: 0.8433300852775574\n",
      "Step 9926/10000- lr: [7.27669818181821e-08] - Loss total: 2.5396811962127686, Last rpr Loss: 0.9999967813491821, Last lagvar Loss: 0.8433296084403992\n",
      "Step 9927/10000- lr: [7.175688484848368e-08] - Loss total: 2.539680004119873, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.8433300256729126\n",
      "Step 9928/10000- lr: [7.074678787878695e-08] - Loss total: 2.5396792888641357, Last rpr Loss: 0.9999964833259583, Last lagvar Loss: 0.8433299660682678\n",
      "Step 9929/10000- lr: [6.973669090909023e-08] - Loss total: 2.5396780967712402, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.8433300256729126\n",
      "Step 9930/10000- lr: [6.872659393939351e-08] - Loss total: 2.539677143096924, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.8433300256729126\n",
      "Step 9931/10000- lr: [6.771649696969679e-08] - Loss total: 2.5396759510040283, Last rpr Loss: 0.9999954700469971, Last lagvar Loss: 0.843330979347229\n",
      "Step 9932/10000- lr: [6.670640000000006e-08] - Loss total: 2.539675235748291, Last rpr Loss: 0.9999955296516418, Last lagvar Loss: 0.843330979347229\n",
      "Step 9933/10000- lr: [6.569630303030165e-08] - Loss total: 2.5396742820739746, Last rpr Loss: 0.9999964237213135, Last lagvar Loss: 0.8433300256729126\n",
      "Step 9934/10000- lr: [6.468620606060662e-08] - Loss total: 2.539673328399658, Last rpr Loss: 0.9999973773956299, Last lagvar Loss: 0.843329131603241\n",
      "Step 9935/10000- lr: [6.36761090909082e-08] - Loss total: 2.539672374725342, Last rpr Loss: 0.9999970197677612, Last lagvar Loss: 0.8433294296264648\n",
      "Step 9936/10000- lr: [6.266601212121148e-08] - Loss total: 2.5396716594696045, Last rpr Loss: 0.9999974370002747, Last lagvar Loss: 0.8433290719985962\n",
      "Step 9937/10000- lr: [6.165591515151475e-08] - Loss total: 2.539670705795288, Last rpr Loss: 0.999997615814209, Last lagvar Loss: 0.8433287739753723\n",
      "Step 9938/10000- lr: [6.064581818181803e-08] - Loss total: 2.539669990539551, Last rpr Loss: 0.999997079372406, Last lagvar Loss: 0.8433294296264648\n",
      "Step 9939/10000- lr: [5.963572121211961e-08] - Loss total: 2.5396690368652344, Last rpr Loss: 0.9999972581863403, Last lagvar Loss: 0.8433291912078857\n",
      "Step 9940/10000- lr: [5.8625624242424586e-08] - Loss total: 2.539668321609497, Last rpr Loss: 0.999997615814209, Last lagvar Loss: 0.8433289527893066\n",
      "Step 9941/10000- lr: [5.761552727272617e-08] - Loss total: 2.5396673679351807, Last rpr Loss: 0.9999973773956299, Last lagvar Loss: 0.8433290719985962\n",
      "Step 9942/10000- lr: [5.6605430303029446e-08] - Loss total: 2.5396664142608643, Last rpr Loss: 0.9999967813491821, Last lagvar Loss: 0.8433295488357544\n",
      "Step 9943/10000- lr: [5.559533333333272e-08] - Loss total: 2.539665699005127, Last rpr Loss: 0.999997615814209, Last lagvar Loss: 0.8433288931846619\n",
      "Step 9944/10000- lr: [5.4585236363636e-08] - Loss total: 2.5396647453308105, Last rpr Loss: 0.9999969005584717, Last lagvar Loss: 0.8433295488357544\n",
      "Step 9945/10000- lr: [5.357513939393928e-08] - Loss total: 2.5396640300750732, Last rpr Loss: 0.999996542930603, Last lagvar Loss: 0.8433299660682678\n",
      "Step 9946/10000- lr: [5.2565042424242554e-08] - Loss total: 2.539663314819336, Last rpr Loss: 0.999997079372406, Last lagvar Loss: 0.8433293700218201\n",
      "Step 9947/10000- lr: [5.155494545454414e-08] - Loss total: 2.5396625995635986, Last rpr Loss: 0.9999969005584717, Last lagvar Loss: 0.8433295488357544\n",
      "Step 9948/10000- lr: [5.0544848484847414e-08] - Loss total: 2.5396618843078613, Last rpr Loss: 0.9999966621398926, Last lagvar Loss: 0.8433297872543335\n",
      "Step 9949/10000- lr: [4.953475151515069e-08] - Loss total: 2.539661169052124, Last rpr Loss: 0.9999972581863403, Last lagvar Loss: 0.8433292508125305\n",
      "Step 9950/10000- lr: [4.852465454545397e-08] - Loss total: 2.539660692214966, Last rpr Loss: 0.9999971985816956, Last lagvar Loss: 0.8433293700218201\n",
      "Step 9951/10000- lr: [4.7514557575757246e-08] - Loss total: 2.5396597385406494, Last rpr Loss: 0.999997079372406, Last lagvar Loss: 0.8433294296264648\n",
      "Step 9952/10000- lr: [4.650446060606052e-08] - Loss total: 2.539659023284912, Last rpr Loss: 0.9999977350234985, Last lagvar Loss: 0.8433287143707275\n",
      "Step 9953/10000- lr: [4.5494363636362106e-08] - Loss total: 2.539658546447754, Last rpr Loss: 0.999997615814209, Last lagvar Loss: 0.8433288335800171\n",
      "Step 9954/10000- lr: [4.448426666666708e-08] - Loss total: 2.5396575927734375, Last rpr Loss: 0.9999971389770508, Last lagvar Loss: 0.8433293104171753\n",
      "Step 9955/10000- lr: [4.347416969696866e-08] - Loss total: 2.5396568775177, Last rpr Loss: 0.9999975562095642, Last lagvar Loss: 0.8433288335800171\n",
      "Step 9956/10000- lr: [4.246407272727194e-08] - Loss total: 2.539656639099121, Last rpr Loss: 0.9999966621398926, Last lagvar Loss: 0.843329668045044\n",
      "Step 9957/10000- lr: [4.1453975757575214e-08] - Loss total: 2.5396556854248047, Last rpr Loss: 0.9999974966049194, Last lagvar Loss: 0.8433290123939514\n",
      "Step 9958/10000- lr: [4.044387878787849e-08] - Loss total: 2.5396552085876465, Last rpr Loss: 0.9999973177909851, Last lagvar Loss: 0.8433290719985962\n",
      "Step 9959/10000- lr: [3.943378181818177e-08] - Loss total: 2.5396547317504883, Last rpr Loss: 0.9999969005584717, Last lagvar Loss: 0.8433295488357544\n",
      "Step 9960/10000- lr: [3.8423684848485045e-08] - Loss total: 2.53965425491333, Last rpr Loss: 0.9999973773956299, Last lagvar Loss: 0.8433290719985962\n",
      "Step 9961/10000- lr: [3.741358787878663e-08] - Loss total: 2.539653778076172, Last rpr Loss: 0.9999969601631165, Last lagvar Loss: 0.8433294296264648\n",
      "Step 9962/10000- lr: [3.6403490909089905e-08] - Loss total: 2.5396530628204346, Last rpr Loss: 0.9999966025352478, Last lagvar Loss: 0.843329906463623\n",
      "Step 9963/10000- lr: [3.539339393939318e-08] - Loss total: 2.5396525859832764, Last rpr Loss: 0.999997079372406, Last lagvar Loss: 0.8433293104171753\n",
      "Step 9964/10000- lr: [3.438329696969646e-08] - Loss total: 2.539652109146118, Last rpr Loss: 0.9999976754188538, Last lagvar Loss: 0.8433287143707275\n",
      "Step 9965/10000- lr: [3.3373199999999737e-08] - Loss total: 2.53965163230896, Last rpr Loss: 0.9999975562095642, Last lagvar Loss: 0.8433288931846619\n",
      "Step 9966/10000- lr: [3.2363103030303014e-08] - Loss total: 2.5396511554718018, Last rpr Loss: 0.9999974966049194, Last lagvar Loss: 0.8433289527893066\n",
      "Step 9967/10000- lr: [3.13530060606046e-08] - Loss total: 2.5396506786346436, Last rpr Loss: 0.9999973773956299, Last lagvar Loss: 0.8433290719985962\n",
      "Step 9968/10000- lr: [3.0342909090907874e-08] - Loss total: 2.5396502017974854, Last rpr Loss: 0.9999976754188538, Last lagvar Loss: 0.8433287143707275\n",
      "Step 9969/10000- lr: [2.933281212121115e-08] - Loss total: 2.539649724960327, Last rpr Loss: 0.9999972581863403, Last lagvar Loss: 0.8433291912078857\n",
      "Step 9970/10000- lr: [2.8322715151514428e-08] - Loss total: 2.539649248123169, Last rpr Loss: 0.9999969005584717, Last lagvar Loss: 0.8433296084403992\n",
      "Step 9971/10000- lr: [2.7312618181817705e-08] - Loss total: 2.539649248123169, Last rpr Loss: 0.9999958276748657, Last lagvar Loss: 0.8433305621147156\n",
      "Step 9972/10000- lr: [2.6302521212120982e-08] - Loss total: 2.5396485328674316, Last rpr Loss: 0.9999959468841553, Last lagvar Loss: 0.8433305025100708\n",
      "Step 9973/10000- lr: [2.5292424242422565e-08] - Loss total: 2.5396482944488525, Last rpr Loss: 0.9999955296516418, Last lagvar Loss: 0.843330979347229\n",
      "Step 9974/10000- lr: [2.4282327272727536e-08] - Loss total: 2.5396478176116943, Last rpr Loss: 0.9999961853027344, Last lagvar Loss: 0.8433303236961365\n",
      "Step 9975/10000- lr: [2.327223030302912e-08] - Loss total: 2.5396475791931152, Last rpr Loss: 0.9999959468841553, Last lagvar Loss: 0.843330442905426\n",
      "Step 9976/10000- lr: [2.2262133333332396e-08] - Loss total: 2.539647102355957, Last rpr Loss: 0.9999969005584717, Last lagvar Loss: 0.8433295488357544\n",
      "Step 9977/10000- lr: [2.1252036363635674e-08] - Loss total: 2.539646863937378, Last rpr Loss: 0.9999968409538269, Last lagvar Loss: 0.843329668045044\n",
      "Step 9978/10000- lr: [2.024193939393895e-08] - Loss total: 2.539646625518799, Last rpr Loss: 0.9999969005584717, Last lagvar Loss: 0.8433295488357544\n",
      "Step 9979/10000- lr: [1.9231842424242228e-08] - Loss total: 2.5396461486816406, Last rpr Loss: 0.9999969005584717, Last lagvar Loss: 0.8433295488357544\n",
      "Step 9980/10000- lr: [1.8221745454545505e-08] - Loss total: 2.5396459102630615, Last rpr Loss: 0.9999970197677612, Last lagvar Loss: 0.8433294296264648\n",
      "Step 9981/10000- lr: [1.7211648484847088e-08] - Loss total: 2.5396456718444824, Last rpr Loss: 0.999997079372406, Last lagvar Loss: 0.8433293700218201\n",
      "Step 9982/10000- lr: [1.6201551515150365e-08] - Loss total: 2.5396454334259033, Last rpr Loss: 0.9999973773956299, Last lagvar Loss: 0.8433290123939514\n",
      "Step 9983/10000- lr: [1.5191454545453642e-08] - Loss total: 2.539645195007324, Last rpr Loss: 0.9999980926513672, Last lagvar Loss: 0.8433282971382141\n",
      "Step 9984/10000- lr: [1.4181357575756919e-08] - Loss total: 2.539644956588745, Last rpr Loss: 0.9999982714653015, Last lagvar Loss: 0.8433281183242798\n",
      "Step 9985/10000- lr: [1.3171260606060196e-08] - Loss total: 2.539644718170166, Last rpr Loss: 0.9999982714653015, Last lagvar Loss: 0.8433281183242798\n",
      "Step 9986/10000- lr: [1.2161163636363473e-08] - Loss total: 2.539644479751587, Last rpr Loss: 0.9999982714653015, Last lagvar Loss: 0.8433281183242798\n",
      "Step 9987/10000- lr: [1.1151066666665056e-08] - Loss total: 2.539644241333008, Last rpr Loss: 0.999998152256012, Last lagvar Loss: 0.8433282375335693\n",
      "Step 9988/10000- lr: [1.0140969696968333e-08] - Loss total: 2.5396440029144287, Last rpr Loss: 0.9999983310699463, Last lagvar Loss: 0.8433281183242798\n",
      "Step 9989/10000- lr: [9.13087272727161e-09] - Loss total: 2.5396440029144287, Last rpr Loss: 0.9999982714653015, Last lagvar Loss: 0.8433282375335693\n",
      "Step 9990/10000- lr: [8.120775757574887e-09] - Loss total: 2.5396437644958496, Last rpr Loss: 0.9999983310699463, Last lagvar Loss: 0.8433281779289246\n",
      "Step 9991/10000- lr: [7.1106787878781646e-09] - Loss total: 2.5396437644958496, Last rpr Loss: 0.9999982714653015, Last lagvar Loss: 0.8433281183242798\n",
      "Step 9992/10000- lr: [6.100581818181442e-09] - Loss total: 2.5396435260772705, Last rpr Loss: 0.9999982714653015, Last lagvar Loss: 0.8433282375335693\n",
      "Step 9993/10000- lr: [5.090484848483025e-09] - Loss total: 2.5396435260772705, Last rpr Loss: 0.9999983310699463, Last lagvar Loss: 0.8433281183242798\n",
      "Step 9994/10000- lr: [4.080387878787996e-09] - Loss total: 2.5396435260772705, Last rpr Loss: 0.9999979734420776, Last lagvar Loss: 0.8433285355567932\n",
      "Step 9995/10000- lr: [3.070290909089579e-09] - Loss total: 2.5396435260772705, Last rpr Loss: 0.999998152256012, Last lagvar Loss: 0.8433284759521484\n",
      "Step 9996/10000- lr: [2.060193939392856e-09] - Loss total: 2.5396435260772705, Last rpr Loss: 0.9999979734420776, Last lagvar Loss: 0.8433284759521484\n",
      "Step 9997/10000- lr: [1.050096969696133e-09] - Loss total: 2.5396432876586914, Last rpr Loss: 0.9999982714653015, Last lagvar Loss: 0.8433282375335693\n",
      "Step 9998/10000- lr: [3.999999999941008e-11] - Loss total: 2.5396432876586914, Last rpr Loss: 0.9999982714653015, Last lagvar Loss: 0.8433281183242798\n",
      "Step 9999/10000- lr: [-9.700969696973128e-10] - Loss total: 2.5396432876586914, Last rpr Loss: 0.9999982714653015, Last lagvar Loss: 0.8433281183242798\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "tot_steps = 10000\n",
    "lr = 1e-5\n",
    "params = [(n, p) for n, p in model.named_parameters() if p.requires_grad]\n",
    "all_params = [p for n, p in params]\n",
    "optimizer = torch.optim.Adam(all_params, lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "        lr, tot_steps, pct_start=0.01, cycle_momentum=False, anneal_strategy='linear')\n",
    "\n",
    "step = 0\n",
    "data = next(iter(train_loader))\n",
    "data = batch_to_device(data, device, non_blocking=True)\n",
    "data.update({'tr_logvar': False})\n",
    "start_tr_logvar = tot_steps // 20\n",
    "while(step < tot_steps):\n",
    "    # for _, data in enumerate(train_loader):\n",
    "        if step >= start_tr_logvar:\n",
    "            data.update({'tr_logvar': True})\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(data)\n",
    "        losses, _ = model.loss(pred, data)\n",
    "        loss = torch.mean(losses[\"total\"])\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(all_params, conf.train.clip_grad)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        print(f\"Step {step}/{tot_steps}- lr: {scheduler.get_last_lr()} - Loss total: {loss.item()}, Last rpr Loss: {losses['last_rp'].item()}, Last lagvar Loss: {losses['last_logvar'].item()}\")\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: tensor([2.5396], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "last_rp: tensor([1.0000], device='cuda:0')\n",
      "last_logvar: tensor([0.8433], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for k in losses:\n",
    "    print(f\"{k}: {losses[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "original_image_size\n",
      "H_0to1\n",
      "idx\n",
      "view0\n",
      "view1\n",
      "tr_logvar\n"
     ]
    }
   ],
   "source": [
    "for k in data:\n",
    "    print(f\"{k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints0 torch.Size([1, 512, 2])\n",
      "keypoint_scores0 torch.Size([1, 512])\n",
      "descriptors0 torch.Size([1, 512, 256])\n",
      "keypoints1 torch.Size([1, 512, 2])\n",
      "keypoint_scores1 torch.Size([1, 512])\n",
      "descriptors1 torch.Size([1, 512, 256])\n",
      "matches0 torch.Size([1, 512])\n",
      "matches1 torch.Size([1, 512])\n",
      "matching_scores0 torch.Size([1, 512])\n",
      "matching_scores1 torch.Size([1, 512])\n",
      "ref_descriptors0 torch.Size([1, 9, 512, 256])\n",
      "ref_descriptors1 torch.Size([1, 9, 512, 256])\n",
      "prune0 torch.Size([1, 512])\n",
      "prune1 torch.Size([1, 512])\n",
      "p_rp_01 torch.Size([1, 512, 512])\n",
      "p_rp_10 torch.Size([1, 512, 512])\n",
      "logvar_01 torch.Size([1, 512, 2])\n",
      "logvar_10 torch.Size([1, 512, 2])\n",
      "gt_assignment torch.Size([1, 512, 512])\n",
      "gt_reward torch.Size([1, 512, 512])\n",
      "gt_matches0 torch.Size([1, 512])\n",
      "gt_matches1 torch.Size([1, 512])\n",
      "gt_matching_scores0 torch.Size([1, 512])\n",
      "gt_matching_scores1 torch.Size([1, 512])\n",
      "gt_proj_0to1 torch.Size([1, 512, 2])\n",
      "gt_proj_1to0 torch.Size([1, 512, 2])\n",
      "gt_valid0_1 torch.Size([1, 512])\n",
      "gt_valid1_0 torch.Size([1, 512])\n",
      "gt_res0_1_sq torch.Size([1, 512, 512, 2])\n",
      "gt_res1_0_sq torch.Size([1, 512, 512, 2])\n"
     ]
    }
   ],
   "source": [
    "for k in pred:\n",
    "    print(k, pred[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_p_and_var(tmp_n, kps_tgt, proj, r_square, p_tgt_src, log_var, w = 640, h = 480, tp = False):\n",
    "    var = torch.exp(log_var).squeeze().detach().cpu().numpy()\n",
    "    kps_tgt = kps_tgt.squeeze().detach().cpu().numpy() # target\n",
    "\n",
    "    if tp:\n",
    "        r_square = r_square.transpose(-2, -3)\n",
    "        p_tgt_src = p_tgt_src.transpose(-1, -2)\n",
    "    r_square_n_x = r_square.squeeze().detach()[tmp_n, :, 0].cpu().numpy()\n",
    "    r_square_n_y = r_square.squeeze().detach()[tmp_n, :, 1].cpu().numpy()\n",
    "    # dist = F.softmax(logits[0, 0], dim=0).detach().cpu().numpy()\n",
    "    dist = p_tgt_src.squeeze()[tmp_n].detach().cpu().numpy()\n",
    "\n",
    "    print(f'Max categorical weight {dist.max()} and weight sum {dist.sum()}')\n",
    "    print(f\"Minimum residual_sq x {r_square_n_x.min()}\")\n",
    "    print(f\"Minimum residual_sq y {r_square_n_y.min()}\")\n",
    "    print(f\"Weigted residual_sq sum x {(r_square_n_x * dist).sum()}\")\n",
    "    print(f\"Weigted residual_sq sum y {(r_square_n_y * dist).sum()}\")\n",
    "\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    ax1.bar(kps_tgt[:, 0], dist, width=2, alpha=0.9)\n",
    "    ax2.bar(kps_tgt[:, 1], dist, width=2, alpha=0.9)\n",
    "    ax1.bar(kps_tgt[:, 0], r_square_n_x**0.5 / 100, width=0.5, color='r', alpha=0.5)\n",
    "    ax2.bar(kps_tgt[:, 1], r_square_n_y**0.5 / 100, width=0.5, color='r', alpha=0.5)\n",
    "\n",
    "    kp0_proj1_x = proj.squeeze()[tmp_n, 0].detach().cpu().numpy()\n",
    "    kp0_proj1_y = proj.squeeze()[tmp_n, 1].detach().cpu().numpy() # point 80 projected in image 0\n",
    "    variance_x = var[tmp_n, 0]\n",
    "    variance_y = var[tmp_n, 1]\n",
    "    from scipy.stats import norm\n",
    "\n",
    "    print(f'Var x: {variance_x}, Var y: {variance_y}')\n",
    "    w_x = np.linspace(0, w, 100)\n",
    "    w_x = np.sort(np.append(w_x, kp0_proj1_x))\n",
    "    w_y = norm.pdf(w_x, kp0_proj1_x, variance_x**0.5)\n",
    "    h_x = np.linspace(0, h, 100)\n",
    "    h_x = np.sort(np.append(h_x, kp0_proj1_y))\n",
    "    h_y = norm.pdf(h_x, kp0_proj1_y, variance_y**0.5)\n",
    "    # set ylim\n",
    "    ax1.set_ylim([0, 2])\n",
    "    ax2.set_ylim([0, 2])\n",
    "    ax1.plot(w_x, w_y, 'g--')\n",
    "    ax2.plot(h_x, h_y, 'g--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max categorical weight 1.0 and weight sum 1.0\n",
      "Minimum residual_sq x 0.015140533447265625\n",
      "Minimum residual_sq y 0.017100222408771515\n",
      "Weigted residual_sq sum x 0.015140533447265625\n",
      "Weigted residual_sq sum y 0.017100222408771515\n",
      "Var x: 0.015065889805555344, Var y: 0.017162660136818886\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_p_and_var(346, pred['keypoints1'], pred['gt_proj_0to1'], pred['gt_res0_1_sq'], pred['p_rp_01'], pred['logvar_01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max categorical weight 1.0 and weight sum 1.0\n",
      "Minimum residual_sq x 0.07999671995639801\n",
      "Minimum residual_sq y 0.16094866394996643\n",
      "Weigted residual_sq sum x 0.07999671995639801\n",
      "Weigted residual_sq sum y 0.35858049988746643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var x: 0.08002447336912155, Var y: 0.35609543323516846\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_p_and_var(266, pred['keypoints0'], pred['gt_proj_1to0'], pred['gt_res1_0_sq'], pred['p_rp_10'], pred['logvar_10'], tp = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_var_stats(var):\n",
    "    print(f'Max and Min and Median var_01 x: {var[:, 0].max()}, {var[:, 0].min()}, {var[:, 0].median()}')\n",
    "    print(f'Max and Min and Median var_01 y: {var[:, 1].max()}, {var[:, 1].min()}, {var[:, 1].median()}')\n",
    "    var= var.numpy()\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    ax1.hist(var[:, 0], bins=100)\n",
    "    ax2.hist(var[:, 1], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.min(\n",
       "values=tensor([-10.9466], device='cuda:0', grad_fn=<MinBackward0>),\n",
       "indices=tensor([261], device='cuda:0'))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred['logvar_10'].squeeze()[:,:1].min(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0469, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred['logvar_10'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max and Min and Median var_01 x: 12631.4853515625, 7.945903234940488e-06, 0.6137921214103699\n",
      "Max and Min and Median var_01 y: 14755.5810546875, 1.4084946542425314e-06, 0.7608221173286438\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "var_01 = torch.exp(pred['logvar_01']).squeeze().detach().cpu()\n",
    "plot_var_stats(var_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max and Min and Median var_01 x: 16756.35546875, 1.761707608238794e-05, 1.0622618198394775\n",
      "Max and Min and Median var_01 y: 40654.72265625, 6.257293080125237e-06, 0.6224155426025391\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "var_10 = torch.exp(pred['logvar_10']).squeeze().detach().cpu()\n",
    "plot_var_stats(var_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image\n",
      "H_\n",
      "coords\n",
      "image_size\n"
     ]
    }
   ],
   "source": [
    "for k in data['view0']:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['view0']['image_size'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def draw_keypoints_cv(image, kps, color = (0, 255, 0), select_kp = None):\n",
    "  if image.shape[1] == 3:  # RGB\n",
    "    scale = image.new_tensor([0.299, 0.587, 0.114]).view(1, 3, 1, 1)\n",
    "    image = (image * scale).sum(1, keepdim=True)\n",
    "  image = image.squeeze().detach().cpu().numpy()\n",
    "  image = (image * 255).astype(np.uint8)\n",
    "  kps = kps.squeeze().detach().cpu().numpy()\n",
    "    \n",
    "  cv_kps= [cv2.KeyPoint(kp[0], kp[1], 1) for kp in kps]\n",
    "  out_img = cv2.drawKeypoints(image, cv_kps, None, color=color, flags=0)\n",
    "\n",
    "  if select_kp is not None:\n",
    "    for kp in select_kp:\n",
    "      cv2.circle(out_img, (int(kps[kp][0]), int(kps[kp][1])), 5, (255, 0, 0), -1)\n",
    "\n",
    "  return out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img0 = draw_keypoints_cv(data['view0']['image'], pred['keypoints0'], color=(0,255,0), select_kp=[0])\n",
    "plt.imshow(img0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img1 = draw_keypoints_cv(data['view1']['image'], pred['keypoints1'], color=(0,255,0), select_kp=[266])\n",
    "plt.imshow(img1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img1_0 = draw_keypoints_cv(data['view0']['image'], pred['gt_proj_1to0'], color=(0,255,0))\n",
    "plt.imshow(img1_0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haolong",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
